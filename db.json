{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"themes/yilia/source/slider.e37972.js","path":"slider.e37972.js","modified":1,"renderable":1},{"_id":"themes/yilia/source/main.0cf68a.css","path":"main.0cf68a.css","modified":1,"renderable":1},{"_id":"source/attachments/screenrc","path":"attachments/screenrc","modified":1,"renderable":0},{"_id":"source/attachments/websocket_demo.tar.gz","path":"attachments/websocket_demo.tar.gz","modified":1,"renderable":0},{"_id":"source/pics/homura.jpg","path":"pics/homura.jpg","modified":1,"renderable":0},{"_id":"source/pics/longpolling.png","path":"pics/longpolling.png","modified":1,"renderable":0},{"_id":"source/pics/kurama.jpg","path":"pics/kurama.jpg","modified":1,"renderable":0},{"_id":"source/pics/miku.jpg","path":"pics/miku.jpg","modified":1,"renderable":0},{"_id":"source/pics/nsq.gif","path":"pics/nsq.gif","modified":1,"renderable":0},{"_id":"source/pics/polling.png","path":"pics/polling.png","modified":1,"renderable":0},{"_id":"source/pics/ryuuko.jpg","path":"pics/ryuuko.jpg","modified":1,"renderable":0},{"_id":"source/pics/websocket.png","path":"pics/websocket.png","modified":1,"renderable":0},{"_id":"source/pics/youthy.jpg","path":"pics/youthy.jpg","modified":1,"renderable":0},{"_id":"themes/yilia/source/mobile.992cbe.js","path":"mobile.992cbe.js","modified":1,"renderable":1},{"_id":"themes/yilia/source/main.0cf68a.js","path":"main.0cf68a.js","modified":1,"renderable":1},{"_id":"source/pics/erlang_gc_deep.png","path":"pics/erlang_gc_deep.png","modified":1,"renderable":0},{"_id":"source/pics/erlang_gc_shallow.png","path":"pics/erlang_gc_shallow.png","modified":1,"renderable":0},{"_id":"source/pics/memory_wall.png","path":"pics/memory_wall.png","modified":1,"renderable":0},{"_id":"source/pics/websocket_demo.png","path":"pics/websocket_demo.png","modified":1,"renderable":0},{"_id":"themes/yilia/source/fonts/default-skin.b257fa.svg","path":"fonts/default-skin.b257fa.svg","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.16acc2.ttf","path":"fonts/iconfont.16acc2.ttf","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.45d7ee.svg","path":"fonts/iconfont.45d7ee.svg","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.8c627f.woff","path":"fonts/iconfont.8c627f.woff","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.b322fa.eot","path":"fonts/iconfont.b322fa.eot","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/tooltip.4004ff.svg","path":"fonts/tooltip.4004ff.svg","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/default-skin.png","path":"img/default-skin.png","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/preloader.gif","path":"img/preloader.gif","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/scrollbar_arrow.png","path":"img/scrollbar_arrow.png","modified":1,"renderable":1},{"_id":"source/attachments/go_replay_sgf/1.sgf","path":"attachments/go_replay_sgf/1.sgf","modified":1,"renderable":0},{"_id":"source/attachments/go_replay_sgf/2.sgf","path":"attachments/go_replay_sgf/2.sgf","modified":1,"renderable":0},{"_id":"source/attachments/go_replay_sgf/3.sgf","path":"attachments/go_replay_sgf/3.sgf","modified":1,"renderable":0},{"_id":"source/pics/df/0.png","path":"pics/df/0.png","modified":1,"renderable":0},{"_id":"source/pics/df/1.png","path":"pics/df/1.png","modified":1,"renderable":0},{"_id":"source/pics/df/2.png","path":"pics/df/2.png","modified":1,"renderable":0},{"_id":"source/pics/df/4.png","path":"pics/df/4.png","modified":1,"renderable":0},{"_id":"source/pics/df/3.png","path":"pics/df/3.png","modified":1,"renderable":0},{"_id":"source/pics/df/5.png","path":"pics/df/5.png","modified":1,"renderable":0},{"_id":"source/pics/df/6.png","path":"pics/df/6.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_000.png","path":"pics/df/df_000.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_001.png","path":"pics/df/df_001.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_002.png","path":"pics/df/df_002.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_006.png","path":"pics/df/df_006.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_003.png","path":"pics/df/df_003.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_005.png","path":"pics/df/df_005.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_010.png","path":"pics/df/df_010.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_016.png","path":"pics/df/df_016.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_015.png","path":"pics/df/df_015.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_018.png","path":"pics/df/df_018.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_019.png","path":"pics/df/df_019.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_021.png","path":"pics/df/df_021.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_022.png","path":"pics/df/df_022.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_024.png","path":"pics/df/df_024.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_025.png","path":"pics/df/df_025.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_026.png","path":"pics/df/df_026.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_029.png","path":"pics/df/df_029.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_027.png","path":"pics/df/df_027.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_028.png","path":"pics/df/df_028.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_030.png","path":"pics/df/df_030.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_032.png","path":"pics/df/df_032.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_033.png","path":"pics/df/df_033.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_040.png","path":"pics/df/df_040.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_041.png","path":"pics/df/df_041.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_042.png","path":"pics/df/df_042.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_043.png","path":"pics/df/df_043.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_045.png","path":"pics/df/df_045.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_046.png","path":"pics/df/df_046.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_049.png","path":"pics/df/df_049.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_047.png","path":"pics/df/df_047.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_050.png","path":"pics/df/df_050.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_051.png","path":"pics/df/df_051.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_054.png","path":"pics/df/df_054.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_053.png","path":"pics/df/df_053.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_052.png","path":"pics/df/df_052.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_055.png","path":"pics/df/df_055.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_057.png","path":"pics/df/df_057.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_059.png","path":"pics/df/df_059.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_1.png","path":"pics/df/df_1.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_058.png","path":"pics/df/df_058.png","modified":1,"renderable":0},{"_id":"source/pics/df/df_056.png","path":"pics/df/df_056.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/3.png","path":"pics/go_replay1/3.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay3/1.png","path":"pics/go_replay3/1.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay3/2.png","path":"pics/go_replay3/2.png","modified":1,"renderable":0},{"_id":"source/pics/tcp/tcp.gif","path":"pics/tcp/tcp.gif","modified":1,"renderable":0},{"_id":"source/pics/windows_nocaps.png","path":"pics/windows_nocaps.png","modified":1,"renderable":0},{"_id":"source/pics/tcp/tcp_establish.gif","path":"pics/tcp/tcp_establish.gif","modified":1,"renderable":0},{"_id":"source/pics/tcp/tcp_close.gif","path":"pics/tcp/tcp_close.gif","modified":1,"renderable":0},{"_id":"source/pics/go_replay2/1.png","path":"pics/go_replay2/1.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay2/2.png","path":"pics/go_replay2/2.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay2/3.png","path":"pics/go_replay2/3.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay3/3.png","path":"pics/go_replay3/3.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay3/5.png","path":"pics/go_replay3/5.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay3/6.png","path":"pics/go_replay3/6.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay2/4.png","path":"pics/go_replay2/4.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay3/11.png","path":"pics/go_replay3/11.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay3/4.png","path":"pics/go_replay3/4.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay3/8.png","path":"pics/go_replay3/8.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay3/9.png","path":"pics/go_replay3/9.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay3/13.png","path":"pics/go_replay3/13.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay3/10.png","path":"pics/go_replay3/10.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay3/7.png","path":"pics/go_replay3/7.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay3/12.png","path":"pics/go_replay3/12.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay2/5.png","path":"pics/go_replay2/5.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/2.png","path":"pics/go_replay1/2.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/5.png","path":"pics/go_replay1/5.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/17.png","path":"pics/go_replay1/17.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/4.png","path":"pics/go_replay1/4.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/20.png","path":"pics/go_replay1/20.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/18.png","path":"pics/go_replay1/18.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/6.png","path":"pics/go_replay1/6.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/7.png","path":"pics/go_replay1/7.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/9.png","path":"pics/go_replay1/9.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/13.png","path":"pics/go_replay1/13.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/14.png","path":"pics/go_replay1/14.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/16.png","path":"pics/go_replay1/16.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/15.png","path":"pics/go_replay1/15.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/19.png","path":"pics/go_replay1/19.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/12.png","path":"pics/go_replay1/12.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/10.png","path":"pics/go_replay1/10.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/1.png","path":"pics/go_replay1/1.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/8.png","path":"pics/go_replay1/8.png","modified":1,"renderable":0},{"_id":"source/pics/go_replay1/11.png","path":"pics/go_replay1/11.png","modified":1,"renderable":0},{"_id":"source/attachments/interoperability.tar.gz","path":"attachments/interoperability.tar.gz","modified":1,"renderable":0}],"Cache":[{"_id":"themes/yilia/.babelrc","hash":"b1b76475ac17dc9e2fa50af96c9e31eea2d0f2b4","modified":1566995518144},{"_id":"themes/yilia/.editorconfig","hash":"da6d022b8f4d9c961e2f8f80677e92af8de0db4d","modified":1566995518161},{"_id":"themes/yilia/.eslintignore","hash":"df0a50b13cc00acb749226fee3cee6e0351fb1d9","modified":1566995518179},{"_id":"themes/yilia/.gitignore","hash":"9c4b7d27a1e3e5efa0c8ed143a032a85d586b03b","modified":1566995518164},{"_id":"themes/yilia/.eslintrc.js","hash":"5696ae049de010ed3786768b0c359f14c05b5ec6","modified":1566995518179},{"_id":"themes/yilia/.gitattributes","hash":"e0f24dceeb1e6878a1dd9b01a2b9df1bc037a867","modified":1566995518178},{"_id":"themes/yilia/README.md","hash":"1bf755806af9d8874bd22e1abbdaaa24328ef4dc","modified":1566995518163},{"_id":"themes/yilia/_config.yml","hash":"27979b92d6e2c3e745b222993a22ca0ead4bbeee","modified":1626096163616},{"_id":"themes/yilia/package.json","hash":"367cb9579d35968a942c243ab248a5f5ebfaf462","modified":1566995518164},{"_id":"themes/yilia/webpack.config.js","hash":"05ba46a4ae744272f5312e684928910dccad3755","modified":1566995518161},{"_id":"source/.DS_Store","hash":"0629ea61f269dc8a09f76a031519d0bd60d6fce6","modified":1623600552905},{"_id":"source/CNAME","hash":"bc5888d957934526b4563e82dfc0469306c15341","modified":1609072278142},{"_id":"source/protobuf.md","hash":"967c8068780565f2b9cf63ffe8036c16bacb0edf","modified":1517200638000},{"_id":"themes/yilia/languages/default.yml","hash":"3083f319b352d21d80fc5e20113ddf27889c9d11","modified":1566995518161},{"_id":"themes/yilia/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1566995518163},{"_id":"themes/yilia/languages/fr.yml","hash":"84ab164b37c6abf625473e9a0c18f6f815dd5fd9","modified":1566995518162},{"_id":"themes/yilia/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1566995518162},{"_id":"themes/yilia/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1566995518162},{"_id":"themes/yilia/languages/zh-CN.yml","hash":"ca40697097ab0b3672a80b455d3f4081292d1eed","modified":1566995518162},{"_id":"themes/yilia/languages/zh-tw.yml","hash":"53ce3000c5f767759c7d2c4efcaa9049788599c3","modified":1566995518162},{"_id":"themes/yilia/layout/layout.ejs","hash":"0a332bdbd3b86c231d690614687f5b97186b85d5","modified":1566995518145},{"_id":"themes/yilia/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1566995518145},{"_id":"themes/yilia/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1566995518144},{"_id":"themes/yilia/layout/index.ejs","hash":"a35dc900203f9d8dd863ea4c1722198d6d457ec8","modified":1566995518145},{"_id":"themes/yilia/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1566995518156},{"_id":"themes/yilia/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1566995518145},{"_id":"themes/yilia/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1566995518145},{"_id":"themes/yilia/source/slider.e37972.js","hash":"6dec4e220c89049037eebc44404abd8455d22ad7","modified":1566995518158},{"_id":"themes/yilia/source/main.0cf68a.css","hash":"f950af60f361539b11d3f29f453dcc6323266807","modified":1623937792865},{"_id":"themes/yilia/source-src/css.ejs","hash":"94dbdb02ca11849e415d54fb28546a598f2cffb1","modified":1566995518178},{"_id":"themes/yilia/source-src/script.ejs","hash":"c21381e1317db7bb157f1d182b8c088cb7cba411","modified":1566995518178},{"_id":"source/.obsidian/config","hash":"1c05ed9e333220416f104d62c5a6ae83be3f9213","modified":1609486045239},{"_id":"source/.obsidian/graph.json","hash":"f03ae6e96e1667cefc3b60a43f018370be22429a","modified":1609069366859},{"_id":"source/.obsidian/workspace","hash":"a7e6e76f20209d675c4ead4660d22f42514f733d","modified":1609486045532},{"_id":"source/attachments/.DS_Store","hash":"d288cc23c2534b52e069f9bde56936a456754a71","modified":1539355551000},{"_id":"source/attachments/screenrc","hash":"9e26574ce04fd2a29be807b08ea5fb39768f6a73","modified":1517200638000},{"_id":"source/attachments/websocket_demo.tar.gz","hash":"9a2a11c3390fbe76e194bbbaf3c0265f553389aa","modified":1517200638000},{"_id":"source/pics/.DS_Store","hash":"dcfd399f8049f96cbbeae33eb4894eaa3f7ebe1b","modified":1609421123510},{"_id":"source/pics/homura.jpg","hash":"699add4d3bc34d91146ff94782541cddb05b1405","modified":1517200638000},{"_id":"source/pics/longpolling.png","hash":"3368c882710d707d4e0fedd0e61ad0566de58041","modified":1517200638000},{"_id":"source/pics/kurama.jpg","hash":"d2c037570355dadad6c1c65dc5c3801efa36ed0d","modified":1517200638000},{"_id":"source/pics/miku.jpg","hash":"5260a74b0d84c8f3b2733472c45ddf40ca04494c","modified":1566998758394},{"_id":"source/pics/nsq.gif","hash":"c6c1214b81423649f218926ca4c69b0ddf2b7726","modified":1517200638000},{"_id":"source/pics/polling.png","hash":"84baf98838ff6c3a7e1b8d92830083ad65c22572","modified":1517200638000},{"_id":"source/pics/ryuuko.jpg","hash":"56f582dcad9bbf6bf118bd12a81ced4cff48375d","modified":1517200638000},{"_id":"source/pics/websocket.png","hash":"ebc3eb092525a380ec675fdfa1dacace5d4620a5","modified":1517200638000},{"_id":"source/pics/youthy.jpg","hash":"8f8a73ddbc1b7c104921f8a783e797ab1fd92c44","modified":1517200638000},{"_id":"source/_posts/CLRS.md","hash":"28c757404721ce050dfaf3fe0bce0eecdc13caf1","modified":1517200638000},{"_id":"source/_posts/CSAPP.md","hash":"ec89934fd8bb80181594b4d438904cde80d263ef","modified":1517200638000},{"_id":"source/_posts/127_0_1_1.md","hash":"9e16ee2fe0818d133729520a0ef84f6f57419f1a","modified":1566992688353},{"_id":"source/_posts/TLCL_notes_10.md","hash":"9ccddf62938a8d6852cf3c7189270bf53614542e","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_13.md","hash":"d150116fed1803fff948d4ba67de64cdeb179ac0","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_11.md","hash":"73403aac8d5d7dd83f9c732971c6941b172bc749","modified":1517200638000},{"_id":"source/_posts/.DS_Store","hash":"ae667ef0ff66966caa7394bb95d45503fa526a46","modified":1620032575819},{"_id":"source/_posts/TLCL_notes_14.md","hash":"6456b05f265ee215d988cb9e9f06a2e712c547b7","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_12.md","hash":"93b6c1aa23efe78528bf7b5a30294a9688b6b1af","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_15.md","hash":"08d0d9f65dbf882bb1b70b421a6789d9dba827d1","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_16.md","hash":"15db7df2e46b6bb5b68ec0ec2bc0b2204ffceaea","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_18.md","hash":"ee3f03a27b0aeffcc9587fefdf0bda8ce8be9e07","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_19.md","hash":"113fac6a37acc6b7f292532faa1d11a66b0dc3cc","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_17.md","hash":"810bbc281914992652126104ab08ec946c76ee23","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_2.md","hash":"f896a7bdeb834b57124ee8159043d157c0140585","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_20.md","hash":"ca5aa192fa94d324864a6cedcd8489f3e254a402","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_21.md","hash":"7f0eb1ff6fe397665da8062b8491d870cf1d1272","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_22.md","hash":"6e6cc90c9ad7ca42ac247647fde3530189f2d730","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_23.md","hash":"1e7dd282609771eb8bf00e1ebef4467c965b3169","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_24.md","hash":"7f7581e47a4b3f8b05fbe6fe7ee8719a824360f0","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_25.md","hash":"a2e3e5791943163e381dc1cc8373408b09c5b84f","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_27.md","hash":"6db2fb3423b0f79a90aec772dff179aac2ebce37","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_28.md","hash":"41b29599fe4fe844667bee659b9bc3feddd9954f","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_29.md","hash":"7cbb20176e37393682110c5f24a39cbd1b31b13c","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_26.md","hash":"87eb33d82b087f063969aba044fe0654e4aa947c","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_3.md","hash":"786c035f83b3079484653635fbf51f8c68511a7f","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_30.md","hash":"4e7960b2c5de2e6d263a77fd345d58ec0cbaa2fc","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_31.md","hash":"29d2c36735458745422b6a04d4cafa32d8eb3c5c","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_32.md","hash":"64ad7a11259b75994dc6bc2a7c32371b16793116","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_33.md","hash":"8ca1970ad1b45bf400d505dd396f604830ca6a43","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_34.md","hash":"31fd8d0320ce8138c68d8b4cfea165d19d0183e7","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_36.md","hash":"71aa3c05af15e52dfd14c3e4c253cf686bc8aef6","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_37.md","hash":"eb3517b7d2c8b4afe1bb8d4e528a7a1045d1606f","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_4.md","hash":"76b450e87bd9c99dbbb17e31e98545046051cb02","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_5.md","hash":"9c9a570f8325fd7aa9e51759a37c8c4eee6ffbe0","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_35.md","hash":"f1bef683e035f0f6af57d2cf7d6c22649b9c1d0f","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_6.md","hash":"1164441a89e357392a9fe8b8be46ff965ad3e14e","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_7.md","hash":"06ae2ffb3b38e0fe0cf64b37f985adb761afa69a","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_8.md","hash":"4f16d7bc2ec24e05f4f2a73b287fc17bceb4a426","modified":1517200638000},{"_id":"source/_posts/TLCL_notes_9.md","hash":"871cf897bd261d1fdf433598745fb580284fec4f","modified":1517200638000},{"_id":"source/_posts/TTL.md","hash":"99d7ede1a95bb71d0b4fb6d3e00bfb48a8ce276e","modified":1517200638000},{"_id":"source/_posts/Ubuntu中创建SWAP交换文件.md","hash":"460c5cdf7308f86c6083da69e12a83196652b80f","modified":1517200638000},{"_id":"source/_posts/XMonad.md","hash":"a24361b92c275a496edd538f203c4b65104c249a","modified":1517200638000},{"_id":"source/_posts/apple_iap.md","hash":"88e65f306004611814f04c21194c105e2fa42730","modified":1539243241000},{"_id":"source/_posts/base64指南.md","hash":"47a1d0c2440f0315011958e00a20111cf2078c50","modified":1517200638000},{"_id":"source/_posts/apache_ab.md","hash":"12244b54b47d624d0dfc210a348157efc8d200e6","modified":1539243221000},{"_id":"source/_posts/aws_ec2_timezone.md","hash":"6238844062dff17db0e4375260f000a2c767f661","modified":1536735566000},{"_id":"source/_posts/bash.md","hash":"61e45badb9d42d7f552d622f9b27e9eb5a69e251","modified":1517200638000},{"_id":"source/_posts/bash_builtin.md","hash":"5a97a3e16574219ed77c45e610c5b5b96764daa1","modified":1517200638000},{"_id":"source/_posts/chrome.md","hash":"4f5ef298d774625bfe4ed434cff5827afdecea9c","modified":1517200638000},{"_id":"source/_posts/cpu_and_alignment.md","hash":"9f988addb6f03d87fb8cc27ac5e20d7fdee3761e","modified":1517200638000},{"_id":"source/_posts/dead_force.md","hash":"39442c4f69a27ab792037f7d290e90f6d2f421b0","modified":1517200638000},{"_id":"source/_posts/cycle_in_linkedlist.md","hash":"9f73a403f32a08609adf629f37c02637ad0ac4e7","modified":1517200638000},{"_id":"source/_posts/dhcp.md","hash":"b2a3dfbf7f63dd852fd9c3a6bb3cb1875973277d","modified":1517200638000},{"_id":"source/_posts/design_drips.md","hash":"7b7ba1df0ec5ebbc24598d1eb616afdfb919340c","modified":1575901066000},{"_id":"source/_posts/devops1.md","hash":"ad5854ee04db8ddd0de3fd97032aa8e3ebe91705","modified":1538133159000},{"_id":"source/_posts/dialyzer.md","hash":"76fd7a13e23f577feced6926f87ac01a505a5300","modified":1517200638000},{"_id":"source/_posts/dig_command.md","hash":"f84d99ba3e6638403771b92a5e19924850858db9","modified":1517200638000},{"_id":"source/_posts/dnsmasq.md","hash":"c7c8dd215c463be1919714deff8abbc9bf9af231","modified":1517200638000},{"_id":"source/_posts/docker_network.md","hash":"6887d64fc7fa519568860b680e976b39c98d79a8","modified":1517200638000},{"_id":"source/_posts/docker_problems.md","hash":"21598b6918f8ba9d787174753de5be50a2ba82c6","modified":1517200638000},{"_id":"source/_posts/dnspod_change_dns.md","hash":"09c6f53fff8459998af992f7acec56f8b50e129f","modified":1517200638000},{"_id":"source/_posts/domain.md","hash":"1661306e68d4ca81e56257511597a5206cb5a831","modified":1521008890000},{"_id":"source/_posts/dsn.md","hash":"32231464e9c42df22030ecc675ed1c908ea06072","modified":1517200638000},{"_id":"source/_posts/dynamic_programming.md","hash":"8016363ade6d69858021535311b341a2632f19c5","modified":1517200638000},{"_id":"source/_posts/email.md","hash":"19a1a105bdc56f4b8bdaadb9271c220fbd5b497e","modified":1517200638000},{"_id":"source/_posts/elixir_runtime_config.md","hash":"972ed658102c575dd9e7c5358a570c7c644b37af","modified":1624794214797},{"_id":"source/_posts/elixir_struct.md","hash":"5965bc85d7a3da8ee3b039cdbe962dd6dbdaf605","modified":1624630000132},{"_id":"source/_posts/erlang_19.0.md","hash":"6d08d6bb4efa0de63344173cee40535e20bf69e3","modified":1517200638000},{"_id":"source/_posts/erlang_app_seq.md","hash":"f1a340471fd37e18ced3aa5ede1815e803917fac","modified":1517200638000},{"_id":"source/_posts/erlang_array.md","hash":"0efc8bb6e430dec9e38339dae07e3a5ca777961b","modified":1517200638000},{"_id":"source/_posts/erlang_bitsyntax.md","hash":"1d81f58a2ddc2de75a19df3cff8b55d08fe3ded8","modified":1517200638000},{"_id":"source/_posts/erlang_code.md","hash":"c67366eeeaed17f441aa45c6b2fffe9c62a6eb4a","modified":1517200638000},{"_id":"source/_posts/erlang_concurrency.md","hash":"43721a768f9c2f925a7b488f6b442b24ed492078","modified":1517200638000},{"_id":"source/_posts/erlang_comment.md","hash":"baad97c9b444368266c0f7dd49385c470f75fdfa","modified":1549854167762},{"_id":"source/_posts/erlang_distribution.md","hash":"82ea6042592f6065f9933ae424390fa97f274f41","modified":1517200638000},{"_id":"source/_posts/erlang_ets.md","hash":"5b2a407730ea606fbe45d5f2058818086d9d00ea","modified":1517200638000},{"_id":"source/_posts/erlang_config.md","hash":"c1dab0a7737365fe2d88edd8cd8f26e55171ebcc","modified":1624629748033},{"_id":"source/_posts/erlang_fun.md","hash":"bc53df185470e7ede2d4979b702446e713d15b8c","modified":1517200638000},{"_id":"source/_posts/erlang_ets_performance_tune.md","hash":"feeff98ce2b3925248656253295c1e52a1848ba4","modified":1624705888238},{"_id":"source/_posts/erlang_float.md","hash":"f5470ac94a124ec4ae85c9ad81e7574993be0b82","modified":1538981033000},{"_id":"source/_posts/erlang_functions.md","hash":"e67f148bf6b71c7eca4467afba1daf68e2a2de9f","modified":1517200638000},{"_id":"source/_posts/erlang_gc.md","hash":"9cc2d04c8924c13f27e5301294fdf8ad3eda5561","modified":1517200638000},{"_id":"source/_posts/erlang_gen_server_call.md","hash":"2404b6d746221212c3c7d57d2e35ac7d38300fe2","modified":1517200638000},{"_id":"source/_posts/erlang_hipe_incompatible.md","hash":"2d8860800efc361914d135de9508aa340a5bbc18","modified":1517200638000},{"_id":"source/_posts/erlang_inline.md","hash":"69d642c0b6d8969844c1dd46caebbf0525d1b706","modified":1517200638000},{"_id":"source/_posts/erlang_graph.md","hash":"ce49ab4d26cbd4a41a8dffafe96cbd207e697ac9","modified":1625924256561},{"_id":"source/_posts/erlang_interoperability.md","hash":"89f49c10fb7a7c157626f6a82c5bc42908d921b2","modified":1517200638000},{"_id":"source/_posts/erlang_io.md","hash":"1d35a29057dd99bd6c68f18bb4f575f2e843d106","modified":1517200638000},{"_id":"source/_posts/erlang_install.md","hash":"56afd8f2db6689136220b4236983fd01fa173750","modified":1627619845596},{"_id":"source/_posts/erlang_native_array_nif.md","hash":"0642526a49c256f1ce61a0fc61af358c8d3e404d","modified":1517200638000},{"_id":"source/_posts/erlang_macro.md","hash":"14702e955a9be2acfecc8ec35e315006511b1b3a","modified":1624535167096},{"_id":"source/_posts/erlang_nif.md","hash":"8d395e354e10c79dfa6ee781f618f79cc35c9101","modified":1517200638000},{"_id":"source/_posts/erlang_pretty_print.md","hash":"e34b885f376bb065ee5a949ae9fdd14009d07fee","modified":1517200638000},{"_id":"source/_posts/erlang_rebar.md","hash":"23fc33bc2fb9598eadb060f9f903c6255fe7542a","modified":1517200638000},{"_id":"source/_posts/erlang_receive_infinity.md","hash":"bb7212c407ac8cd8dbe65631f98712efefac02c3","modified":1517200638000},{"_id":"source/_posts/erlang_relx.md","hash":"addaf733e7762ebdcd8f2fffb8e6af069dd81c1c","modified":1517200638000},{"_id":"source/_posts/erlang_remsh.md","hash":"562676005ca169cf42af67bf82ec0f8bb683cda1","modified":1517200638000},{"_id":"source/_posts/erlang_regex.md","hash":"678db28f7958810127b74b34d2b5f2b20a2ce5f9","modified":1538980892000},{"_id":"source/_posts/erlang_scope.md","hash":"39d7fba31e284fa8fd97259ca0864448837cf981","modified":1517200638000},{"_id":"source/_posts/erlang_socket.md","hash":"fe7f53a48405a87b551a8c3099fa1699d7672684","modified":1517200638000},{"_id":"source/_posts/erlang_tags.md","hash":"2c47adae3c265636c662cf4c49d5a68faeccfede","modified":1517200638000},{"_id":"source/_posts/erlang_sediment.md","hash":"01c5be5fbf32865485b79c8ee0e5788b5f701751","modified":1527842148000},{"_id":"source/_posts/erlang_taste.md","hash":"e17edd1087fa67a3932c9719ce46823f6c1b08f1","modified":1517200638000},{"_id":"source/_posts/erlang_time.md","hash":"73edc02378506b114df8dd222561511ff9895039","modified":1517200638000},{"_id":"source/_posts/erlang_tips.md","hash":"e8feb6c7b012ad27ae646d081db5ec225f5601ff","modified":1517200638000},{"_id":"source/_posts/erlang_tcp.md","hash":"515603de5d4b310b5b48212965870a037f5f0ce3","modified":1623600761350},{"_id":"source/_posts/erlang_unicode.md","hash":"35dcb053acaab2153b46765b08190393bf7ce44d","modified":1517200638000},{"_id":"source/_posts/erlang_websocket.md","hash":"306080e1b1b45db930fe673a5872029f606ba91c","modified":1517200638000},{"_id":"source/_posts/fcitx.md","hash":"a7f8f11f4efddefb73ee1ead4955ad0cdb9ea61b","modified":1517200638000},{"_id":"source/_posts/erlang_vm_flags.md","hash":"96b92cfdb13b684021639ade687d5746103635af","modified":1587203039664},{"_id":"source/_posts/erlang查看当前atom数量和上限.md","hash":"f778c9b5b29986c2e8bd8fd30335f6483132bd43","modified":1544604596725},{"_id":"source/_posts/fdisk.md","hash":"6135f55cd519be201d3d287895a8876f73cde8c8","modified":1517200638000},{"_id":"source/_posts/fcm.md","hash":"14f010dc371bc6199c1add5dfe021d76311f8160","modified":1519383131000},{"_id":"source/_posts/firefox.md","hash":"e2652e5ead088bea11c3e557ce982e69a9107893","modified":1517200638000},{"_id":"source/_posts/firewalld.md","hash":"c481bd6fe585d995e4602b5196c267eff13c00cb","modified":1517200638000},{"_id":"source/_posts/firewalld_iptables.md","hash":"c9d803b05e61fdb2d69b68d6f923398137ce9e2b","modified":1517200638000},{"_id":"source/_posts/float.md","hash":"836454e7fab45776a4aa4e7ed565f7f0a9d5a4f4","modified":1517200638000},{"_id":"source/_posts/functional.md","hash":"df733b1de9eb7c22a54d73ac50751c6d2d245101","modified":1517200638000},{"_id":"source/_posts/gcc_code_gen_options.md","hash":"3a6f2908a834caa392888fca1d475e8b41bcefea","modified":1517200638000},{"_id":"source/_posts/gedit.md","hash":"9e6c31cb1791a7d1551a38213f2b3c0536f84883","modified":1517200638000},{"_id":"source/_posts/gen_server_cast.md","hash":"a4fdeece2530212fc362d2c556ad796fa55acf38","modified":1517200638000},{"_id":"source/_posts/generating_function.md","hash":"2641d269eb001b74ea48d99522b6edc042b388fb","modified":1517200638000},{"_id":"source/_posts/git.md","hash":"e779e9fa06be3005cbb28720d703df7c12bdfabe","modified":1517200638000},{"_id":"source/_posts/go_flaws.md","hash":"0e910d5ecb9d717dab1fb99cea55d14c3ee3e920","modified":1517200638000},{"_id":"source/_posts/gnu_screen_change_tab_name.md","hash":"3182d404b5ae56e34c26f4e493f06fd3745d3c17","modified":1576812752061},{"_id":"source/_posts/go_replay_1.md","hash":"e22299148a0743cd70f265e6195fadfdd5342299","modified":1539265243000},{"_id":"source/_posts/go_replay_2.md","hash":"af7a65e75a924aefc6218c7dc931423bd453473a","modified":1539265248000},{"_id":"source/_posts/go_slice.md","hash":"8f36e6908f8ccb86ca8704728f18572d495c4078","modified":1517200638000},{"_id":"source/_posts/go_replay_3.md","hash":"4c383e6039ec7331288032af5667859545232654","modified":1539355823000},{"_id":"source/_posts/go_test.md","hash":"ccfd2a58dfb9fda60c8cc72d372dc5219361a764","modified":1517200638000},{"_id":"source/_posts/go_tools.md","hash":"221436b0d9ec17c569e992a36a7cba4b8574d6bd","modified":1517200638000},{"_id":"source/_posts/gogs.md","hash":"900cd67146b71a2d7c9309a89be73fbcc53f187e","modified":1517200638000},{"_id":"source/_posts/graph_theory.md","hash":"9753957c29653dabda309770b75a6e136ab2153f","modified":1517200638000},{"_id":"source/_posts/go_style.md","hash":"6493c98e2aed333186ac17b111bda757c225a876","modified":1517200638000},{"_id":"source/_posts/grep.md","hash":"837c5fd89c30049a5f0e131a590398f59d02bae0","modified":1517200638000},{"_id":"source/_posts/grub.md","hash":"3e2d5fb28f29417cdeaf776b653c08f38af70b58","modified":1517200638000},{"_id":"source/_posts/hasee_linux_kernel_problem.md","hash":"a34e23504562c627868d49dfdd5837e826bd119a","modified":1517200638000},{"_id":"source/_posts/haskell_applicative.md","hash":"7fdfbef47f43ccfb6bdca4cc160289e189826e40","modified":1517200638000},{"_id":"source/_posts/haskell_basics.md","hash":"5a4c48315110092ab81a2080f75a188dd4b8d8f6","modified":1517200638000},{"_id":"source/_posts/haskell_concurrent.md","hash":"40c23fb09824bf939edb1aaebf81e2e5b3c1a7df","modified":1517200638000},{"_id":"source/_posts/haskell_concurrent2.md","hash":"8a1abc9e20ea8363f7c3fd0c40af80df2f30b04a","modified":1517200638000},{"_id":"source/_posts/haskell_concurrent3.md","hash":"053b9cfd1a7befdeb0214338311626239a087a56","modified":1517200638000},{"_id":"source/_posts/haskell_functor.md","hash":"d257958c4a1f837d7938d104c433b145a89d0762","modified":1517200638000},{"_id":"source/_posts/haskell_module.md","hash":"9bcc548108e3780a6211ebe0edbd83fd27e6a617","modified":1517200638000},{"_id":"source/_posts/haskell_monad.md","hash":"4987a72f0ea0617611ad186cb2ad5426917c8fa2","modified":1517200638000},{"_id":"source/_posts/haskell_monoid.md","hash":"6a1124e3d488ec214e1f63ba80d4bccd2df0c10c","modified":1517200638000},{"_id":"source/_posts/haskell_zipper.md","hash":"0a0223a9996251715cebb06b083ddb756ba01b3f","modified":1517200638000},{"_id":"source/_posts/hexo_docker.md","hash":"5ae6f95d5d1353ce4aa473a1630049fca4dd2344","modified":1517200638000},{"_id":"source/_posts/hex_publish.md","hash":"819b72457aaf1bf67552009c685c106004397c7b","modified":1624175560313},{"_id":"source/_posts/hexo写博客指南.md","hash":"adc414e4b74adfa7b65a1e50d6992df6abfc1aca","modified":1517200638000},{"_id":"source/_posts/highorder_function.md","hash":"ea276c85dffe042a434f5a668397bb785a2c0619","modified":1517200638000},{"_id":"source/_posts/hosts.md","hash":"f6d4229b3b80c466a920a42febe79f9d493b8341","modified":1517200638000},{"_id":"source/_posts/icmp.md","hash":"cc2fc6706a4ed8637719788da963d4f40b30d940","modified":1517200638000},{"_id":"source/_posts/immutable.md","hash":"4a8e5c2f2c5a1899cf958b4d8846a9e4fd77c4c6","modified":1517200638000},{"_id":"source/_posts/inode.md","hash":"b8904b603885c35059d8b4024029061368196559","modified":1517200638000},{"_id":"source/_posts/interrupt.md","hash":"a79a19bb31e6307fea87833c715cead16043a4f9","modified":1517200638000},{"_id":"source/_posts/iostat.md","hash":"2e6e5453152bec68a6a12d44ea1f905cc159a84e","modified":1517200638000},{"_id":"source/_posts/jinterface.md","hash":"e0f1b827b51ed61d8f851194370815a0bcfd6d75","modified":1627830498924},{"_id":"source/_posts/ip_addr_class.md","hash":"0ba493d760084bdc33aaa9927d238f99d82f5053","modified":1517200638000},{"_id":"source/_posts/jit.md","hash":"4318ca9478e5b2167a371571abb3b10512686db8","modified":1517200638000},{"_id":"source/_posts/linux_cmd_env.md","hash":"1ece5d9f88a8806c11dba99ae5b87218eda78609","modified":1517200638000},{"_id":"source/_posts/linux_cmd_hostname.md","hash":"21b7787821388bbf8b348360c2be22c4c43553f5","modified":1517200638000},{"_id":"source/_posts/json.md","hash":"1808902e5d3e0b140d883ffe72136dad69f42898","modified":1538038179000},{"_id":"source/_posts/linux_add_sudoer.md","hash":"a4fa4ecb0c40c6cff224eb7d885014ef63e06586","modified":1536722068000},{"_id":"source/_posts/linux_history.md","hash":"7e0ca5f5443d6d907b4c1b6e8bd0430427512717","modified":1517200638000},{"_id":"source/_posts/linux_storage.md","hash":"ba69dfd4f2bc62e7e096ae4026f225a0eec41c6f","modified":1517200638000},{"_id":"source/_posts/linux_terminal.md","hash":"628f7879bd4fc1c77aacead51fc03d8781981abe","modified":1517200638000},{"_id":"source/_posts/linux_tips.md","hash":"4e38d38be0448af9ebd2d8d91c89de9d0e3ba1c5","modified":1517200638000},{"_id":"source/_posts/logrotate.md","hash":"4bb05c0d9fb9a21bd1d31f0645c71b3c321cff10","modified":1517200638000},{"_id":"source/_posts/lsmod命令.md","hash":"873e0d4c5ea0959e33d3209a250ef3fc300e3be9","modified":1517200638000},{"_id":"source/_posts/locale.md","hash":"6f2b542e408abf9738b8a0da9edda0dfa55acff8","modified":1540036710214},{"_id":"source/_posts/memory_wall.md","hash":"fc1ba65a114731c7ad524e58ff262963e06b9b0a","modified":1517200638000},{"_id":"source/_posts/mac_chinese.md","hash":"fbfdea3966ae539d2b5d0e240998349cc4152234","modified":1540117429664},{"_id":"source/_posts/mysql_cmd.md","hash":"de5e4bfc190ec441b1eee5fec3df35e5244fce87","modified":1517200638000},{"_id":"source/_posts/mysql_collation.md","hash":"c78f4e295a20e58c12e5ed286527797d07cc5f44","modified":1517200638000},{"_id":"source/_posts/mysql_dml.md","hash":"3da48142ae5643cce91c4af455eb93d174b883f9","modified":1517200638000},{"_id":"source/_posts/mysql_ddl.md","hash":"5db27447dbe2030beb28f6abe876e151b1eb1d5f","modified":1609072291732},{"_id":"source/_posts/mysql_maintain.md","hash":"4c7637b9e1fa1f872f8977d2ac3b6799bd0c3196","modified":1517200638000},{"_id":"source/_posts/mysql_install.md","hash":"d33fd9ef79f2bac97c79316124e5eb2e090e40df","modified":1536733787000},{"_id":"source/_posts/mysql_opti.md","hash":"0ac62d1638e58d64ef1f91b2400c7165dce29ce1","modified":1517200638000},{"_id":"source/_posts/mysql_replication.md","hash":"99515225d8d30835b19fa2f8dac33a98016df2f8","modified":1517200638000},{"_id":"source/_posts/mysql_select.md","hash":"fe0a5c18ceaf40a66798500da162486cf87d2b8a","modified":1517200638000},{"_id":"source/_posts/mysql_strict_mode.md","hash":"0422123e589f5704800cee8ac2357b5aad699ca4","modified":1517200638000},{"_id":"source/_posts/mysql_transaction.md","hash":"9a92a281a68973530a35e6e99fe0319eb018bf8f","modified":1517200638000},{"_id":"source/_posts/mysqld_multi.md","hash":"8407b866301de4dbeabec8599787aa092d112f5c","modified":1517200638000},{"_id":"source/_posts/mysqld_config.md","hash":"4f492e0f1406b0d34d1974d152b723a580788411","modified":1537239431000},{"_id":"source/_posts/nautilus.md","hash":"07a1ce29dcaa4d372e5ff101736f50cf44ee50a7","modified":1517200638000},{"_id":"source/_posts/neo4j.md","hash":"b64d554a215ba98bbc4323577297bf6488806100","modified":1517200638000},{"_id":"source/_posts/nat_expose.md","hash":"1f5a14aa93f7772ca752c90118b0ebc5bf49d3f0","modified":1536810042000},{"_id":"source/_posts/netcat.md","hash":"cd47b3cf213c7924aa7d8c421adb0b215929f155","modified":1517200638000},{"_id":"source/_posts/netstat.md","hash":"237cd13bdc05dc71ac448252065d15f2747267d2","modified":1517200638000},{"_id":"source/_posts/nginx_server_location.md","hash":"3d0af2a694f46b52c114bf965b560123b956c176","modified":1517200638000},{"_id":"source/_posts/nginx.md","hash":"b4b27705d2d6c7584e41ffba6ef8f97a1e785bf7","modified":1536893689000},{"_id":"source/_posts/nmap.md","hash":"49b03329cfa33c70c8776784b822077b653c2da6","modified":1517200638000},{"_id":"source/_posts/noshell_unicode.md","hash":"824f96d170b19205124561572a598ff579ef34b9","modified":1517200638000},{"_id":"source/_posts/noteasy_open_vm_tools.md","hash":"fd18b840ed5ac79ee90ebff65f7856ffcfbafb8e","modified":1517200638000},{"_id":"source/_posts/noproxy_env.md","hash":"87db6758afe768f00768ecd546835793565f08b4","modified":1539145439000},{"_id":"source/_posts/odbc.md","hash":"c34aff5370a1bb5b8e0ff33bf515701ce0491394","modified":1627624158600},{"_id":"source/_posts/oo_sucks.md","hash":"e33ef05d861d613866b22f5b03022ac89263cbcf","modified":1517200638000},{"_id":"source/_posts/npm.md","hash":"c3a686aa8d0147ecabb16a2f9f0501ca14d65950","modified":1540041151885},{"_id":"source/_posts/os_copyfile_toobig.md","hash":"2e83b6f21f781d3f362863351e5176a3cf279cfd","modified":1517200638000},{"_id":"source/_posts/os_lock.md","hash":"b0da57a8f20131946041d6aec7bebf5e19d82839","modified":1517200638000},{"_id":"source/_posts/pgrep_pkill_cmd.md","hash":"540ca2f6c8b00e7c826aecce0b9e04f3845e093a","modified":1517200638000},{"_id":"source/_posts/phpmyadmin.md","hash":"cc5be0e75ee7a998c109ddc8d93d625c5604b18a","modified":1517200638000},{"_id":"source/_posts/polipo.md","hash":"f8bf43033514f6d2e3b5d875e1ffa9ef190cb805","modified":1517200638000},{"_id":"source/_posts/ppa源.md","hash":"f09d83e167aa9723f8f9b2645b4d644e470c9109","modified":1517200638000},{"_id":"source/_posts/polardb.md","hash":"9c494569f5d992d2f2de5e77cabf54aa3a3477fe","modified":1627563197841},{"_id":"source/_posts/programming_mind.md","hash":"7d5de969a56beb6cc9bea3beb61094a40b66261f","modified":1517200638000},{"_id":"source/_posts/programming_drips.md","hash":"f8087ec535c7a7835b6cbda764297f60440df807","modified":1548745899286},{"_id":"source/_posts/python.md","hash":"8cc696515f005dd840cce706be843dabbf8e7999","modified":1517200638000},{"_id":"source/_posts/python_flaws.md","hash":"45cdd35b412e39c7040a44edaf974bd7cc2d450d","modified":1517200638000},{"_id":"source/_posts/radix_complement.md","hash":"c34cdd50a5a3d71158f7f0fe984634b70808329f","modified":1517200638000},{"_id":"source/_posts/redis.md","hash":"063a2c73ae12a228c445c555a8ccb2ae6825d3ab","modified":1517200638000},{"_id":"source/_posts/querystring_array.md","hash":"c428b37426f3b0621fbf9e39a4997f05199b5ee2","modified":1624461057321},{"_id":"source/_posts/regular_expression.md","hash":"db89057abf5397a04e289bc939bcab75a00f0d20","modified":1517200638000},{"_id":"source/_posts/rlwrap.md","hash":"57840510843ddfb2c6935facd555bf647626547c","modified":1517200638000},{"_id":"source/_posts/rsync.md","hash":"2a4ea9a98abe53293fd6f7fea17ea5e0f80aeb0c","modified":1517200638000},{"_id":"source/_posts/scancode.md","hash":"94d547461634b4e70e747672f0f06f364db195e1","modified":1517200638000},{"_id":"source/_posts/screen.md","hash":"3c7e848b49bb132c41a423a69c0b8fd0be18ec75","modified":1517200638000},{"_id":"source/_posts/ruby.md","hash":"c813adc21bc0294888d3d8fd6414626b6da063f9","modified":1540008302064},{"_id":"source/_posts/script_defer.md","hash":"582dff3cbd72da1589f32cec8e6024970ee59adb","modified":1517200638000},{"_id":"source/_posts/socket.markdown","hash":"860bdde1bf640d83492c09e0c9d454759669b597","modified":1517200638000},{"_id":"source/_posts/sort.md","hash":"3e14c29409209824dad7cb5b554d916e81daf45f","modified":1517200638000},{"_id":"source/_posts/ssh.md","hash":"e0d5d5e756f8ec38c7ce129d4225778943bc3270","modified":1517200638000},{"_id":"source/_posts/ssl.md","hash":"d90073b9839b0b4264657d3abe0cbbabbc670f06","modified":1517200638000},{"_id":"source/_posts/string_immutable.md","hash":"231faf00f5edeed52543e8e156a5f5575ca1ded4","modified":1517200638000},{"_id":"source/_posts/su_sudo_gksudo.md","hash":"114dc3df14139bae4bd612c82472252782f01e30","modified":1517200638000},{"_id":"source/_posts/svn.md","hash":"0bed7cb2af9d198f3ab4ee31d60c7c626d5726eb","modified":1517200638000},{"_id":"source/_posts/svn_client.markdown","hash":"b541f3572a3ccb7c52f48daf9918899365ffac5a","modified":1517200638000},{"_id":"source/_posts/tcp.md","hash":"4dfea614987e979515fe6fe17c064e0f7d090a62","modified":1517200638000},{"_id":"source/_posts/timer.md","hash":"82accb53eb7e08fe0c176ee49cf3fc100dc9ca23","modified":1517200638000},{"_id":"source/_posts/top_cmd.md","hash":"0bcc7c532ee201ff16e1f27cb06119851be88002","modified":1517200638000},{"_id":"source/_posts/traceroute.md","hash":"58ab116f2c89dfc3c2016dd81f00044025f5946e","modified":1517200638000},{"_id":"source/_posts/tsocks.md","hash":"425d7e3f932ba42985a445cd8d534a4c6ae4dca3","modified":1517200638000},{"_id":"source/_posts/ubuntu_16.04_noteasy.md","hash":"7cc196cfdf5039482aedb04347abe5cd9bd2890a","modified":1517200638000},{"_id":"source/_posts/ubuntu_bundle.md","hash":"0034529090305eabf220ee6702ab343723f32425","modified":1517200638000},{"_id":"source/_posts/ubuntu_nocaps.md","hash":"ba85f69b7c2dfb70de6e1cad3c50aa6003bed5ee","modified":1517200638000},{"_id":"source/_posts/ubuntu_python_noteasy.md","hash":"0433b67cf76873cbab7c0d03efac182bea6daa7f","modified":1517200638000},{"_id":"source/_posts/ubuntu_screenshot.md","hash":"53d2da2cfe37ab9609cbb09ddf33304999134d0a","modified":1517200638000},{"_id":"source/_posts/ubuntu_swappiness.md","hash":"2ea6edc154d5b3c9459bdef228a95763909637f6","modified":1517200638000},{"_id":"source/_posts/ubuntu_touchpad.md","hash":"92e733cdaa318c792714cafe030b86458944a52a","modified":1517200638000},{"_id":"source/_posts/ubuntu_wifi_unclaimed.md","hash":"d1218256a3bcc15416213f65bdc4bc9af30fac87","modified":1517200638000},{"_id":"source/_posts/ulimit.md","hash":"941f410123ea9d1499d5752665acad60af0fceed","modified":1517200638000},{"_id":"source/_posts/unicode.md","hash":"38e04ccd6f0bee92c676b8184cea48bf81679ac6","modified":1517200638000},{"_id":"source/_posts/vim.md","hash":"fa7b4fc6e236d803c6904b493bff796c4917d481","modified":1517200638000},{"_id":"source/_posts/vmware.md","hash":"acddc9a22d6140e2a510660661dd18c1cbb6566c","modified":1517200638000},{"_id":"source/_posts/vsftpd指南.md","hash":"29f5c4390e2939cf187fcfccd605ba4674305a3f","modified":1517200638000},{"_id":"source/_posts/wecenter.md","hash":"83309cd50abd03fcf8c7162d26d14cd7a3b077d6","modified":1517200638000},{"_id":"source/_posts/websocket.md","hash":"3b593149d87bcd3c779eab81f254b823c288dc79","modified":1517200797000},{"_id":"source/_posts/windows_nocaps.md","hash":"0db42b949f0150f84deee043a8c85afec1369c6c","modified":1517200638000},{"_id":"source/_posts/win8修改Windows目录下文件遇到的权限问题.md","hash":"4864e9bd90f76e49cde6f923bb0cba0741bf5639","modified":1517200638000},{"_id":"source/_posts/windows和ubuntu的时间差问题.md","hash":"57a6d94bd43506c7f93331da0a8e62420ccad5f2","modified":1517200638000},{"_id":"source/_posts/wireshark.md","hash":"2da9e2ff098bf28432584e3416d154dda71a38e1","modified":1517200638000},{"_id":"source/_posts/火狐和FoxyProxy.md","hash":"1ee9d5ed96c40b32d7ad5537cbccf933cb549ad5","modified":1517200638000},{"_id":"source/_posts/xcode_upgrade.md","hash":"ac76273be9d009551fc543adf43ae72c08711450","modified":1540128750342},{"_id":"source/_posts/环回地址.md","hash":"82d9bb5d71614e2a4e93d77b3826c3e78eea6461","modified":1517200638000},{"_id":"source/_posts/阿里公共DNS.md","hash":"3e917ef4cf89c702a066dde52713f6fc382b9c3d","modified":1517200638000},{"_id":"themes/yilia/layout/_partial/toc.ejs","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1566995518153},{"_id":"themes/yilia/source/mobile.992cbe.js","hash":"01b35e71e37aa2849664eb5daf26daede2278398","modified":1566995518157},{"_id":"themes/yilia/source/main.0cf68a.js","hash":"422cda90b608924df9e8136dd1d7f30be7204220","modified":1623937958377},{"_id":"source/pics/erlang_gc_deep.png","hash":"adde8b6d2d641c34abf65f444a7fd9c17f69778d","modified":1517200638000},{"_id":"source/pics/erlang_gc_shallow.png","hash":"8d79c8669d89e520d23373cdf578aa911298f503","modified":1517200638000},{"_id":"source/pics/memory_wall.png","hash":"a4834fee80c3d274bbe6d1c0c4271104d6cc8c1a","modified":1517200638000},{"_id":"source/pics/websocket_demo.png","hash":"9fdfb7113409aba86e21585d752b5f3fc833a38d","modified":1517200638000},{"_id":"themes/yilia/layout/_partial/after-footer.ejs","hash":"b86b248720ad415ec1b5fee53fb583776c776f83","modified":1566995518154},{"_id":"themes/yilia/layout/_partial/archive-post.ejs","hash":"1f7d4819b7f67602c4a1b99871808d2160b60978","modified":1566995518150},{"_id":"themes/yilia/layout/_partial/article.ejs","hash":"630c6ec866d056657d3d91e34b4c64eb993c0654","modified":1566995518156},{"_id":"themes/yilia/layout/_partial/archive.ejs","hash":"a6e94061ac55b9eb55275f87b608d62f6ea35659","modified":1566995518150},{"_id":"themes/yilia/layout/_partial/aside.ejs","hash":"8edbd7993b9b061611a193533a664e2e85eae748","modified":1566995518153},{"_id":"themes/yilia/layout/_partial/baidu-analytics.ejs","hash":"f0e6e88f9f7eb08b8fe51449a8a3016273507924","modified":1566995518152},{"_id":"themes/yilia/layout/_partial/css.ejs","hash":"236f8a377b2e4e35754319c3029bcd4a4115431d","modified":1566995518155},{"_id":"themes/yilia/layout/_partial/footer.ejs","hash":"f2994e0acd1d606ebf4680afc4fa652e148ccf4e","modified":1566995518155},{"_id":"themes/yilia/layout/_partial/google-analytics.ejs","hash":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1566995518151},{"_id":"themes/yilia/layout/_partial/head.ejs","hash":"64f092186b5a744aa1603ce22bb1d44a34446add","modified":1566995518154},{"_id":"themes/yilia/layout/_partial/header.ejs","hash":"6387a93dad7c3d778eb91e3821852fbf6813880c","modified":1566995518152},{"_id":"themes/yilia/layout/_partial/mathjax.ejs","hash":"151a1ef2173ba7b6789d349f0f8da89616cc1394","modified":1566995518146},{"_id":"themes/yilia/layout/_partial/mobile-nav.ejs","hash":"7fbbfabf5e29525b24ada14613c21a26789132b4","modified":1566995518155},{"_id":"themes/yilia/layout/_partial/left-col.ejs","hash":"17efc9005bd1db802fb28534181063db7a506974","modified":1567008022079},{"_id":"themes/yilia/layout/_partial/tools.ejs","hash":"c41341b9618e591538e1136a2d1637587c1bbd90","modified":1566995518151},{"_id":"themes/yilia/layout/_partial/viewer.ejs","hash":"e495790b2abe2290875817e42bd505bc611d3e26","modified":1566995518156},{"_id":"themes/yilia/source/fonts/default-skin.b257fa.svg","hash":"2ac727c9e092331d35cce95af209ccfac6d4c7c7","modified":1566995518160},{"_id":"themes/yilia/source/fonts/iconfont.16acc2.ttf","hash":"f342ac8bf4d937f42a7d6a0032ad267ab47eb7f2","modified":1566995518160},{"_id":"themes/yilia/source/fonts/iconfont.45d7ee.svg","hash":"f9304e5714d20861be7d8f4d36687e88e86b9e1b","modified":1566995518160},{"_id":"themes/yilia/source/fonts/iconfont.8c627f.woff","hash":"aa9672cb097f7fd73ae5a03bcd3d9d726935bc0a","modified":1566995518159},{"_id":"themes/yilia/source/fonts/iconfont.b322fa.eot","hash":"bc8c5e88f4994a852041b4d83f126d9c4d419b4a","modified":1566995518159},{"_id":"themes/yilia/source/fonts/tooltip.4004ff.svg","hash":"397fe4b1093bf9b62457dac48aa15dac06b54a3c","modified":1566995518160},{"_id":"themes/yilia/source/img/default-skin.png","hash":"ed95a8e40a2c3478c5915376acb8e5f33677f24d","modified":1566995518158},{"_id":"themes/yilia/source/img/preloader.gif","hash":"6342367c93c82da1b9c620e97c84a389cc43d96d","modified":1566995518158},{"_id":"themes/yilia/source/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1566995518158},{"_id":"themes/yilia/source-src/css/_core.scss","hash":"24f347a2412abbf58318369152504da9538f8d3b","modified":1566995518172},{"_id":"themes/yilia/source-src/css/archive.scss","hash":"7d27e22ac898e8fafec14549e940c73cbea1fba8","modified":1566995518173},{"_id":"themes/yilia/source-src/css/article-inner.scss","hash":"d79f2d35a06de83a2a226ca790b7a0a34789c115","modified":1566995518173},{"_id":"themes/yilia/source-src/css/_function.scss","hash":"93a50dd19a93485712da1f8d0a1672482dd1eabc","modified":1566995518173},{"_id":"themes/yilia/source-src/css/article-main.scss","hash":"3fad68bd74260326f83090b0974dd80707e7bac7","modified":1566995518168},{"_id":"themes/yilia/source-src/css/aside.scss","hash":"578a67464dd0f542197f7fcee158c991db058563","modified":1566995518173},{"_id":"themes/yilia/source-src/css/article.scss","hash":"0f6d61af99ed4db87f8589db1feaea7747b55963","modified":1566995518168},{"_id":"themes/yilia/source-src/css/comment.scss","hash":"cafe3834017a3bf47420f37543725025225a2c89","modified":1566995518172},{"_id":"themes/yilia/source-src/css/article-nav.scss","hash":"43e507f2a48504079afd9471353337e23ca47470","modified":1566995518164},{"_id":"themes/yilia/source-src/css/highlight.scss","hash":"3719994c2c9393813cc1d42b657205c368a329cb","modified":1566995518165},{"_id":"themes/yilia/source-src/css/global.scss","hash":"b4cb4f45a55d4250cd9056f76dab2a3c0dabcec4","modified":1566995518169},{"_id":"themes/yilia/source-src/css/grid.scss","hash":"849a29fcd7150214fcf7b9715fa5dc71d1f9b896","modified":1566995518168},{"_id":"themes/yilia/source-src/css/footer.scss","hash":"7c995410b25baaf61dfc5e148e22ca60330abcd3","modified":1566995518175},{"_id":"themes/yilia/source-src/css/main.scss","hash":"2f86a014af93583caba78a563d9549826bf28294","modified":1566995518171},{"_id":"themes/yilia/source-src/css/left.scss","hash":"0d30c0e7cdb831c3881a017006c782f2214ac195","modified":1566995518171},{"_id":"themes/yilia/source-src/css/mobile.scss","hash":"ace041d72f95b419f6a5e443191703c2b62007f4","modified":1566995518173},{"_id":"themes/yilia/source-src/css/mobile-slider.scss","hash":"f053c609d84df0dd9eee1d11ddf0c19163a456be","modified":1566995518175},{"_id":"themes/yilia/source-src/css/page.scss","hash":"bf206bb7f7d0967bc8b7fdf01b7ffc99aff9ba88","modified":1566995518167},{"_id":"themes/yilia/source-src/css/social.scss","hash":"724162ccf3977e70a45d189abfaa20b6e2fba87b","modified":1566995518172},{"_id":"themes/yilia/source-src/css/scroll.scss","hash":"9c8dfd1c76854ef063494ca76fac6360b391ed6d","modified":1566995518175},{"_id":"themes/yilia/source-src/css/reward.scss","hash":"80a4fcf9171d4a33235da96ac8a2b7dcabc45dfb","modified":1566995518175},{"_id":"themes/yilia/source-src/css/share.scss","hash":"150c6425f6582e7ec78a873256ce49c9930e8805","modified":1566995518173},{"_id":"themes/yilia/source-src/css/tags-cloud.scss","hash":"c8aa84fca93862d3caae77c552873b8610f33327","modified":1566995518175},{"_id":"themes/yilia/source-src/css/tools.scss","hash":"1b1aa0908e58cf942b28e3881d07c5573c4129e1","modified":1566995518171},{"_id":"themes/yilia/source-src/css/tags.scss","hash":"ac67a3c7097849206244db9b0ba91daaba017ef5","modified":1566995518165},{"_id":"themes/yilia/source-src/css/tooltip.scss","hash":"53d5a554bc2f38e9bb3d26400a47767013c05216","modified":1566995518169},{"_id":"themes/yilia/source-src/js/anm.js","hash":"4a4c5d82b09a3063f91a434388e6aa064fd7fd98","modified":1566995518176},{"_id":"themes/yilia/source-src/js/aside.js","hash":"754f771264548a6c5a8ad842908e59ae4e7ed099","modified":1566995518176},{"_id":"themes/yilia/source-src/js/fix.js","hash":"d6782d53c992e712af39c84e804eccaf38830b94","modified":1566995518178},{"_id":"themes/yilia/source-src/js/Q.js","hash":"d011af172064b6c6e0c7051d8f9879373ddac113","modified":1566995518177},{"_id":"themes/yilia/source-src/js/browser.js","hash":"04095b38cfd4316a23f8eb14b1ffaf95f78a4260","modified":1566995518177},{"_id":"themes/yilia/source-src/js/main.js","hash":"3894e60827c817319e43c9ff3ed045fc3d7336ce","modified":1566995518177},{"_id":"themes/yilia/source-src/js/report.js","hash":"4f1d9a18a936ce40b037f636a39127dd19175b6e","modified":1566995518177},{"_id":"themes/yilia/source-src/js/mobile.js","hash":"4d823b039fd296d24a454eae5a798b93c44560cb","modified":1566995518176},{"_id":"themes/yilia/source-src/js/share.js","hash":"b090f82cf80cba7da764753906d9e2cc2acdf30d","modified":1566995518178},{"_id":"themes/yilia/source-src/js/slider.js","hash":"e846bcc5aac9c68b93f7b8de353df54d8d29f666","modified":1566995518177},{"_id":"themes/yilia/source-src/js/util.js","hash":"8456e9d6b19532742582c99b2fb9d09e146e1c58","modified":1566995518176},{"_id":"themes/yilia/source-src/js/viewer.js","hash":"2577deb6a9fe4f5436360b2ce9afcc7f9a7f0116","modified":1566995518176},{"_id":"source/attachments/go_replay_sgf/1.sgf","hash":"6e33c74db703002d350dcfea699606233e979d2a","modified":1539097872000},{"_id":"source/attachments/go_replay_sgf/2.sgf","hash":"1ed6d94bddcfde2bc2a9319a517f60f8da846588","modified":1539236973000},{"_id":"source/attachments/go_replay_sgf/3.sgf","hash":"8b926ddbf0f2a31ab40b5438aeddb69be309308d","modified":1539324384000},{"_id":"source/pics/df/0.png","hash":"debad1495e032749a2865e4343e584abc65ef9d4","modified":1517200638000},{"_id":"source/pics/df/1.png","hash":"b4af64c1ff7db10654d4fad3b11fd44c98611bda","modified":1517200638000},{"_id":"source/pics/df/2.png","hash":"8ffad37c6e913aed4657ff80d18d7babc88ae767","modified":1517200638000},{"_id":"source/pics/df/4.png","hash":"420bb1835c40e16c4f5ddcde9708e0bd9a41e737","modified":1517200638000},{"_id":"source/pics/df/3.png","hash":"82409118f5a50688e1283d875d9e4389e3573b66","modified":1517200638000},{"_id":"source/pics/df/5.png","hash":"a165cc586facef038ec291e00b8feee7a99fb863","modified":1517200638000},{"_id":"source/pics/df/6.png","hash":"9d22188e9c968be56cb1e2f8058cc70ccc7a2456","modified":1517200638000},{"_id":"source/pics/df/df_000.png","hash":"3125fbbb7e3de64c8950edd08d52cf3c992fa6ba","modified":1517200638000},{"_id":"source/pics/df/df_001.png","hash":"16e85e0b708dbbe32de458ceb34864aa47e920dc","modified":1517200638000},{"_id":"source/pics/df/df_002.png","hash":"c54b6194755ca59e0b00f504e93d10c0e9b3a29d","modified":1517200638000},{"_id":"source/pics/df/df_006.png","hash":"e14f031708762d57649d315988bfa16afec2a624","modified":1517200638000},{"_id":"source/pics/df/df_003.png","hash":"bbb48b8cd19af8c5ce179c811d06df19096563e7","modified":1517200638000},{"_id":"source/pics/df/df_005.png","hash":"92039bdb09e26658b27622275508b6b09a868e47","modified":1517200638000},{"_id":"source/pics/df/df_010.png","hash":"b494267b09b0854c9c266f9502460260eaca6b71","modified":1517200638000},{"_id":"source/pics/df/df_016.png","hash":"8384daf5ba98db9b95751fde5b0195669546d66c","modified":1517200638000},{"_id":"source/pics/df/df_015.png","hash":"6d23981c04f1981312413fb338ec3e25ed58ccbd","modified":1517200638000},{"_id":"source/pics/df/df_018.png","hash":"34032cbe583f1751478ac18ff684cae21cbdd8ab","modified":1517200638000},{"_id":"source/pics/df/df_019.png","hash":"b184f694bf8569853e8a92826a1ab15235b7ae54","modified":1517200638000},{"_id":"source/pics/df/df_021.png","hash":"f6b42d87899b0d96a39350a0f3fba340dfc3c55b","modified":1517200638000},{"_id":"source/pics/df/df_022.png","hash":"cd2c9c82e6ba6441e435573f2622b9e2360509fb","modified":1517200638000},{"_id":"source/pics/df/df_024.png","hash":"ffc9426b0fe7082de4b2e7f1d577cc26c04297bf","modified":1517200638000},{"_id":"source/pics/df/df_025.png","hash":"81fe66e21dafcc112a55dc3a0da4a750f6ba198d","modified":1517200638000},{"_id":"source/pics/df/df_026.png","hash":"c1cb68d2053712a129e3e23024f832a9459da027","modified":1517200638000},{"_id":"source/pics/df/df_029.png","hash":"4d00641fb5d05fb35eade993cecfbb3e9268830a","modified":1517200638000},{"_id":"source/pics/df/df_027.png","hash":"e5eadd5e24c9fb461e7aac228bcc2d0bebba5a5b","modified":1517200638000},{"_id":"source/pics/df/df_028.png","hash":"2b3f0fe4f78b1e52804aa885461d94a3a4f7eac8","modified":1517200638000},{"_id":"source/pics/df/df_030.png","hash":"74c56e04659bd5a69efce0692838b4b93f172f9e","modified":1517200638000},{"_id":"source/pics/df/df_032.png","hash":"bc4329edd57ea87fbce63ae92bd0791b9d7b6456","modified":1517200638000},{"_id":"source/pics/df/df_033.png","hash":"295b15208a8dcb99eeca36e0b809f64fe3c812ea","modified":1517200638000},{"_id":"source/pics/df/df_040.png","hash":"852184e930de221c1e0c2781c93ff328666390ed","modified":1517200638000},{"_id":"source/pics/df/df_041.png","hash":"d522f2555216577dbd16772a09b60a6e0a4a8ee8","modified":1517200638000},{"_id":"source/pics/df/df_042.png","hash":"df67748348779ee473652e1bcb428e88b62e3f3d","modified":1517200638000},{"_id":"source/pics/df/df_043.png","hash":"a418e7cd092755e3c8568d0420db732ed6814ae1","modified":1517200638000},{"_id":"source/pics/df/df_045.png","hash":"12597718bc2e9b0dbf67cb3bfb084b6c4492e948","modified":1517200638000},{"_id":"source/pics/df/df_046.png","hash":"90cf33111e283ba5a990505205e1026660f5d805","modified":1517200638000},{"_id":"source/pics/df/df_049.png","hash":"3956478409fa0577bb6d2a4e441263b1c7e5371e","modified":1517200638000},{"_id":"source/pics/df/df_047.png","hash":"e3605861edfce0107e5626ce567ead4dbc43916d","modified":1517200638000},{"_id":"source/pics/df/df_050.png","hash":"c10e62a321d9bbede4a4056f4ac4c8bc4fc41599","modified":1517200638000},{"_id":"source/pics/df/df_051.png","hash":"004520f65a2c8262042dc6c4af1ce2edd84cb195","modified":1517200638000},{"_id":"source/pics/df/df_054.png","hash":"c8eadb0e40359a888cba4d1188ef750b54324b8b","modified":1517200638000},{"_id":"source/pics/df/df_053.png","hash":"ba6802da67dd41dfbf59d5921af1a080c3674b3f","modified":1517200638000},{"_id":"source/pics/df/df_052.png","hash":"e9646cd1ffbb8817518e0a1af336dca19a0a1db4","modified":1517200638000},{"_id":"source/pics/df/df_055.png","hash":"9b38333777d139ab163c2f200d4ae76a98b71c71","modified":1517200638000},{"_id":"source/pics/df/df_057.png","hash":"810e96c23a0dac119de4a1b59dd620d38e576ec2","modified":1517200638000},{"_id":"source/pics/df/df_059.png","hash":"ff178705875146ac14e452e7f7b15a009b02437d","modified":1517200638000},{"_id":"source/pics/df/df_1.png","hash":"debad1495e032749a2865e4343e584abc65ef9d4","modified":1517200638000},{"_id":"source/pics/df/df_058.png","hash":"9e99b83816bfe9aa38a970c4cdb66f43f9e1998c","modified":1517200638000},{"_id":"source/pics/df/df_056.png","hash":"dc17e85a6500b14830692f8189b16909f78ed684","modified":1517200638000},{"_id":"source/pics/go_replay1/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1539150585000},{"_id":"source/pics/go_replay1/3.png","hash":"35b4ff57dab24eddeb710b64218151998194103c","modified":1539147953000},{"_id":"themes/yilia/layout/_partial/script.ejs","hash":"4cb685f07e89dd5175c2a576e73a1a957aec5637","modified":1566995518153},{"_id":"themes/yilia/source-src/css/fonts.scss","hash":"97b8fba41c914145710b90091f400b845879577f","modified":1566995518165},{"_id":"source/pics/go_replay3/1.png","hash":"0fa174b13efb3f5326c459310bc5ee4364d9e432","modified":1539355865000},{"_id":"source/pics/go_replay3/2.png","hash":"b5c3d99b15b6fdb6e62cca6299eb337af49202d1","modified":1539355868000},{"_id":"source/pics/tcp/tcp.gif","hash":"52328e00c06a03d9cd25ed51de41ee70075b5b97","modified":1517200638000},{"_id":"source/pics/windows_nocaps.png","hash":"285def979a8f8c0e80cdc986fb3d2480d01ba1bd","modified":1517200638000},{"_id":"source/pics/tcp/tcp_establish.gif","hash":"6bbcba429599bae1fdfb48d4f631d074d5583ddd","modified":1517200638000},{"_id":"source/pics/tcp/tcp_close.gif","hash":"5bfd73cddf911dd346958d519a2438496e13bd47","modified":1517200638000},{"_id":"themes/yilia/layout/_partial/post/category.ejs","hash":"385ff8cf192bf029a2ec5ef087b210d5df87db5f","modified":1567001805766},{"_id":"themes/yilia/layout/_partial/post/changyan.ejs","hash":"5f99b55980da64a723a8e14d5a7daba0d6504647","modified":1566995518147},{"_id":"themes/yilia/layout/_partial/post/date.ejs","hash":"ef71c4081e866a494367575c59610e7e6339ece0","modified":1566995518149},{"_id":"themes/yilia/layout/_partial/post/duoshuo.ejs","hash":"e8399025ed3b980aedb821c92855889f5f12fd5b","modified":1566995518148},{"_id":"themes/yilia/layout/_partial/post/gitment.ejs","hash":"e68bbac9ffb1ad27b56837c9abad6ed6bb7daa0c","modified":1566995518149},{"_id":"themes/yilia/layout/_partial/post/nav.ejs","hash":"1036c8e4e1a7bc935ba173744da735a0d6ed09cd","modified":1566995518147},{"_id":"themes/yilia/layout/_partial/post/share.ejs","hash":"5dccfbe165b23a101f1333cc65ed8efbd197453c","modified":1566995518149},{"_id":"themes/yilia/layout/_partial/post/tag.ejs","hash":"749b60ab8dcc8791d38dff975833f092e837893a","modified":1567001951402},{"_id":"themes/yilia/layout/_partial/post/title.ejs","hash":"2f275739b6f1193c123646a5a31f37d48644c667","modified":1566995518147},{"_id":"themes/yilia/layout/_partial/post/wangyiyun.ejs","hash":"ea41c462168d9697caef9485862e9cac718a12c1","modified":1566995518148},{"_id":"themes/yilia/source-src/css/core/_animation.scss","hash":"63a37f26276f9207405afe0f2d65339ce295bbaf","modified":1566995518167},{"_id":"themes/yilia/source-src/css/core/_media-queries.scss","hash":"491ab3378d5c11005ba65c607608bb36b368a9d5","modified":1566995518167},{"_id":"themes/yilia/source-src/css/core/_mixin.scss","hash":"3bba5c77bad5981eac859fe05c9561d580ba7fa9","modified":1566995518166},{"_id":"themes/yilia/source-src/css/core/_reset.scss","hash":"fab871fa93bd542e76a71a56428f2994a4aaf443","modified":1566995518166},{"_id":"themes/yilia/source-src/css/core/_variables.scss","hash":"fb511c505d1309249f21dc577d4ad2bad99a764f","modified":1566995518166},{"_id":"themes/yilia/source-src/css/fonts/iconfont.eot","hash":"bc8c5e88f4994a852041b4d83f126d9c4d419b4a","modified":1566995518174},{"_id":"themes/yilia/source-src/css/fonts/iconfont.svg","hash":"f9304e5714d20861be7d8f4d36687e88e86b9e1b","modified":1566995518174},{"_id":"themes/yilia/source-src/css/img/checkered-pattern.png","hash":"049262fa0886989d750637b264bed34ab51c23c8","modified":1566995518170},{"_id":"themes/yilia/source-src/css/fonts/iconfont.ttf","hash":"f342ac8bf4d937f42a7d6a0032ad267ab47eb7f2","modified":1566995518174},{"_id":"themes/yilia/source-src/css/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1566995518170},{"_id":"themes/yilia/source-src/css/img/tooltip.svg","hash":"397fe4b1093bf9b62457dac48aa15dac06b54a3c","modified":1566995518170},{"_id":"source/pics/go_replay2/1.png","hash":"22ace9fa7b0775e4b4582549de32afc92403bca0","modified":1539265134000},{"_id":"source/pics/go_replay2/2.png","hash":"7bc2057b50cbf7d6c6ed9dbb1532da44f6c72c0f","modified":1539265135000},{"_id":"source/pics/go_replay2/3.png","hash":"af24687e928c2e6281c887e05c968b8084227885","modified":1539265135000},{"_id":"source/pics/go_replay3/3.png","hash":"fa2b7c84b5b8361ff40ad3f79443704fd57d47c7","modified":1539355869000},{"_id":"source/pics/go_replay3/5.png","hash":"c453ff7ea858684b3de21592b6806379ba1e7c87","modified":1539355870000},{"_id":"source/pics/go_replay3/6.png","hash":"8ca4cc617d871b54cdbf0f602d19dea97d2985f3","modified":1539355871000},{"_id":"themes/yilia/source-src/css/fonts/iconfont.woff","hash":"aa9672cb097f7fd73ae5a03bcd3d9d726935bc0a","modified":1566995518174},{"_id":"source/pics/go_replay2/4.png","hash":"98b0dff8f214db2e6c03d8fd93c41f91480b03e9","modified":1539265136000},{"_id":"source/pics/go_replay3/11.png","hash":"ac0c4cc3d1961ada942ea46c6ac59e0a71fde873","modified":1539355866000},{"_id":"source/pics/go_replay3/4.png","hash":"b643316ea965411a3cac302095428e123e724a41","modified":1539355870000},{"_id":"source/pics/go_replay3/8.png","hash":"5f943f94a2b269f5a13b3f6ec5c284a25cda29ef","modified":1539355872000},{"_id":"source/pics/go_replay3/9.png","hash":"9565fb9ba013c1a882ece239db37a3ffbf2d6795","modified":1539355873000},{"_id":"source/pics/go_replay3/13.png","hash":"0f4eae1a7d814c282b048fa2e53cc1cfecfa3f8f","modified":1539355867000},{"_id":"source/pics/go_replay3/10.png","hash":"17e6bc078b243f68c7b2f26921049d2a1bc7f187","modified":1539355866000},{"_id":"source/pics/go_replay3/7.png","hash":"a681e62bb6c03c5ee9155c03645b62fa107fcaf1","modified":1539355872000},{"_id":"source/pics/go_replay3/12.png","hash":"8b903ef68b597d534baf35d6cafc0cc4169bb7cd","modified":1539355867000},{"_id":"source/pics/go_replay2/5.png","hash":"eaac26b459364bada03e1227fb1b5f3dc8ff619a","modified":1539265137000},{"_id":"source/pics/go_replay1/2.png","hash":"73f0b4a6727b9feee8b8f3570c95caf4d2cdc06a","modified":1539147739000},{"_id":"source/pics/go_replay1/5.png","hash":"0940fc91411e4f90529c7ff5832b5e9dd84047a7","modified":1539148430000},{"_id":"source/pics/go_replay1/17.png","hash":"5b4a0bc6e331eb48869fc4bb147b100832a946b4","modified":1539148400000},{"_id":"source/pics/go_replay1/4.png","hash":"d3ad52ea47e9894384ae71dff76b620b08027b7b","modified":1539148425000},{"_id":"source/pics/go_replay1/20.png","hash":"53ae74b39fa8f983634b13e44dc383bfd54c7fc0","modified":1539148410000},{"_id":"source/pics/go_replay1/18.png","hash":"503cbbcb64669a835af08a9c39dffc8016c7e29d","modified":1539148406000},{"_id":"source/pics/go_replay1/6.png","hash":"184942a545edd2ededd835346efeeee8b0753488","modified":1539148426000},{"_id":"source/pics/go_replay1/7.png","hash":"8bdb9e1fbf0e5cad422a8d6732accec4905d7686","modified":1539148444000},{"_id":"source/pics/go_replay1/9.png","hash":"98ba6d18b063482a7819c78dcb2d9d611316c021","modified":1539148443000},{"_id":"source/pics/go_replay1/13.png","hash":"321097ddb6812b007081f3aec32558d12493a191","modified":1539148374000},{"_id":"source/pics/go_replay1/14.png","hash":"b078f6ecb82a9d0646e70d7f15f032a1b32370ae","modified":1539148377000},{"_id":"source/pics/go_replay1/16.png","hash":"f13b320e7c609c2ccc9cb7b676736b6559350823","modified":1539148367000},{"_id":"source/pics/go_replay1/15.png","hash":"24db6d851eb70259591eda144c11d9e4ed6a00ec","modified":1539148375000},{"_id":"source/pics/go_replay1/19.png","hash":"701a6449242c4d282c39dd65cc4f04ca29a5c990","modified":1539148410000},{"_id":"source/pics/go_replay1/12.png","hash":"f3ec81e3547ae1713d8920b13636d6015ea315d8","modified":1539148372000},{"_id":"source/pics/go_replay1/10.png","hash":"4c7d2cc1d292475010adb03c122985d3ef0652e7","modified":1539148375000},{"_id":"source/pics/go_replay1/1.png","hash":"8009f9d8fc76a0107a71db5d6fa10dc29200125f","modified":1539147531000},{"_id":"source/pics/go_replay1/8.png","hash":"d609eaed33942e296eec033b93e189ba7e59565c","modified":1539148440000},{"_id":"source/pics/go_replay1/11.png","hash":"bd4f62d770084ad1b70c826ec731a2f5f8319509","modified":1539148375000},{"_id":"source/attachments/interoperability.tar.gz","hash":"ca00f3a359c084fab96dec94fadc38006e00cec6","modified":1517200638000}],"Category":[],"Data":[],"Page":[{"title":"protobuf","date":"2016-07-20T05:06:00.000Z","tags":["idl","rpc"],"_content":"\n从下面下载protoc-3.0.0-beta-4-linux-x86_64.zip\nhttps://github.com/google/protobuf/releases\n\n","source":"protobuf.md","raw":"title: protobuf\ndate: 2016-07-20 13:06:00\ntags: [idl, rpc]\n---\n\n从下面下载protoc-3.0.0-beta-4-linux-x86_64.zip\nhttps://github.com/google/protobuf/releases\n\n","updated":"2018-01-29T04:37:18.000Z","path":"protobuf.html","comments":1,"layout":"page","_id":"ckrtcb5gx0000mcxqit5qlhz9","content":"<p>从下面下载protoc-3.0.0-beta-4-linux-x86_64.zip<br><a href=\"https://github.com/google/protobuf/releases\" target=\"_blank\" rel=\"noopener\">https://github.com/google/protobuf/releases</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>从下面下载protoc-3.0.0-beta-4-linux-x86_64.zip<br><a href=\"https://github.com/google/protobuf/releases\" target=\"_blank\" rel=\"noopener\">https://github.com/google/protobuf/releases</a></p>\n"}],"Post":[{"title":"CLRS","date":"2016-08-14T13:35:00.000Z","_content":"\n什么是算法, 通过一系列计算步骤将输入转换为输出. 一个算法甚至可以是一个硬件设计.\n\n算法的正确性:有时偶尔不正确的算法也有用,只要能将错误率限制在可以接受的水平即可\n\n数据结构关心的是数据的读写效率\n\n思路: 分治,动态规划,均摊\n\nNP完全问题, 这些问题没有最优解, 只能尝试找较好的解\n\n并行\n\n","source":"_posts/CLRS.md","raw":"title: CLRS\ndate: 2016-08-14 21:35:00\ntags: [cs]\n---\n\n什么是算法, 通过一系列计算步骤将输入转换为输出. 一个算法甚至可以是一个硬件设计.\n\n算法的正确性:有时偶尔不正确的算法也有用,只要能将错误率限制在可以接受的水平即可\n\n数据结构关心的是数据的读写效率\n\n思路: 分治,动态规划,均摊\n\nNP完全问题, 这些问题没有最优解, 只能尝试找较好的解\n\n并行\n\n","slug":"CLRS","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ih0001mcxqs142sohz","content":"<p>什么是算法, 通过一系列计算步骤将输入转换为输出. 一个算法甚至可以是一个硬件设计.</p>\n<p>算法的正确性:有时偶尔不正确的算法也有用,只要能将错误率限制在可以接受的水平即可</p>\n<p>数据结构关心的是数据的读写效率</p>\n<p>思路: 分治,动态规划,均摊</p>\n<p>NP完全问题, 这些问题没有最优解, 只能尝试找较好的解</p>\n<p>并行</p>\n","site":{"data":{}},"excerpt":"","more":"<p>什么是算法, 通过一系列计算步骤将输入转换为输出. 一个算法甚至可以是一个硬件设计.</p>\n<p>算法的正确性:有时偶尔不正确的算法也有用,只要能将错误率限制在可以接受的水平即可</p>\n<p>数据结构关心的是数据的读写效率</p>\n<p>思路: 分治,动态规划,均摊</p>\n<p>NP完全问题, 这些问题没有最优解, 只能尝试找较好的解</p>\n<p>并行</p>\n"},{"title":"CSAPP","date":"2016-08-14T13:35:00.000Z","_content":"\n深入理解计算机系统, 可以像下面这样:\n\n* 避免由于计算机表示数字的方式引入奇怪的数字错误\n* 利用现在处理器和内存的设计优化C代码\n* 理解编译器如何实现过程调用,避免缓存溢出带来的安全漏洞\n* 写自己的shell,自己的动态存储分配等\n\n# Chapter 1 A Tour of Computer Systems\n\n## 1.1 Information Is Bits + Context\n\n计算机里的一切都是0和1, 代表什么意义都看按什么方式去解释(由Context决定),\n如文件的基本的解释方式有文本和二进制两种\n\n## 1.2 Programs Are Translated by Other Programs into Different Forms\n\n源代码(如hello.c)到目标代码的几个步骤:\n预处理(Pre Processor), 输出hello.i文件 ->\n编译(Compiler), 输出hello.s文件 ->\n汇编(Assembler), 输出hello.o文件(relocatable object program) ->\n链接(Linker), 输出hello文件\n\n## 1.3 It Pays to Understand How Compilation Systems Work\n\n我们需要知道编译系统如何工作\n\n性能优化:\n\nIs a switch statement always more efficient than a sequence of if-else statements?\nHow much overhead is incurred by a function call?\nIs a while loop more efficient than a for loop?\nAre pointer references more efficient than array indexes?\nWhy does our loop run so much faster if .we sum into a local variable instead of an argument that is passed by reference?\nHow can a function run faster when we simply rearrange the parentheses in an arithmetic expression?\n\n理解链接错误:\n\nwhat does it mean when the linker reports that it cannot resolve a reference?\nWhat is the difference between a static variable and a.global variable?\nWhat happens if you define two global variables in different C files with the same name?\nWhat is the difference between a static library and a dynamic library?\nWhy does it matter what order we list libraries on the command line?\nAnd scariest of all, why do some linker-related errors not appear until runtime?\n\n避免安全漏洞:\n\n## 1.4 Processors. Read and Interpret Instructions Stored-in Memory\n\nPC: 程序计数器, 是CPU中的一个寄存器, 保存一个内存地址, 这个地址指向下一个要执行的指令\n\n执行指令时CPU的几种简单操作:\n\n* Load 从内存读到寄存器\n* Store 从寄存器写到内存\n* Operate 从两个寄存器取出值, 进行算术运算后覆盖到一个寄存器\n* Jump 从指令中取出一个word并覆盖PC的值, 实现跳转\n\n## 1.5 Caches Matter\n\n为了尽可能匹配CPU和内存的速度差, CPU内有多级缓存(L1, L2, L3),\n只在缓存未命中时才去访问内存, 减少了访问内存的次数\n\n## 1.6 Storage Devices From a Hierarchy\n\n缓存体系: 寄存器 -> 高速缓存 -> 内存 -> 硬盘 -> 分布式系统中网络上的存储\n\n## 1.7 The Operating System Manages the Hardware\n\n操作系统处于应用程序和硬件之间\n1, 保护硬件, 避免应用程序误用导致硬件损坏\n2, 提供简单通用的接口供应用程序使用硬件\n\n操作系统的三层抽象: 文件 虚拟内存 进程\n\n进程之间的独立使得应用程序之间没有互相干扰,对一个进程而言,好像整个计算机是他独占一样\n多个进程通过上下文切换实现并发,\n上下文包括PC, register, 内存\n上下文切换: 保存当前上下文, 读取并恢复新进程的上下文\n\n线程之间共享code和global data\n线程之间共享数据比进程之间要容易 为什么?\n而且线程一般比进程高效 为什么?\n\n虚拟内存的概念使得每个进程感觉好像内存是他独占一样\n每个进程看到的内存都是一样的, 这叫做虚拟地址空间\n进程虚拟地址空间如下:\nKernel virtual memory, 应用程序不允许读写这个区域, 需要调用内核\nUser stack(created at run time)\nMemory-mapped region for shared libraries\nRun-time heap(created by malloc)\nRead/write data(全局变量之类的)\nRead-only code and data(操作系统的代码和数据, 用户进程的代码和数据)\n\n虚拟内存一般是保存在磁盘上并以内存做为缓存\n\n文件就是一列字节\nUnix中一切都是文件统一了不同的IO设备(键盘,鼠标,磁盘,显示器,网络,打印机等)\n\n## 1.8 Systems Communicate with Other Systems Using Networks\n\n网络可以视为另一个IO设备, 也是文件\n\n## 1.9 Important Themes\n\nAmdahl定律\n\n超线程: 一个核能同时跑多个线程, 比如Intel Core i7一个核可以同时跑两个线程\n有多个程序计数器和寄存器,但是只有一个ALU等,普通CPU线程切换要20000个时钟周期,\n而超线程每个周期都要决定在哪个线程上执行, 这样可以更好地利用计算资源,\n当一个线程等待(比如因为内存太慢在等)时这个核就可以去执行另一个线程\n\n指令级并行\n现在CPU可以同时执行多个指令.原理是将指令的执行分成多个step,分成组,每组由一个硬件执行\n\n单指令,多数据并行(SIMD)\n有些硬件支持一条执行,多数据并行,比如一个浮点加法,八对数据同时做加法\n主要用于视频,声音图像的处理\n\n计算机系统中抽象的重要性\n\n文件 + 内存 -> 虚存 + CPU -> 进程 + 操作系统 -> 虚拟机\n\n# Chapter 2 Representing and Manipulating Information\n\n整型要考虑溢出\n浮点数不满足结合律, (3.14 + 1e20) - 1e20 = 0.0 而 3.14 + (1e20 - 1e20) = 3.14\n\n\n","source":"_posts/CSAPP.md","raw":"title: CSAPP\ndate: 2016-08-14 21:35:00\ntags: [cs]\n---\n\n深入理解计算机系统, 可以像下面这样:\n\n* 避免由于计算机表示数字的方式引入奇怪的数字错误\n* 利用现在处理器和内存的设计优化C代码\n* 理解编译器如何实现过程调用,避免缓存溢出带来的安全漏洞\n* 写自己的shell,自己的动态存储分配等\n\n# Chapter 1 A Tour of Computer Systems\n\n## 1.1 Information Is Bits + Context\n\n计算机里的一切都是0和1, 代表什么意义都看按什么方式去解释(由Context决定),\n如文件的基本的解释方式有文本和二进制两种\n\n## 1.2 Programs Are Translated by Other Programs into Different Forms\n\n源代码(如hello.c)到目标代码的几个步骤:\n预处理(Pre Processor), 输出hello.i文件 ->\n编译(Compiler), 输出hello.s文件 ->\n汇编(Assembler), 输出hello.o文件(relocatable object program) ->\n链接(Linker), 输出hello文件\n\n## 1.3 It Pays to Understand How Compilation Systems Work\n\n我们需要知道编译系统如何工作\n\n性能优化:\n\nIs a switch statement always more efficient than a sequence of if-else statements?\nHow much overhead is incurred by a function call?\nIs a while loop more efficient than a for loop?\nAre pointer references more efficient than array indexes?\nWhy does our loop run so much faster if .we sum into a local variable instead of an argument that is passed by reference?\nHow can a function run faster when we simply rearrange the parentheses in an arithmetic expression?\n\n理解链接错误:\n\nwhat does it mean when the linker reports that it cannot resolve a reference?\nWhat is the difference between a static variable and a.global variable?\nWhat happens if you define two global variables in different C files with the same name?\nWhat is the difference between a static library and a dynamic library?\nWhy does it matter what order we list libraries on the command line?\nAnd scariest of all, why do some linker-related errors not appear until runtime?\n\n避免安全漏洞:\n\n## 1.4 Processors. Read and Interpret Instructions Stored-in Memory\n\nPC: 程序计数器, 是CPU中的一个寄存器, 保存一个内存地址, 这个地址指向下一个要执行的指令\n\n执行指令时CPU的几种简单操作:\n\n* Load 从内存读到寄存器\n* Store 从寄存器写到内存\n* Operate 从两个寄存器取出值, 进行算术运算后覆盖到一个寄存器\n* Jump 从指令中取出一个word并覆盖PC的值, 实现跳转\n\n## 1.5 Caches Matter\n\n为了尽可能匹配CPU和内存的速度差, CPU内有多级缓存(L1, L2, L3),\n只在缓存未命中时才去访问内存, 减少了访问内存的次数\n\n## 1.6 Storage Devices From a Hierarchy\n\n缓存体系: 寄存器 -> 高速缓存 -> 内存 -> 硬盘 -> 分布式系统中网络上的存储\n\n## 1.7 The Operating System Manages the Hardware\n\n操作系统处于应用程序和硬件之间\n1, 保护硬件, 避免应用程序误用导致硬件损坏\n2, 提供简单通用的接口供应用程序使用硬件\n\n操作系统的三层抽象: 文件 虚拟内存 进程\n\n进程之间的独立使得应用程序之间没有互相干扰,对一个进程而言,好像整个计算机是他独占一样\n多个进程通过上下文切换实现并发,\n上下文包括PC, register, 内存\n上下文切换: 保存当前上下文, 读取并恢复新进程的上下文\n\n线程之间共享code和global data\n线程之间共享数据比进程之间要容易 为什么?\n而且线程一般比进程高效 为什么?\n\n虚拟内存的概念使得每个进程感觉好像内存是他独占一样\n每个进程看到的内存都是一样的, 这叫做虚拟地址空间\n进程虚拟地址空间如下:\nKernel virtual memory, 应用程序不允许读写这个区域, 需要调用内核\nUser stack(created at run time)\nMemory-mapped region for shared libraries\nRun-time heap(created by malloc)\nRead/write data(全局变量之类的)\nRead-only code and data(操作系统的代码和数据, 用户进程的代码和数据)\n\n虚拟内存一般是保存在磁盘上并以内存做为缓存\n\n文件就是一列字节\nUnix中一切都是文件统一了不同的IO设备(键盘,鼠标,磁盘,显示器,网络,打印机等)\n\n## 1.8 Systems Communicate with Other Systems Using Networks\n\n网络可以视为另一个IO设备, 也是文件\n\n## 1.9 Important Themes\n\nAmdahl定律\n\n超线程: 一个核能同时跑多个线程, 比如Intel Core i7一个核可以同时跑两个线程\n有多个程序计数器和寄存器,但是只有一个ALU等,普通CPU线程切换要20000个时钟周期,\n而超线程每个周期都要决定在哪个线程上执行, 这样可以更好地利用计算资源,\n当一个线程等待(比如因为内存太慢在等)时这个核就可以去执行另一个线程\n\n指令级并行\n现在CPU可以同时执行多个指令.原理是将指令的执行分成多个step,分成组,每组由一个硬件执行\n\n单指令,多数据并行(SIMD)\n有些硬件支持一条执行,多数据并行,比如一个浮点加法,八对数据同时做加法\n主要用于视频,声音图像的处理\n\n计算机系统中抽象的重要性\n\n文件 + 内存 -> 虚存 + CPU -> 进程 + 操作系统 -> 虚拟机\n\n# Chapter 2 Representing and Manipulating Information\n\n整型要考虑溢出\n浮点数不满足结合律, (3.14 + 1e20) - 1e20 = 0.0 而 3.14 + (1e20 - 1e20) = 3.14\n\n\n","slug":"CSAPP","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ik0002mcxqrk9j21lq"},{"title":"什么是127.0.1.1?","date":"2016-06-04T12:04:00.000Z","_content":"\n由于一些软件期望hostname能像domainname那样解析成一个ip地址,\n为支持这些软件,往往在/etc/hosts文件中将hostname解析成127.0.1.1\n\n## 参考链接\nhttp://www.linuxquestions.org/questions/linux-networking-3/what-does-127-0-1-1-mean-623421/\n\n","source":"_posts/127_0_1_1.md","raw":"title: 什么是127.0.1.1?\ndate: 2016-06-04 20:04:00\ntags: linux\n---\n\n由于一些软件期望hostname能像domainname那样解析成一个ip地址,\n为支持这些软件,往往在/etc/hosts文件中将hostname解析成127.0.1.1\n\n## 参考链接\nhttp://www.linuxquestions.org/questions/linux-networking-3/what-does-127-0-1-1-mean-623421/\n\n","slug":"127_0_1_1","published":1,"updated":"2019-08-28T11:44:48.353Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5in0004mcxq9vm711li"},{"title":"<<The Linux Command Line>> 第十三章笔记 vi简介","date":"2015-09-07T12:00:13.000Z","_content":"\nCtrl-e, Ctrl-y 分别是向下滚动和向上滚动。用于查看建议替换的上下文。\n:r foo.txt     读取整个文件的内容并复制到当前位置\n\n","source":"_posts/TLCL_notes_13.md","raw":"title: <<The Linux Command Line>> 第十三章笔记 vi简介\ndate: 2015-09-07 20:00:13\ntags: [linux, bash]\n---\n\nCtrl-e, Ctrl-y 分别是向下滚动和向上滚动。用于查看建议替换的上下文。\n:r foo.txt     读取整个文件的内容并复制到当前位置\n\n","slug":"TLCL_notes_13","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ip0005mcxqx8221er3"},{"title":"<<The Linux Command Line>> 第十章笔记 权限","date":"2015-09-07T12:00:10.000Z","_content":"用户帐户 定义在/etc/passwd 文件里面，用户组定义在/etc/group 文件里面。\n当用户帐户和用户组创建以后， 这些文件随着文件/etc/shadow 的变动而修改，文件/etc/shadow 包含了关于用户密码的信息。 \n对于每个用户帐号，文件/etc/passwd 定义了用户（登录）名，uid，gid，帐号的真实姓名，家目录， 和登录 shell。\n\n文件类型\n* \\-     一个普通文件\n* d     一个目录\n* l     一个符号链接。注意对于符号链接文件，剩余的文件属性总是\"rwxrwxrwx\"，而且都是 虚拟值。真正的文件属性是指符号链接所指向的文件的属性。\n* c     一个字符设备文件。这种文件类型是指按照字节流，来处理数据的设备。 比如说终端机，或者调制解调器\n* b     一个块设备文件。这种文件类型是指按照数据块，来处理数据的设备，例如一个硬盘，或者 CD-ROM 盘。\n\n## chmod\n更改文件模式\n\n八进制数字表示法 如: chmod 600 foo.txt\n符号表示法 如: u+x,go=rw     给文件拥有者执行权限并给组和其他人读和执行的权限。多种设定可以用逗号分开。\n\nchmod 命令符号表示法 \n* u     \"user\"的简写，意思是文件或目录的所有者。\n* g     用户组。\n* o     \"others\"的简写，意思是其他所有的人。\n* a     \"all\"的简写，是\"u\", \"g\"和“o”三者的联合。\n\n如果没有指定字符，则假定使用”all”。\n执行的操作可能是一个“＋”字符，表示加上一个权限， 一个“－”，表示删掉一个权限，或者是一个“＝”，表示只有指定的权限可用，其它所有的权限被删除。\n权限由 “r”，“w”，和 “x” 来指定。\n\n要注意chmod的`\"--recursive\"`选项： 它可以同时作用于文件和目录，所以它并不是如我们期望的那么有用处，因为我们很少希望文件和 目录拥有同样的权限。\n\n## umask\n设置默认权限\n当创建一个文件时，umask 命令控制着文件的默认权限。\numask 命令使用八进制表示法来表达 从文件模式属性中删除一个位掩码。\n例如:\n```\nOriginal file mode     --- rw- rw- rw-\nMask                   000 000 010 010\nResult                 --- rw- r-- r--\n```\n\n## 一些特殊权限\n\n虽然我们通常看到一个八进制的权限掩码用三位数字来表示，但是从技术层面上来讲， 用四位数字来表示它更确切些。\n为什么呢？因为，除了读取，写入，和执行权限之外，还有 其它的，较少用到的权限设置。\n\n其中之一是 setuid 位（八进制4000)。\n当应用到一个可执行文件时，它把有效用户 ID 从真正的用户（实际运行程序的用户）设置成程序所有者的 ID。\n这种操作通常会应用到 一些由超级用户所拥有的程序。\n当一个普通用户运行一个程序，这个程序由根用户(root) 所有，并且设置了 setuid 位，这个程序运行时具有超级用户的特权，这样程序就可以 访问普通用户禁止访问的文件和目录。\n很明显，因为这会引起安全方面的问题，所有可以 设置 setuid 位的程序个数，必须控制在绝对小的范围内。\n\n第二个是 setgid 位（八进制2000），这个相似于 setuid 位，把有效用户组 ID 从真正的 用户组 ID 更改为文件所有者的组 ID。\n如果设置了一个目录的 setgid 位，则目录中新创建的文件 具有这个目录用户组的所有权，而不是文件创建者所属用户组的所有权。\n对于共享目录来说， 当一个普通用户组中的成员，需要访问共享目录中的所有文件，而不管文件所有者的主用户组时， 那么设置 setgid 位很有用处。\n\n第三个是 sticky 位（八进制1000）。这个继承于 Unix，在 Unix 中，它可能把一个可执行文件 标志为“不可交换的”。\n在 Linux 中，会忽略文件的 sticky 位，但是如果一个目录设置了 sticky 位， 那么它能阻止用户删除或重命名文件，除非用户是这个目录的所有者，或者是文件所有者，或是 超级用户。\n这个经常用来控制访问共享目录，比方说/tmp。\n\n这里有一些例子，使用 chmod 命令和符号表示法，来设置这些特殊的权限。首先， 授予一个程序 setuid 权限。\nchmod u+s program\n下一步，授予一个目录 setgid 权限：\nchmod g+s dir\n最后，授予一个目录 sticky 权限：\nchmod +t dir\n当浏览 ls 命令的输出结果时，你可以确认这些特殊权限。这里有一些例子。首先，一个程序被设置为setuid属性：\n-rwsr-xr-x\n具有 setgid 属性的目录：\ndrwxrwsr-x\n设置了 sticky 位的目录：\ndrwxrwxrwt\n\n## chown\n更改文件所有者和用户组\n\nchown参数\n* bob       把文件所有者从当前属主更改为用户 bob。\n* bob:users 把文件所有者改为用户 bob，文件用户组改为用户组 users。\n* :admins   把文件用户组改为组 admins，文件所有者不变。\n* bob:      文件所有者改为用户 bob，文件用户组改为用户 bob 登录系统时，所属的用户组。\n\n## chgrp\n更改用户组所有权\n\n## passwd [user]\n更改用户密码\n\n","source":"_posts/TLCL_notes_10.md","raw":"title: <<The Linux Command Line>> 第十章笔记 权限\ndate: 2015-09-07 20:00:10\ntags: [linux, bash]\n---\n用户帐户 定义在/etc/passwd 文件里面，用户组定义在/etc/group 文件里面。\n当用户帐户和用户组创建以后， 这些文件随着文件/etc/shadow 的变动而修改，文件/etc/shadow 包含了关于用户密码的信息。 \n对于每个用户帐号，文件/etc/passwd 定义了用户（登录）名，uid，gid，帐号的真实姓名，家目录， 和登录 shell。\n\n文件类型\n* \\-     一个普通文件\n* d     一个目录\n* l     一个符号链接。注意对于符号链接文件，剩余的文件属性总是\"rwxrwxrwx\"，而且都是 虚拟值。真正的文件属性是指符号链接所指向的文件的属性。\n* c     一个字符设备文件。这种文件类型是指按照字节流，来处理数据的设备。 比如说终端机，或者调制解调器\n* b     一个块设备文件。这种文件类型是指按照数据块，来处理数据的设备，例如一个硬盘，或者 CD-ROM 盘。\n\n## chmod\n更改文件模式\n\n八进制数字表示法 如: chmod 600 foo.txt\n符号表示法 如: u+x,go=rw     给文件拥有者执行权限并给组和其他人读和执行的权限。多种设定可以用逗号分开。\n\nchmod 命令符号表示法 \n* u     \"user\"的简写，意思是文件或目录的所有者。\n* g     用户组。\n* o     \"others\"的简写，意思是其他所有的人。\n* a     \"all\"的简写，是\"u\", \"g\"和“o”三者的联合。\n\n如果没有指定字符，则假定使用”all”。\n执行的操作可能是一个“＋”字符，表示加上一个权限， 一个“－”，表示删掉一个权限，或者是一个“＝”，表示只有指定的权限可用，其它所有的权限被删除。\n权限由 “r”，“w”，和 “x” 来指定。\n\n要注意chmod的`\"--recursive\"`选项： 它可以同时作用于文件和目录，所以它并不是如我们期望的那么有用处，因为我们很少希望文件和 目录拥有同样的权限。\n\n## umask\n设置默认权限\n当创建一个文件时，umask 命令控制着文件的默认权限。\numask 命令使用八进制表示法来表达 从文件模式属性中删除一个位掩码。\n例如:\n```\nOriginal file mode     --- rw- rw- rw-\nMask                   000 000 010 010\nResult                 --- rw- r-- r--\n```\n\n## 一些特殊权限\n\n虽然我们通常看到一个八进制的权限掩码用三位数字来表示，但是从技术层面上来讲， 用四位数字来表示它更确切些。\n为什么呢？因为，除了读取，写入，和执行权限之外，还有 其它的，较少用到的权限设置。\n\n其中之一是 setuid 位（八进制4000)。\n当应用到一个可执行文件时，它把有效用户 ID 从真正的用户（实际运行程序的用户）设置成程序所有者的 ID。\n这种操作通常会应用到 一些由超级用户所拥有的程序。\n当一个普通用户运行一个程序，这个程序由根用户(root) 所有，并且设置了 setuid 位，这个程序运行时具有超级用户的特权，这样程序就可以 访问普通用户禁止访问的文件和目录。\n很明显，因为这会引起安全方面的问题，所有可以 设置 setuid 位的程序个数，必须控制在绝对小的范围内。\n\n第二个是 setgid 位（八进制2000），这个相似于 setuid 位，把有效用户组 ID 从真正的 用户组 ID 更改为文件所有者的组 ID。\n如果设置了一个目录的 setgid 位，则目录中新创建的文件 具有这个目录用户组的所有权，而不是文件创建者所属用户组的所有权。\n对于共享目录来说， 当一个普通用户组中的成员，需要访问共享目录中的所有文件，而不管文件所有者的主用户组时， 那么设置 setgid 位很有用处。\n\n第三个是 sticky 位（八进制1000）。这个继承于 Unix，在 Unix 中，它可能把一个可执行文件 标志为“不可交换的”。\n在 Linux 中，会忽略文件的 sticky 位，但是如果一个目录设置了 sticky 位， 那么它能阻止用户删除或重命名文件，除非用户是这个目录的所有者，或者是文件所有者，或是 超级用户。\n这个经常用来控制访问共享目录，比方说/tmp。\n\n这里有一些例子，使用 chmod 命令和符号表示法，来设置这些特殊的权限。首先， 授予一个程序 setuid 权限。\nchmod u+s program\n下一步，授予一个目录 setgid 权限：\nchmod g+s dir\n最后，授予一个目录 sticky 权限：\nchmod +t dir\n当浏览 ls 命令的输出结果时，你可以确认这些特殊权限。这里有一些例子。首先，一个程序被设置为setuid属性：\n-rwsr-xr-x\n具有 setgid 属性的目录：\ndrwxrwsr-x\n设置了 sticky 位的目录：\ndrwxrwxrwt\n\n## chown\n更改文件所有者和用户组\n\nchown参数\n* bob       把文件所有者从当前属主更改为用户 bob。\n* bob:users 把文件所有者改为用户 bob，文件用户组改为用户组 users。\n* :admins   把文件用户组改为组 admins，文件所有者不变。\n* bob:      文件所有者改为用户 bob，文件用户组改为用户 bob 登录系统时，所属的用户组。\n\n## chgrp\n更改用户组所有权\n\n## passwd [user]\n更改用户密码\n\n","slug":"TLCL_notes_10","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5iq0006mcxqdvx8cyh1"},{"title":"<<The Linux Command Line>> 第十一章笔记 进程","date":"2015-09-07T12:00:11.000Z","_content":"进程是怎样工作的\n\n当系统启动的时候，内核先把一些它自己的程序初始化为进程，然后运行一个叫做 init 的程序。\ninit， 依次地，再运行一系列的称为 init 脚本的 shell 脚本（位于/etc），它们可以启动所有的系统服务。\n\n## ps命令\n\n字段含义\n* TIME 字段表示 进程所消耗的 CPU 时间数量。\n* TTY ?表示没有终端\n* USER     用户 ID. 进程的所有者。\n* %CPU     以百分比表示的 CPU 使用率\n* %MEM     以百分比表示的内存使用率\n* VSZ     虚拟内存大小\n* RSS     进程占用的物理内存的大小，以千字节为单位。\n* START     进程运行的起始时间。若超过24小时，则用天表示。\n\n进程状态\n* R     运行。这意味着，进程正在运行或准备运行。\n* S     正在睡眠。 进程没有运行，而是，正在等待一个事件， 比如说，一个按键或者网络数据包。\n* D     不可中断睡眠。进程正在等待 I/O，比方说，一个磁盘驱动器的 I/O。\n* T     已停止. 已经指示进程停止运行。稍后介绍更多。\n* Z     一个死进程或“僵尸”进程。这是一个已经终止的子进程，但是它的父进程还没有清空它。 （父进程没有把子进程从进程表中删除）\n* <     一个高优先级进程。这可能会授予一个进程更多重要的资源，给它更多的 CPU 时间。 进程的这种属性叫做 niceness。具有高优先级的进程据说是不好的（less nice）， 因为它占用了比较多的 CPU 时间，这样就给其它进程留下很少时间。\n* N     低优先级进程。 一个低优先级进程（一个“好”进程）只有当其它高优先级进程执行之后，才会得到处理器时间。\n\n## 用top命令动态查看进程\ntop 命令信息字段\n**load average:**     加载平均值是指，等待运行的进程数目，也就是说，处于运行状态的进程个数， 这些进程共享 CPU。展示了三个数值，每个数值对应不同的时间周期。第一个是最后60秒的平均值， 下一个是前5分钟的平均值，最后一个是前15分钟的平均值。若平均值低于1.0，则指示计算机 工作不忙碌。\n**Tasks:**     总结了进程数目和各种进程状态。\n**Cpu(s):**     这一行描述了 CPU 正在执行的进程的特性。\n                  0.7%us     0.7% of the CPU is being used for user processes. 这意味着进程在内核之外。\n                  1.0%sy     1.0%的 CPU 时间被用于系统（内核）进程。\n                  0.0%ni     0.0%的 CPU 时间被用于\"nice\"（低优先级）进程。\n                  98.3%id     98.3%的 CPU 时间是空闲的。\n                  0.0%wa     0.0%的 CPU 时间来等待 I/O。\n                  0.1% hi 硬中断（Hardware IRQ）占用CPU的百分比\n                  0.0% si 软中断（Software Interrupts）占用CPU的百分比\n                  0.0% st 虚拟机偷取时间,是专门对虚拟机来说的，一台物理是可以虚拟化出几台虚拟机的。在其中一台虚拟机上用top查看发现st不为0，就说明本来有这么多个cpu时间是安排给我这个虚拟机的，但是由于某种虚拟技术，把这个cpu时间分配给了其他的虚拟机了。这就叫做偷取。\n**Mem:**     展示物理内存的使用情况。\n**Swap:**     展示交换分区（虚拟内存）的使用情况。\n\nh 帮助\nq 退出\n\n## jobs\n&可以在后台执行\n\n## fg %1\n## bg %1\n\n## kill\n常用信号\n* 1     HUP     挂起。这是美好往昔的痕迹，那时候终端机通过电话线和调制解调器连接到 远端的计算机。这个信号被用来告诉程序，控制的终端机已经“挂起”。 通过关闭一个终端会话，可以说明这个信号的作用。发送这个信号到终端机上的前台程序，程序会终止。\n* 许多守护进程也使用这个信号，来重新初始化。这意味着，当发送这个信号到一个守护进程后， 这个进程会重新启动，并且重新读取它的配置文件。Apache 网络服务器守护进程就是一个例子。\n* 2     INT     中断。实现和 Ctrl-c 一样的功能，由终端发送。通常，它会终止一个程序。\n* 9     KILL     杀死。这个信号很特别。鉴于进程可能会选择不同的方式，来处理发送给它的 信号，其中也包含忽略信号，这样呢，从不发送 Kill 信号到目标进程。而是内核立即终止 这个进程。当一个进程以这种方式终止的时候，它没有机会去做些“清理”工作，或者是保存劳动成果。 因为这个原因，把 KILL 信号看作杀手锏，当其它终止信号失败后，再使用它。\n* 15     TERM     终止。这是 kill 命令发送的默认信号。如果程序仍然“活着”，可以接受信号，那么 这个信号终止。\n* 18     CONT     继续。在停止一段时间后，进程恢复运行。\n* 19     STOP     停止。这个信号导致进程停止运行，而没有终止。像 KILL 信号，它不被 发送到目标进程，因此它不能被忽略。\n* 3     QUIT     退出\n* 11     SEGV     段错误。如果一个程序非法使用内存，就会发送这个信号。也就是说， 程序试图写入内存，而这个内存空间是不允许此程序写入的。\n* 20     TSTP     终端停止。当按下 Ctrl-z 组合键后，终端发送这个信号。不像 STOP 信号， TSTP 信号由目标进程接收，且可能被忽略。\n* 28     WINCH     改变窗口大小。当改变窗口大小时，系统会发送这个信号。 一些程序，像 top 和 less 程序会响应这个信号，按照新窗口的尺寸，刷新显示的内容。\n\nkill -l 可以得到一个完整的信号列表\n\n## killall\n给多个进程发送信号\n也有可能通过 killall 命令，给匹配特定程序或用户名的多个进程发送信号。\n\n## 其它与进程相关的命令\npstree     输出一个树型结构的进程列表，这个列表展示了进程间父/子关系。\nvmstat     输出一个系统资源使用快照，包括内存，交换分区和磁盘 I/O。 为了看到连续的显示结果，则在命令名后加上延时的时间（以秒为单位）。例如，“vmstat 5”。 终止输出，按下 Ctrl-c 组合键。\nxload      一个图形界面程序，可以画出系统负载的图形。\ntload      与 xload 程序相似，但是在终端中画出图形。使用 Ctrl-c，来终止输出。\n\n","source":"_posts/TLCL_notes_11.md","raw":"title: <<The Linux Command Line>> 第十一章笔记 进程\ndate: 2015-09-07 20:00:11\ntags: [linux, bash]\n---\n进程是怎样工作的\n\n当系统启动的时候，内核先把一些它自己的程序初始化为进程，然后运行一个叫做 init 的程序。\ninit， 依次地，再运行一系列的称为 init 脚本的 shell 脚本（位于/etc），它们可以启动所有的系统服务。\n\n## ps命令\n\n字段含义\n* TIME 字段表示 进程所消耗的 CPU 时间数量。\n* TTY ?表示没有终端\n* USER     用户 ID. 进程的所有者。\n* %CPU     以百分比表示的 CPU 使用率\n* %MEM     以百分比表示的内存使用率\n* VSZ     虚拟内存大小\n* RSS     进程占用的物理内存的大小，以千字节为单位。\n* START     进程运行的起始时间。若超过24小时，则用天表示。\n\n进程状态\n* R     运行。这意味着，进程正在运行或准备运行。\n* S     正在睡眠。 进程没有运行，而是，正在等待一个事件， 比如说，一个按键或者网络数据包。\n* D     不可中断睡眠。进程正在等待 I/O，比方说，一个磁盘驱动器的 I/O。\n* T     已停止. 已经指示进程停止运行。稍后介绍更多。\n* Z     一个死进程或“僵尸”进程。这是一个已经终止的子进程，但是它的父进程还没有清空它。 （父进程没有把子进程从进程表中删除）\n* <     一个高优先级进程。这可能会授予一个进程更多重要的资源，给它更多的 CPU 时间。 进程的这种属性叫做 niceness。具有高优先级的进程据说是不好的（less nice）， 因为它占用了比较多的 CPU 时间，这样就给其它进程留下很少时间。\n* N     低优先级进程。 一个低优先级进程（一个“好”进程）只有当其它高优先级进程执行之后，才会得到处理器时间。\n\n## 用top命令动态查看进程\ntop 命令信息字段\n**load average:**     加载平均值是指，等待运行的进程数目，也就是说，处于运行状态的进程个数， 这些进程共享 CPU。展示了三个数值，每个数值对应不同的时间周期。第一个是最后60秒的平均值， 下一个是前5分钟的平均值，最后一个是前15分钟的平均值。若平均值低于1.0，则指示计算机 工作不忙碌。\n**Tasks:**     总结了进程数目和各种进程状态。\n**Cpu(s):**     这一行描述了 CPU 正在执行的进程的特性。\n                  0.7%us     0.7% of the CPU is being used for user processes. 这意味着进程在内核之外。\n                  1.0%sy     1.0%的 CPU 时间被用于系统（内核）进程。\n                  0.0%ni     0.0%的 CPU 时间被用于\"nice\"（低优先级）进程。\n                  98.3%id     98.3%的 CPU 时间是空闲的。\n                  0.0%wa     0.0%的 CPU 时间来等待 I/O。\n                  0.1% hi 硬中断（Hardware IRQ）占用CPU的百分比\n                  0.0% si 软中断（Software Interrupts）占用CPU的百分比\n                  0.0% st 虚拟机偷取时间,是专门对虚拟机来说的，一台物理是可以虚拟化出几台虚拟机的。在其中一台虚拟机上用top查看发现st不为0，就说明本来有这么多个cpu时间是安排给我这个虚拟机的，但是由于某种虚拟技术，把这个cpu时间分配给了其他的虚拟机了。这就叫做偷取。\n**Mem:**     展示物理内存的使用情况。\n**Swap:**     展示交换分区（虚拟内存）的使用情况。\n\nh 帮助\nq 退出\n\n## jobs\n&可以在后台执行\n\n## fg %1\n## bg %1\n\n## kill\n常用信号\n* 1     HUP     挂起。这是美好往昔的痕迹，那时候终端机通过电话线和调制解调器连接到 远端的计算机。这个信号被用来告诉程序，控制的终端机已经“挂起”。 通过关闭一个终端会话，可以说明这个信号的作用。发送这个信号到终端机上的前台程序，程序会终止。\n* 许多守护进程也使用这个信号，来重新初始化。这意味着，当发送这个信号到一个守护进程后， 这个进程会重新启动，并且重新读取它的配置文件。Apache 网络服务器守护进程就是一个例子。\n* 2     INT     中断。实现和 Ctrl-c 一样的功能，由终端发送。通常，它会终止一个程序。\n* 9     KILL     杀死。这个信号很特别。鉴于进程可能会选择不同的方式，来处理发送给它的 信号，其中也包含忽略信号，这样呢，从不发送 Kill 信号到目标进程。而是内核立即终止 这个进程。当一个进程以这种方式终止的时候，它没有机会去做些“清理”工作，或者是保存劳动成果。 因为这个原因，把 KILL 信号看作杀手锏，当其它终止信号失败后，再使用它。\n* 15     TERM     终止。这是 kill 命令发送的默认信号。如果程序仍然“活着”，可以接受信号，那么 这个信号终止。\n* 18     CONT     继续。在停止一段时间后，进程恢复运行。\n* 19     STOP     停止。这个信号导致进程停止运行，而没有终止。像 KILL 信号，它不被 发送到目标进程，因此它不能被忽略。\n* 3     QUIT     退出\n* 11     SEGV     段错误。如果一个程序非法使用内存，就会发送这个信号。也就是说， 程序试图写入内存，而这个内存空间是不允许此程序写入的。\n* 20     TSTP     终端停止。当按下 Ctrl-z 组合键后，终端发送这个信号。不像 STOP 信号， TSTP 信号由目标进程接收，且可能被忽略。\n* 28     WINCH     改变窗口大小。当改变窗口大小时，系统会发送这个信号。 一些程序，像 top 和 less 程序会响应这个信号，按照新窗口的尺寸，刷新显示的内容。\n\nkill -l 可以得到一个完整的信号列表\n\n## killall\n给多个进程发送信号\n也有可能通过 killall 命令，给匹配特定程序或用户名的多个进程发送信号。\n\n## 其它与进程相关的命令\npstree     输出一个树型结构的进程列表，这个列表展示了进程间父/子关系。\nvmstat     输出一个系统资源使用快照，包括内存，交换分区和磁盘 I/O。 为了看到连续的显示结果，则在命令名后加上延时的时间（以秒为单位）。例如，“vmstat 5”。 终止输出，按下 Ctrl-c 组合键。\nxload      一个图形界面程序，可以画出系统负载的图形。\ntload      与 xload 程序相似，但是在终端中画出图形。使用 Ctrl-c，来终止输出。\n\n","slug":"TLCL_notes_11","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5it0009mcxqp3j4jybg"},{"title":"<<The Linux Command Line>> 第十四章笔记 自定义shell提示符","date":"2015-09-07T12:00:14.000Z","_content":"## Shell 提示符中用到的转义字符\n* \\\\a     以 ASCII 格式编码的铃声 . 当遇到这个转义序列时，计算机会发出嗡嗡的响声。\n* \\\\d     以日，月，天格式来表示当前日期。例如，“Mon May 26.”\n* \\\\h     本地机的主机名，但不带末尾的域名。\n* \\\\H     完整的主机名。\n* \\\\j     运行在当前 shell 会话中的工作数。\n* \\\\l     当前终端设备名。\n* \\\\n     一个换行符。\n* \\\\r     一个回车符。\n* \\\\s     shell 程序名。\n* \\\\t     以24小时制，hours:minutes:seconds 的格式表示当前时间.\n* \\\\T     以12小时制表示当前时间。\n* \\\\@     以12小时制，AM/PM 格式来表示当前时间。\n* \\\\A     以24小时制，hours:minutes 格式表示当前时间。\n* \\\\u     当前用户名。\n* \\\\v     shell 程序的版本号。\n* \\\\V     Version and release numbers of the shell.\n* \\\\w     当前工作目录名。\n* \\\\W     当前工作目录名的最后部分。\n* \\\\!     当前命令的历史号。\n* \\\\#     当前 shell 会话中的命令数。\n* \\\\\\$    这会显示一个\"$\"字符，除非你拥有超级用户权限。在那种情况下， 它会显示一个\"#\"字符。\n* \\\\[     标志着一系列一个或多个非打印字符的开始。这被用来嵌入非打印 的控制字符，这些字符以某种方式来操作终端仿真器，比方说移动光标或者是更改文本颜色。\n* \\\\]     标志着非打印字符序列结束\n\n## 用转义序列来设置文本颜色\n* \\033[0;30m     黑色     \\033[1;30m     深灰色\n* \\033[0;31m     红色     \\033[1;31m     浅红色\n* \\033[0;32m     绿色     \\033[1;32m     浅绿色\n* \\033[0;33m     棕色     \\033[1;33m     黄色\n* \\033[0;34m     蓝色     \\033[1;34m     浅蓝色\n* \\033[0;35m     粉红     \\033[1;35m     浅粉色\n* \\033[0;36m     青色     \\033[1;36m     浅青色\n* \\033[0;37m     浅灰色   \\033[1;37m     白色\n\n## 用转义序列来设置背景颜色\n* \\033[0;40m     蓝色     \\033[1;44m     黑色\n* \\033[0;41m     红色     \\033[1;45m     粉红\n* \\033[0;42m     绿色     \\033[1;46m     青色\n* \\033[0;43m     棕色     \\033[1;47m     浅灰色\n\n例: PS1='\\[\\033[0;31m\\]<\\u@\\h \\W>\\$\\[\\033[0m\\]'\n\n注意：除了正常的 (0) 和黑体 (1) 字符属性之外，文本也可以具有下划线 (4)，闪烁 (5)等属性。\n为了拥有好品味，许多终端仿真器拒绝使用这个闪烁属性。\n\n## 光标移动转义序列\n* \\033[l;cH  把光标移到第 l 行，第 c 列。\n* \\033[nA    把光标向上移动 n 行。\n* \\033[nB    把光标向下移动 n 行。\n* \\033[nC    把光标向前移动 n 个字符。\n* \\033[nD    把光标向后移动 n 个字符。\n* \\033[2J    清空屏幕，把光标移到左上角（第零行，第零列）。\n* \\033[K     清空从光标位置到当前行末的内容。\n* \\033[s     存储当前光标位置。\n* \\033[u     唤醒之前存储的光标位置。\n\n例:\nPS1='\\[\\033[s\\033[0;0H\\033[0;41m\\033[K\\033[1;33m\\t\\033[0m\\033[u\\]<\\u@\\h \\W>\\$ '\n每次当这个提示符出现的时候，会在屏幕的上方画出一个 包含时钟（由黄色文本渲染）的红色长条。\n\n","source":"_posts/TLCL_notes_14.md","raw":"title: <<The Linux Command Line>> 第十四章笔记 自定义shell提示符\ndate: 2015-09-07 20:00:14\ntags: [linux, bash]\n---\n## Shell 提示符中用到的转义字符\n* \\\\a     以 ASCII 格式编码的铃声 . 当遇到这个转义序列时，计算机会发出嗡嗡的响声。\n* \\\\d     以日，月，天格式来表示当前日期。例如，“Mon May 26.”\n* \\\\h     本地机的主机名，但不带末尾的域名。\n* \\\\H     完整的主机名。\n* \\\\j     运行在当前 shell 会话中的工作数。\n* \\\\l     当前终端设备名。\n* \\\\n     一个换行符。\n* \\\\r     一个回车符。\n* \\\\s     shell 程序名。\n* \\\\t     以24小时制，hours:minutes:seconds 的格式表示当前时间.\n* \\\\T     以12小时制表示当前时间。\n* \\\\@     以12小时制，AM/PM 格式来表示当前时间。\n* \\\\A     以24小时制，hours:minutes 格式表示当前时间。\n* \\\\u     当前用户名。\n* \\\\v     shell 程序的版本号。\n* \\\\V     Version and release numbers of the shell.\n* \\\\w     当前工作目录名。\n* \\\\W     当前工作目录名的最后部分。\n* \\\\!     当前命令的历史号。\n* \\\\#     当前 shell 会话中的命令数。\n* \\\\\\$    这会显示一个\"$\"字符，除非你拥有超级用户权限。在那种情况下， 它会显示一个\"#\"字符。\n* \\\\[     标志着一系列一个或多个非打印字符的开始。这被用来嵌入非打印 的控制字符，这些字符以某种方式来操作终端仿真器，比方说移动光标或者是更改文本颜色。\n* \\\\]     标志着非打印字符序列结束\n\n## 用转义序列来设置文本颜色\n* \\033[0;30m     黑色     \\033[1;30m     深灰色\n* \\033[0;31m     红色     \\033[1;31m     浅红色\n* \\033[0;32m     绿色     \\033[1;32m     浅绿色\n* \\033[0;33m     棕色     \\033[1;33m     黄色\n* \\033[0;34m     蓝色     \\033[1;34m     浅蓝色\n* \\033[0;35m     粉红     \\033[1;35m     浅粉色\n* \\033[0;36m     青色     \\033[1;36m     浅青色\n* \\033[0;37m     浅灰色   \\033[1;37m     白色\n\n## 用转义序列来设置背景颜色\n* \\033[0;40m     蓝色     \\033[1;44m     黑色\n* \\033[0;41m     红色     \\033[1;45m     粉红\n* \\033[0;42m     绿色     \\033[1;46m     青色\n* \\033[0;43m     棕色     \\033[1;47m     浅灰色\n\n例: PS1='\\[\\033[0;31m\\]<\\u@\\h \\W>\\$\\[\\033[0m\\]'\n\n注意：除了正常的 (0) 和黑体 (1) 字符属性之外，文本也可以具有下划线 (4)，闪烁 (5)等属性。\n为了拥有好品味，许多终端仿真器拒绝使用这个闪烁属性。\n\n## 光标移动转义序列\n* \\033[l;cH  把光标移到第 l 行，第 c 列。\n* \\033[nA    把光标向上移动 n 行。\n* \\033[nB    把光标向下移动 n 行。\n* \\033[nC    把光标向前移动 n 个字符。\n* \\033[nD    把光标向后移动 n 个字符。\n* \\033[2J    清空屏幕，把光标移到左上角（第零行，第零列）。\n* \\033[K     清空从光标位置到当前行末的内容。\n* \\033[s     存储当前光标位置。\n* \\033[u     唤醒之前存储的光标位置。\n\n例:\nPS1='\\[\\033[s\\033[0;0H\\033[0;41m\\033[K\\033[1;33m\\t\\033[0m\\033[u\\]<\\u@\\h \\W>\\$ '\n每次当这个提示符出现的时候，会在屏幕的上方画出一个 包含时钟（由黄色文本渲染）的红色长条。\n\n","slug":"TLCL_notes_14","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5iu000amcxqn278qsts"},{"title":"<<The Linux Command Line>> 第十二章笔记 shell 环境","date":"2015-09-07T12:00:12.000Z","_content":"## set & printenv\nset 命令可以 显示 shell 和环境变量两者且按字母顺序排列，而 printenv 只是显示环境变量。\nprintenv | less\nprintenv USER\n\n## alias\n查看所有别名\n\n## 登录 shell 会话的启动文件\n* /etc/profile     应用于所有用户的全局配置脚本。\n* ~/.bash_profile  用户私人的启动文件。可以用来扩展或重写全局配置脚本中的设置。\n* ~/.bash_login    如果文件 ~/.bash_profile 没有找到，bash 会尝试读取这个脚本。\n* ~/.profile       如果文件 ~/.bash_profile 或文件 ~/.bash_login 都没有找到，bash 会试图读取这个文件。 这是基于 Debian 发行版的默认设置，比方说 Ubuntu。\n\n## 非登录 shell 会话的启动文件\n* /etc/bash.bashrc 应用于所有用户的全局配置文件。\n* ~/.bashrc        用户私有的启动文件。可以用来扩展或重写全局配置脚本中的设置。\n\n","source":"_posts/TLCL_notes_12.md","raw":"title: <<The Linux Command Line>> 第十二章笔记 shell 环境\ndate: 2015-09-07 20:00:12\ntags: [linux, bash]\n---\n## set & printenv\nset 命令可以 显示 shell 和环境变量两者且按字母顺序排列，而 printenv 只是显示环境变量。\nprintenv | less\nprintenv USER\n\n## alias\n查看所有别名\n\n## 登录 shell 会话的启动文件\n* /etc/profile     应用于所有用户的全局配置脚本。\n* ~/.bash_profile  用户私人的启动文件。可以用来扩展或重写全局配置脚本中的设置。\n* ~/.bash_login    如果文件 ~/.bash_profile 没有找到，bash 会尝试读取这个脚本。\n* ~/.profile       如果文件 ~/.bash_profile 或文件 ~/.bash_login 都没有找到，bash 会试图读取这个文件。 这是基于 Debian 发行版的默认设置，比方说 Ubuntu。\n\n## 非登录 shell 会话的启动文件\n* /etc/bash.bashrc 应用于所有用户的全局配置文件。\n* ~/.bashrc        用户私有的启动文件。可以用来扩展或重写全局配置脚本中的设置。\n\n","slug":"TLCL_notes_12","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5iw000dmcxqqt6f3ae3"},{"title":"<<The Linux Command Line>> 第十五章笔记 软件包管理","date":"2015-09-07T12:00:15.000Z","_content":"\n## 通过软件包文件来安装软件\n```\ndpkg --install package_file\n```\n\n## 列出所安装的软件包\n```\ndpkg --list\n```\n\n## 确定是否安装了一个软件包\n```\ndpkg --status package_name\n```\n\n## 显示所安装软件包的信息\n```\napt-cache show package_name\n```\n\n## 查找安装了某个文件的软件包\n```\ndpkg --search file_name\n```\n\n","source":"_posts/TLCL_notes_15.md","raw":"title: <<The Linux Command Line>> 第十五章笔记 软件包管理\ndate: 2015-09-07 20:00:15\ntags: [linux, bash]\n---\n\n## 通过软件包文件来安装软件\n```\ndpkg --install package_file\n```\n\n## 列出所安装的软件包\n```\ndpkg --list\n```\n\n## 确定是否安装了一个软件包\n```\ndpkg --status package_name\n```\n\n## 显示所安装软件包的信息\n```\napt-cache show package_name\n```\n\n## 查找安装了某个文件的软件包\n```\ndpkg --search file_name\n```\n\n","slug":"TLCL_notes_15","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ix000emcxqwqah24dp"},{"title":"<<The Linux Command Line>> 第十六章笔记 存储媒介","date":"2015-09-07T12:00:16.000Z","_content":"## /etc/fstab\n/etc/fstab 的文件可以列出系统启动时要挂载的设备（典型地，硬盘分区）\n/etc/fstab 字段\n* 设备名     传统上，这个字段包含与物理设备相关联的设备文件的实际名字，比如说/dev/hda1（第一个 IDE 通道上第一个主设备分区）。然而今天的计算机，有很多热插拔设备（像 USB 驱动设备），许多 现代的 Linux 发行版用一个文本标签和设备相关联。当这个设备连接到系统中时， 这个标签（当储存媒介格式化时，这个标签会被添加到存储媒介中）会被操作系统读取。 那样的话，不管赋给实际物理设备哪个设备文件，这个设备仍然能被系统正确地识别。\n* 挂载点     设备所连接到的文件系统树的目录。\n* 文件系统类型     Linux 允许挂载许多文件系统类型。大多数本地的 Linux 文件系统是 ext3， 但是也支持很多其它的，比方说 FAT16 (msdos), FAT32 (vfat)，NTFS (ntfs)，CD-ROM (iso9660)，等等。\n* 选项     文件系统可以通过各种各样的选项来挂载。有可能，例如，挂载只读的文件系统， 或者挂载阻止执行任何程序的文件系统（一个有用的安全特性，避免删除媒介。）\n* 频率     一位数字，指定是否和在什么时间用 dump 命令来备份一个文件系统。\n* 次序     一位数字，指定 fsck 命令按照什么次序来检查文件系统。\n\n## mount & umount\n用来挂载文件系统。执行这个不带参数的命令，将会显示 一系列当前挂载的文件系统\n\n一个挂载点就是文件系统树中的一个目录。它没有 什么特殊的。\n它甚至不必是一个空目录，即使你把设备挂载到了一个非空目录上，你也不能看到 这个目录中原来的内容，直到你卸载这个设备。\n\n我们不能卸载一个设备，如果某个用户或进程正在使用这个设备的话。\n在这种 情况下，我们把工作目录更改到了 CD-ROW 的挂载点，这个挂载点导致设备忙碌。\n我们可以很容易地修复这个问题 通过把工作目录改到其它目录而不是这个挂载点。\numount很重要,如果不umount可能会丢失缓冲区中的暂未发往设备的数据\n\n## Linux 存储设备名称\n* /dev/fd*     软盘驱动器\n* /dev/hd*     老系统中的 IDE(PATA)磁盘。典型的主板包含两个 IDE 连接器或者是通道，每个连接器 带有一根缆线，每根缆线上有两个硬盘驱动器连接点。缆线上的第一个驱动器叫做主设备， 第二个叫做从设备。\n* 设备名称这样安排，/dev/hda 是指第一通道上的主设备名；/dev/hdb 是第一通道上的从设备名；/dev/hdc 是第二通道上的主设备名，等等。末尾的数字表示 硬盘驱动器上的分区。例如，/dev/hda1是指系统中第一硬盘驱动器上的第一个分区，而 /dev/hda 则是指整个硬盘驱动器。\n* /dev/lp*     打印机\n* /dev/sd*     SCSI 磁盘。在最近的 Linux 系统中，内核把所有类似于磁盘的设备（包括 PATA/SATA 硬盘， 闪存，和 USB 存储设备，比如说可移动的音乐播放器和数码相机）看作 SCSI 磁盘。 剩下的命名系统类似于上述所描述的旧的/dev/hd*命名方案。\n* /dev/sr*     光盘（CD/DVD 读取器和烧写器）\n\n## fsck\n除了检查文件系统的完整性之外，fsck 还能修复受损的文件系统，其成功度依赖于损坏的数量。 \n在类 Unix 的文件系统中，文件恢复的部分被放置于 lost+found 目录里面，位于每个文件 系统的根目录下面。\n\n## dd\n直接把数据移入/出设备\n把第一个驱动器中的所有数据复制到第二个 驱动器中\ndd if=/dev/sdb of=/dev/sdc\n如果只有第一个驱动器被连接到计算机上，我们可以把它的内容复制到一个普通文件中供 以后恢复或复制数据\ndd if=/dev/sdb of=flash_drive.img\n警告！这个 dd 命令非常强大。虽然它的名字来自于“数据定义”，有时候也把它叫做“清除磁盘” 因为用户经常会误输入 if 或 of 的规范。在按下回车键之前，要再三检查输入与输出规范！\n\n通过CD-ROM制作iso\ndd if=/dev/cdrom of=ubuntu.iso\n这项技术也适用于 DVD 光盘，但是不能用于音频 CD，因为它们不使用文件系统来存储数据。 对于音频 CD，看一下 cdrdao 命令。\n\n## genisoimage \n创建一个包含目录内容的 iso 映像文件，我们使用 genisoimage 程序。\n为此，我们首先创建 一个目录，这个目录中包含了要包括到此映像中的所有文件，然后执行这个 genisoimage 命令 来创建映像文件。\n例如，如果我们已经创建一个叫做~/cd-rom-files 的目录，然后用文件 填充此目录，再通过下面的命令来创建一个叫做 cd-rom.iso 映像文件：\ngenisoimage -o cd-rom.iso -R -J ~/cd-rom-files\n“-R”选项添加元数据为 Rock Ridge 扩展，这允许使用长文件名和 POSIX 风格的文件权限。 \n同样地，这个”-J”选项使 Joliet 扩展生效，这样 Windows 中就支持长文件名了。\n\n## 直接挂载一个 ISO 镜像\n有一个诀窍，我们可以用它来挂载 iso 映像文件，虽然此文件仍然在我们的硬盘中，但我们 当作它已经在光盘中了。\n添加 “-o loop” 选项来挂载（同时带有必需的 “-t iso9660” 文件系统类型）， 挂载这个映像文件就好像它是一台设备，把它连接到文件系统树上：\nmkdir /mnt/iso_image\nmount -t iso9660 -o loop image.iso /mnt/iso_image\n\n## wodim \n清除一张可重写入的 CD-ROM\n可重写入的 CD-RW 媒介在被重使用之前需要擦除或清空。\n为此，我们可以用 wodim 命令，指定 设备名称和清空的类型。此 wodim 程序提供了几种清空类型。最小（且最快）的是 “fast” 类型：\nwodim dev=/dev/cdrw blank=fast\n\n写入一个映像文件，我们再次使用 wodim 命令，指定光盘设备名称和映像文件名：\nwodim dev=/dev/cdrw image.iso\n\n## md5sum检验完整性\n一个以 disk-at-once 模式写入的 CD-R，可以用下面的方式检验完整性\nmd5sum /dev/cdrom\n34e354760f9bb7fbf85c96f6a3f94ece    /dev/cdrom\n与iso文件的md5sum对比即可\n\n","source":"_posts/TLCL_notes_16.md","raw":"title: <<The Linux Command Line>> 第十六章笔记 存储媒介\ndate: 2015-09-07 20:00:16\ntags: [linux, bash]\n---\n## /etc/fstab\n/etc/fstab 的文件可以列出系统启动时要挂载的设备（典型地，硬盘分区）\n/etc/fstab 字段\n* 设备名     传统上，这个字段包含与物理设备相关联的设备文件的实际名字，比如说/dev/hda1（第一个 IDE 通道上第一个主设备分区）。然而今天的计算机，有很多热插拔设备（像 USB 驱动设备），许多 现代的 Linux 发行版用一个文本标签和设备相关联。当这个设备连接到系统中时， 这个标签（当储存媒介格式化时，这个标签会被添加到存储媒介中）会被操作系统读取。 那样的话，不管赋给实际物理设备哪个设备文件，这个设备仍然能被系统正确地识别。\n* 挂载点     设备所连接到的文件系统树的目录。\n* 文件系统类型     Linux 允许挂载许多文件系统类型。大多数本地的 Linux 文件系统是 ext3， 但是也支持很多其它的，比方说 FAT16 (msdos), FAT32 (vfat)，NTFS (ntfs)，CD-ROM (iso9660)，等等。\n* 选项     文件系统可以通过各种各样的选项来挂载。有可能，例如，挂载只读的文件系统， 或者挂载阻止执行任何程序的文件系统（一个有用的安全特性，避免删除媒介。）\n* 频率     一位数字，指定是否和在什么时间用 dump 命令来备份一个文件系统。\n* 次序     一位数字，指定 fsck 命令按照什么次序来检查文件系统。\n\n## mount & umount\n用来挂载文件系统。执行这个不带参数的命令，将会显示 一系列当前挂载的文件系统\n\n一个挂载点就是文件系统树中的一个目录。它没有 什么特殊的。\n它甚至不必是一个空目录，即使你把设备挂载到了一个非空目录上，你也不能看到 这个目录中原来的内容，直到你卸载这个设备。\n\n我们不能卸载一个设备，如果某个用户或进程正在使用这个设备的话。\n在这种 情况下，我们把工作目录更改到了 CD-ROW 的挂载点，这个挂载点导致设备忙碌。\n我们可以很容易地修复这个问题 通过把工作目录改到其它目录而不是这个挂载点。\numount很重要,如果不umount可能会丢失缓冲区中的暂未发往设备的数据\n\n## Linux 存储设备名称\n* /dev/fd*     软盘驱动器\n* /dev/hd*     老系统中的 IDE(PATA)磁盘。典型的主板包含两个 IDE 连接器或者是通道，每个连接器 带有一根缆线，每根缆线上有两个硬盘驱动器连接点。缆线上的第一个驱动器叫做主设备， 第二个叫做从设备。\n* 设备名称这样安排，/dev/hda 是指第一通道上的主设备名；/dev/hdb 是第一通道上的从设备名；/dev/hdc 是第二通道上的主设备名，等等。末尾的数字表示 硬盘驱动器上的分区。例如，/dev/hda1是指系统中第一硬盘驱动器上的第一个分区，而 /dev/hda 则是指整个硬盘驱动器。\n* /dev/lp*     打印机\n* /dev/sd*     SCSI 磁盘。在最近的 Linux 系统中，内核把所有类似于磁盘的设备（包括 PATA/SATA 硬盘， 闪存，和 USB 存储设备，比如说可移动的音乐播放器和数码相机）看作 SCSI 磁盘。 剩下的命名系统类似于上述所描述的旧的/dev/hd*命名方案。\n* /dev/sr*     光盘（CD/DVD 读取器和烧写器）\n\n## fsck\n除了检查文件系统的完整性之外，fsck 还能修复受损的文件系统，其成功度依赖于损坏的数量。 \n在类 Unix 的文件系统中，文件恢复的部分被放置于 lost+found 目录里面，位于每个文件 系统的根目录下面。\n\n## dd\n直接把数据移入/出设备\n把第一个驱动器中的所有数据复制到第二个 驱动器中\ndd if=/dev/sdb of=/dev/sdc\n如果只有第一个驱动器被连接到计算机上，我们可以把它的内容复制到一个普通文件中供 以后恢复或复制数据\ndd if=/dev/sdb of=flash_drive.img\n警告！这个 dd 命令非常强大。虽然它的名字来自于“数据定义”，有时候也把它叫做“清除磁盘” 因为用户经常会误输入 if 或 of 的规范。在按下回车键之前，要再三检查输入与输出规范！\n\n通过CD-ROM制作iso\ndd if=/dev/cdrom of=ubuntu.iso\n这项技术也适用于 DVD 光盘，但是不能用于音频 CD，因为它们不使用文件系统来存储数据。 对于音频 CD，看一下 cdrdao 命令。\n\n## genisoimage \n创建一个包含目录内容的 iso 映像文件，我们使用 genisoimage 程序。\n为此，我们首先创建 一个目录，这个目录中包含了要包括到此映像中的所有文件，然后执行这个 genisoimage 命令 来创建映像文件。\n例如，如果我们已经创建一个叫做~/cd-rom-files 的目录，然后用文件 填充此目录，再通过下面的命令来创建一个叫做 cd-rom.iso 映像文件：\ngenisoimage -o cd-rom.iso -R -J ~/cd-rom-files\n“-R”选项添加元数据为 Rock Ridge 扩展，这允许使用长文件名和 POSIX 风格的文件权限。 \n同样地，这个”-J”选项使 Joliet 扩展生效，这样 Windows 中就支持长文件名了。\n\n## 直接挂载一个 ISO 镜像\n有一个诀窍，我们可以用它来挂载 iso 映像文件，虽然此文件仍然在我们的硬盘中，但我们 当作它已经在光盘中了。\n添加 “-o loop” 选项来挂载（同时带有必需的 “-t iso9660” 文件系统类型）， 挂载这个映像文件就好像它是一台设备，把它连接到文件系统树上：\nmkdir /mnt/iso_image\nmount -t iso9660 -o loop image.iso /mnt/iso_image\n\n## wodim \n清除一张可重写入的 CD-ROM\n可重写入的 CD-RW 媒介在被重使用之前需要擦除或清空。\n为此，我们可以用 wodim 命令，指定 设备名称和清空的类型。此 wodim 程序提供了几种清空类型。最小（且最快）的是 “fast” 类型：\nwodim dev=/dev/cdrw blank=fast\n\n写入一个映像文件，我们再次使用 wodim 命令，指定光盘设备名称和映像文件名：\nwodim dev=/dev/cdrw image.iso\n\n## md5sum检验完整性\n一个以 disk-at-once 模式写入的 CD-R，可以用下面的方式检验完整性\nmd5sum /dev/cdrom\n34e354760f9bb7fbf85c96f6a3f94ece    /dev/cdrom\n与iso文件的md5sum对比即可\n\n","slug":"TLCL_notes_16","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5iz000gmcxqpzcs28bj"},{"title":"<<The Linux Command Line>> 第十八章笔记 查找文件","date":"2015-09-07T12:00:18.000Z","_content":"## locate & updatedb \n数据库由另一个叫做 updatedb 的程序创建\n\n## find\n添加测试条件-type d 限制了只搜索目录。-type f 限制只搜索文件, -size 指定大小\n```\nfind ~ -type f -name \"\\*.JPG\" -size +1M | wc -l\n```\nfind命令的预定义操作例如-delete,一定要放到末尾,否则可能会有灾难性后果,因为可能测试(如-type, -name)还没做就删除了\n-ok参数可以在执行前询问用户是否确认\n```\nfind ~ -type f -name 'foo*' -exec ls -l '{}' +\n```\n### 处理古怪的文件名\n类 Unix 的系统允许在文件名中嵌入空格（甚至换行符）。\n这就给一些程序，如为其它 程序构建参数列表的 xargs 程序，造成了问题。\n一个嵌入的空格会被看作是一个界定符，生成的 命令会把每个空格分离的单词解释为单独的参数。\n为了解决这个问题，find 命令和 xarg 程序 允许可选择的使用一个 null 字符作为参数分隔符。\n一个 null 字符被定义在 ASCII 码中，由数字 零来表示（相反的，例如，空格字符在 ASCII 码中由数字32表示）。\nfind 命令提供的 -print0 行为， 则会产生由 null 字符分离的输出，并且 xargs 命令有一个 –null 选项，这个选项会接受由 null 字符 分离的输入。\n这里有一个例子：\n```\nfind ~ -iname ‘*.jpg’ -print0 | xargs –null ls -l\n```\n使用这项技术，我们可以保证所有文件，甚至那些文件名中包含空格的文件，都能被正确地处理。\n                \n## stat命令\n显示文件详细信息\n\n","source":"_posts/TLCL_notes_18.md","raw":"title: <<The Linux Command Line>> 第十八章笔记 查找文件\ndate: 2015-09-07 20:00:18\ntags: [linux, bash]\n---\n## locate & updatedb \n数据库由另一个叫做 updatedb 的程序创建\n\n## find\n添加测试条件-type d 限制了只搜索目录。-type f 限制只搜索文件, -size 指定大小\n```\nfind ~ -type f -name \"\\*.JPG\" -size +1M | wc -l\n```\nfind命令的预定义操作例如-delete,一定要放到末尾,否则可能会有灾难性后果,因为可能测试(如-type, -name)还没做就删除了\n-ok参数可以在执行前询问用户是否确认\n```\nfind ~ -type f -name 'foo*' -exec ls -l '{}' +\n```\n### 处理古怪的文件名\n类 Unix 的系统允许在文件名中嵌入空格（甚至换行符）。\n这就给一些程序，如为其它 程序构建参数列表的 xargs 程序，造成了问题。\n一个嵌入的空格会被看作是一个界定符，生成的 命令会把每个空格分离的单词解释为单独的参数。\n为了解决这个问题，find 命令和 xarg 程序 允许可选择的使用一个 null 字符作为参数分隔符。\n一个 null 字符被定义在 ASCII 码中，由数字 零来表示（相反的，例如，空格字符在 ASCII 码中由数字32表示）。\nfind 命令提供的 -print0 行为， 则会产生由 null 字符分离的输出，并且 xargs 命令有一个 –null 选项，这个选项会接受由 null 字符 分离的输入。\n这里有一个例子：\n```\nfind ~ -iname ‘*.jpg’ -print0 | xargs –null ls -l\n```\n使用这项技术，我们可以保证所有文件，甚至那些文件名中包含空格的文件，都能被正确地处理。\n                \n## stat命令\n显示文件详细信息\n\n","slug":"TLCL_notes_18","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5j0000imcxqyvqp59g3"},{"title":"<<The Linux Command Line>> 第十九章笔记 归档和备份","date":"2015-09-07T12:00:19.000Z","_content":"## gzip, gunzip, zcat, zless\n\n## bzip2, bunzip2, bzcat, bzip2recover\n\n## tar\n是 tape archive 的简称\n除非你是超级用户，要不然从归档文件中抽取的文件 和目录的所有权由执行此复原操作的用户所拥有，而不属于原始所有者。\n\ntar 命令另一个有趣的行为是它处理归档文件路径名的方式。默认情况下，路径名是相对的，而不是绝对 路径。\n当创建归档文件的时候，tar 命令会简单地删除路径名开头的斜杠。\nz参数使用gzip压缩, j参数使用bzip2压缩\n```\nfind playground -name 'file-A' | tar czf playground.tgz -T -\n```\n\n## zip, unzip\n\n## rsync\n(remote sync之意), 用来备份挺好的,  \n```\nsudo rsync -av --delete /etc /home /usr/local /media/BigDisk/backup\nsudo rsync -av --delete --rsh=ssh /etc /home /usr/local remote-sys:/backup\nrsync -av -delete rsync://rsync.gtlib.gatech.edu/fedora-linux-core/development/i386/os fedora-devel\n```\n\n","source":"_posts/TLCL_notes_19.md","raw":"title: <<The Linux Command Line>> 第十九章笔记 归档和备份\ndate: 2015-09-07 20:00:19\ntags: [linux, bash]\n---\n## gzip, gunzip, zcat, zless\n\n## bzip2, bunzip2, bzcat, bzip2recover\n\n## tar\n是 tape archive 的简称\n除非你是超级用户，要不然从归档文件中抽取的文件 和目录的所有权由执行此复原操作的用户所拥有，而不属于原始所有者。\n\ntar 命令另一个有趣的行为是它处理归档文件路径名的方式。默认情况下，路径名是相对的，而不是绝对 路径。\n当创建归档文件的时候，tar 命令会简单地删除路径名开头的斜杠。\nz参数使用gzip压缩, j参数使用bzip2压缩\n```\nfind playground -name 'file-A' | tar czf playground.tgz -T -\n```\n\n## zip, unzip\n\n## rsync\n(remote sync之意), 用来备份挺好的,  \n```\nsudo rsync -av --delete /etc /home /usr/local /media/BigDisk/backup\nsudo rsync -av --delete --rsh=ssh /etc /home /usr/local remote-sys:/backup\nrsync -av -delete rsync://rsync.gtlib.gatech.edu/fedora-linux-core/development/i386/os fedora-devel\n```\n\n","slug":"TLCL_notes_19","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5j1000kmcxqh886e5a7"},{"title":"<<The Linux Command Line>> 第十七章笔记 网络系统","date":"2015-09-07T12:00:17.000Z","_content":"## ping命令\n发送一个特殊的网络数据包，叫做 IMCP ECHO_REQUEST，到 一台指定的主机。\n大多数接收这个包的网络设备将会回复它，来允许网络连接验证。\n\n注意：大多数网络设备（包括 Linux 主机）都可以被配置为忽略这些数据包。\n通常，这样做是出于网络安全 原因，部分地遮蔽一台主机免受一个潜在攻击者地侵袭。配置防火墙来阻塞 IMCP 流量也很普遍。\n\n## traceroute （一些系统使用相似的 tracepath 程序来代替）\n显示从本地到指定主机 要经过的所有“跳数”的网络流量列表。\n\n## netstat -ie\n\n## netstat -r\nIP 地址以零结尾是指网络，而不是个人主机， 所以这个目的地意味着局域网中的任何一台主机。\nGateway， 是网关（路由器）的名字或 IP 地址，用它来连接当前的主机和目的地的网络。 若这个字段显示一个星号，则表明不需要网关。\n目的地 default,指的是发往任何表上没有列出的目的地网络的流量。\n\n## sftp\n正如其名字所示，它是 ftp 程序的安全替代品。\nsftp 工作起来与我们 之前使用的 ftp 程序很相似；然而，它不用明码形式来传递数据，它使用加密的 SSH 通道。\nsftp 有一个 重要特性强于传统的 ftp 命令，就是 sftp 不需要远端系统中运行 FTP 服务器。它仅仅要求 SSH 服务器。 \n这意味着任何一台能用 SSH 客户端连接的远端机器，也可当作类似于 FTP 的服务器来使用。\n\n小贴示：这个 SFTP 协议被许多 Linux 发行版中的图形化文件管理器支持。\n使用 Nautilus (GNOME), 或者是 Konqueror (KDE)，我们都能在位置栏中输入以 sftp:// 开头的 URI， 来操作存储在运行着 SSH 服务器的远端系统中的文件。\n\n","source":"_posts/TLCL_notes_17.md","raw":"title: <<The Linux Command Line>> 第十七章笔记 网络系统\ndate: 2015-09-07 20:00:17\ntags: [linux, bash]\n---\n## ping命令\n发送一个特殊的网络数据包，叫做 IMCP ECHO_REQUEST，到 一台指定的主机。\n大多数接收这个包的网络设备将会回复它，来允许网络连接验证。\n\n注意：大多数网络设备（包括 Linux 主机）都可以被配置为忽略这些数据包。\n通常，这样做是出于网络安全 原因，部分地遮蔽一台主机免受一个潜在攻击者地侵袭。配置防火墙来阻塞 IMCP 流量也很普遍。\n\n## traceroute （一些系统使用相似的 tracepath 程序来代替）\n显示从本地到指定主机 要经过的所有“跳数”的网络流量列表。\n\n## netstat -ie\n\n## netstat -r\nIP 地址以零结尾是指网络，而不是个人主机， 所以这个目的地意味着局域网中的任何一台主机。\nGateway， 是网关（路由器）的名字或 IP 地址，用它来连接当前的主机和目的地的网络。 若这个字段显示一个星号，则表明不需要网关。\n目的地 default,指的是发往任何表上没有列出的目的地网络的流量。\n\n## sftp\n正如其名字所示，它是 ftp 程序的安全替代品。\nsftp 工作起来与我们 之前使用的 ftp 程序很相似；然而，它不用明码形式来传递数据，它使用加密的 SSH 通道。\nsftp 有一个 重要特性强于传统的 ftp 命令，就是 sftp 不需要远端系统中运行 FTP 服务器。它仅仅要求 SSH 服务器。 \n这意味着任何一台能用 SSH 客户端连接的远端机器，也可当作类似于 FTP 的服务器来使用。\n\n小贴示：这个 SFTP 协议被许多 Linux 发行版中的图形化文件管理器支持。\n使用 Nautilus (GNOME), 或者是 Konqueror (KDE)，我们都能在位置栏中输入以 sftp:// 开头的 URI， 来操作存储在运行着 SSH 服务器的远端系统中的文件。\n\n","slug":"TLCL_notes_17","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5j1000lmcxqh1ilmswg"},{"title":"<<The Linux Command Line>> 第二十章笔记 正则表达式","date":"2015-09-07T12:00:20.000Z","_content":"## grep, global regular expression print\n* -c     打印匹配的数量（或者是不匹配的数目，若指定了-v 选项），而不是文本行本身。 也可用`--count`选项来指定。\n* -l     打印包含匹配项的文件名，而不是文本行本身，也可用--files-with-matches 选项来指定。\n* -L     相似于-l 选项，但是只是打印不包含匹配项的文件名。也可用--files-without-match 来指定。\n\n## /usr/share/dict下有英文字典\n你知道你的 Linux 系统中带有一本英文字典吗？千真万确。\n看一下 /usr/share/dict 目录，你就能找到一本， 或几本。\n\n## locale\n使用 locale 命令，来查看 locale 的设置。\n把这个 LANG 变量设置为 POSIX，来更改 locale，使其使用传统的 Unix 行为。\n```\n[me@linuxbox ~]$ export LANG=POSIX\n```\n注意这个改动使系统为它的字符集使用 U.S.英语（更准确地说，ASCII），所以要确认一下这 是否是你真正想要的效果。\n通过把这条语句添加到你的.bashrc 文件中，你可以使这个更改永久有效。\n\n## Alternation\n例: \n```\necho \"AAA\" | grep -E 'AAA|BBB|CCC'\n```\n为了把 alternation 和其它正则表达式元素结合起来，我们可以使用()来分离 alternation。\n```\n[me@linuxbox ~]$ grep -Eh '^(bz|gz|zip)' dirlist*.txt\n```\n\n## 限定符\n扩展的正则表达式支持几种方法，来指定一个元素被匹配的次数。\n```\n^\\(?[0-9]{3}\\)?  [0-9]{3}-[0-9]{4}$\n```\n这样一种扫描会发现包含空格和其它潜在不规范字符的路径名：\n```\n[me@linuxbox ~]$ find . -regex '.*[^-\\_./0-9a-zA-Z].*'\n```\n\n## zgrep 程序\ngrep 的前端，允许 grep 来读取压缩文件。\n\n","source":"_posts/TLCL_notes_20.md","raw":"title: <<The Linux Command Line>> 第二十章笔记 正则表达式\ndate: 2015-09-07 20:00:20\ntags: [linux, bash]\n---\n## grep, global regular expression print\n* -c     打印匹配的数量（或者是不匹配的数目，若指定了-v 选项），而不是文本行本身。 也可用`--count`选项来指定。\n* -l     打印包含匹配项的文件名，而不是文本行本身，也可用--files-with-matches 选项来指定。\n* -L     相似于-l 选项，但是只是打印不包含匹配项的文件名。也可用--files-without-match 来指定。\n\n## /usr/share/dict下有英文字典\n你知道你的 Linux 系统中带有一本英文字典吗？千真万确。\n看一下 /usr/share/dict 目录，你就能找到一本， 或几本。\n\n## locale\n使用 locale 命令，来查看 locale 的设置。\n把这个 LANG 变量设置为 POSIX，来更改 locale，使其使用传统的 Unix 行为。\n```\n[me@linuxbox ~]$ export LANG=POSIX\n```\n注意这个改动使系统为它的字符集使用 U.S.英语（更准确地说，ASCII），所以要确认一下这 是否是你真正想要的效果。\n通过把这条语句添加到你的.bashrc 文件中，你可以使这个更改永久有效。\n\n## Alternation\n例: \n```\necho \"AAA\" | grep -E 'AAA|BBB|CCC'\n```\n为了把 alternation 和其它正则表达式元素结合起来，我们可以使用()来分离 alternation。\n```\n[me@linuxbox ~]$ grep -Eh '^(bz|gz|zip)' dirlist*.txt\n```\n\n## 限定符\n扩展的正则表达式支持几种方法，来指定一个元素被匹配的次数。\n```\n^\\(?[0-9]{3}\\)?  [0-9]{3}-[0-9]{4}$\n```\n这样一种扫描会发现包含空格和其它潜在不规范字符的路径名：\n```\n[me@linuxbox ~]$ find . -regex '.*[^-\\_./0-9a-zA-Z].*'\n```\n\n## zgrep 程序\ngrep 的前端，允许 grep 来读取压缩文件。\n\n","slug":"TLCL_notes_20","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5j3000omcxqiwng1r6u"},{"title":"<<The Linux Command Line>> 第二章笔记","date":"2015-09-07T12:00:02.000Z","_content":"如果提示符的最后一个字符是“#”, 而不是“$”, 那么这个终端会话就有超级用户权限。\n\nX 窗口系统 （使 GUI 工作的底层引擎）内建了一种机制，支持快速拷贝和粘贴技巧。\n如果你按下鼠标左键，沿着文本拖动鼠标（或者双击一个单词）高亮了一些文本， 那么这些高亮的文本就被拷贝到了一个由 X 管理的缓冲区里面。\n然后按下鼠标中键或Ctrl+Insert， 这些文本就被粘贴到光标所在的位置。\n注意： 不要在一个终端窗口里使用 Ctrl-c 和 Ctrl-v 快捷键来执行拷贝和粘贴操作。 它们不起作用。\n\n设置聚焦策略为“聚焦跟随着鼠标”，可以使拷贝和粘贴更方便易用。\n\n```\ncal，它默认显示当前月份的日历。\n```\n\n","source":"_posts/TLCL_notes_2.md","raw":"title: <<The Linux Command Line>> 第二章笔记\ndate: 2015-09-07 20:00:02\ntags: [linux, bash]\n---\n如果提示符的最后一个字符是“#”, 而不是“$”, 那么这个终端会话就有超级用户权限。\n\nX 窗口系统 （使 GUI 工作的底层引擎）内建了一种机制，支持快速拷贝和粘贴技巧。\n如果你按下鼠标左键，沿着文本拖动鼠标（或者双击一个单词）高亮了一些文本， 那么这些高亮的文本就被拷贝到了一个由 X 管理的缓冲区里面。\n然后按下鼠标中键或Ctrl+Insert， 这些文本就被粘贴到光标所在的位置。\n注意： 不要在一个终端窗口里使用 Ctrl-c 和 Ctrl-v 快捷键来执行拷贝和粘贴操作。 它们不起作用。\n\n设置聚焦策略为“聚焦跟随着鼠标”，可以使拷贝和粘贴更方便易用。\n\n```\ncal，它默认显示当前月份的日历。\n```\n\n","slug":"TLCL_notes_2","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5j4000qmcxqbmxfxrgh"},{"title":"<<The Linux Command Line>> 第二一章笔记 文本处理","date":"2015-09-07T12:00:21.000Z","_content":"\n## cat -A \n显示非打印字符\n\n## dos2unix & unix2dos\n在windows和linux的文本格式之间转换\n\n## sort \n程序能接受命令行中的多个文件作为参数，所以有可能把多个文件合并成一个有序的文件。\n例如， 如果我们有三个文本文件，想要把它们合并为一个有序的文件，我们可以这样做：\n```\nsort file1.txt file2.txt file3.txt > final_sorted_list.txt\n```\n\n## uniq \n会删除任意重复行\nsort 程序支持一个 -u 选项，其可以从排好序的输出结果中删除重复行。\n\n## cut\n```\ncut -f 3 distros.txt | cut -c 7-10\n```\n\n## expand & unexpand\n它既可以接受一个或多个文件参数，也可以接受标准输入，并且把 修改过的文本送到标准输出。\nCoreutils 软件包也提供了 unexpand 程序，用 tab 来代替空格。\n\n## paste\n与cut相反\n```\npaste distros-dates.txt distros-versions.txt\n```\n\n## join \n操作通常与关系型数据库有关联，在关系型数据库中来自多个享有共同关键域的表格的 数据结合起来，得到一个期望的结果。\n\n## comm\ncomm -12 file1.txt file2.txt\n\n## diff\n\n## patch\n\n## tr\ntranslate\n\n## sed\nstream editor\n\n## aspell\n\n","source":"_posts/TLCL_notes_21.md","raw":"title: <<The Linux Command Line>> 第二一章笔记 文本处理\ndate: 2015-09-07 20:00:21\ntags: [linux, bash]\n---\n\n## cat -A \n显示非打印字符\n\n## dos2unix & unix2dos\n在windows和linux的文本格式之间转换\n\n## sort \n程序能接受命令行中的多个文件作为参数，所以有可能把多个文件合并成一个有序的文件。\n例如， 如果我们有三个文本文件，想要把它们合并为一个有序的文件，我们可以这样做：\n```\nsort file1.txt file2.txt file3.txt > final_sorted_list.txt\n```\n\n## uniq \n会删除任意重复行\nsort 程序支持一个 -u 选项，其可以从排好序的输出结果中删除重复行。\n\n## cut\n```\ncut -f 3 distros.txt | cut -c 7-10\n```\n\n## expand & unexpand\n它既可以接受一个或多个文件参数，也可以接受标准输入，并且把 修改过的文本送到标准输出。\nCoreutils 软件包也提供了 unexpand 程序，用 tab 来代替空格。\n\n## paste\n与cut相反\n```\npaste distros-dates.txt distros-versions.txt\n```\n\n## join \n操作通常与关系型数据库有关联，在关系型数据库中来自多个享有共同关键域的表格的 数据结合起来，得到一个期望的结果。\n\n## comm\ncomm -12 file1.txt file2.txt\n\n## diff\n\n## patch\n\n## tr\ntranslate\n\n## sed\nstream editor\n\n## aspell\n\n","slug":"TLCL_notes_21","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5j5000tmcxqqcb9k8qx"},{"title":"<<The Linux Command Line>> 第二二章笔记 格式化输出","date":"2015-09-07T12:00:22.000Z","_content":" \n## nl\n\n## fold\n\n## fmt\n\n","source":"_posts/TLCL_notes_22.md","raw":"title: <<The Linux Command Line>> 第二二章笔记 格式化输出\ndate: 2015-09-07 20:00:22\ntags: [linux, bash]\n---\n \n## nl\n\n## fold\n\n## fmt\n\n","slug":"TLCL_notes_22","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5j6000vmcxq013tzkzi"},{"title":"<<The Linux Command Line>> 第二三章笔记 打印","date":"2015-09-07T12:00:23.000Z","_content":"\n","source":"_posts/TLCL_notes_23.md","raw":"title: <<The Linux Command Line>> 第二三章笔记 打印\ndate: 2015-09-07 20:00:23\ntags: [linux, bash]\n---\n\n","slug":"TLCL_notes_23","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5j7000ymcxqypa6ocsg"},{"title":"<<The Linux Command Line>> 第二四章笔记 编译程序","date":"2015-09-07T12:00:24.000Z","_content":"\n","source":"_posts/TLCL_notes_24.md","raw":"title: <<The Linux Command Line>> 第二四章笔记 编译程序\ndate: 2015-09-07 20:00:24\ntags: [linux, bash]\n---\n\n","slug":"TLCL_notes_24","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5j80010mcxq0emt38in"},{"title":"<<The Linux Command Line>> 第二五章笔记","date":"2015-09-07T12:00:25.000Z","_content":"## 编写第一个 Shell 脚本\n:set autoindent\n打开 “auto indent” 功能。这导致 vim 能对新的文本行缩进与刚输入的文本行相同的列数。 \n对于许多编程结构来说，这就加速了输入。停止缩进，输入 Ctrl-d。\n\n","source":"_posts/TLCL_notes_25.md","raw":"title: <<The Linux Command Line>> 第二五章笔记\ndate: 2015-09-07 20:00:25\ntags: [linux, bash]\n---\n## 编写第一个 Shell 脚本\n:set autoindent\n打开 “auto indent” 功能。这导致 vim 能对新的文本行缩进与刚输入的文本行相同的列数。 \n对于许多编程结构来说，这就加速了输入。停止缩进，输入 Ctrl-d。\n\n","slug":"TLCL_notes_25","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5j90013mcxqfim7ygdw"},{"title":"<<The Linux Command Line>> 第二七章笔记 自顶向下设计","date":"2015-09-07T12:00:27.000Z","_content":"## 函数\nShell 函数有两种语法形式：\n```\nfunction name {\n    commands\n    return\n}\n```\n和\n```\nname () {\n    commands\n    return\n}\n```\n\n注意为了使函数调用被识别出是 shell 函数，而不是被解释为外部程序的名字，所以在脚本中 shell 函数定义必须出现在函数调用之前。\n\n## 局部变量\n```\nfoo=0 # global variable foo\nfunct_1 () {\n    local foo  # variable foo local to funct_1\n    foo=1\n    echo \"funct_1: foo = $foo\"\n}\n```\n\n## .bashrc 文件中的 shell 函数\nShell 函数是更为完美的别名替代物，实际上是创建较小的个人所用命令的首选方法。\n别名 非常局限于命令的种类和它们支持的 shell 功能，然而 shell 函数允许任何可以编写脚本的东西。\n\n","source":"_posts/TLCL_notes_27.md","raw":"title: <<The Linux Command Line>> 第二七章笔记 自顶向下设计\ndate: 2015-09-07 20:00:27\ntags: [linux, bash]\n---\n## 函数\nShell 函数有两种语法形式：\n```\nfunction name {\n    commands\n    return\n}\n```\n和\n```\nname () {\n    commands\n    return\n}\n```\n\n注意为了使函数调用被识别出是 shell 函数，而不是被解释为外部程序的名字，所以在脚本中 shell 函数定义必须出现在函数调用之前。\n\n## 局部变量\n```\nfoo=0 # global variable foo\nfunct_1 () {\n    local foo  # variable foo local to funct_1\n    foo=1\n    echo \"funct_1: foo = $foo\"\n}\n```\n\n## .bashrc 文件中的 shell 函数\nShell 函数是更为完美的别名替代物，实际上是创建较小的个人所用命令的首选方法。\n别名 非常局限于命令的种类和它们支持的 shell 功能，然而 shell 函数允许任何可以编写脚本的东西。\n\n","slug":"TLCL_notes_27","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ja0015mcxq4j4twb0c"},{"title":"<<The Linux Command Line>> 第二八章笔记 流程控制：if 分支结构","date":"2015-09-07T12:00:28.000Z","_content":"## if语法\n```\nx=5\nif [ $x = 5 ]; then\n    echo \"x equals 5.\"\nelif [ $x = 3 ]; then\n    echo \"x equals 3.\"\nelse\n    echo \"x does not equal 5.\"\nfi\n```\n\n## 退出状态 & true & false\n\n当命令执行完毕后，命令（包括我们编写的脚本和 shell 函数）会给系统发送一个值，叫做退出状态。 \n这个值是一个 0 到 255 之间的整数，说明命令执行成功或是失败。\n按照惯例，一个零值说明成功，其它所有值说明失败。 Shell 提供了一个参数，我们可以用echo $?检查退出状态。\nshell 提供了两个极其简单的内部命令，它们不做任何事情，除了以一个零或1退出状态来终止执行。 \ntrue 命令总是执行成功，而 false 命令总是执行失败：\n如果 if 之后跟随一系列命令，则将计算列表中的最后一个命令：\n\n## 测试\n\n到目前为止，经常与 if 一块使用的命令是 test。\n这个 test 命令执行各种各样的检查与比较。 它有两种等价模式：\ntest expression\n比较流行的格式是：\n[ expression ]\n例:\n```\n#!/bin/bash\n# test-file: Evaluate the status of a file\nFILE=~/.bashrc\nif [ -e \"$FILE\" ]; then\n    if [ -f \"$FILE\" ]; then\n        echo \"$FILE is a regular file.\"\n    fi\n    if [ -d \"$FILE\" ]; then\n        echo \"$FILE is a directory.\"\n    fi\n    if [ -r \"$FILE\" ]; then\n        echo \"$FILE is readable.\"\n    fi\n    if [ -w \"$FILE\" ]; then\n        echo \"$FILE is writable.\"\n    fi\n    if [ -x \"$FILE\" ]; then\n        echo \"$FILE is executable/searchable.\"\n    fi\nelse\n    echo \"$FILE does not exist\"\n    exit 1\nfi\nexit\n```\n引号并不是必需的，但这是为了防范空参数。如果$FILE的参数展开 是一个空值，就会导致一个错误（操作符将会被解释为非空的字符串而不是操作符）。用引号把参数引起来就 确保了操作符之后总是跟随着一个字符串，即使字符串为空。\nexit 命令接受一个单独的，可选的参数，其成为脚本的退出状态。当不传递参数时，退出状态默认为零。\n\n## 更现代的测试版本\n目前的 bash 版本包括一个复合命令，作为加强的 test 命令替代物。它使用以下语法：\n[[ expression ]]\n\n这个[[ ]]命令非常 相似于 test 命令（它支持所有的表达式），但是增加了一个重要的新的字符串表达式：\n\nstring1 =~ regex\n如果 string1匹配扩展的正则表达式 regex,其返回值为真\n\n[[ ]]添加的另一个功能是==操作符支持类型匹配，正如路径名展开所做的那样。\n\n## (( )) - 为整数设计\n\n## 结合表达式\n操作符     测试     [[ ]] and (( ))\n* AND        -a     &&\n* OR         -o     ||\n* NOT         !     !\n\n一个像这样的命令：\n```\n[me@linuxbox ~]$ [ -d temp ] || mkdir temp\n```\n会测试目录 temp 是否存在，并且只有测试失败之后，才会创建这个目录。\n\n","source":"_posts/TLCL_notes_28.md","raw":"title: <<The Linux Command Line>> 第二八章笔记 流程控制：if 分支结构\ndate: 2015-09-07 20:00:28\ntags: [linux, bash]\n---\n## if语法\n```\nx=5\nif [ $x = 5 ]; then\n    echo \"x equals 5.\"\nelif [ $x = 3 ]; then\n    echo \"x equals 3.\"\nelse\n    echo \"x does not equal 5.\"\nfi\n```\n\n## 退出状态 & true & false\n\n当命令执行完毕后，命令（包括我们编写的脚本和 shell 函数）会给系统发送一个值，叫做退出状态。 \n这个值是一个 0 到 255 之间的整数，说明命令执行成功或是失败。\n按照惯例，一个零值说明成功，其它所有值说明失败。 Shell 提供了一个参数，我们可以用echo $?检查退出状态。\nshell 提供了两个极其简单的内部命令，它们不做任何事情，除了以一个零或1退出状态来终止执行。 \ntrue 命令总是执行成功，而 false 命令总是执行失败：\n如果 if 之后跟随一系列命令，则将计算列表中的最后一个命令：\n\n## 测试\n\n到目前为止，经常与 if 一块使用的命令是 test。\n这个 test 命令执行各种各样的检查与比较。 它有两种等价模式：\ntest expression\n比较流行的格式是：\n[ expression ]\n例:\n```\n#!/bin/bash\n# test-file: Evaluate the status of a file\nFILE=~/.bashrc\nif [ -e \"$FILE\" ]; then\n    if [ -f \"$FILE\" ]; then\n        echo \"$FILE is a regular file.\"\n    fi\n    if [ -d \"$FILE\" ]; then\n        echo \"$FILE is a directory.\"\n    fi\n    if [ -r \"$FILE\" ]; then\n        echo \"$FILE is readable.\"\n    fi\n    if [ -w \"$FILE\" ]; then\n        echo \"$FILE is writable.\"\n    fi\n    if [ -x \"$FILE\" ]; then\n        echo \"$FILE is executable/searchable.\"\n    fi\nelse\n    echo \"$FILE does not exist\"\n    exit 1\nfi\nexit\n```\n引号并不是必需的，但这是为了防范空参数。如果$FILE的参数展开 是一个空值，就会导致一个错误（操作符将会被解释为非空的字符串而不是操作符）。用引号把参数引起来就 确保了操作符之后总是跟随着一个字符串，即使字符串为空。\nexit 命令接受一个单独的，可选的参数，其成为脚本的退出状态。当不传递参数时，退出状态默认为零。\n\n## 更现代的测试版本\n目前的 bash 版本包括一个复合命令，作为加强的 test 命令替代物。它使用以下语法：\n[[ expression ]]\n\n这个[[ ]]命令非常 相似于 test 命令（它支持所有的表达式），但是增加了一个重要的新的字符串表达式：\n\nstring1 =~ regex\n如果 string1匹配扩展的正则表达式 regex,其返回值为真\n\n[[ ]]添加的另一个功能是==操作符支持类型匹配，正如路径名展开所做的那样。\n\n## (( )) - 为整数设计\n\n## 结合表达式\n操作符     测试     [[ ]] and (( ))\n* AND        -a     &&\n* OR         -o     ||\n* NOT         !     !\n\n一个像这样的命令：\n```\n[me@linuxbox ~]$ [ -d temp ] || mkdir temp\n```\n会测试目录 temp 是否存在，并且只有测试失败之后，才会创建这个目录。\n\n","slug":"TLCL_notes_28","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5jc0018mcxqpdc78iiq"},{"title":"<<The Linux Command Line>> 第二九章笔记 读取键盘输入","date":"2015-09-07T12:00:29.000Z","_content":"## read - 从标准输入读取数值\nread [-options] [variable...]\n这里的 options 是下面列出的可用选项中的一个或多个，且 variable 是用来存储输入数值的一个或多个变量名。 \n如果没有提供变量名，shell 变量 REPLY 会包含数据行。\n\n注意: 你**不能管道read**, 管道线 会创建子 shell, \n在类 Unix 的系统中，子 shell 执行的时候，会为进程创建父环境的副本。当进程结束 之后，环境副本就会被破坏掉。\n这意味着一个子 shell 永远不能改变父进程的环境。\n\n## IFS\n通常，shell 对提供给 read 的输入按照单词进行分离。\n正如我们所见到的，这意味着多个由一个或几个空格 分离开的单词在输入行中变成独立的个体，并被 read 赋值给单独的变量。\n这种行为由 shell 变量`__IFS__`（内部字符分隔符）配置。IFS 的默认值包含一个空格，一个 tab，和一个换行符，每一个都会把 字段分割开。\n\nShell 允许在一个命令之前立即发生一个或多个变量赋值。这些赋值为跟随着的命令更改环境变量。 \n这个赋值的影响是暂时的；只是在命令存在期间改变环境变量。\n\n## <<< 操作符指示一个 here 字符串\n一个 here 字符串就像一个 here 文档，只是比较简短，由 单个字符串组成。\n\n","source":"_posts/TLCL_notes_29.md","raw":"title: <<The Linux Command Line>> 第二九章笔记 读取键盘输入\ndate: 2015-09-07 20:00:29\ntags: [linux, bash]\n---\n## read - 从标准输入读取数值\nread [-options] [variable...]\n这里的 options 是下面列出的可用选项中的一个或多个，且 variable 是用来存储输入数值的一个或多个变量名。 \n如果没有提供变量名，shell 变量 REPLY 会包含数据行。\n\n注意: 你**不能管道read**, 管道线 会创建子 shell, \n在类 Unix 的系统中，子 shell 执行的时候，会为进程创建父环境的副本。当进程结束 之后，环境副本就会被破坏掉。\n这意味着一个子 shell 永远不能改变父进程的环境。\n\n## IFS\n通常，shell 对提供给 read 的输入按照单词进行分离。\n正如我们所见到的，这意味着多个由一个或几个空格 分离开的单词在输入行中变成独立的个体，并被 read 赋值给单独的变量。\n这种行为由 shell 变量`__IFS__`（内部字符分隔符）配置。IFS 的默认值包含一个空格，一个 tab，和一个换行符，每一个都会把 字段分割开。\n\nShell 允许在一个命令之前立即发生一个或多个变量赋值。这些赋值为跟随着的命令更改环境变量。 \n这个赋值的影响是暂时的；只是在命令存在期间改变环境变量。\n\n## <<< 操作符指示一个 here 字符串\n一个 here 字符串就像一个 here 文档，只是比较简短，由 单个字符串组成。\n\n","slug":"TLCL_notes_29","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5jd001amcxq667cdea3"},{"title":"<<The Linux Command Line>> 第二六章笔记 启动一个项目","date":"2015-09-07T12:00:26.000Z","_content":"## 常量和变量\n一个常用惯例是指定大写字母来表示常量，小写字母表示真正的变量。\n注意：实际上，shell 确实提供了一种方法，通过使用带有-r（只读）选项的内部命令 declare， 来强制常量的不变性。如果我们给 TITLE 这样赋值：\n那么 shell 会阻止之后给 TITLE 的任意赋值。这个功能极少被使用，但为了很早之前的脚本， 它仍然存在。\n\n## 整型\n通过使用带有-i 选项的 declare 命令，你可以强制 shell 把 赋值限制为整型，但是，正如像设置变量为只读一样，极少这样做。\n\n## 赋值\n注意在赋值过程中，变量名，等号和变量值之间必须没有空格\n\n## Here Documents\n如果我们把重定向操作符从 “<<” 改为 “<<-”，shell 会忽略在此 here document 中开头的 tab 字符。\n\n","source":"_posts/TLCL_notes_26.md","raw":"title: <<The Linux Command Line>> 第二六章笔记 启动一个项目\ndate: 2015-09-07 20:00:26\ntags: [linux, bash]\n---\n## 常量和变量\n一个常用惯例是指定大写字母来表示常量，小写字母表示真正的变量。\n注意：实际上，shell 确实提供了一种方法，通过使用带有-r（只读）选项的内部命令 declare， 来强制常量的不变性。如果我们给 TITLE 这样赋值：\n那么 shell 会阻止之后给 TITLE 的任意赋值。这个功能极少被使用，但为了很早之前的脚本， 它仍然存在。\n\n## 整型\n通过使用带有-i 选项的 declare 命令，你可以强制 shell 把 赋值限制为整型，但是，正如像设置变量为只读一样，极少这样做。\n\n## 赋值\n注意在赋值过程中，变量名，等号和变量值之间必须没有空格\n\n## Here Documents\n如果我们把重定向操作符从 “<<” 改为 “<<-”，shell 会忽略在此 here document 中开头的 tab 字符。\n\n","slug":"TLCL_notes_26","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5je001dmcxqmj28pxiu"},{"title":"<<The Linux Command Line>> 第三章笔记","date":"2015-09-07T12:00:03.000Z","_content":"注意(类 Unix 系统)不像 Windows ，每个存储设备都有一个独自的文件系统。\n类 Unix 操作系统， 比如 Linux，总是只有一个单一的文件系统树，不管有多少个磁盘或者存储设备连接到计算机上。 \n根据负责维护系统安全的系统管理员的兴致，存储设备连接到（或着更精确些，是挂载到）目录树的各个节点上。\n\n```\ncd ~user_name     更改工作目录到用户家目录。例如, cd ~bob 会更改工作目录到用户“bob”的家目录。\n```\n\n虽然 Linux 支持长文件名，文件名可能包含空格，标点符号，但标点符号仅限 使用 “.”，“－”，下划线。\n最重要的是，不要在文件名中使用空格。如果你想表示词与 词间的空格，用下划线字符来代替。过些时候，你会感激自己这样做。\n\n","source":"_posts/TLCL_notes_3.md","raw":"title: <<The Linux Command Line>> 第三章笔记\ndate: 2015-09-07 20:00:03\ntags: [linux, bash]\n---\n注意(类 Unix 系统)不像 Windows ，每个存储设备都有一个独自的文件系统。\n类 Unix 操作系统， 比如 Linux，总是只有一个单一的文件系统树，不管有多少个磁盘或者存储设备连接到计算机上。 \n根据负责维护系统安全的系统管理员的兴致，存储设备连接到（或着更精确些，是挂载到）目录树的各个节点上。\n\n```\ncd ~user_name     更改工作目录到用户家目录。例如, cd ~bob 会更改工作目录到用户“bob”的家目录。\n```\n\n虽然 Linux 支持长文件名，文件名可能包含空格，标点符号，但标点符号仅限 使用 “.”，“－”，下划线。\n最重要的是，不要在文件名中使用空格。如果你想表示词与 词间的空格，用下划线字符来代替。过些时候，你会感激自己这样做。\n\n","slug":"TLCL_notes_3","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5jf001fmcxq89j2zefz"},{"title":"<<The Linux Command Line>> 第三十章笔记","date":"2015-09-07T12:00:30.000Z","_content":"## 流程控制：while/until 循环\n```\n#!/bin/bash\n# while-count: display a series of numbers\ncount=1\nwhile [ $count -le 5 ]; do\n    echo $count\n    count=$((count + 1))\ndone\necho \"Finished.\"\n```\n\n### break & continue\nbash 提供了两个内部命令，它们可以用来在循环内部控制程序流程。\n这个 break 命令立即终止一个循环， 且程序继续执行循环之后的语句。\n这个 continue 命令导致程序跳过循环中剩余的语句，且程序继续执行 下一次循环。\n\n### until\n这个 until 命令与 while 非常相似，除了当遇到一个非零退出状态的时候， while 退出循环， 而 until 不退出。一个 until 循环会继续执行直到它接受了一个退出状态零。\n\n### 使用循环读取文件\nwhile 和 until 能够处理标准输入。这就可以使用 while 和 until 处理文件。\n```\n#!/bin/bash\n# while-read: read lines from a file\nwhile read distro version release; do\n    printf \"Distro: %s\\tVersion: %s\\tReleased: %s\\n\" \\\n        $distro \\\n        $version \\\n        $release\ndone < distros.txt\n```\n\n","source":"_posts/TLCL_notes_30.md","raw":"title: <<The Linux Command Line>> 第三十章笔记\ndate: 2015-09-07 20:00:30\ntags: [linux, bash]\n---\n## 流程控制：while/until 循环\n```\n#!/bin/bash\n# while-count: display a series of numbers\ncount=1\nwhile [ $count -le 5 ]; do\n    echo $count\n    count=$((count + 1))\ndone\necho \"Finished.\"\n```\n\n### break & continue\nbash 提供了两个内部命令，它们可以用来在循环内部控制程序流程。\n这个 break 命令立即终止一个循环， 且程序继续执行循环之后的语句。\n这个 continue 命令导致程序跳过循环中剩余的语句，且程序继续执行 下一次循环。\n\n### until\n这个 until 命令与 while 非常相似，除了当遇到一个非零退出状态的时候， while 退出循环， 而 until 不退出。一个 until 循环会继续执行直到它接受了一个退出状态零。\n\n### 使用循环读取文件\nwhile 和 until 能够处理标准输入。这就可以使用 while 和 until 处理文件。\n```\n#!/bin/bash\n# while-read: read lines from a file\nwhile read distro version release; do\n    printf \"Distro: %s\\tVersion: %s\\tReleased: %s\\n\" \\\n        $distro \\\n        $version \\\n        $release\ndone < distros.txt\n```\n\n","slug":"TLCL_notes_30","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5jg001imcxqackpj2qi"},{"title":"<<The Linux Command Line>> 第三一章笔记 疑难排解","date":"2015-09-07T12:00:31.000Z","_content":"## 追踪\nbash 还提供了一种名为追踪的方法，这种方法可通过 -x 选项和 set 命令加上 -x 选项两种途径实现。 \n拿我们之前的 trouble 脚本为例，给该脚本的第一行语句添加 -x 选项，我们就能追踪整个脚本。\n```\n#!/bin/bash -x\n# trouble: script to demonstrate common errors\nnumber=1\nif [ $number = 1 ]; then\n    echo \"Number is equal to 1.\"\nelse\n    echo \"Number is not equal to 1.\"\nfi\n```\n当脚本执行后，输出结果看起来像这样:\n```\n[me@linuxbox ~]$ trouble\n+ number=1\n+ '[' 1 = 1 ']'\n+ echo 'Number is equal to 1.'\nNumber is equal to 1.\n```\n\n追踪生效后，我们看到脚本命令展开后才执行。行首的加号表明追踪的迹象，使其与常规输出结果区分开来。 \n加号是追踪输出的默认字符。它包含在 PS4（提示符4）shell 变量中。可以调整这个变量值让提示信息更有意义。 \n这里，我们修改该变量的内容，让其包含脚本中追踪执行到的当前行的行号。\n注意这里必须使用单引号是为了防止变量展开，直到 提示符真正使用的时候，就不需要了。\n\n```\n[me@linuxbox ~]$ export PS4='$LINENO + '\n[me@linuxbox ~]$ trouble\n5 + number=1\n7 + '[' 1 = 1 ']'\n8 + echo 'Number is equal to 1.'\nNumber is equal to 1.\n```\n\n我们还可以使用 set 命令加上 -x 选项，为脚本中的一块选择区域，而不是整个脚本启用追踪。\n\n```\n#!/bin/bash\n# trouble: script to demonstrate common errors\nnumber=1\nset -x # Turn on tracing\nif [ $number = 1 ]; then\n    echo \"Number is equal to 1.\"\nelse\n    echo \"Number is not equal to 1.\"\nfi\nset +x # Turn off tracing\n```\n我们使用 set 命令加上 -x 选项来启动追踪，+x 选项关闭追踪。这种技术可以用来检查一个有错误的脚本的多个部分。\n\n## Bash Debugger\n对于真正的高强度的调试，参考这个：\nhttp://bashdb.sourceforge.net/\n\n","source":"_posts/TLCL_notes_31.md","raw":"title: <<The Linux Command Line>> 第三一章笔记 疑难排解\ndate: 2015-09-07 20:00:31\ntags: [linux, bash]\n---\n## 追踪\nbash 还提供了一种名为追踪的方法，这种方法可通过 -x 选项和 set 命令加上 -x 选项两种途径实现。 \n拿我们之前的 trouble 脚本为例，给该脚本的第一行语句添加 -x 选项，我们就能追踪整个脚本。\n```\n#!/bin/bash -x\n# trouble: script to demonstrate common errors\nnumber=1\nif [ $number = 1 ]; then\n    echo \"Number is equal to 1.\"\nelse\n    echo \"Number is not equal to 1.\"\nfi\n```\n当脚本执行后，输出结果看起来像这样:\n```\n[me@linuxbox ~]$ trouble\n+ number=1\n+ '[' 1 = 1 ']'\n+ echo 'Number is equal to 1.'\nNumber is equal to 1.\n```\n\n追踪生效后，我们看到脚本命令展开后才执行。行首的加号表明追踪的迹象，使其与常规输出结果区分开来。 \n加号是追踪输出的默认字符。它包含在 PS4（提示符4）shell 变量中。可以调整这个变量值让提示信息更有意义。 \n这里，我们修改该变量的内容，让其包含脚本中追踪执行到的当前行的行号。\n注意这里必须使用单引号是为了防止变量展开，直到 提示符真正使用的时候，就不需要了。\n\n```\n[me@linuxbox ~]$ export PS4='$LINENO + '\n[me@linuxbox ~]$ trouble\n5 + number=1\n7 + '[' 1 = 1 ']'\n8 + echo 'Number is equal to 1.'\nNumber is equal to 1.\n```\n\n我们还可以使用 set 命令加上 -x 选项，为脚本中的一块选择区域，而不是整个脚本启用追踪。\n\n```\n#!/bin/bash\n# trouble: script to demonstrate common errors\nnumber=1\nset -x # Turn on tracing\nif [ $number = 1 ]; then\n    echo \"Number is equal to 1.\"\nelse\n    echo \"Number is not equal to 1.\"\nfi\nset +x # Turn off tracing\n```\n我们使用 set 命令加上 -x 选项来启动追踪，+x 选项关闭追踪。这种技术可以用来检查一个有错误的脚本的多个部分。\n\n## Bash Debugger\n对于真正的高强度的调试，参考这个：\nhttp://bashdb.sourceforge.net/\n\n","slug":"TLCL_notes_31","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5jh001kmcxqgjjtbznf"},{"title":"<<The Linux Command Line>> 第三二章笔记 流程控制：case 分支","date":"2015-09-07T12:00:32.000Z","_content":"## case\nBash 的多选复合命令称为 case。它的语法规则如下所示：\n```\ncase word in\n    [pattern [| pattern]...) commands ;;]...\nesac\n```\n\n### 模式\n* a)     若单词为 “a”，则匹配\n* [[:alpha:]])     若单词是一个字母字符，则匹配\n* ???)     若单词只有3个字符，则匹配\n* *.txt)     若单词以 “.txt” 字符结尾，则匹配\n* *)     匹配任意单词。把这个模式做为 case 命令的最后一个模式，是一个很好的做法， 可以捕捉到任意一个与先前模式不匹配的数值；也就是说，捕捉到任何可能的无效值。\n还可以使用竖线字符作为分隔符，把多个模式结合起来。这就创建了一个 “或” 条件模式。\n\n### 执行多个动作\n现在的 bash 版本，添加 “;;&” 表达式来终允许 case 语句继续执行下一条测试，而不是简单地终止运行。\n```\n#!/bin/bash\n# case4-2: test a character\nread -n 1 -p \"Type a character > \"\necho\ncase $REPLY in\n    [[:upper:]])    echo \"'$REPLY' is upper case.\" ;;&\n    [[:lower:]])    echo \"'$REPLY' is lower case.\" ;;&\n    [[:alpha:]])    echo \"'$REPLY' is alphabetic.\" ;;&\n    [[:digit:]])    echo \"'$REPLY' is a digit.\" ;;&\n    [[:graph:]])    echo \"'$REPLY' is a visible character.\" ;;&\n    [[:punct:]])    echo \"'$REPLY' is a punctuation symbol.\" ;;&\n    [[:space:]])    echo \"'$REPLY' is a whitespace character.\" ;;&\n    [[:xdigit:]])   echo \"'$REPLY' is a hexadecimal digit.\" ;;&\nesac\n```\n当我们运行这个脚本的时候，我们得到这些：\n```\n[me@linuxbox ~]$ case4-2\nType a character > a\n'a' is lower case.\n'a' is alphabetic.\n'a' is a visible character.\n'a' is a hexadecimal digit.\n```\n\n","source":"_posts/TLCL_notes_32.md","raw":"title: <<The Linux Command Line>> 第三二章笔记 流程控制：case 分支\ndate: 2015-09-07 20:00:32\ntags: [linux, bash]\n---\n## case\nBash 的多选复合命令称为 case。它的语法规则如下所示：\n```\ncase word in\n    [pattern [| pattern]...) commands ;;]...\nesac\n```\n\n### 模式\n* a)     若单词为 “a”，则匹配\n* [[:alpha:]])     若单词是一个字母字符，则匹配\n* ???)     若单词只有3个字符，则匹配\n* *.txt)     若单词以 “.txt” 字符结尾，则匹配\n* *)     匹配任意单词。把这个模式做为 case 命令的最后一个模式，是一个很好的做法， 可以捕捉到任意一个与先前模式不匹配的数值；也就是说，捕捉到任何可能的无效值。\n还可以使用竖线字符作为分隔符，把多个模式结合起来。这就创建了一个 “或” 条件模式。\n\n### 执行多个动作\n现在的 bash 版本，添加 “;;&” 表达式来终允许 case 语句继续执行下一条测试，而不是简单地终止运行。\n```\n#!/bin/bash\n# case4-2: test a character\nread -n 1 -p \"Type a character > \"\necho\ncase $REPLY in\n    [[:upper:]])    echo \"'$REPLY' is upper case.\" ;;&\n    [[:lower:]])    echo \"'$REPLY' is lower case.\" ;;&\n    [[:alpha:]])    echo \"'$REPLY' is alphabetic.\" ;;&\n    [[:digit:]])    echo \"'$REPLY' is a digit.\" ;;&\n    [[:graph:]])    echo \"'$REPLY' is a visible character.\" ;;&\n    [[:punct:]])    echo \"'$REPLY' is a punctuation symbol.\" ;;&\n    [[:space:]])    echo \"'$REPLY' is a whitespace character.\" ;;&\n    [[:xdigit:]])   echo \"'$REPLY' is a hexadecimal digit.\" ;;&\nesac\n```\n当我们运行这个脚本的时候，我们得到这些：\n```\n[me@linuxbox ~]$ case4-2\nType a character > a\n'a' is lower case.\n'a' is alphabetic.\n'a' is a visible character.\n'a' is a hexadecimal digit.\n```\n\n","slug":"TLCL_notes_32","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ji001nmcxquublvtnw"},{"title":"<<The Linux Command Line>> 第三三章笔记 位置参数","date":"2015-09-07T12:00:33.000Z","_content":"## 位置参数\n```\n[me@linuxbox ~]$ posit-param a b c d\n$0 = /home/me/bin/posit-param\n$1 = a\n$2 = b\n$3 = c\n$4 = d\n$5 =\n$6 =\n$7 =\n$8 =\n$9 =\n```\n注意： 实际上通过参数展开方式你可以访问的参数个数多于9个。\n只要指定一个大于9的数字，用花括号把该数字括起来就可以。 例如 `${10}， ${55}， ${211}`\n\n## 确定参数个数\n另外 shell 还提供了一个名为 `$#`，可以得到命令行参数个数的变量:\n\n## shift\n执行一次 shift 命令， 就会导致所有的位置参数 “向下移动一个位置”。\n每次 shift 命令执行的时候，变量 `$2` 的值会移动到变量 `$1` 中，变量 `$3` 的值会移动到变量 `$2` 中，依次类推。 变量 `$#` 的值也会相应的减1。\n\n## basename\nbasename 命令清除 一个路径名的开头部分，只留下一个文件的基本名称。\n\n## Shell 函数中使用位置参数\n正如位置参数被用来给 shell 脚本传递参数一样，它们也能够被用来给 shell 函数传递参数。\n\n位置参数 `$0` 总是包含命令行中第一项的完整路径名\n\n## `$* $@`  \n* $*     展开成一个从1开始的位置参数列表。当它被用双引号引起来的时候，展开成一个由双引号引起来 的字符串，包含了所有的位置参数，每个位置参数由 shell 变量 IFS 的第一个字符（默认为一个空格）分隔开。\n* $@     展开成一个从1开始的位置参数列表。当它被用双引号引起来的时候， 它把每一个位置参数展开成一个由双引号引起来的分开的字符串。\n\n","source":"_posts/TLCL_notes_33.md","raw":"title: <<The Linux Command Line>> 第三三章笔记 位置参数\ndate: 2015-09-07 20:00:33\ntags: [linux, bash]\n---\n## 位置参数\n```\n[me@linuxbox ~]$ posit-param a b c d\n$0 = /home/me/bin/posit-param\n$1 = a\n$2 = b\n$3 = c\n$4 = d\n$5 =\n$6 =\n$7 =\n$8 =\n$9 =\n```\n注意： 实际上通过参数展开方式你可以访问的参数个数多于9个。\n只要指定一个大于9的数字，用花括号把该数字括起来就可以。 例如 `${10}， ${55}， ${211}`\n\n## 确定参数个数\n另外 shell 还提供了一个名为 `$#`，可以得到命令行参数个数的变量:\n\n## shift\n执行一次 shift 命令， 就会导致所有的位置参数 “向下移动一个位置”。\n每次 shift 命令执行的时候，变量 `$2` 的值会移动到变量 `$1` 中，变量 `$3` 的值会移动到变量 `$2` 中，依次类推。 变量 `$#` 的值也会相应的减1。\n\n## basename\nbasename 命令清除 一个路径名的开头部分，只留下一个文件的基本名称。\n\n## Shell 函数中使用位置参数\n正如位置参数被用来给 shell 脚本传递参数一样，它们也能够被用来给 shell 函数传递参数。\n\n位置参数 `$0` 总是包含命令行中第一项的完整路径名\n\n## `$* $@`  \n* $*     展开成一个从1开始的位置参数列表。当它被用双引号引起来的时候，展开成一个由双引号引起来 的字符串，包含了所有的位置参数，每个位置参数由 shell 变量 IFS 的第一个字符（默认为一个空格）分隔开。\n* $@     展开成一个从1开始的位置参数列表。当它被用双引号引起来的时候， 它把每一个位置参数展开成一个由双引号引起来的分开的字符串。\n\n","slug":"TLCL_notes_33","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5jj001pmcxqr4zer4wq"},{"title":"<<The Linux Command Line>> 第三四章笔记 流程控制：for 循环","date":"2015-09-07T12:00:34.000Z","_content":"## for: 传统 shell 格式\n原来的 for 命令语法是：\n```\nfor variable [in words]; do\n    commands\ndone\n```\n如果省略掉 for 命令的可选项 words 部分，for 命令会默认处理位置参数。\n\n## for: C 语言格式\n最新版本的 bash 已经添加了第二种格式的 for 命令语法，该语法相似于 C 语言中的 for 语法格式。 \n其它许多编程语言也支持这种格式：\n```\nfor (( expression1; expression2; expression3 )); do\n    commands\ndone\n```\n\n","source":"_posts/TLCL_notes_34.md","raw":"title: <<The Linux Command Line>> 第三四章笔记 流程控制：for 循环\ndate: 2015-09-07 20:00:34\ntags: [linux, bash]\n---\n## for: 传统 shell 格式\n原来的 for 命令语法是：\n```\nfor variable [in words]; do\n    commands\ndone\n```\n如果省略掉 for 命令的可选项 words 部分，for 命令会默认处理位置参数。\n\n## for: C 语言格式\n最新版本的 bash 已经添加了第二种格式的 for 命令语法，该语法相似于 C 语言中的 for 语法格式。 \n其它许多编程语言也支持这种格式：\n```\nfor (( expression1; expression2; expression3 )); do\n    commands\ndone\n```\n\n","slug":"TLCL_notes_34","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5jk001smcxqquaoho9j"},{"title":"<<The Linux Command Line>> 第三六章笔记 数组","date":"2015-09-07T12:00:36.000Z","_content":"Bash 中的数组仅限制为单一维度\n\n数组变量就像其它 bash 变量一样命名，当被访问的时候，它们会被自动地创建。这里是一个例子：\n```\n[me@linuxbox ~]$ a[1]=foo\n[me@linuxbox ~]$ echo ${a[1]}\nfoo\n```\n也可以用 declare 命令创建一个数组：\n```\n[me@linuxbox ~]$ declare -a a\n```\n数组赋值\n有两种方式可以给数组赋值。单个值赋值使用以下语法：\n```\nname[subscript]=value\n```\n这里的 name 是数组的名字，subscript 是一个大于或等于零的整数（或算术表达式）。\n注意数组第一个元素的下标是0， 而不是1。数组元素的值可以是一个字符串或整数。\n\n多个值赋值使用下面的语法：\n```\nname=(value1 value2 ...)\n```\n\n还可以通过指定下标，把值赋给数组中的特定元素：\n```\n[me@linuxbox ~]$ days=([0]=Sun [1]=Mon [2]=Tue [3]=Wed [4]=Thu [5]=Fri [6]=Sat)\n```\n\n找到数组使用的下标\n因为 bash 允许赋值的数组下标包含 “间隔”，有时候确定哪个元素真正存在是很有用的。\n\n","source":"_posts/TLCL_notes_36.md","raw":"title: <<The Linux Command Line>> 第三六章笔记 数组\ndate: 2015-09-07 20:00:36\ntags: [linux, bash]\n---\nBash 中的数组仅限制为单一维度\n\n数组变量就像其它 bash 变量一样命名，当被访问的时候，它们会被自动地创建。这里是一个例子：\n```\n[me@linuxbox ~]$ a[1]=foo\n[me@linuxbox ~]$ echo ${a[1]}\nfoo\n```\n也可以用 declare 命令创建一个数组：\n```\n[me@linuxbox ~]$ declare -a a\n```\n数组赋值\n有两种方式可以给数组赋值。单个值赋值使用以下语法：\n```\nname[subscript]=value\n```\n这里的 name 是数组的名字，subscript 是一个大于或等于零的整数（或算术表达式）。\n注意数组第一个元素的下标是0， 而不是1。数组元素的值可以是一个字符串或整数。\n\n多个值赋值使用下面的语法：\n```\nname=(value1 value2 ...)\n```\n\n还可以通过指定下标，把值赋给数组中的特定元素：\n```\n[me@linuxbox ~]$ days=([0]=Sun [1]=Mon [2]=Tue [3]=Wed [4]=Thu [5]=Fri [6]=Sat)\n```\n\n找到数组使用的下标\n因为 bash 允许赋值的数组下标包含 “间隔”，有时候确定哪个元素真正存在是很有用的。\n\n","slug":"TLCL_notes_36","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5jl001umcxq8w3wplgn"},{"title":"<<The Linux Command Line>> 第三七章笔记 奇珍异宝","date":"2015-09-07T12:00:37.000Z","_content":"","source":"_posts/TLCL_notes_37.md","raw":"title: <<The Linux Command Line>> 第三七章笔记 奇珍异宝\ndate: 2015-09-07 20:00:37\ntags: [linux, bash]\n---\n","slug":"TLCL_notes_37","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5jn001xmcxq78i4qnzn"},{"title":"<<The Linux Command Line>> 第四章笔记","date":"2015-09-07T12:00:04.000Z","_content":"## 探究操作系统\n\nls允许同时列出多个指定目录的内容。在这个例子中，将会列出用户家目录（用字符“~”代表）和/usr 目录的内容方便对比：\n```\n[me@linuxbox ~]$ ls ~ /usr\n```\n\n下面这个例子，ls 命令有两个选项， “l” 选项产生长格式输出，“t”选项按文件修改时间的先后来排序。\n\n```\n[me@linuxbox ~]$ ls -lt\n```\n\n加上长选项 “--reverse”或短选项-r，则结果会以相反的顺序输出：\n\n```\n[me@linuxbox ~]$ ls -lt --reverse\n```\n或\n```\n[me@linuxbox ~]$ ls -ltr\n```\n\nls部分选项\n* -d     --directory          通常，如果指定了目录名，ls 命令会列出这个目录中的内容，而不是目录本身。 把这个选项与 -l 选项结合使用，可以看到所指定目录的详细信息，而不是目录中的内容。\n* -F     --classify           这个选项会在每个所列出的名字后面加上一个指示符。例如，如果名字是 目录名，则会加上一个'/'字符。\n* -h     --human-readable     当以长格式列出时，以人们可读的格式，而不是以字节数来显示文件的大小。\n* -S                          命令输出结果按照文件大小来排序。\n* -i                          显示inode id\n* -A                          与-a相比不显示.和..目录\n\nls -l的输出解释:\n-rw-r--r-- 1 root root   32059 2007-04-03 11:05 oo-cd-cover.odf\n-rw-r--r--     \n对于文件的访问权限。第一个字符指明文件类型。在不同类型之间， 开头的“－”说明是一个普通文件，“d”表明是一个目录。\n其后三个字符是文件所有者的 访问权限，再其后的三个字符是文件所属组中成员的访问权限，最后三个字符是其他所 有人的访问权限。这个字段的完整含义将在第十章讨论。\n1     \n文件的硬链接数目。参考随后讨论的关于链接的内容。\nroot     \n文件属主的用户名。\nroot     \n文件所属用户组的名字。\n\n```\nfile filename\n```\n确定文件类型\n\nASCII（发音是”As-Key”）\n\n* /     根目录，万物起源。\n* /bin     包含系统启动和运行所必须的二进制程序。\n* /boot     包含 Linux 内核，最初的 RMA 磁盘映像（系统启动时，由驱动程序所需），和 启动加载程序。\n* /dev     这是一个包含设备结点的特殊目录。“一切都是文件”，也使用于设备。 在这个目录里，内核维护着它支持的设备。\n* /etc     这个目录包含所有系统层面的配置文件。它也包含一系列的 shell 脚本， 在系统启动时，这些脚本会运行每个系统服务。这个目录中的任何文件应该是可读的文本文件。\n* /home     在通常的配置环境下，系统会在/home 下，给每个用户分配一个目录。普通只能 在他们自己的目录下创建文件。这个限制保护系统免受错误的用户活动破坏。\n* /lib     包含核心系统程序所需的库文件。这些文件与 Windows 中的动态链接库相似。\n* /lost+found     每个使用 Linux 文件系统的格式化分区或设备，例如 ext3文件系统， 都会有这个目录。当部分恢复一个损坏的文件系统时，会用到这个目录。除非文件系统 真正的损坏了，那么这个目录会是个空目录。\n* /media     在现在的 Linux 系统中，/media 目录会包含可移除媒体设备的挂载点， 例如 USB 驱动器，CD-ROMs 等等。这些设备连接到计算机之后，会自动地挂载到这个目录结点下。\n* /mnt     在早些的 Linux 系统中，/mnt 目录包含可移除设备的挂载点。\n* /opt     这个/opt 目录被用来安装“可选的”软件。这个主要用来存储可能 安装在系统中的商业软件产品。\n* /proc     这个/proc 目录很特殊。从存储在硬盘上的文件的意义上说，它不是真正的文件系统。 反而，它是一个由 Linux 内核维护的虚拟文件系统。它所包含的文件是内核的窥视孔。这些文件是可读的， 它们会告诉你内核是怎样监管计算机的。\n* /root     root 帐户的家目录。\n* /sbin     这个目录包含“系统”二进制文件。它们是完成重大系统任务的程序，通常为超级用户保留。\n* /tmp     这个/tmp 目录，是用来存储由各种程序创建的临时文件的地方。一些配置，导致系统每次 重新启动时，都会清空这个目录。\n* /usr     在 Linux 系统中，/usr 目录可能是最大的一个。它包含普通用户所需要的所有程序和文件。\n* /usr/bin     /usr/bin 目录包含系统安装的可执行程序。通常，这个目录会包含许多程序。\n* /usr/lib     包含由/usr/bin 目录中的程序所用的共享库。\n* /usr/local     这个/usr/local 目录，是非系统发行版自带，却打算让系统使用的程序的安装目录。 通常，由源码编译的程序会安装在/usr/local/bin 目录下。新安装的 Linux 系统中，会存在这个目录， 但却是空目录，直到系统管理员放些东西到它里面。\n* /usr/sbin     包含许多系统管理程序。\n* /usr/share     /usr/share 目录包含许多由/usr/bin 目录中的程序使用的共享数据。 其中包括像默认的配置文件，图标，桌面背景，音频文件等等。\n* /usr/share/doc     大多数安装在系统中的软件包会包含一些文档。在/usr/share/doc 目录下， 我们可以找到按照软件包分类的文档。\n* /var     除了/tmp 和/home 目录之外，相对来说，目前我们看到的目录是静态的，这是说， 它们的内容不会改变。/var 目录是可能需要改动的文件存储的地方。各种数据库，假脱机文件， 用户邮件等等，都驻扎在这里。\n* /var/log     这个/var/log 目录包含日志文件，各种系统活动的记录。这些文件非常重要，并且 应该时时监测它们。其中最重要的一个文件是/var/log/messages。注意，为了系统安全，在一些系统中， 你必须是超级用户才能查看这些日志文件。\n\n","source":"_posts/TLCL_notes_4.md","raw":"title: <<The Linux Command Line>> 第四章笔记\ndate: 2015-09-07 20:00:04\ntags: [linux, bash]\n---\n## 探究操作系统\n\nls允许同时列出多个指定目录的内容。在这个例子中，将会列出用户家目录（用字符“~”代表）和/usr 目录的内容方便对比：\n```\n[me@linuxbox ~]$ ls ~ /usr\n```\n\n下面这个例子，ls 命令有两个选项， “l” 选项产生长格式输出，“t”选项按文件修改时间的先后来排序。\n\n```\n[me@linuxbox ~]$ ls -lt\n```\n\n加上长选项 “--reverse”或短选项-r，则结果会以相反的顺序输出：\n\n```\n[me@linuxbox ~]$ ls -lt --reverse\n```\n或\n```\n[me@linuxbox ~]$ ls -ltr\n```\n\nls部分选项\n* -d     --directory          通常，如果指定了目录名，ls 命令会列出这个目录中的内容，而不是目录本身。 把这个选项与 -l 选项结合使用，可以看到所指定目录的详细信息，而不是目录中的内容。\n* -F     --classify           这个选项会在每个所列出的名字后面加上一个指示符。例如，如果名字是 目录名，则会加上一个'/'字符。\n* -h     --human-readable     当以长格式列出时，以人们可读的格式，而不是以字节数来显示文件的大小。\n* -S                          命令输出结果按照文件大小来排序。\n* -i                          显示inode id\n* -A                          与-a相比不显示.和..目录\n\nls -l的输出解释:\n-rw-r--r-- 1 root root   32059 2007-04-03 11:05 oo-cd-cover.odf\n-rw-r--r--     \n对于文件的访问权限。第一个字符指明文件类型。在不同类型之间， 开头的“－”说明是一个普通文件，“d”表明是一个目录。\n其后三个字符是文件所有者的 访问权限，再其后的三个字符是文件所属组中成员的访问权限，最后三个字符是其他所 有人的访问权限。这个字段的完整含义将在第十章讨论。\n1     \n文件的硬链接数目。参考随后讨论的关于链接的内容。\nroot     \n文件属主的用户名。\nroot     \n文件所属用户组的名字。\n\n```\nfile filename\n```\n确定文件类型\n\nASCII（发音是”As-Key”）\n\n* /     根目录，万物起源。\n* /bin     包含系统启动和运行所必须的二进制程序。\n* /boot     包含 Linux 内核，最初的 RMA 磁盘映像（系统启动时，由驱动程序所需），和 启动加载程序。\n* /dev     这是一个包含设备结点的特殊目录。“一切都是文件”，也使用于设备。 在这个目录里，内核维护着它支持的设备。\n* /etc     这个目录包含所有系统层面的配置文件。它也包含一系列的 shell 脚本， 在系统启动时，这些脚本会运行每个系统服务。这个目录中的任何文件应该是可读的文本文件。\n* /home     在通常的配置环境下，系统会在/home 下，给每个用户分配一个目录。普通只能 在他们自己的目录下创建文件。这个限制保护系统免受错误的用户活动破坏。\n* /lib     包含核心系统程序所需的库文件。这些文件与 Windows 中的动态链接库相似。\n* /lost+found     每个使用 Linux 文件系统的格式化分区或设备，例如 ext3文件系统， 都会有这个目录。当部分恢复一个损坏的文件系统时，会用到这个目录。除非文件系统 真正的损坏了，那么这个目录会是个空目录。\n* /media     在现在的 Linux 系统中，/media 目录会包含可移除媒体设备的挂载点， 例如 USB 驱动器，CD-ROMs 等等。这些设备连接到计算机之后，会自动地挂载到这个目录结点下。\n* /mnt     在早些的 Linux 系统中，/mnt 目录包含可移除设备的挂载点。\n* /opt     这个/opt 目录被用来安装“可选的”软件。这个主要用来存储可能 安装在系统中的商业软件产品。\n* /proc     这个/proc 目录很特殊。从存储在硬盘上的文件的意义上说，它不是真正的文件系统。 反而，它是一个由 Linux 内核维护的虚拟文件系统。它所包含的文件是内核的窥视孔。这些文件是可读的， 它们会告诉你内核是怎样监管计算机的。\n* /root     root 帐户的家目录。\n* /sbin     这个目录包含“系统”二进制文件。它们是完成重大系统任务的程序，通常为超级用户保留。\n* /tmp     这个/tmp 目录，是用来存储由各种程序创建的临时文件的地方。一些配置，导致系统每次 重新启动时，都会清空这个目录。\n* /usr     在 Linux 系统中，/usr 目录可能是最大的一个。它包含普通用户所需要的所有程序和文件。\n* /usr/bin     /usr/bin 目录包含系统安装的可执行程序。通常，这个目录会包含许多程序。\n* /usr/lib     包含由/usr/bin 目录中的程序所用的共享库。\n* /usr/local     这个/usr/local 目录，是非系统发行版自带，却打算让系统使用的程序的安装目录。 通常，由源码编译的程序会安装在/usr/local/bin 目录下。新安装的 Linux 系统中，会存在这个目录， 但却是空目录，直到系统管理员放些东西到它里面。\n* /usr/sbin     包含许多系统管理程序。\n* /usr/share     /usr/share 目录包含许多由/usr/bin 目录中的程序使用的共享数据。 其中包括像默认的配置文件，图标，桌面背景，音频文件等等。\n* /usr/share/doc     大多数安装在系统中的软件包会包含一些文档。在/usr/share/doc 目录下， 我们可以找到按照软件包分类的文档。\n* /var     除了/tmp 和/home 目录之外，相对来说，目前我们看到的目录是静态的，这是说， 它们的内容不会改变。/var 目录是可能需要改动的文件存储的地方。各种数据库，假脱机文件， 用户邮件等等，都驻扎在这里。\n* /var/log     这个/var/log 目录包含日志文件，各种系统活动的记录。这些文件非常重要，并且 应该时时监测它们。其中最重要的一个文件是/var/log/messages。注意，为了系统安全，在一些系统中， 你必须是超级用户才能查看这些日志文件。\n\n","slug":"TLCL_notes_4","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5jn001zmcxqk68ufyyb"},{"title":"<<The Linux Command Line>> 第五章笔记","date":"2015-09-07T12:00:05.000Z","_content":"## 第五章 操作文件和目录\n\n通配符     意义\n*     匹配任意多个字符（包括零个或一个）\n?     匹配任意一个字符（不包括零个）\n[characters]     匹配任意一个属于字符集中的字符\n[!characters]     匹配任意一个不是字符集中的字符\n[[:class:]]     匹配任意一个属于指定字符类中的字符\n\n字符类     意义\n[:alnum:]     匹配任意一个字母或数字\n[:alpha:]     匹配任意一个字母\n[:digit:]     匹配任意一个数字\n[:lower:]     匹配任意一个小写字母\n[:upper]     匹配任意一个大写字母\n\n模式     匹配对象\n*     所有文件\ng*     文件名以“g”开头的文件\nb*.txt     以\"b\"开头，中间有零个或任意多个字符，并以\".txt\"结尾的文件\nData???     以“Data”开头，其后紧接着3个字符的文件\n[abc]*     文件名以\"a\",\"b\",或\"c\"开头的文件\nBACKUP.[0-9][0-9][0-9]     以\"BACKUP.\"开头，并紧接着3个数字的文件\n[[:upper:]]*     以大写字母开头的文件\n[![:digit:]]*     不以数字开头的文件\n*[[:lower:]123]     文件名以小写字母结尾，或以 “1”，“2”，或 “3” 结尾的文件\n\nmkdir directory...\n在描述一个命令时（如上所示），当有三个圆点跟在一个命令的参数后面， 这意味着那个参数可以重复，就像这样：\nmkdir dir1 dir2 dir3\n\ncp\n选项     意义\n-a, --archive     复制文件和目录，以及它们的属性，包括所有权和权限。 通常，复本具有用户所操作文件的默认属性。\n-u, --update     当把文件从一个目录复制到另一个目录时，仅复制 目标目录中不存在的文件，或者是文件内容新于目标目录中已经存在的文件。\n\n一个文件名就是一个链接,软链是软链,其他的全是硬链\n硬链接有两个重要局限性：\n    一个硬链接不能关联它所在文件系统之外的文件。这是说一个链接不能关联 与链接本身不在同一个磁盘分区上的文件。\n    一个硬链接不能关联一个目录。\n\n\n在 GNOME 里面，当拖动文件时，同时按下 Ctrl会创建一个复本，同时按下 Ctrl+Shift 按键会创建一个链接，而不是 复制（或移动）文件。\n\n\n","source":"_posts/TLCL_notes_5.md","raw":"title: <<The Linux Command Line>> 第五章笔记\ndate: 2015-09-07 20:00:05\ntags: [linux, bash]\n---\n## 第五章 操作文件和目录\n\n通配符     意义\n*     匹配任意多个字符（包括零个或一个）\n?     匹配任意一个字符（不包括零个）\n[characters]     匹配任意一个属于字符集中的字符\n[!characters]     匹配任意一个不是字符集中的字符\n[[:class:]]     匹配任意一个属于指定字符类中的字符\n\n字符类     意义\n[:alnum:]     匹配任意一个字母或数字\n[:alpha:]     匹配任意一个字母\n[:digit:]     匹配任意一个数字\n[:lower:]     匹配任意一个小写字母\n[:upper]     匹配任意一个大写字母\n\n模式     匹配对象\n*     所有文件\ng*     文件名以“g”开头的文件\nb*.txt     以\"b\"开头，中间有零个或任意多个字符，并以\".txt\"结尾的文件\nData???     以“Data”开头，其后紧接着3个字符的文件\n[abc]*     文件名以\"a\",\"b\",或\"c\"开头的文件\nBACKUP.[0-9][0-9][0-9]     以\"BACKUP.\"开头，并紧接着3个数字的文件\n[[:upper:]]*     以大写字母开头的文件\n[![:digit:]]*     不以数字开头的文件\n*[[:lower:]123]     文件名以小写字母结尾，或以 “1”，“2”，或 “3” 结尾的文件\n\nmkdir directory...\n在描述一个命令时（如上所示），当有三个圆点跟在一个命令的参数后面， 这意味着那个参数可以重复，就像这样：\nmkdir dir1 dir2 dir3\n\ncp\n选项     意义\n-a, --archive     复制文件和目录，以及它们的属性，包括所有权和权限。 通常，复本具有用户所操作文件的默认属性。\n-u, --update     当把文件从一个目录复制到另一个目录时，仅复制 目标目录中不存在的文件，或者是文件内容新于目标目录中已经存在的文件。\n\n一个文件名就是一个链接,软链是软链,其他的全是硬链\n硬链接有两个重要局限性：\n    一个硬链接不能关联它所在文件系统之外的文件。这是说一个链接不能关联 与链接本身不在同一个磁盘分区上的文件。\n    一个硬链接不能关联一个目录。\n\n\n在 GNOME 里面，当拖动文件时，同时按下 Ctrl会创建一个复本，同时按下 Ctrl+Shift 按键会创建一个链接，而不是 复制（或移动）文件。\n\n\n","slug":"TLCL_notes_5","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5jp0021mcxqmkxlf6c1"},{"title":"<<The Linux Command Line>> 第三五章笔记 字符串和数字","date":"2015-09-07T12:00:35.000Z","_content":"## \\${parameter:-word}\n若 parameter 没有设置（例如，不存在）或者为空，展开结果是 word 的值。\n若 parameter 不为空，则展开结果是 parameter 的值。\n```\n$ echo ${foo:-\"substitute value if unset\"}\n```\nsubstitute value if unset\n\n## \\${parameter:=word}\n若 parameter 没有设置或为空，展开结果是 word 的值。另外，word 的值会赋值给 parameter。 \n若 parameter 不为空，展开结果是 parameter 的值。\n注意： 位置参数或其它的特殊参数不能以这种方式赋值。\n\n## \\${parameter:?word}\n若 parameter 没有设置或为空，这种展开导致脚本带有错误退出，并且 word 的内容会发送到标准错误。\n若 parameter 不为空， 展开结果是 parameter 的值。\n```\n$ echo ${foo:?\"parameter is empty\"}\n```\nbash: foo: parameter is empty\n\n## \\${parameter:+word}\n若 parameter 没有设置或为空，展开结果为空。\n若 parameter 不为空， 展开结果是 word 的值会替换掉 parameter 的值；然而，parameter 的值不会改变。\n返回变量名的参数展开\nshell 具有返回变量名的能力。这会用在一些相当独特的情况下。\n\n## \\${!prefix*}\n## \\${!prefix@}\n这种展开会返回以 prefix 开头的已有变量名。根据 bash 文档，这两种展开形式的执行结果相同。 \n这里，我们列出了所有以 BASH 开头的环境变量名：\n```\n[me@linuxbox ~]$ echo ${!BASH*}\nBASH BASH_ARGC BASH_ARGV BASH_COMMAND BASH_COMPLETION\nBASH_COMPLETION_DIR BASH_LINENO BASH_SOURCE BASH_SUBSHELL\nBASH_VERSINFO BASH_VERSION\n```\n\n## \\${&#35;parameter}\n展开成由 parameter 所包含的字符串的长度。\n\n## \\${parameter:offset}\n## \\${parameter:offset:length}\n\n这些展开用来从 parameter 所包含的字符串中提取一部分字符。\n若 offset 的值为负数，则认为 offset 值是从字符串的末尾开始算起，而不是从开头。\n注意负数前面必须有一个空格， 为防止与 \\${parameter:-word} 展开形式混淆。length，若出现，则必须不能小于零。\n\n## \\${parameter#pattern}\n## \\${parameter##pattern}\n这些展开会从 paramter 所包含的字符串中清除开头一部分文本，这些字符要匹配定义的 patten。p\nattern 是 通配符模式，就如那些用在路径名展开中的模式。这两种形式的差异之处是该 \\# 形式清除最短的匹配结果， 而该 \\## 模式清除最长的匹配结果。\n\n```\n[me@linuxbox ~]$ foo=file.txt.zip\n[me@linuxbox ~]$ echo ${foo#*.}\ntxt.zip\n[me@linuxbox ~]$ echo ${foo##*.}\nzip\n```\n\n## \\${parameter%pattern}\n## \\${parameter%%pattern}\n\n这些展开和上面的 \\# 和 \\## 展开一样，除了它们清除的文本从 parameter 所包含字符串的末尾开始，而不是开头。\n```\n[me@linuxbox ~]$ foo=file.txt.zip\n[me@linuxbox ~]$ echo ${foo%.*}\nfile.txt\n[me@linuxbox ~]$ echo ${foo%%.*}\nfile\n```\n\n## time\n使用 time 命令来比较这两个脚本版本的效率\ntime可以测试脚本的执行时间\n\n## declare 命令可以用来把字符串规范成大写或小写字符\n使用 declare 命令，我们能强制一个 变量总是包含所需的格式，无论如何赋值给它。\ndeclare -u upper\ndeclare -l lower\n\n## 大小写转换参数展开\n* ${parameter,,}    把 parameter 的值全部展开成小写字母。\n* ${parameter,}     仅仅把 parameter 的第一个字符展开成小写字母。\n* ${parameter^^}    把 parameter 的值全部转换成大写字母。\n* ${parameter^}     仅仅把 parameter 的第一个字符转换成大写字母（首字母大写）。\n\n## 在算术表达式中，shell 支持任意进制的整形常量。\n* number      默认情况下，没有任何表示法的数字被看做是十进制数（以10为底）。\n* 0number     在算术表达式中，以零开头的数字被认为是八进制数。\n* 0xnumber    十六进制表示法\n* base#number number 以 base 为底\n\n## bc - 一种高精度计算器语言\n\n","source":"_posts/TLCL_notes_35.md","raw":"title: <<The Linux Command Line>> 第三五章笔记 字符串和数字\ndate: 2015-09-07 20:00:35\ntags: [linux, bash]\n---\n## \\${parameter:-word}\n若 parameter 没有设置（例如，不存在）或者为空，展开结果是 word 的值。\n若 parameter 不为空，则展开结果是 parameter 的值。\n```\n$ echo ${foo:-\"substitute value if unset\"}\n```\nsubstitute value if unset\n\n## \\${parameter:=word}\n若 parameter 没有设置或为空，展开结果是 word 的值。另外，word 的值会赋值给 parameter。 \n若 parameter 不为空，展开结果是 parameter 的值。\n注意： 位置参数或其它的特殊参数不能以这种方式赋值。\n\n## \\${parameter:?word}\n若 parameter 没有设置或为空，这种展开导致脚本带有错误退出，并且 word 的内容会发送到标准错误。\n若 parameter 不为空， 展开结果是 parameter 的值。\n```\n$ echo ${foo:?\"parameter is empty\"}\n```\nbash: foo: parameter is empty\n\n## \\${parameter:+word}\n若 parameter 没有设置或为空，展开结果为空。\n若 parameter 不为空， 展开结果是 word 的值会替换掉 parameter 的值；然而，parameter 的值不会改变。\n返回变量名的参数展开\nshell 具有返回变量名的能力。这会用在一些相当独特的情况下。\n\n## \\${!prefix*}\n## \\${!prefix@}\n这种展开会返回以 prefix 开头的已有变量名。根据 bash 文档，这两种展开形式的执行结果相同。 \n这里，我们列出了所有以 BASH 开头的环境变量名：\n```\n[me@linuxbox ~]$ echo ${!BASH*}\nBASH BASH_ARGC BASH_ARGV BASH_COMMAND BASH_COMPLETION\nBASH_COMPLETION_DIR BASH_LINENO BASH_SOURCE BASH_SUBSHELL\nBASH_VERSINFO BASH_VERSION\n```\n\n## \\${&#35;parameter}\n展开成由 parameter 所包含的字符串的长度。\n\n## \\${parameter:offset}\n## \\${parameter:offset:length}\n\n这些展开用来从 parameter 所包含的字符串中提取一部分字符。\n若 offset 的值为负数，则认为 offset 值是从字符串的末尾开始算起，而不是从开头。\n注意负数前面必须有一个空格， 为防止与 \\${parameter:-word} 展开形式混淆。length，若出现，则必须不能小于零。\n\n## \\${parameter#pattern}\n## \\${parameter##pattern}\n这些展开会从 paramter 所包含的字符串中清除开头一部分文本，这些字符要匹配定义的 patten。p\nattern 是 通配符模式，就如那些用在路径名展开中的模式。这两种形式的差异之处是该 \\# 形式清除最短的匹配结果， 而该 \\## 模式清除最长的匹配结果。\n\n```\n[me@linuxbox ~]$ foo=file.txt.zip\n[me@linuxbox ~]$ echo ${foo#*.}\ntxt.zip\n[me@linuxbox ~]$ echo ${foo##*.}\nzip\n```\n\n## \\${parameter%pattern}\n## \\${parameter%%pattern}\n\n这些展开和上面的 \\# 和 \\## 展开一样，除了它们清除的文本从 parameter 所包含字符串的末尾开始，而不是开头。\n```\n[me@linuxbox ~]$ foo=file.txt.zip\n[me@linuxbox ~]$ echo ${foo%.*}\nfile.txt\n[me@linuxbox ~]$ echo ${foo%%.*}\nfile\n```\n\n## time\n使用 time 命令来比较这两个脚本版本的效率\ntime可以测试脚本的执行时间\n\n## declare 命令可以用来把字符串规范成大写或小写字符\n使用 declare 命令，我们能强制一个 变量总是包含所需的格式，无论如何赋值给它。\ndeclare -u upper\ndeclare -l lower\n\n## 大小写转换参数展开\n* ${parameter,,}    把 parameter 的值全部展开成小写字母。\n* ${parameter,}     仅仅把 parameter 的第一个字符展开成小写字母。\n* ${parameter^^}    把 parameter 的值全部转换成大写字母。\n* ${parameter^}     仅仅把 parameter 的第一个字符转换成大写字母（首字母大写）。\n\n## 在算术表达式中，shell 支持任意进制的整形常量。\n* number      默认情况下，没有任何表示法的数字被看做是十进制数（以10为底）。\n* 0number     在算术表达式中，以零开头的数字被认为是八进制数。\n* 0xnumber    十六进制表示法\n* base#number number 以 base 为底\n\n## bc - 一种高精度计算器语言\n\n","slug":"TLCL_notes_35","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5jq0023mcxq7ewemcnd"},{"title":"<<The Linux Command Line>> 第六章笔记","date":"2015-09-07T12:00:06.000Z","_content":"## 命令\n\n命令可以是下面四种形式之一：\n\n* 一个可执行程序，就像我们所看到的位于目录/usr/bin中的文件一样。属于这一类的程序，可以是二进制文件，诸如用C和C++语言写成的程序, 也可以是由脚本语言写成的程序，比如说shell，python等等。\n* 一个内建于shell自身的命令。bash 支持若干命令，内部叫做shell内部命令 (builtins)。例如，cd 命令，就是一个shell内部命令。\n* 一个 shell 函数。这些是小规模的shell脚本，它们混合到环境变量中。在后续的章节里，我们将讨论配置环境变量以及书写shell函数。但是现在，仅仅意识到它们的存在就可以了。\n* 一个命令别名。我们可以定义自己的命令，建立在其它命令之上。\n\ntype － 显示命令的类型\n\nwhich － 显示一个可执行程序的位置\n\nhelp － 得到 shell 内部命令的帮助文档\n\napropos － 搜索参考手册并显示适当的命令\n\nwhatis － 显示非常简洁的命令说明\n\n## 别名\n使用alias之前用type检查打算使用的别名名称是否已被占用\n```\nalias foo='cd /usr; ls; cd -'\n```\n\n删除别名，使用 unalias 命令，像这样：\n```\nunalias foo\n```\n\n直接输入alias显示所有别名\n\n","source":"_posts/TLCL_notes_6.md","raw":"title: <<The Linux Command Line>> 第六章笔记\ndate: 2015-09-07 20:00:06\ntags: [linux, bash]\n---\n## 命令\n\n命令可以是下面四种形式之一：\n\n* 一个可执行程序，就像我们所看到的位于目录/usr/bin中的文件一样。属于这一类的程序，可以是二进制文件，诸如用C和C++语言写成的程序, 也可以是由脚本语言写成的程序，比如说shell，python等等。\n* 一个内建于shell自身的命令。bash 支持若干命令，内部叫做shell内部命令 (builtins)。例如，cd 命令，就是一个shell内部命令。\n* 一个 shell 函数。这些是小规模的shell脚本，它们混合到环境变量中。在后续的章节里，我们将讨论配置环境变量以及书写shell函数。但是现在，仅仅意识到它们的存在就可以了。\n* 一个命令别名。我们可以定义自己的命令，建立在其它命令之上。\n\ntype － 显示命令的类型\n\nwhich － 显示一个可执行程序的位置\n\nhelp － 得到 shell 内部命令的帮助文档\n\napropos － 搜索参考手册并显示适当的命令\n\nwhatis － 显示非常简洁的命令说明\n\n## 别名\n使用alias之前用type检查打算使用的别名名称是否已被占用\n```\nalias foo='cd /usr; ls; cd -'\n```\n\n删除别名，使用 unalias 命令，像这样：\n```\nunalias foo\n```\n\n直接输入alias显示所有别名\n\n","slug":"TLCL_notes_6","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5jr0025mcxqyv3w6on5"},{"title":"<<The Linux Command Line>> 第七章笔记 重定向","date":"2015-09-07T12:00:07.000Z","_content":"## uniq\n报道或省略重复行\n如果只想看哪些行是重复的, 使用参数-d\n\n## 重定向\n标准输入0,标准输出1,标准错误2\n重定向错误输出\n```\n[me@linuxbox ~]$ ls -l /bin/usr 2> ls-error.txt\n```\n重定向标准输出和错误到同一个文件\n```\n[me@linuxbox ~]$ ls -l /bin/usr &> ls-output.txt\n```\n或\n```\n[me@linuxbox ~]$ ls -l /bin/usr > ls-output.txt 2>&1\n```\n为了隐瞒命令错误信息，我们这样做：\n```\n[me@linuxbox ~]$ ls -l /bin/usr 2> /dev/null\n```\n\n## cat\n连接用法\n因为cat可以接受不只一个文件作为参数，所以它也可以用来把文件连接在一起。\n比方说我们下载了一个大型文件，这个文件被分离成多个部分（USENET 中的多媒体文件经常以这种方式分离），\n我们能用这个命令把它们连接起来：\n```\ncat movie.mpeg.0* > movie.mpeg\n```\n因为通配符总是以有序的方式展开，所以这些参数会以正确顺序安排。\n\n重定向标准输入\n```\n[me@linuxbox ~]$ cat < lazy_dog.txt\n```\n\n## wc\n打印行，字和字节数\n* -w, --words            显示单词计数\n* -l, --lines            print the newline counts\n* -c, --bytes            print the byte counts\n* -m, --chars            print the character counts\n\n## head & tail\nhead 命令打印文件的前十行\ntail 命令打印文件的后十行\n默认情况下，两个命令 都打印十行文本，但是可以通过”-n”选项来调整命令打印的行数。\n\n## tee\n从 Stdin 读取数据，并同时输出到 Stdout 和文件\n```\n[me@linuxbox ~]$ ls /usr/bin | tee ls.txt | grep zip\n```\n\n","source":"_posts/TLCL_notes_7.md","raw":"title: <<The Linux Command Line>> 第七章笔记 重定向\ndate: 2015-09-07 20:00:07\ntags: [linux, bash]\n---\n## uniq\n报道或省略重复行\n如果只想看哪些行是重复的, 使用参数-d\n\n## 重定向\n标准输入0,标准输出1,标准错误2\n重定向错误输出\n```\n[me@linuxbox ~]$ ls -l /bin/usr 2> ls-error.txt\n```\n重定向标准输出和错误到同一个文件\n```\n[me@linuxbox ~]$ ls -l /bin/usr &> ls-output.txt\n```\n或\n```\n[me@linuxbox ~]$ ls -l /bin/usr > ls-output.txt 2>&1\n```\n为了隐瞒命令错误信息，我们这样做：\n```\n[me@linuxbox ~]$ ls -l /bin/usr 2> /dev/null\n```\n\n## cat\n连接用法\n因为cat可以接受不只一个文件作为参数，所以它也可以用来把文件连接在一起。\n比方说我们下载了一个大型文件，这个文件被分离成多个部分（USENET 中的多媒体文件经常以这种方式分离），\n我们能用这个命令把它们连接起来：\n```\ncat movie.mpeg.0* > movie.mpeg\n```\n因为通配符总是以有序的方式展开，所以这些参数会以正确顺序安排。\n\n重定向标准输入\n```\n[me@linuxbox ~]$ cat < lazy_dog.txt\n```\n\n## wc\n打印行，字和字节数\n* -w, --words            显示单词计数\n* -l, --lines            print the newline counts\n* -c, --bytes            print the byte counts\n* -m, --chars            print the character counts\n\n## head & tail\nhead 命令打印文件的前十行\ntail 命令打印文件的后十行\n默认情况下，两个命令 都打印十行文本，但是可以通过”-n”选项来调整命令打印的行数。\n\n## tee\n从 Stdin 读取数据，并同时输出到 Stdout 和文件\n```\n[me@linuxbox ~]$ ls /usr/bin | tee ls.txt | grep zip\n```\n\n","slug":"TLCL_notes_7","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5js0027mcxqziyuasei"},{"title":"<<The Linux Command Line>> 第八章笔记 从shell眼中看世界","date":"2015-09-07T12:00:08.000Z","_content":"bash在执行你的命令之前做的预处理\n## 展开 \n* 通配符\n* 波浪线~\n* 算术表达式展开\n* 花括号 \n* 参数展开\n* 历史记录展开\n* 命令替换\n* 引用\n* 双引号\n* 单引号\n* 转义字符\n* 转义序列\n\n展开不会包括隐藏文件,除非以.*这样的方式展开\n\n## 算术表达式展开\n$((expression)) 只支持整数四则运算,取余和幂\n\n## 花括号展开\n```\nmkdir {2007..2009}-0{1..9} {2007..2009}-{10..12}\n```\n\n## 历史记录展开\n!!      重复最后一次执行的命令。可能按下上箭头按键和 enter 键更容易些。\n!number 重复历史列表中第 number 行的命令。\n\n## 命令替换 \n```\nls -l $(which cp) 等同于 ls -l `which cp`\n```\n\n## 双引号 \n除了 $，\\ (反斜杠），和 `（反引号）之外， 当作普通字符来看待\n\n## 单引号\n禁止所有的展开\n\n## 转义字符\n反斜杠\n\n## 转义序列\n```\n\\a \\b \\t等等 \n可以这样解释: $'\\n' 或 echo -e 解释转义字符,否则不解释 \n```\n\n","source":"_posts/TLCL_notes_8.md","raw":"title: <<The Linux Command Line>> 第八章笔记 从shell眼中看世界\ndate: 2015-09-07 20:00:08\ntags: [linux, bash]\n---\nbash在执行你的命令之前做的预处理\n## 展开 \n* 通配符\n* 波浪线~\n* 算术表达式展开\n* 花括号 \n* 参数展开\n* 历史记录展开\n* 命令替换\n* 引用\n* 双引号\n* 单引号\n* 转义字符\n* 转义序列\n\n展开不会包括隐藏文件,除非以.*这样的方式展开\n\n## 算术表达式展开\n$((expression)) 只支持整数四则运算,取余和幂\n\n## 花括号展开\n```\nmkdir {2007..2009}-0{1..9} {2007..2009}-{10..12}\n```\n\n## 历史记录展开\n!!      重复最后一次执行的命令。可能按下上箭头按键和 enter 键更容易些。\n!number 重复历史列表中第 number 行的命令。\n\n## 命令替换 \n```\nls -l $(which cp) 等同于 ls -l `which cp`\n```\n\n## 双引号 \n除了 $，\\ (反斜杠），和 `（反引号）之外， 当作普通字符来看待\n\n## 单引号\n禁止所有的展开\n\n## 转义字符\n反斜杠\n\n## 转义序列\n```\n\\a \\b \\t等等 \n可以这样解释: $'\\n' 或 echo -e 解释转义字符,否则不解释 \n```\n\n","slug":"TLCL_notes_8","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5js0029mcxqk1dstqel"},{"title":"TTL","date":"2016-06-07T02:58:00.000Z","_content":"\nTTL值可以被看做是Ip数据报可以在一个网络系统中生存的上限时间.\nTTL值由发送方设置,去往目的地过程中的每一个路由都会减少这个值,\n如果在到达目的地之前该值被减到零,则数据报被丢弃且发送方会收到ICMP超时错误包.\nTTL的设计目的是为了防止不可到达的数据报在网络系统中无限循环,造成拥塞.\n\n理论上, TTL(time to live)应该是以秒为单位, 但事实上每一跳都只减1, 于是Ipv6里就改叫hop limit了.\n\nIp协议中, TTL是一个8位数, 即0-255, 推荐初始值为64.\n\n","source":"_posts/TTL.md","raw":"title: TTL\ndate: 2016-06-07 10:58:00\ntags: [internet]\n---\n\nTTL值可以被看做是Ip数据报可以在一个网络系统中生存的上限时间.\nTTL值由发送方设置,去往目的地过程中的每一个路由都会减少这个值,\n如果在到达目的地之前该值被减到零,则数据报被丢弃且发送方会收到ICMP超时错误包.\nTTL的设计目的是为了防止不可到达的数据报在网络系统中无限循环,造成拥塞.\n\n理论上, TTL(time to live)应该是以秒为单位, 但事实上每一跳都只减1, 于是Ipv6里就改叫hop limit了.\n\nIp协议中, TTL是一个8位数, 即0-255, 推荐初始值为64.\n\n","slug":"TTL","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5jt002bmcxqbgs0p0hq"},{"title":"<<The Linux Command Line>> 第九章笔记 键盘高级操作技巧","date":"2015-09-07T12:00:09.000Z","_content":"* Ctrl-t               光标位置的字符和光标前面的字符互换位置。\n* Alt-l                把从光标位置到字尾的字符转换成小写字母。\n* Alt-u                把从光标位置到字尾的字符转换成大写字母。\n* Ctrl-k               剪切从光标位置到行尾的文本。\n* Alt-d                剪切从光标位置到词尾的文本。\n* Alt-Backspace        剪切从光标位置到词头的文本。如果光标在一个单词的开头，剪切前一个单词。\n* Ctrl-y               把剪切环中的文本粘贴到光标位置。\n* Alt-*(即Alt-Shift-8) 插入所有可能的自动补全。当你想要使用多个可能的匹配项时，这个很有帮助。\n\n可以按下和释放 Esc 键来得到如控制 Alt(meta) 键一样的效果。\n\n可编程自动补全\nset | less\n\n## 搜索历史命令\n在默认情况下，bash 会存储你所输入的最后 500 个命令\n\n启动递增搜索 \n输入 Ctrl-r，其后输入你要寻找的文本。\n当你找到它以后，你可以敲入 Enter 来执行命令，或者输入 Ctrl-j，从历史列表中复制这一行到当前命令行。\n再次输入 Ctrl-r，来找到下一个 匹配项（向上移动历史列表）。输入 Ctrl-g 或者 Ctrl-c，退出搜索。\n\n## 记录整个 shell 会话，并把 shell 会话存在一个文件里面\nscript [file]\n命令中的 file 是指用来存储 shell 会话记录的文件名。如果没有指定文件名，则使用文件 typescript。\n\n","source":"_posts/TLCL_notes_9.md","raw":"title: <<The Linux Command Line>> 第九章笔记 键盘高级操作技巧\ndate: 2015-09-07 20:00:09\ntags: [linux, bash]\n---\n* Ctrl-t               光标位置的字符和光标前面的字符互换位置。\n* Alt-l                把从光标位置到字尾的字符转换成小写字母。\n* Alt-u                把从光标位置到字尾的字符转换成大写字母。\n* Ctrl-k               剪切从光标位置到行尾的文本。\n* Alt-d                剪切从光标位置到词尾的文本。\n* Alt-Backspace        剪切从光标位置到词头的文本。如果光标在一个单词的开头，剪切前一个单词。\n* Ctrl-y               把剪切环中的文本粘贴到光标位置。\n* Alt-*(即Alt-Shift-8) 插入所有可能的自动补全。当你想要使用多个可能的匹配项时，这个很有帮助。\n\n可以按下和释放 Esc 键来得到如控制 Alt(meta) 键一样的效果。\n\n可编程自动补全\nset | less\n\n## 搜索历史命令\n在默认情况下，bash 会存储你所输入的最后 500 个命令\n\n启动递增搜索 \n输入 Ctrl-r，其后输入你要寻找的文本。\n当你找到它以后，你可以敲入 Enter 来执行命令，或者输入 Ctrl-j，从历史列表中复制这一行到当前命令行。\n再次输入 Ctrl-r，来找到下一个 匹配项（向上移动历史列表）。输入 Ctrl-g 或者 Ctrl-c，退出搜索。\n\n## 记录整个 shell 会话，并把 shell 会话存在一个文件里面\nscript [file]\n命令中的 file 是指用来存储 shell 会话记录的文件名。如果没有指定文件名，则使用文件 typescript。\n\n","slug":"TLCL_notes_9","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ju002dmcxqkyfwfwnh"},{"title":"Ubuntu中创建SWAP交换文件","date":"2015-07-21T16:00:00.000Z","_content":"划分交换文件最佳的方式就是将其放到一个单独的分区当中， \n当然，如果无法单独为其划分的话也可以在已有的分区上创建新的交换文件。\n<!--more-->\n## 查看当前系统Swap信息\n\n开始在 Ubuntu 14.04 中创建 Swap 分区之前，我们有必要首先看一下当前操作系统是否有可用的交换分区。\n默认情况下，Ubuntu 在进行系统安装时就会提醒用户划分 Swap 分区，一般情况下划分好之后也是不太会更改的。\n\n我们可以使用如下命令来进行查看：\n```bash\nsudo swapon -s\n```\n当然，我们也可以使用最常用的 free 命令来查看当前系统是否存在 Swap 交换分区：\n```bash\nfree -m\n```\n## 查看磁盘分区的空闲空间\n\n在创建新的 Swap 交换分区或创建交换文件之前，我们需要通过如下命令了解下当前系统对磁盘空间的使用情况：\n```bash\ndf -h\n```\n确定好磁盘的空闲空间后，你已经可以根据你自己的实际情况来决定如何划分和创建 Swap 交换分区了。\n\n## 创建swap文件\n一般情况下，创建 Swap 分区的大小都为当前系统使用的物理内存大小或内存大小的倍数。\n\n如果同样是要创建 4G 大小的交换文件，命令如下：\n```bash\nsudo fallocate -l 4G /swapfile\n```\n## 启用Swap分区文件\n\n我们的 swapfile 交换文件已经创建好了，但 Ubuntu 14.04 还不知道它是被用作交换分区，所以我们还需要将此文件格式化为 Swap 分区交启用它。\n\n首先，我们需要使用如下命令更改下 swapfile 文件的权限，以避免其被无意理性到：\n```bash\nsudo chmod 600 /swapfile\n```\n然后，我们需要用如下将 swapfile 初始化为交换文件：\n```bash\nsudo mkswap /swapfile\n```\n最后，还需要使用如下命令来启用交换文件：\n```bash\nsudo swapon /swapfile\n```\n配置启用时挂载Swap分区文件\n\nSwap 交换文件虽然已经配置好并已经启用了，但 Ubuntu 14.04 在重启后是不会挂载我们刚创建的交换分区文件的，因此我们还需要对 /etc/fstab 文件进行更改，让其在系统启动时就自动挂载我们创建的 /swapfile 文件。\n\n使用 vi 或 nano 在 /etc/fstab 文件底部添加如下内容：\n```bash\n/swapfile none swap sw 0 0\n```\n## 附录\n\n还有一个swapoff命令\n\n","source":"_posts/Ubuntu中创建SWAP交换文件.md","raw":"title: Ubuntu中创建SWAP交换文件\ndate: 2015-07-22\ntags: linux \n---\n划分交换文件最佳的方式就是将其放到一个单独的分区当中， \n当然，如果无法单独为其划分的话也可以在已有的分区上创建新的交换文件。\n<!--more-->\n## 查看当前系统Swap信息\n\n开始在 Ubuntu 14.04 中创建 Swap 分区之前，我们有必要首先看一下当前操作系统是否有可用的交换分区。\n默认情况下，Ubuntu 在进行系统安装时就会提醒用户划分 Swap 分区，一般情况下划分好之后也是不太会更改的。\n\n我们可以使用如下命令来进行查看：\n```bash\nsudo swapon -s\n```\n当然，我们也可以使用最常用的 free 命令来查看当前系统是否存在 Swap 交换分区：\n```bash\nfree -m\n```\n## 查看磁盘分区的空闲空间\n\n在创建新的 Swap 交换分区或创建交换文件之前，我们需要通过如下命令了解下当前系统对磁盘空间的使用情况：\n```bash\ndf -h\n```\n确定好磁盘的空闲空间后，你已经可以根据你自己的实际情况来决定如何划分和创建 Swap 交换分区了。\n\n## 创建swap文件\n一般情况下，创建 Swap 分区的大小都为当前系统使用的物理内存大小或内存大小的倍数。\n\n如果同样是要创建 4G 大小的交换文件，命令如下：\n```bash\nsudo fallocate -l 4G /swapfile\n```\n## 启用Swap分区文件\n\n我们的 swapfile 交换文件已经创建好了，但 Ubuntu 14.04 还不知道它是被用作交换分区，所以我们还需要将此文件格式化为 Swap 分区交启用它。\n\n首先，我们需要使用如下命令更改下 swapfile 文件的权限，以避免其被无意理性到：\n```bash\nsudo chmod 600 /swapfile\n```\n然后，我们需要用如下将 swapfile 初始化为交换文件：\n```bash\nsudo mkswap /swapfile\n```\n最后，还需要使用如下命令来启用交换文件：\n```bash\nsudo swapon /swapfile\n```\n配置启用时挂载Swap分区文件\n\nSwap 交换文件虽然已经配置好并已经启用了，但 Ubuntu 14.04 在重启后是不会挂载我们刚创建的交换分区文件的，因此我们还需要对 /etc/fstab 文件进行更改，让其在系统启动时就自动挂载我们创建的 /swapfile 文件。\n\n使用 vi 或 nano 在 /etc/fstab 文件底部添加如下内容：\n```bash\n/swapfile none swap sw 0 0\n```\n## 附录\n\n还有一个swapoff命令\n\n","slug":"Ubuntu中创建SWAP交换文件","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5jw002gmcxqry83qy3x"},{"title":"XMonad","date":"2015-07-28T16:00:00.000Z","_content":"平铺式窗口管理器,清爽\n<!--more-->\n## 安装\nsudo apt-get install xmonad suckless-tools\n安装完成后,登出并点击登录窗口右侧的图标,选择XMonad再登入,\n登入后界面是空白的,别害怕,就是这样子的,按Alt+Shift+Enter可以打开一个终端\n\n## 快捷键\nAlt+Shift+Enter 打开一个终端\nAlt+J or Alt+K 移动到其他窗口,另外焦点也跟随鼠标\nAlt+Space 在各种平铺风格之间切换\nAlt+P 下拉应用启动器,可以输入应用程序名并找开\nAlt+Shift+C 关闭当前窗口\nAlt+Enter 交换当前窗口和主窗口\nAlt+Shift+J & Alt+Shift+K 交换当前窗口和下一窗口\nAlt+H & Alt+L 放大缩小当前窗口\nAlt+, Alt+. 增减主区窗格数\nAlt+鼠标左键 移出并移动浮动窗口\nAlt+T 将浮动窗口移回\nAlt+Shift+Q 退出Xmonad\nAlt+1 - Alt+9 切换工作区\nAlt+Shift+3 将当前窗口移动到指定工作区\nAlt+Q 重新加载配置\n\n## 配置文件路径 \n~/.xmonad/xmonad.hs\n\n## 参考链接\nhttps://wiki.haskell.org/Xmonad/Using_xmonad_in_Gnome\nhttps://wiki.haskell.org/Xmonad/Config_archive/Template_xmonad.hs_%280.8%29\nhttps://wiki.haskell.org/Xmonad/General_xmonad.hs_config_tips\n\n","source":"_posts/XMonad.md","raw":"title: XMonad\ndate: 2015-07-29\ntags: [linux, haskell, gui]\n---\n平铺式窗口管理器,清爽\n<!--more-->\n## 安装\nsudo apt-get install xmonad suckless-tools\n安装完成后,登出并点击登录窗口右侧的图标,选择XMonad再登入,\n登入后界面是空白的,别害怕,就是这样子的,按Alt+Shift+Enter可以打开一个终端\n\n## 快捷键\nAlt+Shift+Enter 打开一个终端\nAlt+J or Alt+K 移动到其他窗口,另外焦点也跟随鼠标\nAlt+Space 在各种平铺风格之间切换\nAlt+P 下拉应用启动器,可以输入应用程序名并找开\nAlt+Shift+C 关闭当前窗口\nAlt+Enter 交换当前窗口和主窗口\nAlt+Shift+J & Alt+Shift+K 交换当前窗口和下一窗口\nAlt+H & Alt+L 放大缩小当前窗口\nAlt+, Alt+. 增减主区窗格数\nAlt+鼠标左键 移出并移动浮动窗口\nAlt+T 将浮动窗口移回\nAlt+Shift+Q 退出Xmonad\nAlt+1 - Alt+9 切换工作区\nAlt+Shift+3 将当前窗口移动到指定工作区\nAlt+Q 重新加载配置\n\n## 配置文件路径 \n~/.xmonad/xmonad.hs\n\n## 参考链接\nhttps://wiki.haskell.org/Xmonad/Using_xmonad_in_Gnome\nhttps://wiki.haskell.org/Xmonad/Config_archive/Template_xmonad.hs_%280.8%29\nhttps://wiki.haskell.org/Xmonad/General_xmonad.hs_config_tips\n\n","slug":"XMonad","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5jy002imcxqsuelau0h"},{"title":"苹果内购IAP(In Application Purchase)","date":"2018-10-10T16:00:00.000Z","_content":"\n苹果 receipt 中的 in_app 列表为空表示用户并没有付款\n这种 receipt 可能是用户通过工具产生的欺诈数据\n\n<!--more-->\n\n### 参考链接\n\nhttps://forums.developer.apple.com/thread/8954\n\n","source":"_posts/apple_iap.md","raw":"title: 苹果内购IAP(In Application Purchase)\ndate: 2018-10-11\ntags: [apple, iap, payment]\n---\n\n苹果 receipt 中的 in_app 列表为空表示用户并没有付款\n这种 receipt 可能是用户通过工具产生的欺诈数据\n\n<!--more-->\n\n### 参考链接\n\nhttps://forums.developer.apple.com/thread/8954\n\n","slug":"apple_iap","published":1,"updated":"2018-10-11T07:34:01.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5jz002kmcxqbuvoofbv"},{"title":"base64指南","date":"2015-07-20T16:00:00.000Z","_content":"## 用途\n一般用于将二进制数据编码成字符串方便URL传输,也解决了非ASCII字符,比如中文字符,的传输问题。\nBase64 也会经常用作一个简单的“加密”来保护某些数据，而真正的加密通常都比较繁琐。\n垃圾讯息传播者用Base64来避过反垃圾邮件工具，因为那些工具通常都不会翻译Base64的讯息。\n<!--more-->\n## 转码示例 \"hey\" => \"aGV5\"\n| 步骤      | 结果                                |\n|-------------------------------------------------|\n| ascii     | 104 101 121                         |   \n| 2进制     | 01101000 01100101 01111001          |    \n| 6位分组   | 011010 000110 010101 111001         |      \n| 高位补零  | 00011010 00000110 00010101 00111001 |              \n| 10进制    | 26 6 21 57                          |\n| 查对照表  | a G V 5                             |               \n\n转换结果的长度必然是4的倍数,不足的部分补=号,一个字节的转成两个字节补两个=号,两个字节的转成三个字节补一个=号\n如: \"1\" => \"MQ==\", \"12\" => \"MTI=\"\n\n经过Base64编码后的数据会比原始数据长，至少为原来的4/3倍。\nRFC2045还规定，在电子邮件中，每行为76个字符，每行末需添加一个回车换行符(\"\\r\\n\")。\n\n## 变种\n标准的Base64并不适合直接放在URL里传输，因为URL编码器会把标准Base64中的“/”和“+”字符变为形如“%XX”的形式，\n而这些“%”号在存入数据库时还需要再进行转换，因为ANSI SQL中已将“%”号用作通配符。\n为解决此问题，可采用一种用于URL的改进Base64编码，它不仅在末尾填充'='号，并将标准Base64中的“+”和“/”分别改成了“-”和“_”，\n这样就免去了在URL编解码和数据库存储时所要作的转换，避免了编码信息长度在此过程中的增加，并统一了数据库、表单等处对象标识符的格式。\n\n另有一种用于正则表达式的改进Base64变种，它将“+”和“/”改成了“!”和“-”，因为“+”,“*”以及“[”和“]”在正则表达式中都具有特殊含义。\n\n此外还有一些变种，它们将“+/”改为“_-”或“._”（用作编程语言中的标识符名称）或“.-”（用于XML中的Nmtoken）甚至“_:”（用于XML中的Name）。\n\n## Base64编码表\n| 码值 | 字符 | 码值 | 字符 | 码值 | 字符 |  码值 | 字符 |  \n| ------------------------------------------------------ |\n| 0    | A    | 16   | Q    | 32   | g    |  48   | w    | \n| 1    | B    | 17   | R    | 33   | h    |  49   | x    | \n| 2    | C    | 18   | S    | 34   | i    |  50   | y    | \n| 3    | D    | 19   | T    | 35   | j    |  51   | z    | \n| 4    | E    | 20   | U    | 36   | k    |  52   | 0    | \n| 5    | F    | 21   | V    | 37   | l    |  53   | 1    | \n| 6    | G    | 22   | W    | 38   | m    |  54   | 2    | \n| 7    | H    | 23   | X    | 39   | n    |  55   | 3    | \n| 8    | I    | 24   | Y    | 40   | o    |  56   | 4    | \n| 9    | J    | 25   | Z    | 41   | p    |  57   | 5    | \n| 10   | K    | 26   | a    | 42   | q    |  58   | 6    | \n| 11   | L    | 27   | b    | 43   | r    |  59   | 7    | \n| 12   | M    | 28   | c    | 44   | s    |  60   | 8    | \n| 13   | N    | 29   | d    | 45   | t    |  61   | 9    | \n| 14   | O    | 30   | e    | 46   | u    |  62   | +    | \n| 15   | P    | 31   | f    | 47   | v    |  63   | /    | \n\n","source":"_posts/base64指南.md","raw":"title: base64指南\ndate: 2015-07-21\ntags: encoding\n---\n## 用途\n一般用于将二进制数据编码成字符串方便URL传输,也解决了非ASCII字符,比如中文字符,的传输问题。\nBase64 也会经常用作一个简单的“加密”来保护某些数据，而真正的加密通常都比较繁琐。\n垃圾讯息传播者用Base64来避过反垃圾邮件工具，因为那些工具通常都不会翻译Base64的讯息。\n<!--more-->\n## 转码示例 \"hey\" => \"aGV5\"\n| 步骤      | 结果                                |\n|-------------------------------------------------|\n| ascii     | 104 101 121                         |   \n| 2进制     | 01101000 01100101 01111001          |    \n| 6位分组   | 011010 000110 010101 111001         |      \n| 高位补零  | 00011010 00000110 00010101 00111001 |              \n| 10进制    | 26 6 21 57                          |\n| 查对照表  | a G V 5                             |               \n\n转换结果的长度必然是4的倍数,不足的部分补=号,一个字节的转成两个字节补两个=号,两个字节的转成三个字节补一个=号\n如: \"1\" => \"MQ==\", \"12\" => \"MTI=\"\n\n经过Base64编码后的数据会比原始数据长，至少为原来的4/3倍。\nRFC2045还规定，在电子邮件中，每行为76个字符，每行末需添加一个回车换行符(\"\\r\\n\")。\n\n## 变种\n标准的Base64并不适合直接放在URL里传输，因为URL编码器会把标准Base64中的“/”和“+”字符变为形如“%XX”的形式，\n而这些“%”号在存入数据库时还需要再进行转换，因为ANSI SQL中已将“%”号用作通配符。\n为解决此问题，可采用一种用于URL的改进Base64编码，它不仅在末尾填充'='号，并将标准Base64中的“+”和“/”分别改成了“-”和“_”，\n这样就免去了在URL编解码和数据库存储时所要作的转换，避免了编码信息长度在此过程中的增加，并统一了数据库、表单等处对象标识符的格式。\n\n另有一种用于正则表达式的改进Base64变种，它将“+”和“/”改成了“!”和“-”，因为“+”,“*”以及“[”和“]”在正则表达式中都具有特殊含义。\n\n此外还有一些变种，它们将“+/”改为“_-”或“._”（用作编程语言中的标识符名称）或“.-”（用于XML中的Nmtoken）甚至“_:”（用于XML中的Name）。\n\n## Base64编码表\n| 码值 | 字符 | 码值 | 字符 | 码值 | 字符 |  码值 | 字符 |  \n| ------------------------------------------------------ |\n| 0    | A    | 16   | Q    | 32   | g    |  48   | w    | \n| 1    | B    | 17   | R    | 33   | h    |  49   | x    | \n| 2    | C    | 18   | S    | 34   | i    |  50   | y    | \n| 3    | D    | 19   | T    | 35   | j    |  51   | z    | \n| 4    | E    | 20   | U    | 36   | k    |  52   | 0    | \n| 5    | F    | 21   | V    | 37   | l    |  53   | 1    | \n| 6    | G    | 22   | W    | 38   | m    |  54   | 2    | \n| 7    | H    | 23   | X    | 39   | n    |  55   | 3    | \n| 8    | I    | 24   | Y    | 40   | o    |  56   | 4    | \n| 9    | J    | 25   | Z    | 41   | p    |  57   | 5    | \n| 10   | K    | 26   | a    | 42   | q    |  58   | 6    | \n| 11   | L    | 27   | b    | 43   | r    |  59   | 7    | \n| 12   | M    | 28   | c    | 44   | s    |  60   | 8    | \n| 13   | N    | 29   | d    | 45   | t    |  61   | 9    | \n| 14   | O    | 30   | e    | 46   | u    |  62   | +    | \n| 15   | P    | 31   | f    | 47   | v    |  63   | /    | \n\n","slug":"base64指南","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5k0002nmcxqy6twceho"},{"title":"apache ab","date":"2016-06-06T09:07:00.000Z","_content":"\n压力测试常用工具, apache bench\n下例, 模拟1500并发连接, 3000次请求\n```\napt-get install apache2-utils\nab -n 3000 -c 1500 -w http://blog.suexcxine.cc/ >> 1.html\n```\n\n","source":"_posts/apache_ab.md","raw":"title: apache ab\ndate: 2016-06-06 17:07:00\ntags: [internet, test]\n---\n\n压力测试常用工具, apache bench\n下例, 模拟1500并发连接, 3000次请求\n```\napt-get install apache2-utils\nab -n 3000 -c 1500 -w http://blog.suexcxine.cc/ >> 1.html\n```\n\n","slug":"apache_ab","published":1,"updated":"2018-10-11T07:33:41.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5k1002pmcxqd0uupil1"},{"title":"aws ec2时区设定","date":"2018-09-11T16:00:00.000Z","_content":"\n有时候服务器时区不想用UTC, 需要修改\n<!--more-->\n\n## 时区设定\n\n修改这个文件里的ZONE\n```\nsudo vi /etc/sysconfig/clock\n```\n可选项可以看这里\n```\nls /usr/share/zoneinfo\n```\n如下例:\n```\nZONE=\"America/Los_Angeles\"\n```\n\n修改软链\n```\nsudo ln -sf /usr/share/zoneinfo/America/Los_Angeles /etc/localtime\n```\n重启\n```\nsudo reboot\n```\n\n## 参考链接\nhttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/set-time.html#change_time_zone\n\n","source":"_posts/aws_ec2_timezone.md","raw":"title: aws ec2时区设定\ndate: 2018-09-12\ntags: [aws, ec2, timezone]\n---\n\n有时候服务器时区不想用UTC, 需要修改\n<!--more-->\n\n## 时区设定\n\n修改这个文件里的ZONE\n```\nsudo vi /etc/sysconfig/clock\n```\n可选项可以看这里\n```\nls /usr/share/zoneinfo\n```\n如下例:\n```\nZONE=\"America/Los_Angeles\"\n```\n\n修改软链\n```\nsudo ln -sf /usr/share/zoneinfo/America/Los_Angeles /etc/localtime\n```\n重启\n```\nsudo reboot\n```\n\n## 参考链接\nhttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/set-time.html#change_time_zone\n\n","slug":"aws_ec2_timezone","published":1,"updated":"2018-09-12T06:59:26.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5k1002rmcxqzuckbnmx"},{"title":"bash","date":"2015-09-06T16:00:00.000Z","_content":"## .bash_profile和.bashrc的异同\n**.bash_profile** console登录时执行\n**.bashrc** 非登录的交互式shell执行\n\n## 可以在.bash_profile里加入如下代码\n```bash\nif [ -f ~/.bashrc ]; then\n   source ~/.bashrc\nfi\n```\n这样通过console登录时也会执行.bashrc\n\n## bash -c\nbash -c command 执行命令\n\n## 用source命令执行脚本文件和用sh执行脚本文件的区别\n用source执行脚本文件，执行过程不另开进程，脚本文件中设定的变量在当前shell中可以看到；\n用sh执行脚本文件，是在当前进程另开子进程来执行脚本命令，脚本文件中设定的变量在当前shell中不能看到。\n\n## select语句\n提示用户选一项\n```bash\n#!/bin/bash\nmystack='a 123 test'\nselect entry in $mystack; do\n    if [ $entry ]; then\n        echo \"You select the choice '$entry'\"\n    else\n        echo \"choice invalid\"\n    fi\ndone\n```\n\n","source":"_posts/bash.md","raw":"title: bash\ndate: 2015-09-07\ntags: linux\n---\n## .bash_profile和.bashrc的异同\n**.bash_profile** console登录时执行\n**.bashrc** 非登录的交互式shell执行\n\n## 可以在.bash_profile里加入如下代码\n```bash\nif [ -f ~/.bashrc ]; then\n   source ~/.bashrc\nfi\n```\n这样通过console登录时也会执行.bashrc\n\n## bash -c\nbash -c command 执行命令\n\n## 用source命令执行脚本文件和用sh执行脚本文件的区别\n用source执行脚本文件，执行过程不另开进程，脚本文件中设定的变量在当前shell中可以看到；\n用sh执行脚本文件，是在当前进程另开子进程来执行脚本命令，脚本文件中设定的变量在当前shell中不能看到。\n\n## select语句\n提示用户选一项\n```bash\n#!/bin/bash\nmystack='a 123 test'\nselect entry in $mystack; do\n    if [ $entry ]; then\n        echo \"You select the choice '$entry'\"\n    else\n        echo \"choice invalid\"\n    fi\ndone\n```\n\n","slug":"bash","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5k2002umcxq4qp0z6x8"},{"title":"bash builtin","date":"2016-06-04T12:23:00.000Z","_content":"\nbash内建函数在bash内部直接执行,\n而其他函数一般需要另起一个进程执行\n<!--more-->\n\n## export\n\n导出环境变量或函数到当前shell的所有的子进程\n```\nexport varname=value\nexport -f functionname # exports a function in the current shell.\n```\n\n## eval\n将所有的参数拼到一起并执行\n```\nif [ ! -z $1 ]\nthen\n    proccomm=\"ps -e -o pcpu,cpu,nice,state,cputime,args --sort pcpu | grep $1\"\nelse\n    proccomm=\"ps -e -o pcpu,cpu,nice,state,cputime,args --sort pcpu\"\nfi\neval $proccomm\n```\n\n## pwd\npwd与/bin/pwd不同, /bin/pwd不是shell builtin\npwd返回的是${PWD}, 有软链时/bin/pwd可返回真实路径\n\n## hash\nlinux记录最近使用的命令的路径, 以避免每次执行命令都去$PATH里搜索\nhash命令返回hash的命令路径和使用次数\n-d可以删一条, -r全清\n```\n$ hash\nhits    command\n2    /usr/bin/ps\n4    /usr/bin/ls\n```\n\n如下可用于判断某命令是否在$PATH里存在\n```\n$ hash xxx\nbash: hash: xxx: 未找到\n```\n\n## readonly\n标记一个变量或函数为只读\n\n## shift\n位置参数左移, 如每次以$1取参数配合shift就可以遍历所有参数\n\n## test\n判断并返回0或1\n\n## set\n用于设置shell内部变量, 不带参数的set返回所有这些变量和值\nset命令还可用于设置位置参数的值\n\n```\n$ set +o history # To disable the history storing.\n+o disables the given options.\n\n$ set -o history\n-o enables the history\n\n$ cat set.sh\nvar=\"Welcome to thegeekstuff\"\nset -- $var\necho \"\\$1=\" $1\necho \"\\$2=\" $2\necho \"\\$3=\" $3\n\n$ ./set.sh\n$1=Welcome\n$2=to\n$3=thegeekstuff\n```\n\n## 参考链接\nhttp://www.thegeekstuff.com/2010/08/bash-shell-builtin-commands/\n\n","source":"_posts/bash_builtin.md","raw":"title: bash builtin\ndate: 2016-06-04 20:23:00\ntags: [linux, bash]\n---\n\nbash内建函数在bash内部直接执行,\n而其他函数一般需要另起一个进程执行\n<!--more-->\n\n## export\n\n导出环境变量或函数到当前shell的所有的子进程\n```\nexport varname=value\nexport -f functionname # exports a function in the current shell.\n```\n\n## eval\n将所有的参数拼到一起并执行\n```\nif [ ! -z $1 ]\nthen\n    proccomm=\"ps -e -o pcpu,cpu,nice,state,cputime,args --sort pcpu | grep $1\"\nelse\n    proccomm=\"ps -e -o pcpu,cpu,nice,state,cputime,args --sort pcpu\"\nfi\neval $proccomm\n```\n\n## pwd\npwd与/bin/pwd不同, /bin/pwd不是shell builtin\npwd返回的是${PWD}, 有软链时/bin/pwd可返回真实路径\n\n## hash\nlinux记录最近使用的命令的路径, 以避免每次执行命令都去$PATH里搜索\nhash命令返回hash的命令路径和使用次数\n-d可以删一条, -r全清\n```\n$ hash\nhits    command\n2    /usr/bin/ps\n4    /usr/bin/ls\n```\n\n如下可用于判断某命令是否在$PATH里存在\n```\n$ hash xxx\nbash: hash: xxx: 未找到\n```\n\n## readonly\n标记一个变量或函数为只读\n\n## shift\n位置参数左移, 如每次以$1取参数配合shift就可以遍历所有参数\n\n## test\n判断并返回0或1\n\n## set\n用于设置shell内部变量, 不带参数的set返回所有这些变量和值\nset命令还可用于设置位置参数的值\n\n```\n$ set +o history # To disable the history storing.\n+o disables the given options.\n\n$ set -o history\n-o enables the history\n\n$ cat set.sh\nvar=\"Welcome to thegeekstuff\"\nset -- $var\necho \"\\$1=\" $1\necho \"\\$2=\" $2\necho \"\\$3=\" $3\n\n$ ./set.sh\n$1=Welcome\n$2=to\n$3=thegeekstuff\n```\n\n## 参考链接\nhttp://www.thegeekstuff.com/2010/08/bash-shell-builtin-commands/\n\n","slug":"bash_builtin","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5k3002wmcxqhlis0cca"},{"title":"chrome","date":"2016-01-04T16:00:00.000Z","_content":"\n## 快捷键\nC-w             关闭当前标签页,\nC-M-t           重新打开关闭的标签页\nC-t             打开新标签页\nC-M-点击链接    打开并切换到新标签页\nC-1至8          切换到指定编号的标签页\nC-9             切换到最后一个标签页\n\n## 开发者工具\n\n下面这个输入地址栏可以看到网络交互\n\n    chrome://net-internals/#events\n\n如果需要在打开新tab时trace network, 先在console里执行下面的语句\n就可以不打开新tab了\n\n    [].forEach.call(document.querySelectorAll('a'),\n        function(link){\n            if(link.attributes.target) {\n                link.attributes.target.value = '_self';\n            }\n        });\n    window.open = function(url) {\n        location.href = url;\n    };\n\n## 参考链接\nhttp://stackoverflow.com/questions/16210468/chrome-dev-tools-how-to-trace-network-for-a-link-that-opens-a-new-tab\n\n","source":"_posts/chrome.md","raw":"title: chrome\ndate: 2016-01-05\ntags: [web]\n---\n\n## 快捷键\nC-w             关闭当前标签页,\nC-M-t           重新打开关闭的标签页\nC-t             打开新标签页\nC-M-点击链接    打开并切换到新标签页\nC-1至8          切换到指定编号的标签页\nC-9             切换到最后一个标签页\n\n## 开发者工具\n\n下面这个输入地址栏可以看到网络交互\n\n    chrome://net-internals/#events\n\n如果需要在打开新tab时trace network, 先在console里执行下面的语句\n就可以不打开新tab了\n\n    [].forEach.call(document.querySelectorAll('a'),\n        function(link){\n            if(link.attributes.target) {\n                link.attributes.target.value = '_self';\n            }\n        });\n    window.open = function(url) {\n        location.href = url;\n    };\n\n## 参考链接\nhttp://stackoverflow.com/questions/16210468/chrome-dev-tools-how-to-trace-network-for-a-link-that-opens-a-new-tab\n\n","slug":"chrome","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5k5002zmcxqlac8kr5d"},{"title":"数据对齐与CPU","date":"2015-11-19T16:00:00.000Z","_content":"CPU读写内存的单位是一个机器字。\n<!--more-->\n内存可以看成一个byte数组，我们对这个'大数组'中的每个元素进行读写，\n比如在C中我们可以用指针一次读写一个或者更多字节，这是我们一般程序员眼中的内存。\n但是从CPU角度看,CPU是按照'块(chunk)'来读写内存的，\n块的大小可以是2bytes, 4bytes, 8bytes, 16bytes甚至是32bytes。 \n这个CPU访问内存时采用的块的大小，我们可以称为'内存访问粒度'。\n\n程序员眼中的内存：\n```\n-----------------------------------------\n| | | | | | | | | | | | | | | | \n-----------------------------------------\n0 1 2 3 4 5 6 7 8 9 A B C D E F  (地址)\n```\nCPU眼中的内存：(以粒度＝4为例) \n```\n--------------------------------------------------\n| | | |     | | | |     | | | |     | | | | \n--------------------------------------------------\n0 1 2 3     4 5 6 7     8 9 A B     C D E F  (地址)\n```\n\n如果'内存访问粒度'为1，CPU从地址0开始读取，需要4次访问才能将4个字节读到寄存器中； \n同样如果'内存访问粒度'为1，CPU从地址1开始读取，也需要4次访问才能将4个字节读到寄存器中；\n而且对于这种理想中的'内存访问粒度'为1的CPU，所有地址都是'aligned address'。\n\n如果'内存访问粒度'为2，CPU从地址0开始读取，需要2次访问才能将4个字节读到寄存器中；\n每次访存都能从'aligned address'起始。 \n如果'内存访问粒度'为2，CPU从地址1开始读取，相当于内存中数据分布在1,2,3,4三个地址上，\n由于1不是'aligned address'，所以这时CPU要做些其他工作，由于这四个字节分布在三个chunk上，\n所以CPU需要进行三次访存操作，\n第一次读取chunk1(即地址0,1上两个字节，而且仅仅地址1上的数据有用)，\n第二次读取chunk2(即地址2,3上两个字节，这两个地址上的数据都有用)，\n最后一次读取chunk3(即地址5,6上两个字节，而且仅仅地址5上的数据有用)，\n最后CPU会将读取的有用的数据做merge操作，然后放到寄存器中。\n\n同理可以推断如果'内存访问粒度'为4，那么从地址1开始读取，需要2次访问，访问后得到的结果merge后放到寄存器中。\n\n是不是所有的CPU都会帮你这么做呢，当然不是。\n有些厂商的CPU发现你访问unaligned address，就会报错，或者打开调试器或者dump core，\n比如sun sparc solaris绝对不会容忍你访问unaligned address，都会以一个core结束你的程序的执行。\n所以一般编译器都会在编译时做相应的优化,\n以保证程序运行时所有数据都是存储在'aligned address'上的，这就是内存对齐的由来。\n      \n在'Data alignment: Straighten up and fly right'这篇文章中作者还得出一个结论\n那就是：\"如果访问的地址是unaligned的，那么采用大粒度访问内存有可能比小粒度访问内存还要慢\"。\n\n## 参考资料\nhttp://www.cnblogs.com/wanghao111/archive/2009/08/29/1556436.html\nhttp://www.ibm.com/developerworks/library/pa-dalign/\n","source":"_posts/cpu_and_alignment.md","raw":"title: 数据对齐与CPU\ndate: 2015-11-20\ntags: [computer]\n---\nCPU读写内存的单位是一个机器字。\n<!--more-->\n内存可以看成一个byte数组，我们对这个'大数组'中的每个元素进行读写，\n比如在C中我们可以用指针一次读写一个或者更多字节，这是我们一般程序员眼中的内存。\n但是从CPU角度看,CPU是按照'块(chunk)'来读写内存的，\n块的大小可以是2bytes, 4bytes, 8bytes, 16bytes甚至是32bytes。 \n这个CPU访问内存时采用的块的大小，我们可以称为'内存访问粒度'。\n\n程序员眼中的内存：\n```\n-----------------------------------------\n| | | | | | | | | | | | | | | | \n-----------------------------------------\n0 1 2 3 4 5 6 7 8 9 A B C D E F  (地址)\n```\nCPU眼中的内存：(以粒度＝4为例) \n```\n--------------------------------------------------\n| | | |     | | | |     | | | |     | | | | \n--------------------------------------------------\n0 1 2 3     4 5 6 7     8 9 A B     C D E F  (地址)\n```\n\n如果'内存访问粒度'为1，CPU从地址0开始读取，需要4次访问才能将4个字节读到寄存器中； \n同样如果'内存访问粒度'为1，CPU从地址1开始读取，也需要4次访问才能将4个字节读到寄存器中；\n而且对于这种理想中的'内存访问粒度'为1的CPU，所有地址都是'aligned address'。\n\n如果'内存访问粒度'为2，CPU从地址0开始读取，需要2次访问才能将4个字节读到寄存器中；\n每次访存都能从'aligned address'起始。 \n如果'内存访问粒度'为2，CPU从地址1开始读取，相当于内存中数据分布在1,2,3,4三个地址上，\n由于1不是'aligned address'，所以这时CPU要做些其他工作，由于这四个字节分布在三个chunk上，\n所以CPU需要进行三次访存操作，\n第一次读取chunk1(即地址0,1上两个字节，而且仅仅地址1上的数据有用)，\n第二次读取chunk2(即地址2,3上两个字节，这两个地址上的数据都有用)，\n最后一次读取chunk3(即地址5,6上两个字节，而且仅仅地址5上的数据有用)，\n最后CPU会将读取的有用的数据做merge操作，然后放到寄存器中。\n\n同理可以推断如果'内存访问粒度'为4，那么从地址1开始读取，需要2次访问，访问后得到的结果merge后放到寄存器中。\n\n是不是所有的CPU都会帮你这么做呢，当然不是。\n有些厂商的CPU发现你访问unaligned address，就会报错，或者打开调试器或者dump core，\n比如sun sparc solaris绝对不会容忍你访问unaligned address，都会以一个core结束你的程序的执行。\n所以一般编译器都会在编译时做相应的优化,\n以保证程序运行时所有数据都是存储在'aligned address'上的，这就是内存对齐的由来。\n      \n在'Data alignment: Straighten up and fly right'这篇文章中作者还得出一个结论\n那就是：\"如果访问的地址是unaligned的，那么采用大粒度访问内存有可能比小粒度访问内存还要慢\"。\n\n## 参考资料\nhttp://www.cnblogs.com/wanghao111/archive/2009/08/29/1556436.html\nhttp://www.ibm.com/developerworks/library/pa-dalign/\n","slug":"cpu_and_alignment","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5k50031mcxq1buiw9w5"},{"title":"怀旧游戏 新世纪兴亡史","date":"2015-11-29T16:00:00.000Z","_content":"\n终于弥补了小学留下的遗憾\n那时借光盘玩了两关,自己的电脑安装不了,光盘又不能存盘\n可惜不知道游戏名字,多少年来也没能再玩上\n上周搜索了三个小时左右,终于找到游戏名字\n\n![](/pics/df/0.png)\n94年日本FUGA(风雅)System出品, 台湾天堂鸟汉化的战棋类游戏\n\n<!--more-->\n\n有战斗动画, 战争迷雾, 地形(影响移动速度), \n每回合代表两个小时并引发黑夜和白天的切换(会影响各种族角色的战斗属性)\n\n### 生产系统: \n游戏没有钱和交易,装备都来自生产,战斗场景里有生产回合,胜利条件不限制回合数\n各族生产的物品不同, 装备有职业限制\n人物能够携带的物品数量有上限\n\n### 征召系统:\n每个指挥官可以征召最多三队同族的士兵, \n每队士兵的数量是6个, 几乎每被打一次数量都会减少, 被消灭完了部队就消失\n可以重新征召, 征召不需要钱, 只需要一个回合的时间\n\n### 合成系统:\n各族的士兵(人类,精灵,龙族等)可以使用合成胶囊进行融合,以获得更强的能力\n\n![战斗场景](/pics/df/1.png)\n战斗场景\n\n![战斗菜单](/pics/df/2.png)\n战斗菜单\n\n![属性面板](/pics/df/3.png)\n属性面板\n\n![合成部队](/pics/df/4.png)\n合成部队, 图为人类和精灵族合成的混血精灵\n\n![战斗动画](/pics/df/5.png)\n图为阿波\n\n![BOSS喊话](/pics/df/6.png)\nBOSS喊话\n\n![男主角马利欧从监狱岛逃脱来到哈芬公国的港口](/pics/df/df_000.png)\n男主角马利欧从监狱岛逃脱来到哈芬公国的港口\n\n![史兰,珍珠,小红三人加入](/pics/df/df_001.png)\n史兰,珍珠,小红三人加入\n\n![避开草原, 进入树海](/pics/df/df_002.png)\n避开草原, 进入树海\n\n![遇见精灵族, 佳法加入](/pics/df/df_003.png)\n遇见精灵族, 佳法加入\n\n![援救托里斯工业国, 拉玛斯,卡斯加入](/pics/df/df_005.png)\n援救托里斯工业国, 拉玛斯,卡斯加入\n\n![卡路麻大山脉, 越过雪山, 打入敌人腹地, 吉克加入](/pics/df/df_006.png)\n![卡路麻大山脉, 越过雪山, 打入敌人腹地, 吉克加入](/pics/df/df_010.png)\n卡路麻大山脉, 越过雪山, 打入敌人腹地, 吉克加入 \n\n![帝国之村, 梅雅加入](/pics/df/df_015.png)\n帝国之村, 梅雅加入\n\n![对战吸血鬼](/pics/df/df_016.png)\n对战吸血鬼\n\n![神秘人赛亚](/pics/df/df_018.png)\n![神秘人赛亚](/pics/df/df_019.png)\n神秘人赛亚\n\n![雾之城, 芭特和赛亚惨剧](/pics/df/df_021.png)\n![雾之城, 芭特和赛亚惨剧](/pics/df/df_022.png)\n![雾之城, 芭特和赛亚惨剧](/pics/df/df_024.png)\n![雾之城, 芭特和赛亚惨剧](/pics/df/df_025.png)\n![雾之城, 芭特和赛亚惨剧](/pics/df/df_026.png)\n![雾之城, 芭特和赛亚惨剧](/pics/df/df_027.png)\n![雾之城, 芭特和赛亚惨剧](/pics/df/df_028.png)\n雾之城, 芭特和赛亚惨剧\n\n![进入僧院, 葛伦加入](/pics/df/df_029.png)\n![进入僧院, 葛伦加入](/pics/df/df_030.png)\n![进入僧院, 葛伦加入](/pics/df/df_032.png)\n进入僧院, 葛伦加入\n\n![原来达鲁被陨石内的生物所控制,想要获得永生,才有这场战争](/pics/df/df_033.png)\n![原来达鲁被陨石内的生物所控制,想要获得永生,才有这场战争](/pics/df/df_040.png)\n![原来达鲁被陨石内的生物所控制,想要获得永生,才有这场战争](/pics/df/df_041.png)\n![原来达鲁被陨石内的生物所控制,想要获得永生,才有这场战争](/pics/df/df_042.png)\n原来达鲁被陨石内的生物所控制,想要获得永生,才有这场战争\n\n![](/pics/df/df_043.png)\n![](/pics/df/df_045.png)\n![](/pics/df/df_046.png)\n![](/pics/df/df_047.png)\n![](/pics/df/df_049.png)\n![](/pics/df/df_050.png)\n![](/pics/df/df_051.png)\n![](/pics/df/df_052.png)\n![](/pics/df/df_053.png)\n![](/pics/df/df_054.png)\n![](/pics/df/df_055.png)\n![](/pics/df/df_056.png)\n![](/pics/df/df_057.png)\n![](/pics/df/df_058.png)\n![](/pics/df/df_059.png)\n全剧终\n\n","source":"_posts/dead_force.md","raw":"title: 怀旧游戏 新世纪兴亡史\ndate: 2015-11-30\ntags: [game]\n---\n\n终于弥补了小学留下的遗憾\n那时借光盘玩了两关,自己的电脑安装不了,光盘又不能存盘\n可惜不知道游戏名字,多少年来也没能再玩上\n上周搜索了三个小时左右,终于找到游戏名字\n\n![](/pics/df/0.png)\n94年日本FUGA(风雅)System出品, 台湾天堂鸟汉化的战棋类游戏\n\n<!--more-->\n\n有战斗动画, 战争迷雾, 地形(影响移动速度), \n每回合代表两个小时并引发黑夜和白天的切换(会影响各种族角色的战斗属性)\n\n### 生产系统: \n游戏没有钱和交易,装备都来自生产,战斗场景里有生产回合,胜利条件不限制回合数\n各族生产的物品不同, 装备有职业限制\n人物能够携带的物品数量有上限\n\n### 征召系统:\n每个指挥官可以征召最多三队同族的士兵, \n每队士兵的数量是6个, 几乎每被打一次数量都会减少, 被消灭完了部队就消失\n可以重新征召, 征召不需要钱, 只需要一个回合的时间\n\n### 合成系统:\n各族的士兵(人类,精灵,龙族等)可以使用合成胶囊进行融合,以获得更强的能力\n\n![战斗场景](/pics/df/1.png)\n战斗场景\n\n![战斗菜单](/pics/df/2.png)\n战斗菜单\n\n![属性面板](/pics/df/3.png)\n属性面板\n\n![合成部队](/pics/df/4.png)\n合成部队, 图为人类和精灵族合成的混血精灵\n\n![战斗动画](/pics/df/5.png)\n图为阿波\n\n![BOSS喊话](/pics/df/6.png)\nBOSS喊话\n\n![男主角马利欧从监狱岛逃脱来到哈芬公国的港口](/pics/df/df_000.png)\n男主角马利欧从监狱岛逃脱来到哈芬公国的港口\n\n![史兰,珍珠,小红三人加入](/pics/df/df_001.png)\n史兰,珍珠,小红三人加入\n\n![避开草原, 进入树海](/pics/df/df_002.png)\n避开草原, 进入树海\n\n![遇见精灵族, 佳法加入](/pics/df/df_003.png)\n遇见精灵族, 佳法加入\n\n![援救托里斯工业国, 拉玛斯,卡斯加入](/pics/df/df_005.png)\n援救托里斯工业国, 拉玛斯,卡斯加入\n\n![卡路麻大山脉, 越过雪山, 打入敌人腹地, 吉克加入](/pics/df/df_006.png)\n![卡路麻大山脉, 越过雪山, 打入敌人腹地, 吉克加入](/pics/df/df_010.png)\n卡路麻大山脉, 越过雪山, 打入敌人腹地, 吉克加入 \n\n![帝国之村, 梅雅加入](/pics/df/df_015.png)\n帝国之村, 梅雅加入\n\n![对战吸血鬼](/pics/df/df_016.png)\n对战吸血鬼\n\n![神秘人赛亚](/pics/df/df_018.png)\n![神秘人赛亚](/pics/df/df_019.png)\n神秘人赛亚\n\n![雾之城, 芭特和赛亚惨剧](/pics/df/df_021.png)\n![雾之城, 芭特和赛亚惨剧](/pics/df/df_022.png)\n![雾之城, 芭特和赛亚惨剧](/pics/df/df_024.png)\n![雾之城, 芭特和赛亚惨剧](/pics/df/df_025.png)\n![雾之城, 芭特和赛亚惨剧](/pics/df/df_026.png)\n![雾之城, 芭特和赛亚惨剧](/pics/df/df_027.png)\n![雾之城, 芭特和赛亚惨剧](/pics/df/df_028.png)\n雾之城, 芭特和赛亚惨剧\n\n![进入僧院, 葛伦加入](/pics/df/df_029.png)\n![进入僧院, 葛伦加入](/pics/df/df_030.png)\n![进入僧院, 葛伦加入](/pics/df/df_032.png)\n进入僧院, 葛伦加入\n\n![原来达鲁被陨石内的生物所控制,想要获得永生,才有这场战争](/pics/df/df_033.png)\n![原来达鲁被陨石内的生物所控制,想要获得永生,才有这场战争](/pics/df/df_040.png)\n![原来达鲁被陨石内的生物所控制,想要获得永生,才有这场战争](/pics/df/df_041.png)\n![原来达鲁被陨石内的生物所控制,想要获得永生,才有这场战争](/pics/df/df_042.png)\n原来达鲁被陨石内的生物所控制,想要获得永生,才有这场战争\n\n![](/pics/df/df_043.png)\n![](/pics/df/df_045.png)\n![](/pics/df/df_046.png)\n![](/pics/df/df_047.png)\n![](/pics/df/df_049.png)\n![](/pics/df/df_050.png)\n![](/pics/df/df_051.png)\n![](/pics/df/df_052.png)\n![](/pics/df/df_053.png)\n![](/pics/df/df_054.png)\n![](/pics/df/df_055.png)\n![](/pics/df/df_056.png)\n![](/pics/df/df_057.png)\n![](/pics/df/df_058.png)\n![](/pics/df/df_059.png)\n全剧终\n\n","slug":"dead_force","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5k70034mcxqdt8co46u"},{"title":"找出链表中环的起点","date":"2016-03-15T16:00:00.000Z","_content":"一般的思路是遍历链表,每一步的指针都记到一个字典里,\n如果当前指针在字典里存在即环存在,该指针即环的起点,\n这个字典能否省掉呢?\n\n<!--more-->\n\n## 检测链表是否有环,使用双指针追击法\n从head出发,快指针一次走两步,慢指针一次走一步。\n如果两指针在某一点相遇,证明环存在,否则环不存在(快指针必定会遇到NULL结束循环)\n\n## 如何找到环的起点\n如下图,假设链表有环,环长Y,环以外的长度是X。\n![图片标题](http://leanote.com/api/file/getImage?fileId=56e8deb7ab6441777b002123)\n如果两指针走了t次后相遇在K点,\n那么\n\n    慢指针走的路是 t = X + nY + K   ①\n    快指针走的路是2t = X + mY + K   ②    m,n为未知数\n    把等式一代入到等式二中, 有\n    2X + 2nY + 2K = X + mY + K\n    => X + K = (m - 2n)Y   ③\n\nX+K即K+X, 即K的长度加X的长度相当于m-2n个整圈(Y)长度\n而快指针此时在环中K的位置,所以从K点再走X步即可达环的起点(虽然可能多绕了几圈)\n然而X是未知的,如何走X步呢?\n让慢指针指向head,快慢指针这次都一步步地走,相遇时即都走了X步,也就是环的起点\n\n\n    struct ListNode *detectCycle(struct ListNode *head) {                            \n        struct ListNode *slow = head;                                                \n        struct ListNode *fast = head;                                                \n        while (fast != NULL) {                                                       \n            slow = slow -> next;                                                     \n            fast = fast -> next;                                                     \n            if (fast != NULL) {                                                      \n                fast = fast -> next;                                                 \n            } else {                                                                 \n                return NULL;                                                         \n            }                                                                        \n            if (slow == fast) break;                                                 \n        }                                                                            \n        if (fast == NULL) return NULL;                                               \n        slow = head;                                                                 \n        while (slow != fast) {                                                       \n            slow = slow -> next;                                                     \n            fast = fast -> next;                                                     \n        }                                                                            \n        return slow;                                                                 \n    }  \n\n## 参考链接\nhttps://leetcode.com/problems/linked-list-cycle-ii/\nhttp://fisherlei.blogspot.co.id/2013/11/leetcode-linked-list-cycle-ii-solution.html\n\n","source":"_posts/cycle_in_linkedlist.md","raw":"title: 找出链表中环的起点\ndate: 2016-03-16\ntags: [algorithm]\n---\n一般的思路是遍历链表,每一步的指针都记到一个字典里,\n如果当前指针在字典里存在即环存在,该指针即环的起点,\n这个字典能否省掉呢?\n\n<!--more-->\n\n## 检测链表是否有环,使用双指针追击法\n从head出发,快指针一次走两步,慢指针一次走一步。\n如果两指针在某一点相遇,证明环存在,否则环不存在(快指针必定会遇到NULL结束循环)\n\n## 如何找到环的起点\n如下图,假设链表有环,环长Y,环以外的长度是X。\n![图片标题](http://leanote.com/api/file/getImage?fileId=56e8deb7ab6441777b002123)\n如果两指针走了t次后相遇在K点,\n那么\n\n    慢指针走的路是 t = X + nY + K   ①\n    快指针走的路是2t = X + mY + K   ②    m,n为未知数\n    把等式一代入到等式二中, 有\n    2X + 2nY + 2K = X + mY + K\n    => X + K = (m - 2n)Y   ③\n\nX+K即K+X, 即K的长度加X的长度相当于m-2n个整圈(Y)长度\n而快指针此时在环中K的位置,所以从K点再走X步即可达环的起点(虽然可能多绕了几圈)\n然而X是未知的,如何走X步呢?\n让慢指针指向head,快慢指针这次都一步步地走,相遇时即都走了X步,也就是环的起点\n\n\n    struct ListNode *detectCycle(struct ListNode *head) {                            \n        struct ListNode *slow = head;                                                \n        struct ListNode *fast = head;                                                \n        while (fast != NULL) {                                                       \n            slow = slow -> next;                                                     \n            fast = fast -> next;                                                     \n            if (fast != NULL) {                                                      \n                fast = fast -> next;                                                 \n            } else {                                                                 \n                return NULL;                                                         \n            }                                                                        \n            if (slow == fast) break;                                                 \n        }                                                                            \n        if (fast == NULL) return NULL;                                               \n        slow = head;                                                                 \n        while (slow != fast) {                                                       \n            slow = slow -> next;                                                     \n            fast = fast -> next;                                                     \n        }                                                                            \n        return slow;                                                                 \n    }  \n\n## 参考链接\nhttps://leetcode.com/problems/linked-list-cycle-ii/\nhttp://fisherlei.blogspot.co.id/2013/11/leetcode-linked-list-cycle-ii-solution.html\n\n","slug":"cycle_in_linkedlist","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5k70036mcxqpuakeuoj"},{"title":"DHCP","date":"2016-06-07T09:59:00.000Z","_content":"\nDHCP(RFC 2131和2132), 是基于Bootstrap Protocol (BOOTP)的一个标准,\n是为客户端提供TCP/IP配置信息(包括ip地址)的服务\n\n每一个基于TCP/IP的联网设备都需要一个唯一的单播ip地址来访问网络上的资源.\n如果没有DHCP, 从别的子网移过来的电脑和新电脑都需要手动分配ip地址, 有电脑移出的子网需要手动回收ip地址.\n有了DHCP, 这些处理都可以自动化和中心化.\nDHCP服务器维护一个ip地址池, 自动租给接入的电脑使用(动态ip, 每次接入得到的ip地址可能都不同). \n因为是租用而不是静态分配, 不再使用的ip地址可以做到自动回收.\n\n","source":"_posts/dhcp.md","raw":"title: DHCP\ndate: 2016-06-07 17:59:00\ntags: [internet]\n---\n\nDHCP(RFC 2131和2132), 是基于Bootstrap Protocol (BOOTP)的一个标准,\n是为客户端提供TCP/IP配置信息(包括ip地址)的服务\n\n每一个基于TCP/IP的联网设备都需要一个唯一的单播ip地址来访问网络上的资源.\n如果没有DHCP, 从别的子网移过来的电脑和新电脑都需要手动分配ip地址, 有电脑移出的子网需要手动回收ip地址.\n有了DHCP, 这些处理都可以自动化和中心化.\nDHCP服务器维护一个ip地址池, 自动租给接入的电脑使用(动态ip, 每次接入得到的ip地址可能都不同). \n因为是租用而不是静态分配, 不再使用的ip地址可以做到自动回收.\n\n","slug":"dhcp","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5k80039mcxqa9y8t0cg"},{"title":"系统设计点滴","date":"2019-02-01T12:04:00.000Z","_content":"日常引起思考的点点滴滴...\n<!--more-->\n\n#### RBAC和ABAC\nRBAC其实就是ABAC, 的简化版\n权限控制其实是一个 `predicate(params) -> bool`\nRBAC差不多是 `predicate(role, operation_type) -> bool`\nABAC差不多是 `predicate(my_attrs[role, department, location, ...], operation_type, target_attrs[location, ...], environment[nowtime, ...]) -> bool`\n\n另外, 为了方便, 有 grant 方式和 deny 方式, 类似白名单和黑名单\n例如:\n* A user can view a document if the document is in the same department as the user\n* A user can edit a document if they are the owner and if the document is in draft mode\n* Deny access before 9am\n\n广泛一些来说, 就是 predicate 返回 bool, 不仅用户操作权限控制要用到,\n其他地方, 如 api 访问权限, 流控, 规则引擎(比如优惠券是否适用)等处都会用到\n游戏后端的协议层也是如此, 有很多check要在执行操作前判断完\n\n参考链接\nhttp://blog.identityautomation.com/rbac-vs-abac-access-control-models-iam-explained\nhttps://en.wikipedia.org/wiki/Attribute-based_access_control\n\n","source":"_posts/design_drips.md","raw":"title: 系统设计点滴\ndate: 2019-02-01 20:04:00\ntags: design\n---\n日常引起思考的点点滴滴...\n<!--more-->\n\n#### RBAC和ABAC\nRBAC其实就是ABAC, 的简化版\n权限控制其实是一个 `predicate(params) -> bool`\nRBAC差不多是 `predicate(role, operation_type) -> bool`\nABAC差不多是 `predicate(my_attrs[role, department, location, ...], operation_type, target_attrs[location, ...], environment[nowtime, ...]) -> bool`\n\n另外, 为了方便, 有 grant 方式和 deny 方式, 类似白名单和黑名单\n例如:\n* A user can view a document if the document is in the same department as the user\n* A user can edit a document if they are the owner and if the document is in draft mode\n* Deny access before 9am\n\n广泛一些来说, 就是 predicate 返回 bool, 不仅用户操作权限控制要用到,\n其他地方, 如 api 访问权限, 流控, 规则引擎(比如优惠券是否适用)等处都会用到\n游戏后端的协议层也是如此, 有很多check要在执行操作前判断完\n\n参考链接\nhttp://blog.identityautomation.com/rbac-vs-abac-access-control-models-iam-explained\nhttps://en.wikipedia.org/wiki/Attribute-based_access_control\n\n","slug":"design_drips","published":1,"updated":"2019-12-09T14:17:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5k9003bmcxqk3ipi3b1"},{"title":"论我与专业 Devops 的差距","date":"2018-09-27T16:00:00.000Z","_content":"今天线上操作出了点小问题, 服务(a)崩了, 但不是马上崩, 而是十几分钟以后.\n\n<!--more-->\n\n更新一个服务(a)的代码的时候,\n先把新的release包发到a_bak目录下, 停掉原服务进程, 在a_bak目录下启动了新进程,\n本来这就结束了.\n\n但是过了一小会自己觉得在一个叫bak的目录下放真实的release目录貌似不太好,\n就mv a a_bak2 && mv a_bak a && rm -rf a_bak2了, 然后测了一下服务, 一切正常.\n就走开了.\n\n没想到十几分钟后崩掉了.\n发现后赶紧重新启动服务.\n\n还是 journalctl 给了我线索, 发现如下一段红字\n```\nSep 28 18:19:00 gs001 run_erl[28661]: errno=2 'No such file or directory'\n                                      Can't open log file '/data/apps/a_bak/var/log/erlang.log.2'.\n```\n原来是 log rotate 时出的问题.\n\n以后不敢胡乱 mv 胡乱 rm 了\n\n","source":"_posts/devops1.md","raw":"title: 论我与专业 Devops 的差距\ndate: 2018-09-28\ntags: [devops, linux, centos]\n---\n今天线上操作出了点小问题, 服务(a)崩了, 但不是马上崩, 而是十几分钟以后.\n\n<!--more-->\n\n更新一个服务(a)的代码的时候,\n先把新的release包发到a_bak目录下, 停掉原服务进程, 在a_bak目录下启动了新进程,\n本来这就结束了.\n\n但是过了一小会自己觉得在一个叫bak的目录下放真实的release目录貌似不太好,\n就mv a a_bak2 && mv a_bak a && rm -rf a_bak2了, 然后测了一下服务, 一切正常.\n就走开了.\n\n没想到十几分钟后崩掉了.\n发现后赶紧重新启动服务.\n\n还是 journalctl 给了我线索, 发现如下一段红字\n```\nSep 28 18:19:00 gs001 run_erl[28661]: errno=2 'No such file or directory'\n                                      Can't open log file '/data/apps/a_bak/var/log/erlang.log.2'.\n```\n原来是 log rotate 时出的问题.\n\n以后不敢胡乱 mv 胡乱 rm 了\n\n","slug":"devops1","published":1,"updated":"2018-09-28T11:12:39.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ka003dmcxqfxmdg0l8"},{"title":"dialyzer","date":"2015-07-28T16:00:00.000Z","_content":"```bash\ndialyzer --build_plt --apps erts kernel stdlib crypto mnesia sasl common_test eunit --output_plt .dialyzer_plt\ndialyzer --add_to_plt --apps ssl reltool --plt .dialyzer_plt\ndialyzer -r ebin/ -q --plt .dialyzer_plt \n```\n\n","source":"_posts/dialyzer.md","raw":"title: dialyzer\ndate: 2015-07-29\ntags: erlang\n---\n```bash\ndialyzer --build_plt --apps erts kernel stdlib crypto mnesia sasl common_test eunit --output_plt .dialyzer_plt\ndialyzer --add_to_plt --apps ssl reltool --plt .dialyzer_plt\ndialyzer -r ebin/ -q --plt .dialyzer_plt \n```\n\n","slug":"dialyzer","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5kb003gmcxq0gxfxfpw"},{"title":"dig命令","date":"2016-06-13T03:31:00.000Z","_content":"\n据说比nslookup命令好用\n<!--more-->\n\n### 指定公共dns服务器如8.8.8.8\n```\ndig @8.8.8.8 suexcxine.cc\n\n; <<>> DiG 9.9.5-3ubuntu0.3-Ubuntu <<>> @8.8.8.8 suexcxine.cc\n; (1 server found)\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 51934\n;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 512\n;; QUESTION SECTION:\n;suexcxine.cc.          IN  A\n\n;; ANSWER SECTION:\nsuexcxine.cc.       599 IN  A   118.193.216.246\n\n;; Query time: 370 msec\n;; SERVER: 8.8.8.8#53(8.8.8.8)\n;; WHEN: Mon Jun 13 16:00:55 CST 2016\n;; MSG SIZE  rcvd: 57\n\n```\n\n### 跟踪dig全过程\n```\n$ dig +trace suexcxine.cc\n\n; <<>> DiG 9.9.5-3ubuntu0.3-Ubuntu <<>> +trace suexcxine.cc\n;; global options: +cmd\n.           513159  IN  NS  e.root-servers.net.\n.           513159  IN  NS  h.root-servers.net.\n.           513159  IN  NS  l.root-servers.net.\n.           513159  IN  NS  i.root-servers.net.\n.           513159  IN  NS  a.root-servers.net.\n.           513159  IN  NS  d.root-servers.net.\n.           513159  IN  NS  c.root-servers.net.\n.           513159  IN  NS  b.root-servers.net.\n.           513159  IN  NS  j.root-servers.net.\n.           513159  IN  NS  k.root-servers.net.\n.           513159  IN  NS  g.root-servers.net.\n.           513159  IN  NS  m.root-servers.net.\n.           513159  IN  NS  f.root-servers.net.\n;; Received 239 bytes from 127.0.1.1#53(127.0.1.1) in 744 ms\n\ncc.         172800  IN  NS  ac1.nstld.com.\ncc.         172800  IN  NS  ac2.nstld.com.\ncc.         172800  IN  NS  ac3.nstld.com.\ncc.         172800  IN  NS  ac4.nstld.com.\ncc.         86400   IN  DS  519 8 1 7285EF05E1B4E679D4F072EEA9B00953E01F3AE2\ncc.         86400   IN  DS  519 8 2 E1EC6495ABD34562E6F433DEE201E6C6A52CB10AF69C04D675DA692D 2D566897\ncc.         86400   IN  RRSIG   DS 8 1 86400 20160623050000 20160613040000 60615 . kmlYZSZOtDbV2J/J23O4AYUFLZ6N+oD4eICLj+ZN/y1ki4UoUlMyqcJW scXz/ux+DmbQJXhwUwn/ode3uh4EHvBjhbVDvhVET1I0xbyloOqkYhiy WtL400eUF23Bd5rxvmb2i/+LPcmoMkaWZh+6GWA6hH3J8VFOjldnSxVx TBo=\n;; Received 541 bytes from 192.203.230.10#53(e.root-servers.net) in 823 ms\n\nsuexcxine.cc.       172800  IN  NS  f1g1ns2.dnspod.net.\nsuexcxine.cc.       172800  IN  NS  f1g1ns1.dnspod.net.\nRQGAP5UF6Q1NGVCKFNO8RANVDN5ILRIN.cc. 86400 IN NSEC3 1 1 0 - RV11BJCVDH79RSELE61AK8640MB8689H NS SOA RRSIG DNSKEY NSEC3PARAM\nRQGAP5UF6Q1NGVCKFNO8RANVDN5ILRIN.cc. 86400 IN RRSIG NSEC3 8 2 86400 20160619190704 20160612190704 4430 cc. k0e66YorcywAW7+cUSVJrqzHPRJY4YBEhi+j6JjgyONWjxBmaZ1pdB+P QJvs8Dt3HeMrlmSfSe7eOgQ0J0CkuQnNCEoAES18GB0Nv2vICmccx8kq qcjdL2JObtMAN4eerRyYEF4n+3GfK9UMSFbAWsJhgs8YO2WWlWpktot5 rt0=\nJSOFD7DUT1KLQP4ATN919VJUMSMPPKR3.cc. 86400 IN NSEC3 1 1 0 - KBR2RRU7FVEIU4PPG8128HD76RDD86J5 NS DS RRSIG\nJSOFD7DUT1KLQP4ATN919VJUMSMPPKR3.cc. 86400 IN RRSIG NSEC3 8 2 86400 20160620061457 20160613061457 4430 cc. o5Q3Td1Lmxu0H/ESPYIHBJ5lr0zIMOpylFdvvDKsN3mv7TFtzupL3uiD 7oFBjDRl6NxY+lX1rH2pM9+t20AV1R1gE0CclL9UB3zeUbaBRDOeEkDi gs4o3wx0IJyvSry+I3BHxHc/Dt4gcfKEDqIJJSFenu+d0GpcRU/jheUC knU=\n;; Received 578 bytes from 192.42.173.30#53(ac1.nstld.com) in 672 ms\n\nsuexcxine.cc.       600 IN  A   118.193.216.246\nsuexcxine.cc.       86400   IN  NS  f1g1ns2.dnspod.net.\nsuexcxine.cc.       86400   IN  NS  f1g1ns1.dnspod.net.\n;; Received 121 bytes from 125.39.208.193#53(f1g1ns1.dnspod.net) in 5 ms\n```\n\n### 默认追加域\n```\n$ dig +domain=baidu.com blog\n\n; <<>> DiG 9.9.5-3ubuntu0.3-Ubuntu <<>> +domain=baidu.com blog\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 19480\n;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 1280\n;; QUESTION SECTION:\n;blog.baidu.com.            IN  A\n\n;; ANSWER SECTION:\nblog.baidu.com.     7168    IN  CNAME   blog.n.shifen.com.\nblog.n.shifen.com.  268 IN  A   180.149.132.208\n\n;; Query time: 50 msec\n;; SERVER: 127.0.1.1#53(127.0.1.1)\n;; WHEN: Mon Jun 13 16:28:38 CST 2016\n;; MSG SIZE  rcvd: 90\n```\n\n### 查询权威dns server\n```\n$ dig +nssearch youtube.com\nSOA ns4.google.com. dns-admin.google.com. 124701907 900 900 1800 60 from server 216.239.32.10 in 78 ms.\nSOA ns3.google.com. dns-admin.google.com. 124701907 900 900 1800 60 from server 216.239.38.10 in 365 ms.\n;; connection timed out; no servers could be reached\n```\n\n### 查看反向解析\n```\n$ dig -x 180.149.132.47\n```\n\n### 从文件中读取查询内容实现批量查询\n```\n$ cat querylist //文件内容，共有两个域名需要查询\nwww.baidu.com\nwww.sohu.com\n$ dig -f querylist -c IN -t A //设置-f参数开始批量查询\n```\n\n### 不要版本信息, 不要注释, 不要统计信息\n```\n$ dig +nocmd +nocomment +nostat youtube.com\n;youtube.com.           IN  A\nyoutube.com.        200 IN  A   216.58.199.110\n```\n\n### 最简输出\n```\n$ dig +short youtube.com\n216.58.199.110\n```\n\n## 参考链接\nhttp://roclinux.cn/?p=2449\n\n","source":"_posts/dig_command.md","raw":"title: dig命令\ndate: 2016-06-13 11:31:00\ntags: [internet, dns]\n---\n\n据说比nslookup命令好用\n<!--more-->\n\n### 指定公共dns服务器如8.8.8.8\n```\ndig @8.8.8.8 suexcxine.cc\n\n; <<>> DiG 9.9.5-3ubuntu0.3-Ubuntu <<>> @8.8.8.8 suexcxine.cc\n; (1 server found)\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 51934\n;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 512\n;; QUESTION SECTION:\n;suexcxine.cc.          IN  A\n\n;; ANSWER SECTION:\nsuexcxine.cc.       599 IN  A   118.193.216.246\n\n;; Query time: 370 msec\n;; SERVER: 8.8.8.8#53(8.8.8.8)\n;; WHEN: Mon Jun 13 16:00:55 CST 2016\n;; MSG SIZE  rcvd: 57\n\n```\n\n### 跟踪dig全过程\n```\n$ dig +trace suexcxine.cc\n\n; <<>> DiG 9.9.5-3ubuntu0.3-Ubuntu <<>> +trace suexcxine.cc\n;; global options: +cmd\n.           513159  IN  NS  e.root-servers.net.\n.           513159  IN  NS  h.root-servers.net.\n.           513159  IN  NS  l.root-servers.net.\n.           513159  IN  NS  i.root-servers.net.\n.           513159  IN  NS  a.root-servers.net.\n.           513159  IN  NS  d.root-servers.net.\n.           513159  IN  NS  c.root-servers.net.\n.           513159  IN  NS  b.root-servers.net.\n.           513159  IN  NS  j.root-servers.net.\n.           513159  IN  NS  k.root-servers.net.\n.           513159  IN  NS  g.root-servers.net.\n.           513159  IN  NS  m.root-servers.net.\n.           513159  IN  NS  f.root-servers.net.\n;; Received 239 bytes from 127.0.1.1#53(127.0.1.1) in 744 ms\n\ncc.         172800  IN  NS  ac1.nstld.com.\ncc.         172800  IN  NS  ac2.nstld.com.\ncc.         172800  IN  NS  ac3.nstld.com.\ncc.         172800  IN  NS  ac4.nstld.com.\ncc.         86400   IN  DS  519 8 1 7285EF05E1B4E679D4F072EEA9B00953E01F3AE2\ncc.         86400   IN  DS  519 8 2 E1EC6495ABD34562E6F433DEE201E6C6A52CB10AF69C04D675DA692D 2D566897\ncc.         86400   IN  RRSIG   DS 8 1 86400 20160623050000 20160613040000 60615 . kmlYZSZOtDbV2J/J23O4AYUFLZ6N+oD4eICLj+ZN/y1ki4UoUlMyqcJW scXz/ux+DmbQJXhwUwn/ode3uh4EHvBjhbVDvhVET1I0xbyloOqkYhiy WtL400eUF23Bd5rxvmb2i/+LPcmoMkaWZh+6GWA6hH3J8VFOjldnSxVx TBo=\n;; Received 541 bytes from 192.203.230.10#53(e.root-servers.net) in 823 ms\n\nsuexcxine.cc.       172800  IN  NS  f1g1ns2.dnspod.net.\nsuexcxine.cc.       172800  IN  NS  f1g1ns1.dnspod.net.\nRQGAP5UF6Q1NGVCKFNO8RANVDN5ILRIN.cc. 86400 IN NSEC3 1 1 0 - RV11BJCVDH79RSELE61AK8640MB8689H NS SOA RRSIG DNSKEY NSEC3PARAM\nRQGAP5UF6Q1NGVCKFNO8RANVDN5ILRIN.cc. 86400 IN RRSIG NSEC3 8 2 86400 20160619190704 20160612190704 4430 cc. k0e66YorcywAW7+cUSVJrqzHPRJY4YBEhi+j6JjgyONWjxBmaZ1pdB+P QJvs8Dt3HeMrlmSfSe7eOgQ0J0CkuQnNCEoAES18GB0Nv2vICmccx8kq qcjdL2JObtMAN4eerRyYEF4n+3GfK9UMSFbAWsJhgs8YO2WWlWpktot5 rt0=\nJSOFD7DUT1KLQP4ATN919VJUMSMPPKR3.cc. 86400 IN NSEC3 1 1 0 - KBR2RRU7FVEIU4PPG8128HD76RDD86J5 NS DS RRSIG\nJSOFD7DUT1KLQP4ATN919VJUMSMPPKR3.cc. 86400 IN RRSIG NSEC3 8 2 86400 20160620061457 20160613061457 4430 cc. o5Q3Td1Lmxu0H/ESPYIHBJ5lr0zIMOpylFdvvDKsN3mv7TFtzupL3uiD 7oFBjDRl6NxY+lX1rH2pM9+t20AV1R1gE0CclL9UB3zeUbaBRDOeEkDi gs4o3wx0IJyvSry+I3BHxHc/Dt4gcfKEDqIJJSFenu+d0GpcRU/jheUC knU=\n;; Received 578 bytes from 192.42.173.30#53(ac1.nstld.com) in 672 ms\n\nsuexcxine.cc.       600 IN  A   118.193.216.246\nsuexcxine.cc.       86400   IN  NS  f1g1ns2.dnspod.net.\nsuexcxine.cc.       86400   IN  NS  f1g1ns1.dnspod.net.\n;; Received 121 bytes from 125.39.208.193#53(f1g1ns1.dnspod.net) in 5 ms\n```\n\n### 默认追加域\n```\n$ dig +domain=baidu.com blog\n\n; <<>> DiG 9.9.5-3ubuntu0.3-Ubuntu <<>> +domain=baidu.com blog\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 19480\n;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 1280\n;; QUESTION SECTION:\n;blog.baidu.com.            IN  A\n\n;; ANSWER SECTION:\nblog.baidu.com.     7168    IN  CNAME   blog.n.shifen.com.\nblog.n.shifen.com.  268 IN  A   180.149.132.208\n\n;; Query time: 50 msec\n;; SERVER: 127.0.1.1#53(127.0.1.1)\n;; WHEN: Mon Jun 13 16:28:38 CST 2016\n;; MSG SIZE  rcvd: 90\n```\n\n### 查询权威dns server\n```\n$ dig +nssearch youtube.com\nSOA ns4.google.com. dns-admin.google.com. 124701907 900 900 1800 60 from server 216.239.32.10 in 78 ms.\nSOA ns3.google.com. dns-admin.google.com. 124701907 900 900 1800 60 from server 216.239.38.10 in 365 ms.\n;; connection timed out; no servers could be reached\n```\n\n### 查看反向解析\n```\n$ dig -x 180.149.132.47\n```\n\n### 从文件中读取查询内容实现批量查询\n```\n$ cat querylist //文件内容，共有两个域名需要查询\nwww.baidu.com\nwww.sohu.com\n$ dig -f querylist -c IN -t A //设置-f参数开始批量查询\n```\n\n### 不要版本信息, 不要注释, 不要统计信息\n```\n$ dig +nocmd +nocomment +nostat youtube.com\n;youtube.com.           IN  A\nyoutube.com.        200 IN  A   216.58.199.110\n```\n\n### 最简输出\n```\n$ dig +short youtube.com\n216.58.199.110\n```\n\n## 参考链接\nhttp://roclinux.cn/?p=2449\n\n","slug":"dig_command","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5kc003imcxqv9fmf98v"},{"title":"dnsmasq","date":"2016-06-08T08:18:00.000Z","_content":"\n尝试在自己的vps上搭一个dns服务\n<!--more-->\n\n在/root/dnsmasq_conf/dnsmasq.hosts文件里填写自己想要解析的域名\n```\n# cat /root/dnsmasq_conf/dnsmasq.hosts\n118.193.216.246 suexcxine.me\n```\n启动dnsmasq服务, 上游服务器设为opendns的5353(防53的投毒)端口\n```\n# docker run --name dns -d -p 53:53/tcp -p 53:53/udp -v /root/dnsmasq_conf:/etc/dnsmasq --cap-add=NET_ADMIN andyshinn/dnsmasq:2.75 --addn-hosts=/etc/dnsmasq/dnsmasq.hosts --server=208.67.220.220#5353\n```\n在网络连接里将自己机器的dns设为vps的ip, 并测试\n```\nping suexcxine.me\n```\n解析成功\n\n今后修改dnsmasq.hosts文件后, 可以如下reload\n```\ndocker exec -it dns kill -SIGHUP 1\n```\n这样有一个做动态解析的可能\n\n## 关闭/禁用Ubuntu默认开启的dnsmasq服务\n\nUbuntu 默认开启 dnsmasq 服务，占用了本机53端口，\n当需要在本机测试或使用其他 dns 服务器时，\n如何关闭 dnsmasq 服务而且重启电脑后 dnsmasq 服务不会重新被开启？\n\n```\n$ sudo vim /etc/NetworkManager/NetworkManager.conf\n```\n\n注释掉 dns=dnsmasq，如下：\n# dns=dnsmasq\n\n保存后重启 network-manager，\n```\nsudo restart network-manger\n```\n\n\n","source":"_posts/dnsmasq.md","raw":"title: dnsmasq\ndate: 2016-06-08 16:18:00\ntags: [internet, dns]\n---\n\n尝试在自己的vps上搭一个dns服务\n<!--more-->\n\n在/root/dnsmasq_conf/dnsmasq.hosts文件里填写自己想要解析的域名\n```\n# cat /root/dnsmasq_conf/dnsmasq.hosts\n118.193.216.246 suexcxine.me\n```\n启动dnsmasq服务, 上游服务器设为opendns的5353(防53的投毒)端口\n```\n# docker run --name dns -d -p 53:53/tcp -p 53:53/udp -v /root/dnsmasq_conf:/etc/dnsmasq --cap-add=NET_ADMIN andyshinn/dnsmasq:2.75 --addn-hosts=/etc/dnsmasq/dnsmasq.hosts --server=208.67.220.220#5353\n```\n在网络连接里将自己机器的dns设为vps的ip, 并测试\n```\nping suexcxine.me\n```\n解析成功\n\n今后修改dnsmasq.hosts文件后, 可以如下reload\n```\ndocker exec -it dns kill -SIGHUP 1\n```\n这样有一个做动态解析的可能\n\n## 关闭/禁用Ubuntu默认开启的dnsmasq服务\n\nUbuntu 默认开启 dnsmasq 服务，占用了本机53端口，\n当需要在本机测试或使用其他 dns 服务器时，\n如何关闭 dnsmasq 服务而且重启电脑后 dnsmasq 服务不会重新被开启？\n\n```\n$ sudo vim /etc/NetworkManager/NetworkManager.conf\n```\n\n注释掉 dns=dnsmasq，如下：\n# dns=dnsmasq\n\n保存后重启 network-manager，\n```\nsudo restart network-manger\n```\n\n\n","slug":"dnsmasq","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5kd003lmcxq8r4eof5g"},{"title":"docker network","date":"2016-06-01T16:00:00.000Z","_content":"\n今天在使用docker-compose搭建游戏服务器时遇到了问题,\n发现将docker-compose.yml改成version 2之后links没有注入环境变量,\n导致服务器连接数据库失败\n<!--more-->\n\n## link功能的变化\n\n在docker-compose version 2中, 由links生成环境变量这一功能已经过时, \n如果需要兼容性, 可以在docker-compose.yml中增加环境变量设置, 设为service名即可 \nDocker 1.10 不再使用/etc/hosts, 而是使用embedded DNS server \n\n在同一network中的service会被默认连接在一起, 可以使用service名访问其他service\n在如下示例中, 在my-app中可以ping my-redis, 在my-redis中可以ping my-app\n```\nversion: '2'\n\nservices:\n  my-app:\n    image: tomcat:8.0\n    container_name: my-app1\n    links:\n      - my-redis\n  my-redis:\n    image: redis\n    container_name: my-redis1\n```\n\n仅当使用旧式的version 1 Compose文件格式时, links才会生成形如DB_PORT_3306_ADDR这样的环境变量\n\n## 参考链接\nhttp://stackoverflow.com/questions/35297093/links-between-containers-not-working-with-docker-compose-version-2\nhttp://stackoverflow.com/questions/36087173/containers-are-not-linked-with-docker-compose-version-2\n\ncompose networking的详细讲解,非常清晰易懂\nhttps://github.com/docker/compose/blob/master/docs/networking.md\n\n","source":"_posts/docker_network.md","raw":"title: docker network\ndate: 2016-06-02\ntags: [docker, network]\n---\n\n今天在使用docker-compose搭建游戏服务器时遇到了问题,\n发现将docker-compose.yml改成version 2之后links没有注入环境变量,\n导致服务器连接数据库失败\n<!--more-->\n\n## link功能的变化\n\n在docker-compose version 2中, 由links生成环境变量这一功能已经过时, \n如果需要兼容性, 可以在docker-compose.yml中增加环境变量设置, 设为service名即可 \nDocker 1.10 不再使用/etc/hosts, 而是使用embedded DNS server \n\n在同一network中的service会被默认连接在一起, 可以使用service名访问其他service\n在如下示例中, 在my-app中可以ping my-redis, 在my-redis中可以ping my-app\n```\nversion: '2'\n\nservices:\n  my-app:\n    image: tomcat:8.0\n    container_name: my-app1\n    links:\n      - my-redis\n  my-redis:\n    image: redis\n    container_name: my-redis1\n```\n\n仅当使用旧式的version 1 Compose文件格式时, links才会生成形如DB_PORT_3306_ADDR这样的环境变量\n\n## 参考链接\nhttp://stackoverflow.com/questions/35297093/links-between-containers-not-working-with-docker-compose-version-2\nhttp://stackoverflow.com/questions/36087173/containers-are-not-linked-with-docker-compose-version-2\n\ncompose networking的详细讲解,非常清晰易懂\nhttps://github.com/docker/compose/blob/master/docs/networking.md\n\n","slug":"docker_network","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ke003nmcxqq0m43s8x"},{"title":"docker problems","date":"2016-06-03T16:00:00.000Z","_content":"\n学习和尝试docker的这段时间里, 陆续遇到了不少问题\n<!--more-->\n\n### volume ro(只读)\n\n原以为只是container对这个volume只读, 把一个nginx的volume设成ro了\n没想到宿主机这边修改了内容后, nginx的container里没有跟着改,\n这就不方便更新网页内容了, 果断从docker-compose.yml里去掉ro后解决\n\n### 当docker遇到terminal\n\ndocker run时如果没有加-t,则container的环境变量里不会有TERM=xterm,                \n```\ndocker exec -it $container bash\n```\n这样进入后环境变量里仍然没有TERM=xterm, 反直觉, 这里的-t参数无效\ndocker team给出的理由是exec并不会新建一个container, 而是在原来的container里执行, 所以原来没-t现在加-t也没用, \n那exec的-t参数是干什么用的? 结果是exec时不设-t也不行, 也不能正常工作             \n最后只能这样:\n```\ndocker exec -it $container /bin/bash -c \"export TERM=xterm; command\" \n```\n或者在docker run时加上-t\n\n参考链接:\nhttp://stackoverflow.com/questions/30913579/ctrlg-in-erl-doesnt-work\nhttps://andykdocs.de/development/Docker/Fixing+the+Docker+TERM+variable+issue\n\n","source":"_posts/docker_problems.md","raw":"title: docker problems\ndate: 2016-06-04\ntags: docker\n---\n\n学习和尝试docker的这段时间里, 陆续遇到了不少问题\n<!--more-->\n\n### volume ro(只读)\n\n原以为只是container对这个volume只读, 把一个nginx的volume设成ro了\n没想到宿主机这边修改了内容后, nginx的container里没有跟着改,\n这就不方便更新网页内容了, 果断从docker-compose.yml里去掉ro后解决\n\n### 当docker遇到terminal\n\ndocker run时如果没有加-t,则container的环境变量里不会有TERM=xterm,                \n```\ndocker exec -it $container bash\n```\n这样进入后环境变量里仍然没有TERM=xterm, 反直觉, 这里的-t参数无效\ndocker team给出的理由是exec并不会新建一个container, 而是在原来的container里执行, 所以原来没-t现在加-t也没用, \n那exec的-t参数是干什么用的? 结果是exec时不设-t也不行, 也不能正常工作             \n最后只能这样:\n```\ndocker exec -it $container /bin/bash -c \"export TERM=xterm; command\" \n```\n或者在docker run时加上-t\n\n参考链接:\nhttp://stackoverflow.com/questions/30913579/ctrlg-in-erl-doesnt-work\nhttps://andykdocs.de/development/Docker/Fixing+the+Docker+TERM+variable+issue\n\n","slug":"docker_problems","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5kf003qmcxq8ft4yqez"},{"title":"DNSPod购买的域名如何修改DNS Server","date":"2016-06-13T03:02:00.000Z","_content":"\n着实找了好一阵子, ... 一度以为dnspod不提供该功能\n<!--more-->\n\n登录用户中心 -> 总览页 -> 域名注册 -> 我的域名 -> 更多操作 -> 修改dns\n\n## 参考链接\nhttp://shipengliang.com/software-exp/dnspod%E8%B4%AD%E4%B9%B0%E7%9A%84%E5%9F%9F%E5%90%8D%E5%93%AA%E9%87%8C%E4%BF%AE%E6%94%B9dns-server.html\n\n","source":"_posts/dnspod_change_dns.md","raw":"title: DNSPod购买的域名如何修改DNS Server\ndate: 2016-06-13 11:02:00\ntags: [internet, dns]\n---\n\n着实找了好一阵子, ... 一度以为dnspod不提供该功能\n<!--more-->\n\n登录用户中心 -> 总览页 -> 域名注册 -> 我的域名 -> 更多操作 -> 修改dns\n\n## 参考链接\nhttp://shipengliang.com/software-exp/dnspod%E8%B4%AD%E4%B9%B0%E7%9A%84%E5%9F%9F%E5%90%8D%E5%93%AA%E9%87%8C%E4%BF%AE%E6%94%B9dns-server.html\n\n","slug":"dnspod_change_dns","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5kg003smcxqhfb2rlsb"},{"title":"domain","date":"2018-03-14T06:25:00.000Z","_content":"\n域名相关知识\n<!--more-->\n\n### DNS parking (domain parking)\n\nThe Web host registers the domain name with the InterNIC and \"parks\" the domain name on a server until it is ready to be made active.\nBy doing this, the Web host ensures the availability of the domain name for the client's future use so that another individual or company cannot register that same domain name.\n\n","source":"_posts/domain.md","raw":"title: domain\ndate: 2018-03-14 14:25:00\ntags: [internet, dns]\n---\n\n域名相关知识\n<!--more-->\n\n### DNS parking (domain parking)\n\nThe Web host registers the domain name with the InterNIC and \"parks\" the domain name on a server until it is ready to be made active.\nBy doing this, the Web host ensures the availability of the domain name for the client's future use so that another individual or company cannot register that same domain name.\n\n","slug":"domain","published":1,"updated":"2018-03-14T06:28:10.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5kh003vmcxq5blkwrc4"},{"title":"data source name","date":"2016-08-09T16:00:00.000Z","_content":"\n<pre>\n[username[:password]@][protocol[(address)]]/dbname[?param1=value1&...&paramN=valueN]\n</pre>\n大概长这样:\n<pre>\nusername:password@protocol(address)/dbname?param=value\n</pre>\n\n为了方便定义数据库源的一种格式化的字符串,\n程序用起来还是又要parse又要format的(看下面参考链接里的go实现,复杂+不爽),\n也许觉得对人类友好吧,\n真的友好吗?\n\n## 参考链接\nhttps://github.com/go-sql-driver/mysql#dsn-data-source-name\nhttps://github.com/go-sql-driver/mysql/blob/66312f7fe2678aa0f5ec770f96702f4c4ec5aa8e/dsn.go#L246\n\n","source":"_posts/dsn.md","raw":"title: data source name\ndate: 2016-08-10\ntags: [db]\n---\n\n<pre>\n[username[:password]@][protocol[(address)]]/dbname[?param1=value1&...&paramN=valueN]\n</pre>\n大概长这样:\n<pre>\nusername:password@protocol(address)/dbname?param=value\n</pre>\n\n为了方便定义数据库源的一种格式化的字符串,\n程序用起来还是又要parse又要format的(看下面参考链接里的go实现,复杂+不爽),\n也许觉得对人类友好吧,\n真的友好吗?\n\n## 参考链接\nhttps://github.com/go-sql-driver/mysql#dsn-data-source-name\nhttps://github.com/go-sql-driver/mysql/blob/66312f7fe2678aa0f5ec770f96702f4c4ec5aa8e/dsn.go#L246\n\n","slug":"dsn","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5kh003xmcxqee6hcand"},{"title":"email","date":"2015-09-05T16:00:00.000Z","_content":"## 概念\nMUA Mail User Agent\nMTA Mail Transfer Agent\nSMTP Simple Mail Transfer Protocol\n本地IPC Inter Process Communication\n本地MDA\n远程MDA\n\n","source":"_posts/email.md","raw":"title: email\ndate: 2015-09-06\ntags: [linux, internet]\n---\n## 概念\nMUA Mail User Agent\nMTA Mail Transfer Agent\nSMTP Simple Mail Transfer Protocol\n本地IPC Inter Process Communication\n本地MDA\n远程MDA\n\n","slug":"email","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ki003zmcxqv0ahcv9c"},{"title":"elixir runtime config","date":"2021-06-25T16:00:00.000Z","_content":"\n有次在 config.exs 里给 kernel application 配了点东西,\n\n结果出了下面这样的警告:\n\n<!--more-->\n\n```elixir\nCannot configure base applications: [:kernel]\n\nThese applications are already started by the time the configuration\nexecutes and these configurations have no effect.\n\nIf you want to configure these applications for a release, you can\nspecify them in your vm.args file:\n\n\t-kernel config_key config_value\n\nAlternatively, if you must configure them dynamically, you can wrap\nthem in a conditional block in your config files:\n\n  if System.get_env(\"RELEASE_MODE\") do\n    config :kernel, ...\n  end\n\nand then configure your releases to reboot after configuration:\n\n  releases: [\n    my_app: [reboot_system_after_config: true]\n  ]\n\nThis happened when loading config/config.exs or\none of its imports.\n\n```\n\n由于 kernel, stdlib 这些启动得比 config 要早, 所以 config 没法对它们生效\n\n于是, 如果想在 config 里配它们的参数, 要么用 vm.args 来配, \n\n要么用 [runtime config](https://hexdocs.pm/mix/Mix.Tasks.Release.html#module-runtime-configuration) + reboot_system_after_config(在 mix.exs 里配) 才能搞, 就是加载完 config 然后再重启VM(在同一个操作系统进程内) 的方式\n\n也就是下面这种效果\n\n```erlang\n> bin/test_app start_iex\nErlang/OTP 23 [erts-11.2] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]\n\nErlang/OTP 23 [erts-11.2] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]\n\n...... other logs\n```\n\n要我选的话还是 vm.args 吧~\n\n\n\n## runtime config\n\nruntime config 的意义在于, 以前 config.exs(以及import_config加进来的其他东西)是一个编译时的东西, 即编译生成 sys.config 文件. 这样的话, 比如在 config.exs 里用了环境变量的话, 也要重新编译并发布才能生效, 失去环境变量的意义, 太麻烦. \n\n有了 runtime config 的话, 在启动过程中一个比较早的时间点会加载一次配置, 这样环境变量就是在运行时加载了, 另外手动修改配置文件(如 releases/VSN/runtime.exs)也可以生效, 这两种情况就都不需要重新编译和发布了. 太棒啦!\n\n","source":"_posts/elixir_runtime_config.md","raw":"title: elixir runtime config\ndate: 2021-06-26\n\ntags: [elixir, config]\n---\n\n有次在 config.exs 里给 kernel application 配了点东西,\n\n结果出了下面这样的警告:\n\n<!--more-->\n\n```elixir\nCannot configure base applications: [:kernel]\n\nThese applications are already started by the time the configuration\nexecutes and these configurations have no effect.\n\nIf you want to configure these applications for a release, you can\nspecify them in your vm.args file:\n\n\t-kernel config_key config_value\n\nAlternatively, if you must configure them dynamically, you can wrap\nthem in a conditional block in your config files:\n\n  if System.get_env(\"RELEASE_MODE\") do\n    config :kernel, ...\n  end\n\nand then configure your releases to reboot after configuration:\n\n  releases: [\n    my_app: [reboot_system_after_config: true]\n  ]\n\nThis happened when loading config/config.exs or\none of its imports.\n\n```\n\n由于 kernel, stdlib 这些启动得比 config 要早, 所以 config 没法对它们生效\n\n于是, 如果想在 config 里配它们的参数, 要么用 vm.args 来配, \n\n要么用 [runtime config](https://hexdocs.pm/mix/Mix.Tasks.Release.html#module-runtime-configuration) + reboot_system_after_config(在 mix.exs 里配) 才能搞, 就是加载完 config 然后再重启VM(在同一个操作系统进程内) 的方式\n\n也就是下面这种效果\n\n```erlang\n> bin/test_app start_iex\nErlang/OTP 23 [erts-11.2] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]\n\nErlang/OTP 23 [erts-11.2] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]\n\n...... other logs\n```\n\n要我选的话还是 vm.args 吧~\n\n\n\n## runtime config\n\nruntime config 的意义在于, 以前 config.exs(以及import_config加进来的其他东西)是一个编译时的东西, 即编译生成 sys.config 文件. 这样的话, 比如在 config.exs 里用了环境变量的话, 也要重新编译并发布才能生效, 失去环境变量的意义, 太麻烦. \n\n有了 runtime config 的话, 在启动过程中一个比较早的时间点会加载一次配置, 这样环境变量就是在运行时加载了, 另外手动修改配置文件(如 releases/VSN/runtime.exs)也可以生效, 这两种情况就都不需要重新编译和发布了. 太棒啦!\n\n","slug":"elixir_runtime_config","published":1,"updated":"2021-06-27T11:43:34.797Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5kj0042mcxq1nnoekej"},{"title":"dynamic programming","date":"2016-03-01T16:00:00.000Z","_content":"\n动态规划常常适用于有重叠子问题和最优子结构性质的问题。\n**最优子结构性质** 如果问题的最优解所包含的子问题的解也是最优的，我们就称该问题具有最优子结构性质。\n**无后效性** 即子问题的解一旦确定，就不再改变，不受在这之后、包含它的更大的问题的求解决策影响。\n**子问题重叠性质** 子问题重叠性质是指在用递归算法自顶向下对问题求解时，每次产生的子问题并不总是新问题。\n\n通常许多子问题非常相似，为此动态规划法试图仅仅解决每个子问题一次，从而减少计算量：\n一旦某个给定子问题的解已经算出，则将其存储，以便下次需要同一个子问题解之时直接查表。这种做法在重复子问题的数目关于输入的规模呈指数增长时特别有用。\n\n<!--more-->\n\n## 思路\n通常我们从过程的最后一步开始考虑，而不是先考虑过程的开始。\n\n找到任何一个规律后,把这个规律表示出来,未知的部分全部用代数解决\n比如01背包问题对每一件商品无非两种情况, 要么装要么不装, 取两者的大者, 于是这里有一个是否装和max的逻辑,\n写下来就是, 对于商品i而言, 最大价值为: max(装的情况的价值, 不装的情况的价值)\nN为商品种类数量\nF(i, m)表示重量为i的背包, 在有1-m种商品可供选择时能装的最大价值\nW(i)表示商品i的重量, V(i)表示商品i的价值\n状态转移方程即: F(k, m) = max(F(k - W(m), m - 1) + V(m), F(k, m - 1)), k - W(m) >= 0, 1 =< m =< N\n\n给定体积的背包里, 对每一件商品而言有两种选择, 需要找出价值大的,\n遍历完所有商品得到给定体积的背包的最大价值, 体积是一个额外限制, 所以比零钱问题多了一个维度\n而找零问题是对每一个找零目标(如1分钱,2分钱,76分钱)有几种硬币可选, 需要找出硬币数量少的\n\n## 题0 费波那契\n\n使用计算机解决一个问题是在思考如何将这个问题表达成状态（用哪些变量存储哪些数据）以及如何在状态中转移（怎样根据一些变量计算出另一些变量）。\n所以空间复杂度是为了支持计算所必需存储的状态有多少，时间复杂度是从初始状态到最终状态的过程中需要多少步\n比如说计算第100个费波那契数，每一个费波那契数就是这个问题的一个状态，每求一个新数字只需要之前的两个状态。\n所以同一个时刻，最多只需要保存两个状态，空间复杂度就是常数；每计算一个新状态所需要的时间也是常数且状态线性递增，所以时间复杂度也是线性的。\n\n费波那契数这个问题里没有最的概念, 而\"最\"都是比出来的, \n没有最就不用比了, 其实也没得比, 因为每一步的计算结果都只有一个值,\n有些问题每一步有多种可能性, 往往就要选一个最好的\n\n## 题1 用最少的硬币找零钱\n\n给定N种硬币,它们的价值分别是(V1, V2, ..., VN)\n求最少需要几枚硬币才能凑出价值S(每种硬币都是要多少有多少)\n\n这里出现了一个最字, 有N种硬币, 意味着每阶段都要用N种硬币去尝试得到一个\"最\"优解, 即穷举N种硬币的情况并比较\n\n这一点和费波那契很像, 都是从目标值1开始一步步算上去的\n\n## 题2 求最长上升子序列的长度\n\n如: 5，3，4，8，6，7\n\n状态: 以第i个元素结尾的情况\nLIS(i) = max{LIS(j) + 1} j < i and a[j] < a[i]\n\n## 题3 二维地图摘苹果\n\nF(1, 1) = A(1, 1)\nF(1, 2) = F(1, 1) + A(1, 2)\nF(2, 1) = F(1, 1) + A(2, 1)\nF(i, j) = max(F(i - 1, j), F(i, j - 1)) + A(i, j)\n\nN \\* M个子问题, 每个子问题两次判断, O(N \\* M \\* 2)\n\n比之前的问题复杂的是, 这个问题是二维的, 有两个参数\n\n## 题4 三趟摘苹果\n\n给定一个M行N列的矩阵(M*N个格子)，每个格子中放着一定数量的苹果。 \n从左上角的格子开始，只能向下或向右走，目的地是右下角的格子。每走过一个格子，就把格子上的苹果都收集起来。\n然后从右下角走回左上角的格子，每次只能向左或是向上走，同样的，走过一个格子就把里面的苹果都收集起来。\n最后，再一次从左上角走到右下角，每过一个格子同样要收集起里面的苹果 (如果格子里的苹果数为0，就不用收集)。\n求你最多能收集到多少苹果。\n\n题目等价于三次都从左上角到右下角,\n相当于三个人同时从左上角到右下角,\n每步每人有向右和向下两种选择, 三个人即2\\*2\\*2有8种情况\n\n三人位置的组合(如((5,5),(5,5),(5,5))表示三人都在右下角)能采到的苹果最大数为上一步所有可能位置的最大苹果数加当前位置的苹果数\n递归向上直到左上角\n每个位置的最大值计算出来后都保存\n \n## 题5 考虑路费情况下的单源最短路径\n\n有额外限制条件\n寻路时有路费限制, 找最短路径\n\n顶点i的过路费为S(i)\n总经费为M\n\n输出包括长度和所需费用,\n\n对指定的结点(初始结点长度为0)和剩余金钱, \n找出钱够的邻结点, 如果路能更短就更新那个结点的长度和剩余金钱, 也可以再记上来自当前结点(用于回溯路径),\n处理完这个结点后, 找出长度最短的未处理的结点, 再进行上述处理, 直至没有未处理的结点\n\n在dijikstra算法中加入剩余金钱这一参数后得到解法\n时间空间复杂度也是原来的平方级\n \n## 题6 01背包问题\n\n有一个包和n个物品，包的容量为m，每个物品都有各自的体积和价值，\n问当从这n个物品中选择多个物品放在包里而物品体积总数不超过包的容量m时，能够得到的最大价值是多少？\n[对于每个物品不可以取多次，最多只能取一次，之所以叫做01背包，0表示不取，1表示取]\n\nN为商品种类数量\nF(i, m)表示重量为i的背包, 在有1-m种商品可供选择时能装的最大价值\nW(i)表示商品i的重量, V(i)表示商品i的价值\n状态转移方程即: F(k, m) = max(F(k - W(m), m - 1) + V(m), F(k, m - 1)), k - W(m) >= 0, 1 =< m =< N\n\n## 心得\n\n完全不存在具有后效性状态定义的问题都是贪心问题, 如求一个数组中的最大值\n\n如果用组合方法求解, 就是把所有的情况都找出来, 然后取最值\n但凡问题里含有最字,往往都可以这样穷举来求解, 但是往往时间复杂度比较高\n更好的算法意味着可以省一些资源, 所以才说更好\n\n动态规划的时间复杂度一般是:\nO(不同的子问题个数 * 每个子问题的状态数)\n\nBellman是个数学家，DP里的programming不是编程的意思，而是决策。\n但这种决策不是一下就出来的，而是一步步(multistage)积累出来。\n换句话说我们需要一个决策，但这个决策太大了，我们做不了，所以需要把他递归到我们可以简单做出决策的状态，然后从这些状态开始，慢慢的\"动态地\"演进到最终的决策。\n比如说用最少的硬币换零钱，突然和你说要换78分钱，你怎么就能迅速给出答案呢，你不能。但是如果是1分的话，你就可以，2分的话呢，就是在1分的基础上再加1分，你也可以。\n于是你就慢慢地从1分开始一直算到78就有答案了。从另一个角度说，如果你用DP算出了怎么换78分，那如果我问你76分怎么换，你也应该有答案了。\n\n每个阶段只有一个状态->递推；费波那契数\n每个阶段的最优状态都是由上一个阶段的最优状态得到的->贪心；计算数组最大值\n每个阶段的最优状态是由之前所有阶段的状态的组合得到的->搜索；Dijkstra寻路\n每个阶段的最优状态可以从之前某个阶段的某个或某些状态直接得到而不管之前这个状态是如何得到的->动态规划。用最少的硬币换零钱\n\n总的来说还是有些运算和(或)存储可以省, 好的算法也就是好在这里, 运筹的本质就是要省\n找到哪里可以省就是关键, 即找到重叠子问题\n\nDP的关键是通过状态的合并减少计算量, 进行BFS，并对BFS中每个点保存最优状态，如果有不同的路径BFS到了同一个点，留最好的一条就行, dijikstra就是这样\n由于所有计算机上可计算的问题的算法都可以转为图灵机模型，而图灵机是一种带无限存储的自动机模型，也就是说能在计算机上解决的问题基本都能转换成上面这种状态迁移图\n\n自底向上动态规划需要确保按适当顺序计算函数值,以保证在我们需要值的时候可以直接取到\n自顶向下动态规划使用递归,往往更自然,而且不需要所有子问题的解\n\n## 参考链接\nhttps://www.zhihu.com/question/23995189/answer/35429905\nhttps://www.topcoder.com/community/data-science/data-science-tutorials/dynamic-programming-from-novice-to-advanced/\nhttp://www.hawstein.com/posts/dp-novice-to-advanced.html\n\n","source":"_posts/dynamic_programming.md","raw":"title: dynamic programming\ndate: 2016-03-02\ntags: [algorithm]\n---\n\n动态规划常常适用于有重叠子问题和最优子结构性质的问题。\n**最优子结构性质** 如果问题的最优解所包含的子问题的解也是最优的，我们就称该问题具有最优子结构性质。\n**无后效性** 即子问题的解一旦确定，就不再改变，不受在这之后、包含它的更大的问题的求解决策影响。\n**子问题重叠性质** 子问题重叠性质是指在用递归算法自顶向下对问题求解时，每次产生的子问题并不总是新问题。\n\n通常许多子问题非常相似，为此动态规划法试图仅仅解决每个子问题一次，从而减少计算量：\n一旦某个给定子问题的解已经算出，则将其存储，以便下次需要同一个子问题解之时直接查表。这种做法在重复子问题的数目关于输入的规模呈指数增长时特别有用。\n\n<!--more-->\n\n## 思路\n通常我们从过程的最后一步开始考虑，而不是先考虑过程的开始。\n\n找到任何一个规律后,把这个规律表示出来,未知的部分全部用代数解决\n比如01背包问题对每一件商品无非两种情况, 要么装要么不装, 取两者的大者, 于是这里有一个是否装和max的逻辑,\n写下来就是, 对于商品i而言, 最大价值为: max(装的情况的价值, 不装的情况的价值)\nN为商品种类数量\nF(i, m)表示重量为i的背包, 在有1-m种商品可供选择时能装的最大价值\nW(i)表示商品i的重量, V(i)表示商品i的价值\n状态转移方程即: F(k, m) = max(F(k - W(m), m - 1) + V(m), F(k, m - 1)), k - W(m) >= 0, 1 =< m =< N\n\n给定体积的背包里, 对每一件商品而言有两种选择, 需要找出价值大的,\n遍历完所有商品得到给定体积的背包的最大价值, 体积是一个额外限制, 所以比零钱问题多了一个维度\n而找零问题是对每一个找零目标(如1分钱,2分钱,76分钱)有几种硬币可选, 需要找出硬币数量少的\n\n## 题0 费波那契\n\n使用计算机解决一个问题是在思考如何将这个问题表达成状态（用哪些变量存储哪些数据）以及如何在状态中转移（怎样根据一些变量计算出另一些变量）。\n所以空间复杂度是为了支持计算所必需存储的状态有多少，时间复杂度是从初始状态到最终状态的过程中需要多少步\n比如说计算第100个费波那契数，每一个费波那契数就是这个问题的一个状态，每求一个新数字只需要之前的两个状态。\n所以同一个时刻，最多只需要保存两个状态，空间复杂度就是常数；每计算一个新状态所需要的时间也是常数且状态线性递增，所以时间复杂度也是线性的。\n\n费波那契数这个问题里没有最的概念, 而\"最\"都是比出来的, \n没有最就不用比了, 其实也没得比, 因为每一步的计算结果都只有一个值,\n有些问题每一步有多种可能性, 往往就要选一个最好的\n\n## 题1 用最少的硬币找零钱\n\n给定N种硬币,它们的价值分别是(V1, V2, ..., VN)\n求最少需要几枚硬币才能凑出价值S(每种硬币都是要多少有多少)\n\n这里出现了一个最字, 有N种硬币, 意味着每阶段都要用N种硬币去尝试得到一个\"最\"优解, 即穷举N种硬币的情况并比较\n\n这一点和费波那契很像, 都是从目标值1开始一步步算上去的\n\n## 题2 求最长上升子序列的长度\n\n如: 5，3，4，8，6，7\n\n状态: 以第i个元素结尾的情况\nLIS(i) = max{LIS(j) + 1} j < i and a[j] < a[i]\n\n## 题3 二维地图摘苹果\n\nF(1, 1) = A(1, 1)\nF(1, 2) = F(1, 1) + A(1, 2)\nF(2, 1) = F(1, 1) + A(2, 1)\nF(i, j) = max(F(i - 1, j), F(i, j - 1)) + A(i, j)\n\nN \\* M个子问题, 每个子问题两次判断, O(N \\* M \\* 2)\n\n比之前的问题复杂的是, 这个问题是二维的, 有两个参数\n\n## 题4 三趟摘苹果\n\n给定一个M行N列的矩阵(M*N个格子)，每个格子中放着一定数量的苹果。 \n从左上角的格子开始，只能向下或向右走，目的地是右下角的格子。每走过一个格子，就把格子上的苹果都收集起来。\n然后从右下角走回左上角的格子，每次只能向左或是向上走，同样的，走过一个格子就把里面的苹果都收集起来。\n最后，再一次从左上角走到右下角，每过一个格子同样要收集起里面的苹果 (如果格子里的苹果数为0，就不用收集)。\n求你最多能收集到多少苹果。\n\n题目等价于三次都从左上角到右下角,\n相当于三个人同时从左上角到右下角,\n每步每人有向右和向下两种选择, 三个人即2\\*2\\*2有8种情况\n\n三人位置的组合(如((5,5),(5,5),(5,5))表示三人都在右下角)能采到的苹果最大数为上一步所有可能位置的最大苹果数加当前位置的苹果数\n递归向上直到左上角\n每个位置的最大值计算出来后都保存\n \n## 题5 考虑路费情况下的单源最短路径\n\n有额外限制条件\n寻路时有路费限制, 找最短路径\n\n顶点i的过路费为S(i)\n总经费为M\n\n输出包括长度和所需费用,\n\n对指定的结点(初始结点长度为0)和剩余金钱, \n找出钱够的邻结点, 如果路能更短就更新那个结点的长度和剩余金钱, 也可以再记上来自当前结点(用于回溯路径),\n处理完这个结点后, 找出长度最短的未处理的结点, 再进行上述处理, 直至没有未处理的结点\n\n在dijikstra算法中加入剩余金钱这一参数后得到解法\n时间空间复杂度也是原来的平方级\n \n## 题6 01背包问题\n\n有一个包和n个物品，包的容量为m，每个物品都有各自的体积和价值，\n问当从这n个物品中选择多个物品放在包里而物品体积总数不超过包的容量m时，能够得到的最大价值是多少？\n[对于每个物品不可以取多次，最多只能取一次，之所以叫做01背包，0表示不取，1表示取]\n\nN为商品种类数量\nF(i, m)表示重量为i的背包, 在有1-m种商品可供选择时能装的最大价值\nW(i)表示商品i的重量, V(i)表示商品i的价值\n状态转移方程即: F(k, m) = max(F(k - W(m), m - 1) + V(m), F(k, m - 1)), k - W(m) >= 0, 1 =< m =< N\n\n## 心得\n\n完全不存在具有后效性状态定义的问题都是贪心问题, 如求一个数组中的最大值\n\n如果用组合方法求解, 就是把所有的情况都找出来, 然后取最值\n但凡问题里含有最字,往往都可以这样穷举来求解, 但是往往时间复杂度比较高\n更好的算法意味着可以省一些资源, 所以才说更好\n\n动态规划的时间复杂度一般是:\nO(不同的子问题个数 * 每个子问题的状态数)\n\nBellman是个数学家，DP里的programming不是编程的意思，而是决策。\n但这种决策不是一下就出来的，而是一步步(multistage)积累出来。\n换句话说我们需要一个决策，但这个决策太大了，我们做不了，所以需要把他递归到我们可以简单做出决策的状态，然后从这些状态开始，慢慢的\"动态地\"演进到最终的决策。\n比如说用最少的硬币换零钱，突然和你说要换78分钱，你怎么就能迅速给出答案呢，你不能。但是如果是1分的话，你就可以，2分的话呢，就是在1分的基础上再加1分，你也可以。\n于是你就慢慢地从1分开始一直算到78就有答案了。从另一个角度说，如果你用DP算出了怎么换78分，那如果我问你76分怎么换，你也应该有答案了。\n\n每个阶段只有一个状态->递推；费波那契数\n每个阶段的最优状态都是由上一个阶段的最优状态得到的->贪心；计算数组最大值\n每个阶段的最优状态是由之前所有阶段的状态的组合得到的->搜索；Dijkstra寻路\n每个阶段的最优状态可以从之前某个阶段的某个或某些状态直接得到而不管之前这个状态是如何得到的->动态规划。用最少的硬币换零钱\n\n总的来说还是有些运算和(或)存储可以省, 好的算法也就是好在这里, 运筹的本质就是要省\n找到哪里可以省就是关键, 即找到重叠子问题\n\nDP的关键是通过状态的合并减少计算量, 进行BFS，并对BFS中每个点保存最优状态，如果有不同的路径BFS到了同一个点，留最好的一条就行, dijikstra就是这样\n由于所有计算机上可计算的问题的算法都可以转为图灵机模型，而图灵机是一种带无限存储的自动机模型，也就是说能在计算机上解决的问题基本都能转换成上面这种状态迁移图\n\n自底向上动态规划需要确保按适当顺序计算函数值,以保证在我们需要值的时候可以直接取到\n自顶向下动态规划使用递归,往往更自然,而且不需要所有子问题的解\n\n## 参考链接\nhttps://www.zhihu.com/question/23995189/answer/35429905\nhttps://www.topcoder.com/community/data-science/data-science-tutorials/dynamic-programming-from-novice-to-advanced/\nhttp://www.hawstein.com/posts/dp-novice-to-advanced.html\n\n","slug":"dynamic_programming","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5kk0044mcxqswoagww9"},{"title":"elixir struct","date":"2021-06-24T16:00:00.000Z","_content":"\n看下面的示例, 原来还可以这样 pattern match , 现在才知道\n\n```elixir\n> %m{} = %Example.AgentInfo{}\n%Example.AgentInfo{\n  agent_id: 0\n}\n> m\nExample.AgentInfo\n```\n\n\n\n\n\n","source":"_posts/elixir_struct.md","raw":"title: elixir struct\ndate: 2021-06-25\n\ntags: [elixir]\n---\n\n看下面的示例, 原来还可以这样 pattern match , 现在才知道\n\n```elixir\n> %m{} = %Example.AgentInfo{}\n%Example.AgentInfo{\n  agent_id: 0\n}\n> m\nExample.AgentInfo\n```\n\n\n\n\n\n","slug":"elixir_struct","published":1,"updated":"2021-06-25T14:06:40.132Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5km0047mcxq8plch3cm"},{"title":"erlang 19.0发布啦","date":"2016-06-28T03:27:00.000Z","_content":"\n光阴似箭, 迎来了19.0\n\n<!--more-->\n\n看看有哪些新特性吧\n\n### compiler, stdlib\n新的预处理器宏, ?FUNCTION_NAME, ?FUNCTION_ARITY \n新的预处理器指令, -error(Term)和-warning(Term), 用于产生编译错误和警告\n\n### gen_statem\n新的状态机behavior, 取代gen_fsm\n\n### mnesia_ext\n用于接入外部存储的mnesia插件, mnesia可以用上mysql, redis了?\n\n### crypto\n性能更好且支持硬件加速(HW acceleration)\n\n### ssh\n使用gen_statem提升了性能\n\n### ssl\n改善错误日志\n\n### dialyzer\n对map的支持大幅扩展, 包括type specification语法和type analysis\n\n### erts\nerlang:open_port(spawn, ...), 快3-5倍\ntracing, 大幅改进(可伸缩性,性能,send/receive上的match specification,支持lttng,...)\ndirty调度器改进\n单进程级的message_queue配置\n多module的快速加载\n增加一个process flag: max_heap_size\n\n### erts/kernel\nUnix Domain Socket的试验性支持, 如\n```\ngen_udp:open(0, [{ifaddr,{local,\"/tmp/socket\"}}])\n```\n\n## 参考链接\nhttp://www.erlang.org/download/otp_src_19.0.readme\n\n","source":"_posts/erlang_19.0.md","raw":"title: erlang 19.0发布啦\ndate: 2016-06-28 11:27:00\ntags: erlang\n---\n\n光阴似箭, 迎来了19.0\n\n<!--more-->\n\n看看有哪些新特性吧\n\n### compiler, stdlib\n新的预处理器宏, ?FUNCTION_NAME, ?FUNCTION_ARITY \n新的预处理器指令, -error(Term)和-warning(Term), 用于产生编译错误和警告\n\n### gen_statem\n新的状态机behavior, 取代gen_fsm\n\n### mnesia_ext\n用于接入外部存储的mnesia插件, mnesia可以用上mysql, redis了?\n\n### crypto\n性能更好且支持硬件加速(HW acceleration)\n\n### ssh\n使用gen_statem提升了性能\n\n### ssl\n改善错误日志\n\n### dialyzer\n对map的支持大幅扩展, 包括type specification语法和type analysis\n\n### erts\nerlang:open_port(spawn, ...), 快3-5倍\ntracing, 大幅改进(可伸缩性,性能,send/receive上的match specification,支持lttng,...)\ndirty调度器改进\n单进程级的message_queue配置\n多module的快速加载\n增加一个process flag: max_heap_size\n\n### erts/kernel\nUnix Domain Socket的试验性支持, 如\n```\ngen_udp:open(0, [{ifaddr,{local,\"/tmp/socket\"}}])\n```\n\n## 参考链接\nhttp://www.erlang.org/download/otp_src_19.0.readme\n\n","slug":"erlang_19.0","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ko0049mcxq8fr5r9uh"},{"title":"erlang app启动顺序","date":"2015-10-12T16:00:00.000Z","_content":"\n## application启动顺序\n由.boot文件决定,\n.boot文件(二进制文件)由.script编译而来,\n.script文件摘抄如下,可见emysql在ranch之前启动\n<pre>{path,[\"$ROOT/lib/emysql-0.4.1/ebin\"]},                                     \n  {primLoad,                                                                  \n    [emysql,emysql_app,emysql_auth,emysql_conn,emysql_conn_mgr,             \n     emysql_conv,emysql_statements,emysql_sup,emysql_tcp,emysql_util,       \n     emysql_worker]},                                                       \n{path,[\"$ROOT/lib/ranch-1.0.0/ebin\"]},                                      \n  {primLoad,                                                                  \n    [ranch,ranch_acceptor,ranch_acceptors_sup,ranch_app,ranch_conns_sup,    \n     ranch_listener_sup,ranch_protocol,ranch_server,ranch_ssl,ranch_sup,    \n     ranch_tcp,ranch_transport]}, \n...\n</pre>\n\n.script文件由.rel文件决定\n<pre>{release,{\"suex_1\",\"1\"}, {erts,\"7.0\"},                                                           \n         [{kernel,\"4.0\"},\n          {stdlib,\"2.5\"},\n          {crypto,\"3.6\"},\n          {sasl,\"2.5\"},\n          {emysql,\"0.4.1\"},\n          {ranch,\"1.0.0\"},\n          {recon,\"2.2.2\"},\n          {suex,\"1\"}]}.\n</pre>\n\n而使用relx的情况下,.rel文件由relx根据各application的.app文件和relx.config生成\nsuex.app\n<pre>{applications, [                                                             \n         kernel, stdlib, crypto, sasl                                             \n]}, \n</pre>\n\nrelx.config\n<pre>{release, {suex_1, \"1\"}, [emysql, ranch, recon, suex]}. \n</pre>\n\n## 参考链接\nhttp://www.erlang.org/doc/man/rel.html\nhttp://www.erlang.org/doc/man/script.html\n\n","source":"_posts/erlang_app_seq.md","raw":"title: erlang app启动顺序\ndate: 2015-10-13\ntags: [erlang]\n---\n\n## application启动顺序\n由.boot文件决定,\n.boot文件(二进制文件)由.script编译而来,\n.script文件摘抄如下,可见emysql在ranch之前启动\n<pre>{path,[\"$ROOT/lib/emysql-0.4.1/ebin\"]},                                     \n  {primLoad,                                                                  \n    [emysql,emysql_app,emysql_auth,emysql_conn,emysql_conn_mgr,             \n     emysql_conv,emysql_statements,emysql_sup,emysql_tcp,emysql_util,       \n     emysql_worker]},                                                       \n{path,[\"$ROOT/lib/ranch-1.0.0/ebin\"]},                                      \n  {primLoad,                                                                  \n    [ranch,ranch_acceptor,ranch_acceptors_sup,ranch_app,ranch_conns_sup,    \n     ranch_listener_sup,ranch_protocol,ranch_server,ranch_ssl,ranch_sup,    \n     ranch_tcp,ranch_transport]}, \n...\n</pre>\n\n.script文件由.rel文件决定\n<pre>{release,{\"suex_1\",\"1\"}, {erts,\"7.0\"},                                                           \n         [{kernel,\"4.0\"},\n          {stdlib,\"2.5\"},\n          {crypto,\"3.6\"},\n          {sasl,\"2.5\"},\n          {emysql,\"0.4.1\"},\n          {ranch,\"1.0.0\"},\n          {recon,\"2.2.2\"},\n          {suex,\"1\"}]}.\n</pre>\n\n而使用relx的情况下,.rel文件由relx根据各application的.app文件和relx.config生成\nsuex.app\n<pre>{applications, [                                                             \n         kernel, stdlib, crypto, sasl                                             \n]}, \n</pre>\n\nrelx.config\n<pre>{release, {suex_1, \"1\"}, [emysql, ranch, recon, suex]}. \n</pre>\n\n## 参考链接\nhttp://www.erlang.org/doc/man/rel.html\nhttp://www.erlang.org/doc/man/script.html\n\n","slug":"erlang_app_seq","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5kp004cmcxq6zh9zgmh"},{"title":"erlang array","date":"2015-12-28T16:00:00.000Z","_content":"\nerlang的array其实是一个树(默认十叉), 访问效率不是O(1), 是O(lg10(N))\n\n<!--more-->\n\n## 记住array的索引与其他数据结构不同, 是从0开始的!\narray的实现方式是嵌套tuple, 事实上一个树, 就像这样\n```\n> lists:foldl(fun(I, Acc) -> array:set(I - 1, I, Acc) end, array:new(), lists:seq(1, 300)).\n{array,300,1000,undefined,\n    {{{1,2,3,4,5,6,7,8,9,10},\n         {11,12,13,14,15,16,17,18,19,20},\n         {21,22,23,24,25,26,27,28,29,30},\n         {31,32,33,34,35,36,37,38,39,40},\n         {41,42,43,44,45,46,47,48,49,50},\n         {51,52,53,54,55,56,57,58,59,60},\n         {61,62,63,64,65,66,67,68,69,70},\n         {71,72,73,74,75,76,77,78,79,80},\n         {81,82,83,84,85,86,87,88,89,90},\n         {91,92,93,94,95,96,97,98,99,100},\n         10},\n    {{101,102,103,104,105,106,107,108,109,110},\n        {111,112,113,114,115,116,117,118,119,120},\n        {121,122,123,124,125,126,127,128,129,130},\n        {131,132,133,134,135,136,137,138,139,140},\n        {141,142,143,144,145,146,147,148,149,150},\n        {151,152,153,154,155,156,157,158,159,160},\n        {161,162,163,164,165,166,167,168,169,170},\n        {171,172,173,174,175,176,177,178,179,180},\n        {181,182,183,184,185,186,187,188,189,190},\n        {191,192,193,194,195,196,197,198,199,200},\n        10},\n    {{201,202,203,204,205,206,207,208,209,210},\n        {211,212,213,214,215,216,217,218,219,220},\n        {221,222,223,224,225,226,227,228,229,230},\n        {231,232,233,234,235,236,237,238,239,240},\n        {241,242,243,244,245,246,247,248,249,250},\n        {251,252,253,254,255,256,257,258,259,260},\n        {261,262,263,264,265,266,267,268,269,270},\n        {271,272,273,274,275,276,277,278,279,280},\n        {281,282,283,284,285,286,287,288,289,290},\n        {291,292,293,294,295,296,297,298,299,300},\n        10},\n    100,100,100,100,100,100,100,100}}\n```\n\n树在变量单次赋值的语言中很常见\n你可以用一个很长的tuple来得到很快的读取速度, 但是更新时必须重新构建整个tuple会极慢(复制原有数据)且占用大量内存\n而使用tree的话, 更新时只需重新构建一个leaf即可\n如上例中4被改成5的话, 只需重新构建一个{1,2,3,5,5,6,7,8,9,10}leaf, 取代原来的leaf挂上父结点即可, 其他结点都不受影响\n\n另外, 可以使用NIF实现array, 但是如果要写数据到进程堆那么一定不要用可变数据(mutating data), gc会出问题\n\n## 参考链接\nhttp://stackoverflow.com/questions/16447921/arrays-implementation-in-erlang\n\n","source":"_posts/erlang_array.md","raw":"title: erlang array\ndate: 2015-12-29\ntags: [erlang]\n---\n\nerlang的array其实是一个树(默认十叉), 访问效率不是O(1), 是O(lg10(N))\n\n<!--more-->\n\n## 记住array的索引与其他数据结构不同, 是从0开始的!\narray的实现方式是嵌套tuple, 事实上一个树, 就像这样\n```\n> lists:foldl(fun(I, Acc) -> array:set(I - 1, I, Acc) end, array:new(), lists:seq(1, 300)).\n{array,300,1000,undefined,\n    {{{1,2,3,4,5,6,7,8,9,10},\n         {11,12,13,14,15,16,17,18,19,20},\n         {21,22,23,24,25,26,27,28,29,30},\n         {31,32,33,34,35,36,37,38,39,40},\n         {41,42,43,44,45,46,47,48,49,50},\n         {51,52,53,54,55,56,57,58,59,60},\n         {61,62,63,64,65,66,67,68,69,70},\n         {71,72,73,74,75,76,77,78,79,80},\n         {81,82,83,84,85,86,87,88,89,90},\n         {91,92,93,94,95,96,97,98,99,100},\n         10},\n    {{101,102,103,104,105,106,107,108,109,110},\n        {111,112,113,114,115,116,117,118,119,120},\n        {121,122,123,124,125,126,127,128,129,130},\n        {131,132,133,134,135,136,137,138,139,140},\n        {141,142,143,144,145,146,147,148,149,150},\n        {151,152,153,154,155,156,157,158,159,160},\n        {161,162,163,164,165,166,167,168,169,170},\n        {171,172,173,174,175,176,177,178,179,180},\n        {181,182,183,184,185,186,187,188,189,190},\n        {191,192,193,194,195,196,197,198,199,200},\n        10},\n    {{201,202,203,204,205,206,207,208,209,210},\n        {211,212,213,214,215,216,217,218,219,220},\n        {221,222,223,224,225,226,227,228,229,230},\n        {231,232,233,234,235,236,237,238,239,240},\n        {241,242,243,244,245,246,247,248,249,250},\n        {251,252,253,254,255,256,257,258,259,260},\n        {261,262,263,264,265,266,267,268,269,270},\n        {271,272,273,274,275,276,277,278,279,280},\n        {281,282,283,284,285,286,287,288,289,290},\n        {291,292,293,294,295,296,297,298,299,300},\n        10},\n    100,100,100,100,100,100,100,100}}\n```\n\n树在变量单次赋值的语言中很常见\n你可以用一个很长的tuple来得到很快的读取速度, 但是更新时必须重新构建整个tuple会极慢(复制原有数据)且占用大量内存\n而使用tree的话, 更新时只需重新构建一个leaf即可\n如上例中4被改成5的话, 只需重新构建一个{1,2,3,5,5,6,7,8,9,10}leaf, 取代原来的leaf挂上父结点即可, 其他结点都不受影响\n\n另外, 可以使用NIF实现array, 但是如果要写数据到进程堆那么一定不要用可变数据(mutating data), gc会出问题\n\n## 参考链接\nhttp://stackoverflow.com/questions/16447921/arrays-implementation-in-erlang\n\n","slug":"erlang_array","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5kq004emcxq8z53jguh"},{"title":"erlang bit syntax","date":"2015-09-06T16:00:00.000Z","_content":"erlang二进制语法点滴\n<!--more-->\n## 整型默认长度8位及一个疑点\n```erlang\nErlang/OTP 17 [erts-6.0] [source] [smp:2:2] [async-threads:10] [kernel-poll:false]\n\nEshell V6.0  (abort with ^G)\n1> <<100,200,300,400>>.\n<<100,200,44,144>>\n2> <<100,200,300:16,400:16>>.\n<<100,200,1,44,1,144>>\n```\n说明了一个segment默认是8位,高于8位的部分被截断\n\n同理\n```erlang\n1> A = <<15768105>>.\n<<\")\">>\n2> $).\n41\n3> io:format(\"~.16B\", [15768105]).\nF09A29ok\n```\n\n16进制29是10进制的41,由此可以看出<<15768105>>其实等于<<41>>\n\n但是\n```erlang\n1> <<41>> = <<15768105>>.\n<<\")\">>\n2> <<15768105>> = <<41>>.\n** exception error: no match of right hand side value <<\")\">>\n3>  <<1:1>> = <<3:1>>.\n<<1:1>>\n4> <<3:1>> = <<1:1>>.\n** exception error: no match of right hand side value <<1:1>>\n5> <<5:2>> = <<13:2>>.\n** exception error: no match of right hand side value <<1:2>>\n6> A = <<15768105>>.\n<<\")\">>\n7> B = <<41>>.\n<<\")\">>\n8> A = B.\n<<\")\">>\n```\n这些该如何解释呢?\n\n## 基本形式\n```erlang\nValue:Size/TypeSpecifierList\nTypeSpecifierList包括\nType(integer, float, binary, bitstring),\nSignedness(signed, unsigned),\nEndianness(big, little, native),\nUnit(1-256)\ne.g.\nX:4/little-signed-integer-unit:8\n<<X:4/big-signed-float-unit:16>> = <<100.5/float>>.\n```\n\n## 默认值\n类型默认为integer\nSize的默认项:\ninteger默认8位,float默认64位\nbinary或bitstring处于尾部时默认匹配全部\nUnit的默认项:\ninteger和float和bitstring为1, binary为8\nSignedness默认为unsigned\nEndianness默认为big\n\n## 词法注意\n```erlang\nB=<<1>>需要写成B = <<1>>, 否则编译器会理解为小于等于\n<<X+1:8>>需要写成<<(X+1):8>>, 否则编译器会理解为(1:8)\n匹配时Value和Size必须是常量或已绑定的变量\n下面的形式会报N is unbound错,\nfoo(N, <<X:N,T/binary>>) ->\n   {X,T}.\n正确的写法:\nfoo(N, Bin) ->\n   <<X:N,T/binary>> = Bin,\n   {X,T}.\n```\n\n## Unit\n最好不要改binary和bitstring的Unit\n\n## 语法糖\n```erlang\n<<\"hello\">>是<<$h,$e,$l,$l,$o>>的语法糖\n```\n\n## 常用写法\n取尾部的写法:\n```erlang\nfoo(<<A:8,Rest/binary>>) ->\nfoo(<<A:8,Rest/bitstring>>) ->\n```\n\n高效拼binary的写法:\n```erlang\ntriples_to_bin(T) ->\n    triples_to_bin(T, <<>>).\n\ntriples_to_bin([{X,Y,Z} | T], Acc) ->\n    triples_to_bin(T, <<Acc/binary,X:32,Y:32,Z:32>>);   % inefficient before R12B\ntriples_to_bin([], Acc) ->\n    Acc.\n```\n\n## 参考链接\n[官方文档](http://www.erlang.org/doc/programming_examples/bit_syntax.html)\n\n","source":"_posts/erlang_bitsyntax.md","raw":"title: erlang bit syntax\ndate: 2015-09-07\ntags: [erlang]\n---\nerlang二进制语法点滴\n<!--more-->\n## 整型默认长度8位及一个疑点\n```erlang\nErlang/OTP 17 [erts-6.0] [source] [smp:2:2] [async-threads:10] [kernel-poll:false]\n\nEshell V6.0  (abort with ^G)\n1> <<100,200,300,400>>.\n<<100,200,44,144>>\n2> <<100,200,300:16,400:16>>.\n<<100,200,1,44,1,144>>\n```\n说明了一个segment默认是8位,高于8位的部分被截断\n\n同理\n```erlang\n1> A = <<15768105>>.\n<<\")\">>\n2> $).\n41\n3> io:format(\"~.16B\", [15768105]).\nF09A29ok\n```\n\n16进制29是10进制的41,由此可以看出<<15768105>>其实等于<<41>>\n\n但是\n```erlang\n1> <<41>> = <<15768105>>.\n<<\")\">>\n2> <<15768105>> = <<41>>.\n** exception error: no match of right hand side value <<\")\">>\n3>  <<1:1>> = <<3:1>>.\n<<1:1>>\n4> <<3:1>> = <<1:1>>.\n** exception error: no match of right hand side value <<1:1>>\n5> <<5:2>> = <<13:2>>.\n** exception error: no match of right hand side value <<1:2>>\n6> A = <<15768105>>.\n<<\")\">>\n7> B = <<41>>.\n<<\")\">>\n8> A = B.\n<<\")\">>\n```\n这些该如何解释呢?\n\n## 基本形式\n```erlang\nValue:Size/TypeSpecifierList\nTypeSpecifierList包括\nType(integer, float, binary, bitstring),\nSignedness(signed, unsigned),\nEndianness(big, little, native),\nUnit(1-256)\ne.g.\nX:4/little-signed-integer-unit:8\n<<X:4/big-signed-float-unit:16>> = <<100.5/float>>.\n```\n\n## 默认值\n类型默认为integer\nSize的默认项:\ninteger默认8位,float默认64位\nbinary或bitstring处于尾部时默认匹配全部\nUnit的默认项:\ninteger和float和bitstring为1, binary为8\nSignedness默认为unsigned\nEndianness默认为big\n\n## 词法注意\n```erlang\nB=<<1>>需要写成B = <<1>>, 否则编译器会理解为小于等于\n<<X+1:8>>需要写成<<(X+1):8>>, 否则编译器会理解为(1:8)\n匹配时Value和Size必须是常量或已绑定的变量\n下面的形式会报N is unbound错,\nfoo(N, <<X:N,T/binary>>) ->\n   {X,T}.\n正确的写法:\nfoo(N, Bin) ->\n   <<X:N,T/binary>> = Bin,\n   {X,T}.\n```\n\n## Unit\n最好不要改binary和bitstring的Unit\n\n## 语法糖\n```erlang\n<<\"hello\">>是<<$h,$e,$l,$l,$o>>的语法糖\n```\n\n## 常用写法\n取尾部的写法:\n```erlang\nfoo(<<A:8,Rest/binary>>) ->\nfoo(<<A:8,Rest/bitstring>>) ->\n```\n\n高效拼binary的写法:\n```erlang\ntriples_to_bin(T) ->\n    triples_to_bin(T, <<>>).\n\ntriples_to_bin([{X,Y,Z} | T], Acc) ->\n    triples_to_bin(T, <<Acc/binary,X:32,Y:32,Z:32>>);   % inefficient before R12B\ntriples_to_bin([], Acc) ->\n    Acc.\n```\n\n## 参考链接\n[官方文档](http://www.erlang.org/doc/programming_examples/bit_syntax.html)\n\n","slug":"erlang_bitsyntax","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ks004hmcxqiacad2t0"},{"title":"erlang concurrency","date":"2016-02-23T16:00:00.000Z","_content":"\n## gen_server:call的Req参数可以这样子\n{a, {b, {c, Req}}}\n每次剥一层处理一层,\n就像网络协议一样, 每层都有自己的头部\n\n\n","source":"_posts/erlang_concurrency.md","raw":"title: erlang concurrency\ndate: 2016-02-24\ntags: [erlang]\n---\n\n## gen_server:call的Req参数可以这样子\n{a, {b, {c, Req}}}\n每次剥一层处理一层,\n就像网络协议一样, 每层都有自己的头部\n\n\n","slug":"erlang_concurrency","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ku004jmcxqdc97cws9"},{"title":"erlang评论","date":"2016-08-17T13:27:00.000Z","_content":"\n### 对erlang并行及性能的精彩评论\n在stack overflow看到一段话, 句句说到心坎里,\n忍不住转载如下\n\nAlmost any language can be parallelized. In some languages it's simple, in others it's a pain in the butt, but it can be done. If you want to run a C++ program across 8000 CPU's in a grid, go ahead! You can do that. It's been done before.\n\n**Erlang doesn't do anything that's impossible in other languages.** If a single CPU running an Erlang program is less efficient than the same CPU running a C++ program, then two hundred CPU's running Erlang will also be slower than two hundred CPU's running C++.\n\n**What Erlang does do is making this kind of parallelism easy to work with. It saves developer time and reduces the chance of bugs.**\n\nSo I'm going to say no, there is no tipping point at which Erlang's parallelism allows it to outperform another language's numerical number-crunching strength.\n\nWhere Erlang scores is in making it easier to scale out and do so correctly. But it can still be done in other languages which are better at number-crunching, if you're willing to spend the extra development time.\n\nAnd of course, let's not forget the good old point that **languages don't have a speed**. A sufficiently good Erlang compiler would yield perfectly optimal code. **A sufficiently bad C compiler would yield code that runs slower than anything else.**\n\n### 调度问题\nErlang has preemptive scheduling, and so there is no guarantee that a central process will necessarily get all of the CPU time it needs to flush data,\nunless raising the process' priority, but if not done carefully, you can hog a scheduler and make everything rather unfair.\nIn any case, you want to avoid the pattern where a lot of work is done on a single process.\n\n## 参考链接\nhttp://stackoverflow.com/questions/1308527/when-does-erlangs-parallelism-overcome-its-weaknesses-in-numeric-computing\n\n","source":"_posts/erlang_comment.md","raw":"title: erlang评论\ndate: 2016-08-17 21:27:00\ntags: erlang\n---\n\n### 对erlang并行及性能的精彩评论\n在stack overflow看到一段话, 句句说到心坎里,\n忍不住转载如下\n\nAlmost any language can be parallelized. In some languages it's simple, in others it's a pain in the butt, but it can be done. If you want to run a C++ program across 8000 CPU's in a grid, go ahead! You can do that. It's been done before.\n\n**Erlang doesn't do anything that's impossible in other languages.** If a single CPU running an Erlang program is less efficient than the same CPU running a C++ program, then two hundred CPU's running Erlang will also be slower than two hundred CPU's running C++.\n\n**What Erlang does do is making this kind of parallelism easy to work with. It saves developer time and reduces the chance of bugs.**\n\nSo I'm going to say no, there is no tipping point at which Erlang's parallelism allows it to outperform another language's numerical number-crunching strength.\n\nWhere Erlang scores is in making it easier to scale out and do so correctly. But it can still be done in other languages which are better at number-crunching, if you're willing to spend the extra development time.\n\nAnd of course, let's not forget the good old point that **languages don't have a speed**. A sufficiently good Erlang compiler would yield perfectly optimal code. **A sufficiently bad C compiler would yield code that runs slower than anything else.**\n\n### 调度问题\nErlang has preemptive scheduling, and so there is no guarantee that a central process will necessarily get all of the CPU time it needs to flush data,\nunless raising the process' priority, but if not done carefully, you can hog a scheduler and make everything rather unfair.\nIn any case, you want to avoid the pattern where a lot of work is done on a single process.\n\n## 参考链接\nhttp://stackoverflow.com/questions/1308527/when-does-erlangs-parallelism-overcome-its-weaknesses-in-numeric-computing\n\n","slug":"erlang_comment","published":1,"updated":"2019-02-11T03:02:47.762Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5kv004lmcxq6pbimsqc"},{"title":"erlang各编译期的代码","date":"2015-09-10T16:00:00.000Z","_content":"对于如下源码test.erl\n```erlang\n-module(test).      \n-export([fac/1]).                                                                \nfac(1) -> 1;                                                                     \nfac(N) -> N * fac(N - 1).\n```\n在各编译期有不同的形式\n<!--more-->\n可以在erlang shell里使用c命令编译\n> Erlang/OTP 18 [erts-7.0] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]\n> \n> Eshell V7.0  (abort with ^G)\n> 1> `c(test, 'P')`.    \n> ** Warning: No object file created - nothing loaded **\n\n也可以用erlc\n> $ erlc -help\n> Usage: erlc [Options] file.ext ...\n> Options:\n> ...\n> -E             generate listing of expanded code (Erlang compiler)\n> -S             generate assembly listing (Erlang compiler)\n> -P             generate listing of preprocessed code (Erlang compiler)\n> +term          pass the Erlang term unchanged to the compiler\n\n## P\n生成经过预处理和parse transform的代码, 扩展名.P\n$ erlc -P test.erl\n```erlang\n-file(\"test.erl\", 1).                                                            \n                                                                                 \n-module(test).                                                                   \n                                                                                 \n-export([fac/1]).                                                                \n                                                                                 \nfac(1) ->                                                                        \n    1;                                                                           \nfac(N) ->                                                                        \n    N * fac(N - 1). \n```\n\n## E\n生成经过所有源代码处理的代码, 扩展名.E\n$ erlc -E test.erl\n```erlang\n-file(\"test.erl\", 1).                                                            \n                                                                                 \nfac(1) ->                                                                        \n    1;                                                                           \nfac(N) ->                                                                        \n    N * fac(N - 1).                                                              \n                                                                                 \nmodule_info() ->                                                                 \n    erlang:get_module_info(test).                                                \n                                                                                 \nmodule_info(X) ->                                                                \n    erlang:get_module_info(test, X).\n```\n\n## S\n生成中间汇编码, 扩展名.S\n$ erlc -S test.erl\n```\n{module, test}.  %% version = 0                                                  \n                                                                                 \n{exports, [{fac,1},{module_info,0},{module_info,1}]}.                            \n                                                                                 \n{attributes, []}.                                                                \n                                                                                 \n{labels, 8}.                                                                     \n                                                                                 \n                                                                                 \n{function, fac, 1, 2}.                                                           \n  {label,1}.                                                                     \n    {line,[{location,\"test.erl\",3}]}.                                            \n    {func_info,{atom,test},{atom,fac},1}.                                        \n  {label,2}.                                                                     \n    {test,is_eq_exact,{f,3},[{x,0},{integer,1}]}.                                \n    return.                                                                      \n  {label,3}.                                                                     \n    {allocate_zero,1,1}.                                                         \n    {line,[{location,\"test.erl\",4}]}.                                            \n    {gc_bif,'-',{f,0},1,[{x,0},{integer,1}],{x,1}}.                              \n    {move,{x,0},{y,0}}.                                                          \n    {move,{x,1},{x,0}}.                                                          \n    {line,[{location,\"test.erl\",4}]}.                                            \n    {call,1,{f,2}}.                                                              \n    {line,[{location,\"test.erl\",4}]}.                                            \n    {gc_bif,'*',{f,0},1,[{y,0},{x,0}],{x,0}}.                                    \n    {deallocate,1}.                                                              \n    return.                                                                      \n                                                                                 \n                                                                                 \n{function, module_info, 0, 5}.                                                   \n  {label,4}.                                                                     \n    {line,[]}.                                                                   \n    {func_info,{atom,test},{atom,module_info},0}.                                \n  {label,5}.                                                                     \n    {move,{atom,test},{x,0}}.                                                    \n    {line,[]}.                                                                   \n    {call_ext_only,1,{extfunc,erlang,get_module_info,1}}.                        \n                                                                                 \n                                                                                 \n{function, module_info, 1, 7}.                                                   \n  {label,6}.                                                                     \n    {line,[]}.                                                                   \n    {func_info,{atom,test},{atom,module_info},1}.                                \n  {label,7}.                                                                     \n    {move,{x,0},{x,1}}.                                                          \n    {move,{atom,test},{x,0}}.                                                    \n    {line,[]}.                                                                   \n    {call_ext_only,2,{extfunc,erlang,get_module_info,2}}.\n```\n\n## erts_debug:df/1\n从beam生成VM opcode, 扩展名dis\n> $ erl\n> Erlang/OTP 18 [erts-7.0] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]\n> \n> Eshell V7.0  (abort with ^G)\n> 1> erts_debug:df(test).\n> ok\n\n```\n00007F0BDC63C3D0: i_func_info_IaaI 0 test start_link 0                           \n00007F0BDC63C3F8: move_nx [] x(2)                                                \n00007F0BDC63C408: move_x1_c test                                                 \n00007F0BDC63C418: move_nx [] x(3)                                                \n00007F0BDC63C428: move_cr {local,test} x(0)                                      \n00007F0BDC63C438: i_call_ext_only_e gen_server:start_link/4                      \n                                                                                 \n00007F0BDC63C448: i_func_info_IaaI 0 test init 1                                 \n00007F0BDC63C470: is_nil_fr f(00007F0BDC63C448) x(0)                             \n00007F0BDC63C480: allocate_tt 0 0                                                \n00007F0BDC63C490: self_r x(0)                                                    \n00007F0BDC63C498: move_x1_c haha                                                 \n00007F0BDC63C4A8: send                                                           \n00007F0BDC63C4B0: move_deallocate_return_crQ {ok,{state}} x(0) 0                 \n                                                                                 \n00007F0BDC63C4C8: i_func_info_IaaI 0 test handle_call 3                          \n00007F0BDC63C4F0: test_heap_It 4 3                                               \n00007F0BDC63C500: i_put_tuple_rI x(0) 3  reply ok x(2)                           \n00007F0BDC63C528: return                                                         \n                                                                                 \n00007F0BDC63C530: i_func_info_IaaI 0 test handle_cast 2                          \n00007F0BDC63C558: test_heap_It 3 2                                               \n00007F0BDC63C568: i_put_tuple_rI x(0) 2  noreply x(1)                            \n00007F0BDC63C588: return                                                         \n                                                                                 \n00007F0BDC63C590: i_func_info_IaaI 0 test handle_info 2                          \n00007F0BDC63C5B8: allocate_heap_tIt 1 2 2                                        \n00007F0BDC63C5D0: move_xy x(1) y(0)                                              \n00007F0BDC63C5E0: put_list_rnx x(0) [] x(1)                                      \n00007F0BDC63C5F0: i_move_call_ext_cre \"received: ~p~n\" x(0) io:format/2          \n00007F0BDC63C608: test_heap_It 3 0                                               \n00007F0BDC63C618: i_put_tuple_rI x(0) 2  noreply y(1)                            \n00007F0BDC63C638: deallocate_return_Q 1                                          \n                                                                                 \n00007F0BDC63C648: i_func_info_IaaI 0 test terminate 2                            \n00007F0BDC63C670: move_return_cr ok x(0)                                         \n                                                                                 \n00007F0BDC63C680: i_func_info_IaaI 0 test code_change 3                          \n00007F0BDC63C6A8: test_heap_It 3 2                                               \n00007F0BDC63C6B8: i_put_tuple_rI x(0) 2  ok x(1)                                 \n00007F0BDC63C6D8: return                                                         \n                                                                                 \n00007F0BDC63C6E0: i_func_info_IaaI 0 test module_info 0                          \n00007F0BDC63C708: move_cr test x(0)                                              \n00007F0BDC63C718: allocate_tt 0 1                                                \n00007F0BDC63C728: call_bif_e erlang:get_module_info/1                            \n00007F0BDC63C738: deallocate_return_Q 0                                          \n                                                                                 \n00007F0BDC63C748: i_func_info_IaaI 0 test module_info 1                          \n00007F0BDC63C770: move_rx x(0) x(1)                                              \n00007F0BDC63C780: move_cr test x(0)                                              \n00007F0BDC63C790: allocate_tt 0 2                                                \n00007F0BDC63C7A0: call_bif_e erlang:get_module_info/2                            \n00007F0BDC63C7B0: deallocate_return_Q 0 \n```\n\n## Core Erlang\nCore Erlang是Erlang的一种中间表现形式, 尽可能保持语法简单, 稳定和可读性以方便工具解析或手工修改\n换句话说,通过Core Erlang我们可以透过语法糖看到真实的代码逻辑\n> $ erl\n> Erlang/OTP 18 [erts-7.0] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]\n> \n> Eshell V7.0  (abort with ^G)\n> 1> c(test,[to_core]).\n> ** Warning: No object file created - nothing loaded **\n> ok\n\n```erlang\nmodule 'test' ['fac'/1,                                                          \n           'module_info'/0,                                                      \n           'module_info'/1]                                                      \n    attributes []                                                                \n'fac'/1 =                                                                        \n    %% Line 3                                                                    \n    fun (_cor0) ->                                                               \n    case _cor0 of                                                                \n      <1> when 'true' ->                                                         \n          1                                                                      \n      %% Line 4                                                                  \n      <N> when 'true' ->                                                         \n          let <_cor1> =                                                          \n          call 'erlang':'-'                                                      \n              (N, 1)                                                             \n          in  let <_cor2> =                                                      \n              apply 'fac'/1                                                      \n              (_cor1)                                                            \n          in  call 'erlang':'*'                                                  \n              (N, _cor2)                                                         \n    end                                                                          \n'module_info'/0 =                                                                \n    ( fun () ->                                                                  \n      ( call ( 'erlang'                                                          \n           -| ['compiler_generated'] ):( 'get_module_info'                       \n                         -| ['compiler_generated'] )                             \n        (( 'test'                                                                \n           -| ['compiler_generated'] ))                                          \n        -| ['compiler_generated'] )                                              \n      -| ['compiler_generated'] )                                                \n'module_info'/1 =                                                                \n    ( fun (( _cor0                                                               \n         -| ['compiler_generated'] )) ->                                         \n      ( call ( 'erlang'                                                          \n           -| ['compiler_generated'] ):( 'get_module_info'                       \n                         -| ['compiler_generated'] )                             \n        (( 'test'                                                                \n           -| ['compiler_generated'] ), ( _cor0                                  \n                          -| ['compiler_generated'] ))                           \n        -| ['compiler_generated'] )                                              \n      -| ['compiler_generated'] )                                                \nend\n```\n\n## 参考链接\nhttp://www.cnblogs.com/me-sa/p/know-a-little-erlang-opcode.html\nhttp://blog.yufeng.info/archives/498\n\n","source":"_posts/erlang_code.md","raw":"title: erlang各编译期的代码\ndate: 2015-09-11\ntags: [erlang]\n---\n对于如下源码test.erl\n```erlang\n-module(test).      \n-export([fac/1]).                                                                \nfac(1) -> 1;                                                                     \nfac(N) -> N * fac(N - 1).\n```\n在各编译期有不同的形式\n<!--more-->\n可以在erlang shell里使用c命令编译\n> Erlang/OTP 18 [erts-7.0] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]\n> \n> Eshell V7.0  (abort with ^G)\n> 1> `c(test, 'P')`.    \n> ** Warning: No object file created - nothing loaded **\n\n也可以用erlc\n> $ erlc -help\n> Usage: erlc [Options] file.ext ...\n> Options:\n> ...\n> -E             generate listing of expanded code (Erlang compiler)\n> -S             generate assembly listing (Erlang compiler)\n> -P             generate listing of preprocessed code (Erlang compiler)\n> +term          pass the Erlang term unchanged to the compiler\n\n## P\n生成经过预处理和parse transform的代码, 扩展名.P\n$ erlc -P test.erl\n```erlang\n-file(\"test.erl\", 1).                                                            \n                                                                                 \n-module(test).                                                                   \n                                                                                 \n-export([fac/1]).                                                                \n                                                                                 \nfac(1) ->                                                                        \n    1;                                                                           \nfac(N) ->                                                                        \n    N * fac(N - 1). \n```\n\n## E\n生成经过所有源代码处理的代码, 扩展名.E\n$ erlc -E test.erl\n```erlang\n-file(\"test.erl\", 1).                                                            \n                                                                                 \nfac(1) ->                                                                        \n    1;                                                                           \nfac(N) ->                                                                        \n    N * fac(N - 1).                                                              \n                                                                                 \nmodule_info() ->                                                                 \n    erlang:get_module_info(test).                                                \n                                                                                 \nmodule_info(X) ->                                                                \n    erlang:get_module_info(test, X).\n```\n\n## S\n生成中间汇编码, 扩展名.S\n$ erlc -S test.erl\n```\n{module, test}.  %% version = 0                                                  \n                                                                                 \n{exports, [{fac,1},{module_info,0},{module_info,1}]}.                            \n                                                                                 \n{attributes, []}.                                                                \n                                                                                 \n{labels, 8}.                                                                     \n                                                                                 \n                                                                                 \n{function, fac, 1, 2}.                                                           \n  {label,1}.                                                                     \n    {line,[{location,\"test.erl\",3}]}.                                            \n    {func_info,{atom,test},{atom,fac},1}.                                        \n  {label,2}.                                                                     \n    {test,is_eq_exact,{f,3},[{x,0},{integer,1}]}.                                \n    return.                                                                      \n  {label,3}.                                                                     \n    {allocate_zero,1,1}.                                                         \n    {line,[{location,\"test.erl\",4}]}.                                            \n    {gc_bif,'-',{f,0},1,[{x,0},{integer,1}],{x,1}}.                              \n    {move,{x,0},{y,0}}.                                                          \n    {move,{x,1},{x,0}}.                                                          \n    {line,[{location,\"test.erl\",4}]}.                                            \n    {call,1,{f,2}}.                                                              \n    {line,[{location,\"test.erl\",4}]}.                                            \n    {gc_bif,'*',{f,0},1,[{y,0},{x,0}],{x,0}}.                                    \n    {deallocate,1}.                                                              \n    return.                                                                      \n                                                                                 \n                                                                                 \n{function, module_info, 0, 5}.                                                   \n  {label,4}.                                                                     \n    {line,[]}.                                                                   \n    {func_info,{atom,test},{atom,module_info},0}.                                \n  {label,5}.                                                                     \n    {move,{atom,test},{x,0}}.                                                    \n    {line,[]}.                                                                   \n    {call_ext_only,1,{extfunc,erlang,get_module_info,1}}.                        \n                                                                                 \n                                                                                 \n{function, module_info, 1, 7}.                                                   \n  {label,6}.                                                                     \n    {line,[]}.                                                                   \n    {func_info,{atom,test},{atom,module_info},1}.                                \n  {label,7}.                                                                     \n    {move,{x,0},{x,1}}.                                                          \n    {move,{atom,test},{x,0}}.                                                    \n    {line,[]}.                                                                   \n    {call_ext_only,2,{extfunc,erlang,get_module_info,2}}.\n```\n\n## erts_debug:df/1\n从beam生成VM opcode, 扩展名dis\n> $ erl\n> Erlang/OTP 18 [erts-7.0] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]\n> \n> Eshell V7.0  (abort with ^G)\n> 1> erts_debug:df(test).\n> ok\n\n```\n00007F0BDC63C3D0: i_func_info_IaaI 0 test start_link 0                           \n00007F0BDC63C3F8: move_nx [] x(2)                                                \n00007F0BDC63C408: move_x1_c test                                                 \n00007F0BDC63C418: move_nx [] x(3)                                                \n00007F0BDC63C428: move_cr {local,test} x(0)                                      \n00007F0BDC63C438: i_call_ext_only_e gen_server:start_link/4                      \n                                                                                 \n00007F0BDC63C448: i_func_info_IaaI 0 test init 1                                 \n00007F0BDC63C470: is_nil_fr f(00007F0BDC63C448) x(0)                             \n00007F0BDC63C480: allocate_tt 0 0                                                \n00007F0BDC63C490: self_r x(0)                                                    \n00007F0BDC63C498: move_x1_c haha                                                 \n00007F0BDC63C4A8: send                                                           \n00007F0BDC63C4B0: move_deallocate_return_crQ {ok,{state}} x(0) 0                 \n                                                                                 \n00007F0BDC63C4C8: i_func_info_IaaI 0 test handle_call 3                          \n00007F0BDC63C4F0: test_heap_It 4 3                                               \n00007F0BDC63C500: i_put_tuple_rI x(0) 3  reply ok x(2)                           \n00007F0BDC63C528: return                                                         \n                                                                                 \n00007F0BDC63C530: i_func_info_IaaI 0 test handle_cast 2                          \n00007F0BDC63C558: test_heap_It 3 2                                               \n00007F0BDC63C568: i_put_tuple_rI x(0) 2  noreply x(1)                            \n00007F0BDC63C588: return                                                         \n                                                                                 \n00007F0BDC63C590: i_func_info_IaaI 0 test handle_info 2                          \n00007F0BDC63C5B8: allocate_heap_tIt 1 2 2                                        \n00007F0BDC63C5D0: move_xy x(1) y(0)                                              \n00007F0BDC63C5E0: put_list_rnx x(0) [] x(1)                                      \n00007F0BDC63C5F0: i_move_call_ext_cre \"received: ~p~n\" x(0) io:format/2          \n00007F0BDC63C608: test_heap_It 3 0                                               \n00007F0BDC63C618: i_put_tuple_rI x(0) 2  noreply y(1)                            \n00007F0BDC63C638: deallocate_return_Q 1                                          \n                                                                                 \n00007F0BDC63C648: i_func_info_IaaI 0 test terminate 2                            \n00007F0BDC63C670: move_return_cr ok x(0)                                         \n                                                                                 \n00007F0BDC63C680: i_func_info_IaaI 0 test code_change 3                          \n00007F0BDC63C6A8: test_heap_It 3 2                                               \n00007F0BDC63C6B8: i_put_tuple_rI x(0) 2  ok x(1)                                 \n00007F0BDC63C6D8: return                                                         \n                                                                                 \n00007F0BDC63C6E0: i_func_info_IaaI 0 test module_info 0                          \n00007F0BDC63C708: move_cr test x(0)                                              \n00007F0BDC63C718: allocate_tt 0 1                                                \n00007F0BDC63C728: call_bif_e erlang:get_module_info/1                            \n00007F0BDC63C738: deallocate_return_Q 0                                          \n                                                                                 \n00007F0BDC63C748: i_func_info_IaaI 0 test module_info 1                          \n00007F0BDC63C770: move_rx x(0) x(1)                                              \n00007F0BDC63C780: move_cr test x(0)                                              \n00007F0BDC63C790: allocate_tt 0 2                                                \n00007F0BDC63C7A0: call_bif_e erlang:get_module_info/2                            \n00007F0BDC63C7B0: deallocate_return_Q 0 \n```\n\n## Core Erlang\nCore Erlang是Erlang的一种中间表现形式, 尽可能保持语法简单, 稳定和可读性以方便工具解析或手工修改\n换句话说,通过Core Erlang我们可以透过语法糖看到真实的代码逻辑\n> $ erl\n> Erlang/OTP 18 [erts-7.0] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]\n> \n> Eshell V7.0  (abort with ^G)\n> 1> c(test,[to_core]).\n> ** Warning: No object file created - nothing loaded **\n> ok\n\n```erlang\nmodule 'test' ['fac'/1,                                                          \n           'module_info'/0,                                                      \n           'module_info'/1]                                                      \n    attributes []                                                                \n'fac'/1 =                                                                        \n    %% Line 3                                                                    \n    fun (_cor0) ->                                                               \n    case _cor0 of                                                                \n      <1> when 'true' ->                                                         \n          1                                                                      \n      %% Line 4                                                                  \n      <N> when 'true' ->                                                         \n          let <_cor1> =                                                          \n          call 'erlang':'-'                                                      \n              (N, 1)                                                             \n          in  let <_cor2> =                                                      \n              apply 'fac'/1                                                      \n              (_cor1)                                                            \n          in  call 'erlang':'*'                                                  \n              (N, _cor2)                                                         \n    end                                                                          \n'module_info'/0 =                                                                \n    ( fun () ->                                                                  \n      ( call ( 'erlang'                                                          \n           -| ['compiler_generated'] ):( 'get_module_info'                       \n                         -| ['compiler_generated'] )                             \n        (( 'test'                                                                \n           -| ['compiler_generated'] ))                                          \n        -| ['compiler_generated'] )                                              \n      -| ['compiler_generated'] )                                                \n'module_info'/1 =                                                                \n    ( fun (( _cor0                                                               \n         -| ['compiler_generated'] )) ->                                         \n      ( call ( 'erlang'                                                          \n           -| ['compiler_generated'] ):( 'get_module_info'                       \n                         -| ['compiler_generated'] )                             \n        (( 'test'                                                                \n           -| ['compiler_generated'] ), ( _cor0                                  \n                          -| ['compiler_generated'] ))                           \n        -| ['compiler_generated'] )                                              \n      -| ['compiler_generated'] )                                                \nend\n```\n\n## 参考链接\nhttp://www.cnblogs.com/me-sa/p/know-a-little-erlang-opcode.html\nhttp://blog.yufeng.info/archives/498\n\n","slug":"erlang_code","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5kw004omcxqv5ziikuh"},{"title":"erlang distribution","date":"2015-09-05T16:00:00.000Z","_content":"\n## 连不上时怎么办??\ncookie对吗? erlang:get_cookie()看一下两边是否一样\n结点名不是nonode@nohost吧, erlang:is_alive()返回true才行\n两边的端口开了吗?epmd的默认端口是4369, \n不光默认端口, 还得开一批别的端口用于结点间socket通信, \n可以查看自己机器上各结点的端口\n如:\n> $ epmd -names\n> epmd: up and running on port 4369 with data:\n> name aries_game at port 44554\n\n可以设置epmd使用的端口范围, 以便在防火墙中开放这些端口\n> erl -sname abc -kernel inet_dist_listen_min 4370 inet_dist_listen_max 4375\n\n代码中如下设置\n> application:set_env(kernel, inet_dist_listen_min, 4370).\n> application:set_env(kernel, inet_dist_listen_max, 4375).\n\n## -kernel dist_auto_connect never\n该情况下,该结点不会主动连接其他结点,\n使用net_kernel:connect_node可以连上其他结点, \n并且还会跟其他结点的已知结点(没有设dist_auto_connect never的结点)都连上\n因为对面连过来了, 即双方只要有一方没设dist_auto_connect never, 那么你不自动连接它, 它会自动连接你\n\n## erlang Can&apos;t set long node name的问题\n报错信息如下:\n```erlang\n$ erl -name aaa -setcookie abc\n{error_logger,{{2015,7,23},{17,25,1}},\"Can't set long node name!\\nPlease check your configuration\\n\",[]}\n...\n```\n解决办法:\n在/etc/hosts中增加一行,如自己的ip是192.168.1.108\n192.168.1.108   chenduo-desktop.localdomain chenduo-desktop\n\n问题解决:\n$ erl -name aaa -setcookie abc\nErlang R15B (erts-5.9) [source] [64-bit] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9  (abort with ^G)\n(aaa@chenduo-desktop.localdomain)1>\n\n## 如何判断本结点与某结点是否已连接?\n1, lists:member(xxx, nodes()), 但是这个不能保障后续通信成功\n2, erlang:monitor_node, 断开时得到通知\n3, call目标进程, 得到执行结果或得到错误如nodedown的话就没连接\n\n","source":"_posts/erlang_distribution.md","raw":"title: erlang distribution\ndate: 2015-09-06\ntags: erlang\n---\n\n## 连不上时怎么办??\ncookie对吗? erlang:get_cookie()看一下两边是否一样\n结点名不是nonode@nohost吧, erlang:is_alive()返回true才行\n两边的端口开了吗?epmd的默认端口是4369, \n不光默认端口, 还得开一批别的端口用于结点间socket通信, \n可以查看自己机器上各结点的端口\n如:\n> $ epmd -names\n> epmd: up and running on port 4369 with data:\n> name aries_game at port 44554\n\n可以设置epmd使用的端口范围, 以便在防火墙中开放这些端口\n> erl -sname abc -kernel inet_dist_listen_min 4370 inet_dist_listen_max 4375\n\n代码中如下设置\n> application:set_env(kernel, inet_dist_listen_min, 4370).\n> application:set_env(kernel, inet_dist_listen_max, 4375).\n\n## -kernel dist_auto_connect never\n该情况下,该结点不会主动连接其他结点,\n使用net_kernel:connect_node可以连上其他结点, \n并且还会跟其他结点的已知结点(没有设dist_auto_connect never的结点)都连上\n因为对面连过来了, 即双方只要有一方没设dist_auto_connect never, 那么你不自动连接它, 它会自动连接你\n\n## erlang Can&apos;t set long node name的问题\n报错信息如下:\n```erlang\n$ erl -name aaa -setcookie abc\n{error_logger,{{2015,7,23},{17,25,1}},\"Can't set long node name!\\nPlease check your configuration\\n\",[]}\n...\n```\n解决办法:\n在/etc/hosts中增加一行,如自己的ip是192.168.1.108\n192.168.1.108   chenduo-desktop.localdomain chenduo-desktop\n\n问题解决:\n$ erl -name aaa -setcookie abc\nErlang R15B (erts-5.9) [source] [64-bit] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9  (abort with ^G)\n(aaa@chenduo-desktop.localdomain)1>\n\n## 如何判断本结点与某结点是否已连接?\n1, lists:member(xxx, nodes()), 但是这个不能保障后续通信成功\n2, erlang:monitor_node, 断开时得到通知\n3, call目标进程, 得到执行结果或得到错误如nodedown的话就没连接\n\n","slug":"erlang_distribution","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5kw004qmcxqojw87fj7"},{"title":"erlang ets","date":"2015-09-13T16:00:00.000Z","_content":"## 进程terminate后ets被销毁的问题\n\n专门启动一个table manager进程,这个进程只负责做ets表的heir\n这样就不用担心进程terminate后ets表访问不到了\n\n## compressed选项\n\n可以节约一些内存,缺点是操作会慢一些,尤其是match和select操作会慢很多\n目前的实现里key不会压缩\n注意: 简单的数据的情况下,压缩可能反而会占更多的内存,看下面的例子\n\n<pre>\n1> ets:new(abc, [named_table, compressed]).                             \nabc\n2> ets:new(def, [named_table]).                                         \ndef\n3> L = lists:zip(lists:seq(1, 1000000), lists:duplicate(1000000, \"hello world\")).\n...\n4> ets:insert(abc, L).                                                           \ntrue\n5> ets:insert(def, L).                                                           \ntrue\n6> ets:info(abc, memory).\n10144941\n7> ets:info(def, memory).\n29144941\n8> L2 = lists:zip(lists:seq(1, 1000000), lists:duplicate(1000000, xxx)).\n...\n9> ets:insert(abc, L2).                                                           \ntrue\n10> ets:insert(def, L2).                                                           \ntrue\n11> ets:info(abc, memory).\n8144942\n12> ets:info(def, memory).                                                         \n7144942\n13> ets:info(abc, compressed).\ntrue\n14> ets:info(abc).\n[{read_concurrency,false},\n {write_concurrency,false},\n {compressed,true},\n {memory,8144941},\n {owner,<0.34.0>},\n {heir,none},\n {name,abc},\n {size,1000000},\n {node,nonode@nohost},\n {named_table,true},\n {type,set},\n {keypos,1},\n {protection,protected}\n]\n</pre>\n\n## 源码\n首先, 下载erlang源码\nhttps://github.com/erlang/otp \nBIF表\n./erts/emulator/beam/bif.tab \n相关c代码\n./erts/emulator/beam/erl_db_util.c\n./erts/emulator/beam/erl_db.c\n./erts/emulator/beam/erl_db_tree.c\n./erts/emulator/beam/erl_db_hash.c\n相关erl代码\n./lib/stdlib/src/ets.erl\n\n## 参考链接\nhttps://github.com/erlang/otp\nhttp://www.erlang.org/doc/man/ets.html\nhttp://mryufeng.iteye.com/blog/113856\n\n","source":"_posts/erlang_ets.md","raw":"title: erlang ets\ndate: 2015-09-14\ntags: erlang\n---\n## 进程terminate后ets被销毁的问题\n\n专门启动一个table manager进程,这个进程只负责做ets表的heir\n这样就不用担心进程terminate后ets表访问不到了\n\n## compressed选项\n\n可以节约一些内存,缺点是操作会慢一些,尤其是match和select操作会慢很多\n目前的实现里key不会压缩\n注意: 简单的数据的情况下,压缩可能反而会占更多的内存,看下面的例子\n\n<pre>\n1> ets:new(abc, [named_table, compressed]).                             \nabc\n2> ets:new(def, [named_table]).                                         \ndef\n3> L = lists:zip(lists:seq(1, 1000000), lists:duplicate(1000000, \"hello world\")).\n...\n4> ets:insert(abc, L).                                                           \ntrue\n5> ets:insert(def, L).                                                           \ntrue\n6> ets:info(abc, memory).\n10144941\n7> ets:info(def, memory).\n29144941\n8> L2 = lists:zip(lists:seq(1, 1000000), lists:duplicate(1000000, xxx)).\n...\n9> ets:insert(abc, L2).                                                           \ntrue\n10> ets:insert(def, L2).                                                           \ntrue\n11> ets:info(abc, memory).\n8144942\n12> ets:info(def, memory).                                                         \n7144942\n13> ets:info(abc, compressed).\ntrue\n14> ets:info(abc).\n[{read_concurrency,false},\n {write_concurrency,false},\n {compressed,true},\n {memory,8144941},\n {owner,<0.34.0>},\n {heir,none},\n {name,abc},\n {size,1000000},\n {node,nonode@nohost},\n {named_table,true},\n {type,set},\n {keypos,1},\n {protection,protected}\n]\n</pre>\n\n## 源码\n首先, 下载erlang源码\nhttps://github.com/erlang/otp \nBIF表\n./erts/emulator/beam/bif.tab \n相关c代码\n./erts/emulator/beam/erl_db_util.c\n./erts/emulator/beam/erl_db.c\n./erts/emulator/beam/erl_db_tree.c\n./erts/emulator/beam/erl_db_hash.c\n相关erl代码\n./lib/stdlib/src/ets.erl\n\n## 参考链接\nhttps://github.com/erlang/otp\nhttp://www.erlang.org/doc/man/ets.html\nhttp://mryufeng.iteye.com/blog/113856\n\n","slug":"erlang_ets","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5kx004tmcxqmur2aelg"},{"title":"erlang config研究","date":"2021-06-17T16:00:00.000Z","_content":"\nerlang 的配置还是走了一段很曲折的路, ... \n\n<!--more-->\n\n下面这种写法里\n\n```shell\nRELX_REPLACE_OS_VARS=true NODE_NAME=exampleapp@106.15.72.22 PORT=5001 bin/exampleapp start\n```\n\nRELX_REPLACE_OS_VARS=true 告诉系统要在结点启动时将 sys.config 以及 vm.args 文件里的形如 `${PORT}` 的值用对应环境变量的值替换掉\n\n```\n%% sys.config\n[\n {appname, [{port, \"${PORT}\"}]}\n].\n```\n\n\n\n*如果是 elixir + distillery 的项目, RELX_REPLACE_OS_VARS 换成 REPLACE_OS_VARS*\n\n*相关代码在这里: bin/exampleapp -> bin/exampleapp_rc_exec.sh -> releases/VERSION/exampleapp.sh -> releases/VERSION/libexec/config.sh*\n\n*限制: 这种方式下sys.config下只能配字符串, 需要在应用层去做类型转换*\n\n\n\n#### 问题\n\n上面这种做法本质上其实是个 hack\n\n导致我们在 release 之后不方便修改 sys.config 里的配置, 只能通过环境变量来改那些用了这种写法的地方, 不灵活 \n\n\n\n#### 新的选择(OTP-21+ and Rebar3 3.6+)\n\n可以在 config/sys.config.src, config/vm.args.src 文件中使用  ${PORT}, ${NODE_NAME} 这样的写法, 不再有强制字符串的限制\n\n作用方式仍然是在结点启动时将下述模板里的变量用环境变量的值替换\n\n```\n%% sys.config.src\n[\n  {appname, [{port, ${PORT}}]}\n].\n```\n\n(http://rebar3.org/docs/deployment/releases/#environment-variable-replacement)\n\n\n\n#### 新的选择(Distillery 2.0+)\n\n提出了 [config_provider](https://hexdocs.pm/distillery/config/runtime.html#config-providers) 概念\n\n允许使用 toml, yaml, json 等格式, 通过修改 boot script 在启动之前执行 Provider 模块用以帮助生成最终需要的 sys.config 文件\n\n这样做到了支持使用通用配置文件(yaml等), 并且不受限于环境变量\n\n\n\n例: rel/config.exs 这里配置 provider 等信息\n\n```elixir\nCopied to clipboard\nenvironment :prod do\n  set config_providers: [\n    {Toml.Provider, [path: \"${RELEASE_ROOT_DIR}/config.toml\"]}\n  ]\n  set overlays: [\n    {:copy, \"config/defaults.toml\", \"config.toml\"}\n  ]\nend\n```\n\n","source":"_posts/erlang_config.md","raw":"title: erlang config研究\ndate: 2021-06-18\n\ntags: [erlang, config, mix, rebar, distillery]\n---\n\nerlang 的配置还是走了一段很曲折的路, ... \n\n<!--more-->\n\n下面这种写法里\n\n```shell\nRELX_REPLACE_OS_VARS=true NODE_NAME=exampleapp@106.15.72.22 PORT=5001 bin/exampleapp start\n```\n\nRELX_REPLACE_OS_VARS=true 告诉系统要在结点启动时将 sys.config 以及 vm.args 文件里的形如 `${PORT}` 的值用对应环境变量的值替换掉\n\n```\n%% sys.config\n[\n {appname, [{port, \"${PORT}\"}]}\n].\n```\n\n\n\n*如果是 elixir + distillery 的项目, RELX_REPLACE_OS_VARS 换成 REPLACE_OS_VARS*\n\n*相关代码在这里: bin/exampleapp -> bin/exampleapp_rc_exec.sh -> releases/VERSION/exampleapp.sh -> releases/VERSION/libexec/config.sh*\n\n*限制: 这种方式下sys.config下只能配字符串, 需要在应用层去做类型转换*\n\n\n\n#### 问题\n\n上面这种做法本质上其实是个 hack\n\n导致我们在 release 之后不方便修改 sys.config 里的配置, 只能通过环境变量来改那些用了这种写法的地方, 不灵活 \n\n\n\n#### 新的选择(OTP-21+ and Rebar3 3.6+)\n\n可以在 config/sys.config.src, config/vm.args.src 文件中使用  ${PORT}, ${NODE_NAME} 这样的写法, 不再有强制字符串的限制\n\n作用方式仍然是在结点启动时将下述模板里的变量用环境变量的值替换\n\n```\n%% sys.config.src\n[\n  {appname, [{port, ${PORT}}]}\n].\n```\n\n(http://rebar3.org/docs/deployment/releases/#environment-variable-replacement)\n\n\n\n#### 新的选择(Distillery 2.0+)\n\n提出了 [config_provider](https://hexdocs.pm/distillery/config/runtime.html#config-providers) 概念\n\n允许使用 toml, yaml, json 等格式, 通过修改 boot script 在启动之前执行 Provider 模块用以帮助生成最终需要的 sys.config 文件\n\n这样做到了支持使用通用配置文件(yaml等), 并且不受限于环境变量\n\n\n\n例: rel/config.exs 这里配置 provider 等信息\n\n```elixir\nCopied to clipboard\nenvironment :prod do\n  set config_providers: [\n    {Toml.Provider, [path: \"${RELEASE_ROOT_DIR}/config.toml\"]}\n  ]\n  set overlays: [\n    {:copy, \"config/defaults.toml\", \"config.toml\"}\n  ]\nend\n```\n\n","slug":"erlang_config","published":1,"updated":"2021-06-25T14:02:28.033Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ky004vmcxqs7opgy82"},{"title":"erlang fun","date":"2016-03-02T16:00:00.000Z","_content":"\n## Funs with names(eep0037)\n```erlang\n> Fun = fun Quicksort([H|T]) -> Quicksort([I || I <- T, I =< H]) ++ [H] ++ Quicksort([I || I <- T, I > H]); Quicksort([]) -> [] end.\n#Fun<erl_eval.30.54118792>\n> Fun([1,2,3,4,5,6,4,3,2,1]).\n[1,1,2,2,3,3,4,4,5,6]\n```\n\n","source":"_posts/erlang_fun.md","raw":"title: erlang fun\ndate: 2016-03-03\ntags: erlang\n---\n\n## Funs with names(eep0037)\n```erlang\n> Fun = fun Quicksort([H|T]) -> Quicksort([I || I <- T, I =< H]) ++ [H] ++ Quicksort([I || I <- T, I > H]); Quicksort([]) -> [] end.\n#Fun<erl_eval.30.54118792>\n> Fun([1,2,3,4,5,6,4,3,2,1]).\n[1,1,2,2,3,3,4,4,5,6]\n```\n\n","slug":"erlang_fun","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5l0004ymcxq676sihof"},{"title":"erlang ets性能优化","date":"2021-05-03T16:00:00.000Z","_content":"\n假如 ets 里存的数据格式如下\n```\n{{user_id, type}, pid}\n```\nordered_set, keypos = 1\n\n要用上 ordered_set 的前缀匹配高性能, match specification 需要像下面这样写\n```elixir\n[{{{user_id, :_}, :\"$1\"}, [], [:\"$1\"]}]\n```\n这样才能跳过其他 user_id, 只遍历这一个 user_id 对应的记录\n而悲催的是, 如果使用 :ets.fun2ms 函数来做的话, 生成的是这样的 match specification\n```elixir\niex> :ets.fun2ms(fn {{user_id, _}, pid} when user_id == 1 -> pid end)\n[{{{:\"$1\", :_}, :\"$2\"}, [{:==, :\"$1\", 1}], [:\"$2\"]}]\n```\n这种写法将不会用到 ordered_set 的前缀匹配, 而是全表扫描, 是全表扫描!\n\n两者性能差异视表的规模而定, 这也是坑点之一,\n\n因为表小的时候看不出来, 等表大了以后又很难想到是这里的问题, 莫名奇妙 CPU 占用率就飙上去了\n\n下面是一个大约 20 万元素的表的实际数据:\n\n```elixir\n> :timer.tc(fn -> :ets.select(:simple_global, [ {{{:\"$1\", :agent, :\"$2\"}, :_, :_, :_, :_}, [{:==, :\"$1\", ent_id}], [:\"$2\"]} ]) end)\n{12128,\n [9269, 44558, 1001458, 1068440, 1069147, 1092569, 1111688, 1114902, 1118485,\n  1155156, 1161491, 1172293, 1183136, 1186487, 1228076, 1234522, 1268137,\n  1273945, 1359669, 1488611, 1506535, 1513229, 1544955, 1555843, 1560291]}\n> :timer.tc(fn -> :ets.select(:simple_global, [{{{ent_id, :agent, :\"$2\"}, :_, :_, :_, :_}, [], [:\"$2\"]}]) end)\n{25,\n [9269, 44558, 1001458, 1068440, 1069147, 1092569, 1111688, 1114902, 1118485,\n  1155156, 1161491, 1172293, 1183136, 1186487, 1228076, 1234522, 1268137,\n  1273945, 1359669, 1488611, 1506535, 1513229, 1544955, 1555843, 1560291]}\n```\n\n12128 微秒和 25 微秒的差距, 约 500 倍,\n\n笔者的某服务经此优化, CPU 占用率从 80% 降到了 20% !\n\n","source":"_posts/erlang_ets_performance_tune.md","raw":"title: erlang ets性能优化\ndate: 2021-05-04\ntags: [erlang, ets]\n---\n\n假如 ets 里存的数据格式如下\n```\n{{user_id, type}, pid}\n```\nordered_set, keypos = 1\n\n要用上 ordered_set 的前缀匹配高性能, match specification 需要像下面这样写\n```elixir\n[{{{user_id, :_}, :\"$1\"}, [], [:\"$1\"]}]\n```\n这样才能跳过其他 user_id, 只遍历这一个 user_id 对应的记录\n而悲催的是, 如果使用 :ets.fun2ms 函数来做的话, 生成的是这样的 match specification\n```elixir\niex> :ets.fun2ms(fn {{user_id, _}, pid} when user_id == 1 -> pid end)\n[{{{:\"$1\", :_}, :\"$2\"}, [{:==, :\"$1\", 1}], [:\"$2\"]}]\n```\n这种写法将不会用到 ordered_set 的前缀匹配, 而是全表扫描, 是全表扫描!\n\n两者性能差异视表的规模而定, 这也是坑点之一,\n\n因为表小的时候看不出来, 等表大了以后又很难想到是这里的问题, 莫名奇妙 CPU 占用率就飙上去了\n\n下面是一个大约 20 万元素的表的实际数据:\n\n```elixir\n> :timer.tc(fn -> :ets.select(:simple_global, [ {{{:\"$1\", :agent, :\"$2\"}, :_, :_, :_, :_}, [{:==, :\"$1\", ent_id}], [:\"$2\"]} ]) end)\n{12128,\n [9269, 44558, 1001458, 1068440, 1069147, 1092569, 1111688, 1114902, 1118485,\n  1155156, 1161491, 1172293, 1183136, 1186487, 1228076, 1234522, 1268137,\n  1273945, 1359669, 1488611, 1506535, 1513229, 1544955, 1555843, 1560291]}\n> :timer.tc(fn -> :ets.select(:simple_global, [{{{ent_id, :agent, :\"$2\"}, :_, :_, :_, :_}, [], [:\"$2\"]}]) end)\n{25,\n [9269, 44558, 1001458, 1068440, 1069147, 1092569, 1111688, 1114902, 1118485,\n  1155156, 1161491, 1172293, 1183136, 1186487, 1228076, 1234522, 1268137,\n  1273945, 1359669, 1488611, 1506535, 1513229, 1544955, 1555843, 1560291]}\n```\n\n12128 微秒和 25 微秒的差距, 约 500 倍,\n\n笔者的某服务经此优化, CPU 占用率从 80% 降到了 20% !\n\n","slug":"erlang_ets_performance_tune","published":1,"updated":"2021-06-26T11:11:28.238Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5l10050mcxqpbvej7hw"},{"title":"erlang 浮点数的坑点","date":"2018-10-07T16:00:00.000Z","_content":"\n字符串 100,100 会被解析为浮点数 100.1\n\n```erlang\nEshell V8.3  (abort with ^G)\n1> list_to_float(\"100,100\").\n100.1\n```\n\n","source":"_posts/erlang_float.md","raw":"title: erlang 浮点数的坑点\ndate: 2018-10-08\ntags: [erlang, float]\n---\n\n字符串 100,100 会被解析为浮点数 100.1\n\n```erlang\nEshell V8.3  (abort with ^G)\n1> list_to_float(\"100,100\").\n100.1\n```\n\n","slug":"erlang_float","published":1,"updated":"2018-10-08T06:43:53.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5l20053mcxqc2tx84zp"},{"title":"erlang useful functions","date":"2015-09-05T16:00:00.000Z","_content":"## erlang:integer_to_list\n## erlang:list_to_integer\n字符串与整型的相互转换,可以指定进制\n\n## erlang:function_exported\n判断指定的函数是否已导出,要求模块已加载,另外,BIF一律返回false\n#### 另有一种做法\n```erlang\nis_exported({M, F, A}) ->\n    lists:member({F, A}, M:module_info(exports)).\n```\n区别是\n* 这种做法会自动加载模块(调用module_info的时候),而erlang:function_exported不会\n* BIF也会返回true\n* 性能(我机器上平均一次26.1微秒)比erlang:function_exported(0.86微秒)差30倍左右, 能不能大量用呢?\n\n## binary:replace\n## binary:split\n可以使用正则表达式,还是很有用的\n\n## erlang:decode_packet\n要记得用呀, 很好用\n\n## net_kernel:longnames\n判断当前是不是longname \n\n## net_kernel:monitor_nodes\n## erlang:monitor_node的区别\nnet_kernel:monitor_nodes是全监听,erlang:monitor_node只监听一个结点\nnet_kernel:monitor_nodes不会尝试连接,erlang:monitor_node会尝试连接\nnet_kernel:monitor_nodes有nodeup和nodedown消息,erlang:monitor_node只有nodedown消息\nerlang:monitor_node在对应的结点down掉之后即失效,还想监听需要重新调用erlang:monitor_node\n\n## erl_scan:tokens\n## erl_scan:string\n## erl_parse:parse_exprs\n## erl_parse:parse_form\n## compile:forms\n## code:load_binary\n## erl_syntax\n## erl_eval\n编译相关的一些api\n\n## c:i\nshell的i(x,y,z)接口，可以方便替代process_info()\n\n## application:get_application\n可以传入pid或module取所属的application\n\n","source":"_posts/erlang_functions.md","raw":"title: erlang useful functions\ndate: 2015-09-06\ntags: erlang\n---\n## erlang:integer_to_list\n## erlang:list_to_integer\n字符串与整型的相互转换,可以指定进制\n\n## erlang:function_exported\n判断指定的函数是否已导出,要求模块已加载,另外,BIF一律返回false\n#### 另有一种做法\n```erlang\nis_exported({M, F, A}) ->\n    lists:member({F, A}, M:module_info(exports)).\n```\n区别是\n* 这种做法会自动加载模块(调用module_info的时候),而erlang:function_exported不会\n* BIF也会返回true\n* 性能(我机器上平均一次26.1微秒)比erlang:function_exported(0.86微秒)差30倍左右, 能不能大量用呢?\n\n## binary:replace\n## binary:split\n可以使用正则表达式,还是很有用的\n\n## erlang:decode_packet\n要记得用呀, 很好用\n\n## net_kernel:longnames\n判断当前是不是longname \n\n## net_kernel:monitor_nodes\n## erlang:monitor_node的区别\nnet_kernel:monitor_nodes是全监听,erlang:monitor_node只监听一个结点\nnet_kernel:monitor_nodes不会尝试连接,erlang:monitor_node会尝试连接\nnet_kernel:monitor_nodes有nodeup和nodedown消息,erlang:monitor_node只有nodedown消息\nerlang:monitor_node在对应的结点down掉之后即失效,还想监听需要重新调用erlang:monitor_node\n\n## erl_scan:tokens\n## erl_scan:string\n## erl_parse:parse_exprs\n## erl_parse:parse_form\n## compile:forms\n## code:load_binary\n## erl_syntax\n## erl_eval\n编译相关的一些api\n\n## c:i\nshell的i(x,y,z)接口，可以方便替代process_info()\n\n## application:get_application\n可以传入pid或module取所属的application\n\n","slug":"erlang_functions","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5l30055mcxqtojtfuoz"},{"title":"erlang gc","date":"2015-09-08T16:00:00.000Z","_content":"每个Erlang进程创建之后都会有自己的PCB，栈，私有堆。\n<!--more-->\nerlang不知道他创建的进程会用到哪种场合下，所以一开始分配的内存比较小。\n如果分配的空间不够了，erlang gc会动态调整堆大小以满足需求，如果分配的空间大了，就会收缩堆，回收内存。\n\n## erlang进程堆的gc是分代gc\n分代gc的想法基于统计学：大部分数据的生存周期都比较短，最新的数据更容易不再被使用。\n这里erlang使 用young heap 和old heap来区分数据，\nyoung heap放新数据，oldheap放旧数据，也就是gc后存活的数据。\nerlang进程堆gc有两个主要过程：浅扫描和深扫描\n\n## 浅扫描（minor collection）\n![浅扫描](/pics/erlang_gc_shallow.png)\n\n浅扫描是当young heap空间不足时，erlang会对young heap做一次扫描，\n把有用的数据复制到新申请的young heap空间，发现已经扫描过1次以上的数据放入old heap，然后删掉原来的young heap\n在young heap中，erlang使用了高水位线来区分标记一次以上的数据和未标记的数据，\n那么young heap移入old heap的就是超过高水位线的数据\n\n## 深扫描（major collection）\n![深扫描](/pics/erlang_gc_deep.png)\n\n深扫描是一般当old heap空间不足时触发，erlang会对young heap和old heap做扫描，\n把有用的数据放入新申请的young heap，删掉原来的heap\n深扫描的触发条件还有手动执行gc，和gc次数超过fullsweep_after的参数限定\n\n## 控制垃圾回收\n以游戏网关进程为例，网关进程通常有大量消息，而大部分消息都只是在网关这里做转发，生命周期很短，所以网关进程可以设定较大的初始内存，较快的内存回收。\n\nspawn_opt(Fun, [{min_heap_size, 5000},{min_bin_vheap_size, 100000},{fullsweep_after, 500}])\n先看下参数默认值：\n> 1> erlang:system_info(min_heap_size).\n> {min_heap_size,233}\n> 2> erlang:system_info(min_bin_vheap_size).\n> {min_bin_vheap_size,46368}\n> 3> erlang:system_info(fullsweep_after).\n> {fullsweep_after,65535}\n\nmin_heap_size是进程最小堆大小\n\n这个参数两个地方会用到，第一处是erlang初始化进程堆大小，第二处是gc后堆收缩后维持的最小值，min_bin_vheap_size是进 程最小虚拟二进制堆大小，这两个参数都是以word为单位。初始化足够大的初始内存，可以减少轻度gc的次数，减少反复申请和回收内存的开销\n\nfullsweep_after是控制深扫描的频率\n\n这个参数确定多少次gc后执行一次深度gc，默认值为65536，有点大了\n所以，上面3个参数配合起来的意义就是，进程初始化分配足够大的内存，减少反复申请内存的开销，\n当申请的内存不够用，gc会重新申请内存，累计达到500次就做一次gc\n\n## 手动执行垃圾回收\n上面提到了利用fullsweep_after来控制gc的情况，下面再介绍手动gc的情况：\n在rabbitMQ看到这段代码，可以在项目中定期执行这个函数：\n```erlang\ngc() ->\n    [erlang:garbage_collect(P) || P <- erlang:processes(), \n        {status, waiting} =:= erlang:process_info(P, status)],\n    erlang:garbage_collect(),\n    ok.\n```\n当然，你还可以加入一些判断，比如指定占内存过50M的进程执行gc\n\n## erlang进程占用多少内存\n用下面这个方法检查erlang进程占用的内存，你可以换别的参数再试试\nFun = fun()-> receive after infinity -> ok end end.\nerlang:process_info(erlang:spawn(Fun), memory).\n\n## erlang垃圾回收的副作用\n前面讲到erlang进程堆的gc是分代gc的，这个只是全局层面的，在底层erlang还是标记清除。\n标记清除这种gc方式是定期执行的，首先gc不够及时，其次，在gc执行期间开销比较大，会引起中断。\n不过每个erlang进程的堆区域是独立的，gc可以独立进行，\n加上它内存区域比较小，还有erlang的变量是单次赋值，无需多次追踪，因此，erlang进程gc的延迟不会引起全局的中断\n\n## .erl +h选项\n可以调整全局的min_heap_size\n\n## 垃圾回收器的本质\n实际上是改变存活数据结构构成图的连通性.\n堆对象在图中的存活性是由指针的可到达性定义的.\n程序可以操作三种位置的数据:寄存器, 程序栈(局部变量, 临时变量), 全局变量.\n这些位置的变量有一部分保存了指向堆数据的引用,他们构成了应用程序的根(Root).\n对于用户程序动态分配的内存只能通过Root或者根发出的指针链访问,程序不应该访问其地址空间的随机位置.\n\n## 垃圾回收的经典算法\n[1]引用计数方法是和程序执行同时进行,内存管理的开销比较均匀,这样进行没有长时间的挂起内存管理的时间比较稳定,可以获得比较平滑的响应时间;\n[2]标记清除 内存单元不会被立即回收,而是处于不可到达状态,直到所有的内存都被耗尽,进行全局级别的遍历来确定哪些单元可以回收.显然这种全局级别的中断在实时性要求较高的系统并不实用,甚至视频游戏都不可能接受在GC时有这么长的停顿.如果实时性方面要求不高,标记清除可以获得比引用计数更好的性能.标记清除的代价还是较高,标记是全局级别的,算法复杂度与整个堆大小成正比;标记清除使得内存空间倾向于碎片化.在物理存储器中碎片化的影响不大,但虚拟存储中会导致辅助存储器和主存之间频繁的交换页面,系统出现颠簸.\n[3]节点复制将堆分成两个半区,一个包含现有数据,另一个包含已经被废弃的数据,运行时两个半区的角色不断交换;这样做的优势在于内存分配的开销很小,只需要比较指针,不存在内存碎片的问题.但是内存浪费较大;\n[4]标记-整理缩并 标记所有的存活对象 通过重新调整存活对象位置来缩并对象图；更新指向被移动了位置的对象的指针\n[5]分代回收 是基于统计学原理的:多数内存块的生存周期都比较短,垃圾收集器应当把更多的精力放在检查和清理新分配的内存块上 \n\n## 参考链接\nhttp://blog.csdn.net/mycwq/article/details/26613275\nhttp://www.cnblogs.com/me-sa/archive/2011/11/13/erlang0014.html\n\n","source":"_posts/erlang_gc.md","raw":"title: erlang gc \ndate: 2015-09-09\ntags: [erlang]\n---\n每个Erlang进程创建之后都会有自己的PCB，栈，私有堆。\n<!--more-->\nerlang不知道他创建的进程会用到哪种场合下，所以一开始分配的内存比较小。\n如果分配的空间不够了，erlang gc会动态调整堆大小以满足需求，如果分配的空间大了，就会收缩堆，回收内存。\n\n## erlang进程堆的gc是分代gc\n分代gc的想法基于统计学：大部分数据的生存周期都比较短，最新的数据更容易不再被使用。\n这里erlang使 用young heap 和old heap来区分数据，\nyoung heap放新数据，oldheap放旧数据，也就是gc后存活的数据。\nerlang进程堆gc有两个主要过程：浅扫描和深扫描\n\n## 浅扫描（minor collection）\n![浅扫描](/pics/erlang_gc_shallow.png)\n\n浅扫描是当young heap空间不足时，erlang会对young heap做一次扫描，\n把有用的数据复制到新申请的young heap空间，发现已经扫描过1次以上的数据放入old heap，然后删掉原来的young heap\n在young heap中，erlang使用了高水位线来区分标记一次以上的数据和未标记的数据，\n那么young heap移入old heap的就是超过高水位线的数据\n\n## 深扫描（major collection）\n![深扫描](/pics/erlang_gc_deep.png)\n\n深扫描是一般当old heap空间不足时触发，erlang会对young heap和old heap做扫描，\n把有用的数据放入新申请的young heap，删掉原来的heap\n深扫描的触发条件还有手动执行gc，和gc次数超过fullsweep_after的参数限定\n\n## 控制垃圾回收\n以游戏网关进程为例，网关进程通常有大量消息，而大部分消息都只是在网关这里做转发，生命周期很短，所以网关进程可以设定较大的初始内存，较快的内存回收。\n\nspawn_opt(Fun, [{min_heap_size, 5000},{min_bin_vheap_size, 100000},{fullsweep_after, 500}])\n先看下参数默认值：\n> 1> erlang:system_info(min_heap_size).\n> {min_heap_size,233}\n> 2> erlang:system_info(min_bin_vheap_size).\n> {min_bin_vheap_size,46368}\n> 3> erlang:system_info(fullsweep_after).\n> {fullsweep_after,65535}\n\nmin_heap_size是进程最小堆大小\n\n这个参数两个地方会用到，第一处是erlang初始化进程堆大小，第二处是gc后堆收缩后维持的最小值，min_bin_vheap_size是进 程最小虚拟二进制堆大小，这两个参数都是以word为单位。初始化足够大的初始内存，可以减少轻度gc的次数，减少反复申请和回收内存的开销\n\nfullsweep_after是控制深扫描的频率\n\n这个参数确定多少次gc后执行一次深度gc，默认值为65536，有点大了\n所以，上面3个参数配合起来的意义就是，进程初始化分配足够大的内存，减少反复申请内存的开销，\n当申请的内存不够用，gc会重新申请内存，累计达到500次就做一次gc\n\n## 手动执行垃圾回收\n上面提到了利用fullsweep_after来控制gc的情况，下面再介绍手动gc的情况：\n在rabbitMQ看到这段代码，可以在项目中定期执行这个函数：\n```erlang\ngc() ->\n    [erlang:garbage_collect(P) || P <- erlang:processes(), \n        {status, waiting} =:= erlang:process_info(P, status)],\n    erlang:garbage_collect(),\n    ok.\n```\n当然，你还可以加入一些判断，比如指定占内存过50M的进程执行gc\n\n## erlang进程占用多少内存\n用下面这个方法检查erlang进程占用的内存，你可以换别的参数再试试\nFun = fun()-> receive after infinity -> ok end end.\nerlang:process_info(erlang:spawn(Fun), memory).\n\n## erlang垃圾回收的副作用\n前面讲到erlang进程堆的gc是分代gc的，这个只是全局层面的，在底层erlang还是标记清除。\n标记清除这种gc方式是定期执行的，首先gc不够及时，其次，在gc执行期间开销比较大，会引起中断。\n不过每个erlang进程的堆区域是独立的，gc可以独立进行，\n加上它内存区域比较小，还有erlang的变量是单次赋值，无需多次追踪，因此，erlang进程gc的延迟不会引起全局的中断\n\n## .erl +h选项\n可以调整全局的min_heap_size\n\n## 垃圾回收器的本质\n实际上是改变存活数据结构构成图的连通性.\n堆对象在图中的存活性是由指针的可到达性定义的.\n程序可以操作三种位置的数据:寄存器, 程序栈(局部变量, 临时变量), 全局变量.\n这些位置的变量有一部分保存了指向堆数据的引用,他们构成了应用程序的根(Root).\n对于用户程序动态分配的内存只能通过Root或者根发出的指针链访问,程序不应该访问其地址空间的随机位置.\n\n## 垃圾回收的经典算法\n[1]引用计数方法是和程序执行同时进行,内存管理的开销比较均匀,这样进行没有长时间的挂起内存管理的时间比较稳定,可以获得比较平滑的响应时间;\n[2]标记清除 内存单元不会被立即回收,而是处于不可到达状态,直到所有的内存都被耗尽,进行全局级别的遍历来确定哪些单元可以回收.显然这种全局级别的中断在实时性要求较高的系统并不实用,甚至视频游戏都不可能接受在GC时有这么长的停顿.如果实时性方面要求不高,标记清除可以获得比引用计数更好的性能.标记清除的代价还是较高,标记是全局级别的,算法复杂度与整个堆大小成正比;标记清除使得内存空间倾向于碎片化.在物理存储器中碎片化的影响不大,但虚拟存储中会导致辅助存储器和主存之间频繁的交换页面,系统出现颠簸.\n[3]节点复制将堆分成两个半区,一个包含现有数据,另一个包含已经被废弃的数据,运行时两个半区的角色不断交换;这样做的优势在于内存分配的开销很小,只需要比较指针,不存在内存碎片的问题.但是内存浪费较大;\n[4]标记-整理缩并 标记所有的存活对象 通过重新调整存活对象位置来缩并对象图；更新指向被移动了位置的对象的指针\n[5]分代回收 是基于统计学原理的:多数内存块的生存周期都比较短,垃圾收集器应当把更多的精力放在检查和清理新分配的内存块上 \n\n## 参考链接\nhttp://blog.csdn.net/mycwq/article/details/26613275\nhttp://www.cnblogs.com/me-sa/archive/2011/11/13/erlang0014.html\n\n","slug":"erlang_gc","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5l40057mcxqu024ealf"},{"title":"erlang HiPE不兼容警告","date":"2016-06-30T02:31:00.000Z","_content":"\n遇到了这样的警告信息, 意思好像是native code不兼容用不了, fallback成使用byte code了\n```\n=INFO REPORT==== 29-Jun-2016::20:40:28 ===\n<HiPE (v 3.9.3)> Warning: not loading native code for module mod_player: it was compiled for an incompatible runtime system; please regenerate native code for this runtime system\n```\n\nlib/kernel/src/hipe_unified_loader.erl\n```\ncase hipe_bifs:check_crc(CheckSum) of                                          \n  false ->                                                                     \n    ?msg(\"Warning: not loading native code for module ~w: \"                    \n     \"it was compiled for an incompatible runtime system; \"                    \n     \"please regenerate native code for this runtime system\\n\", [Mod]),        \n    bad_crc;\n```\n\nerts/emulator/hipe/hipe_bif0.c\n```\nBIF_RETTYPE hipe_bifs_check_crc_1(BIF_ALIST_1)                                   \n{                                                                                \n    Uint crc;                                                                    \n                                                                                 \n    if (!term_to_Uint(BIF_ARG_1, &crc))                                          \n    BIF_ERROR(BIF_P, BADARG);                                                    \n    if (crc == HIPE_ERTS_CHECKSUM)                                               \n    BIF_RET(am_true);                                                            \n    BIF_RET(am_false);                                                           \n}\n```\n\n","source":"_posts/erlang_hipe_incompatible.md","raw":"title: erlang HiPE不兼容警告\ndate: 2016-06-30 10:31\ntags: [erlang]\n---\n\n遇到了这样的警告信息, 意思好像是native code不兼容用不了, fallback成使用byte code了\n```\n=INFO REPORT==== 29-Jun-2016::20:40:28 ===\n<HiPE (v 3.9.3)> Warning: not loading native code for module mod_player: it was compiled for an incompatible runtime system; please regenerate native code for this runtime system\n```\n\nlib/kernel/src/hipe_unified_loader.erl\n```\ncase hipe_bifs:check_crc(CheckSum) of                                          \n  false ->                                                                     \n    ?msg(\"Warning: not loading native code for module ~w: \"                    \n     \"it was compiled for an incompatible runtime system; \"                    \n     \"please regenerate native code for this runtime system\\n\", [Mod]),        \n    bad_crc;\n```\n\nerts/emulator/hipe/hipe_bif0.c\n```\nBIF_RETTYPE hipe_bifs_check_crc_1(BIF_ALIST_1)                                   \n{                                                                                \n    Uint crc;                                                                    \n                                                                                 \n    if (!term_to_Uint(BIF_ARG_1, &crc))                                          \n    BIF_ERROR(BIF_P, BADARG);                                                    \n    if (crc == HIPE_ERTS_CHECKSUM)                                               \n    BIF_RET(am_true);                                                            \n    BIF_RET(am_false);                                                           \n}\n```\n\n","slug":"erlang_hipe_incompatible","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5l5005amcxqyupi7dy9"},{"title":"erlang gen_server:call消息未得到执行的情况","date":"2016-02-15T16:00:00.000Z","_content":"\ngen_server:call的应用场景往往是需要有一个已处理的保障\n哪些情况下请求未得到执行?该怎么处理这些情况?\n<!--more-->\n\n## gen_server:call\ngen_server:call会monitor目标进程, monitor可能会发'DOWN'消息给当前进程\n目标进程不存在时Info是noproc,\n远程结点无连接时Info是noconnection,\n等待过程中进程die(如call时目标进程正在terminate或目标进程处理其他消息时内部错误崩溃)时Info是exit reason\n处理消息过程中进程die(目标进程内部错误崩溃)时Info也是exit reason\n\ngen_server:call异常情况下返回的都是exit类型,\n使用try catch来捕捉的话, 可以使用如下的pattern,\n```erlang\ntry\n    gen_server:call(Process, Req)\nof\n    {ok, Result} ->\n        % do something\n    Other ->\n        % do something\ncatch\n    exit:{timeout,{gen_server, call, Args}} ->\n        % 超时的情况, 不确定消息有没有得到执行, call/3且Timeout为infinity时无此情况\n        % do something    \n    exit:{Reason,{gen_server, call, Args}} \n        when Reason =:= noproc; element(1, Reason) =:= nodedown; Reason =:= normal ->\n        % 消息因进程不存在或无连接或正常退出未得到处理的情况, 一般算正常情况\n        % do something\n    exit:{Reason,{gen_server, call, Args}} ->\n        % 其他情况, 写日志并按异常处理, 应该是出bug了\nend\n```\n注意: 目标进程内部崩溃erlang:error的Reason里有调用栈信息, erlang:exit的Reason里没有调用栈信息\n\n## 参考erlang源码\ngen_server.erl\n```erlang\ncall(Name, Request, Timeout) ->                                                  \n    case catch gen:call(Name, '$gen_call', Request, Timeout) of                  \n    {ok,Res} ->                                                                  \n        Res;                                                                     \n    {'EXIT',Reason} ->                                                           \n        exit({Reason, {?MODULE, call, [Name, Request, Timeout]}})                \n    end. \n```\n\ngen.erl\n```erlang\ndo_call(Process, Label, Request, Timeout) ->                                     \n    try erlang:monitor(process, Process) of                                      \n    Mref ->                                                                      \n        %% If the monitor/2 call failed to set up a connection to a              \n        %% remote node, we don't want the '!' operator to attempt                \n        %% to set up the connection again. (If the monitor/2 call                \n        %% failed due to an expired timeout, '!' too would probably              \n        %% have to wait for the timeout to expire.) Therefore,                   \n        %% use erlang:send/3 with the 'noconnect' option so that it              \n        %% will fail immediately if there is no connection to the                \n        %% remote node.                                                          \n                                                                                 \n        catch erlang:send(Process, {Label, {self(), Mref}, Request},             \n          [noconnect]),                                                          \n        receive                                                                  \n        {Mref, Reply} ->                                                         \n            erlang:demonitor(Mref, [flush]),                                     \n            {ok, Reply};                                                         \n        {'DOWN', Mref, _, _, noconnection} ->                                    \n            Node = get_node(Process),                                            \n            exit({nodedown, Node});                                              \n        {'DOWN', Mref, _, _, Reason} ->                                          \n            exit(Reason)                                                         \n        after Timeout ->                                                         \n            erlang:demonitor(Mref, [flush]),                                     \n            exit(timeout)                                                        \n        end                                                                      \n    catch                                                                        \n    error:_ ->                                                                   \n        %% Node (C/Java?) is not supporting the monitor.                         \n        %% The other possible case -- this node is not distributed               \n        %% -- should have been handled earlier.                                  \n        %% Do the best possible with monitor_node/2.                             \n        %% This code may hang indefinitely if the Process                        \n        %% does not exist. It is only used for featureweak remote nodes.         \n        Node = get_node(Process),                                                \n        monitor_node(Node, true),                                                \n        receive                                                                  \n        {nodedown, Node} ->                                                      \n            monitor_node(Node, false),                                           \n            exit({nodedown, Node})                                               \n        after 0 ->                                                               \n            Tag = make_ref(),                                                    \n            Process ! {Label, {self(), Tag}, Request},                           \n            wait_resp(Node, Tag, Timeout)                                        \n        end                                                                      \n    end. \n```\n\ngen_server.erl\n```erlang\ntry_handle_call(Mod, Msg, From, State) ->                                        \n    try                                                                          \n    {ok, Mod:handle_call(Msg, From, State)}                                      \n    catch                                                                        \n    throw:R ->                                                                   \n        {ok, R};                                                                 \n    error:R ->                                                                   \n        Stacktrace = erlang:get_stacktrace(),                                    \n        {'EXIT', {R, Stacktrace}, {R, Stacktrace}};                              \n    exit:R ->                                                                    \n        Stacktrace = erlang:get_stacktrace(),                                    \n        {'EXIT', R, {R, Stacktrace}}                                             \n    end. \n```\n\n## 参考链接\nhttps://github.com/erlang/otp/blob/maint/lib%2Fstdlib%2Fsrc%2Fgen_server.erl\nhttps://github.com/erlang/otp/blob/maint/lib%2Fstdlib%2Fsrc%2Fgen.erl\nhttp://erlang.org/doc/man/erlang.html#monitor-2\n","source":"_posts/erlang_gen_server_call.md","raw":"title: erlang gen_server:call消息未得到执行的情况\ndate: 2016-02-16\ntags: [erlang]\n---\n\ngen_server:call的应用场景往往是需要有一个已处理的保障\n哪些情况下请求未得到执行?该怎么处理这些情况?\n<!--more-->\n\n## gen_server:call\ngen_server:call会monitor目标进程, monitor可能会发'DOWN'消息给当前进程\n目标进程不存在时Info是noproc,\n远程结点无连接时Info是noconnection,\n等待过程中进程die(如call时目标进程正在terminate或目标进程处理其他消息时内部错误崩溃)时Info是exit reason\n处理消息过程中进程die(目标进程内部错误崩溃)时Info也是exit reason\n\ngen_server:call异常情况下返回的都是exit类型,\n使用try catch来捕捉的话, 可以使用如下的pattern,\n```erlang\ntry\n    gen_server:call(Process, Req)\nof\n    {ok, Result} ->\n        % do something\n    Other ->\n        % do something\ncatch\n    exit:{timeout,{gen_server, call, Args}} ->\n        % 超时的情况, 不确定消息有没有得到执行, call/3且Timeout为infinity时无此情况\n        % do something    \n    exit:{Reason,{gen_server, call, Args}} \n        when Reason =:= noproc; element(1, Reason) =:= nodedown; Reason =:= normal ->\n        % 消息因进程不存在或无连接或正常退出未得到处理的情况, 一般算正常情况\n        % do something\n    exit:{Reason,{gen_server, call, Args}} ->\n        % 其他情况, 写日志并按异常处理, 应该是出bug了\nend\n```\n注意: 目标进程内部崩溃erlang:error的Reason里有调用栈信息, erlang:exit的Reason里没有调用栈信息\n\n## 参考erlang源码\ngen_server.erl\n```erlang\ncall(Name, Request, Timeout) ->                                                  \n    case catch gen:call(Name, '$gen_call', Request, Timeout) of                  \n    {ok,Res} ->                                                                  \n        Res;                                                                     \n    {'EXIT',Reason} ->                                                           \n        exit({Reason, {?MODULE, call, [Name, Request, Timeout]}})                \n    end. \n```\n\ngen.erl\n```erlang\ndo_call(Process, Label, Request, Timeout) ->                                     \n    try erlang:monitor(process, Process) of                                      \n    Mref ->                                                                      \n        %% If the monitor/2 call failed to set up a connection to a              \n        %% remote node, we don't want the '!' operator to attempt                \n        %% to set up the connection again. (If the monitor/2 call                \n        %% failed due to an expired timeout, '!' too would probably              \n        %% have to wait for the timeout to expire.) Therefore,                   \n        %% use erlang:send/3 with the 'noconnect' option so that it              \n        %% will fail immediately if there is no connection to the                \n        %% remote node.                                                          \n                                                                                 \n        catch erlang:send(Process, {Label, {self(), Mref}, Request},             \n          [noconnect]),                                                          \n        receive                                                                  \n        {Mref, Reply} ->                                                         \n            erlang:demonitor(Mref, [flush]),                                     \n            {ok, Reply};                                                         \n        {'DOWN', Mref, _, _, noconnection} ->                                    \n            Node = get_node(Process),                                            \n            exit({nodedown, Node});                                              \n        {'DOWN', Mref, _, _, Reason} ->                                          \n            exit(Reason)                                                         \n        after Timeout ->                                                         \n            erlang:demonitor(Mref, [flush]),                                     \n            exit(timeout)                                                        \n        end                                                                      \n    catch                                                                        \n    error:_ ->                                                                   \n        %% Node (C/Java?) is not supporting the monitor.                         \n        %% The other possible case -- this node is not distributed               \n        %% -- should have been handled earlier.                                  \n        %% Do the best possible with monitor_node/2.                             \n        %% This code may hang indefinitely if the Process                        \n        %% does not exist. It is only used for featureweak remote nodes.         \n        Node = get_node(Process),                                                \n        monitor_node(Node, true),                                                \n        receive                                                                  \n        {nodedown, Node} ->                                                      \n            monitor_node(Node, false),                                           \n            exit({nodedown, Node})                                               \n        after 0 ->                                                               \n            Tag = make_ref(),                                                    \n            Process ! {Label, {self(), Tag}, Request},                           \n            wait_resp(Node, Tag, Timeout)                                        \n        end                                                                      \n    end. \n```\n\ngen_server.erl\n```erlang\ntry_handle_call(Mod, Msg, From, State) ->                                        \n    try                                                                          \n    {ok, Mod:handle_call(Msg, From, State)}                                      \n    catch                                                                        \n    throw:R ->                                                                   \n        {ok, R};                                                                 \n    error:R ->                                                                   \n        Stacktrace = erlang:get_stacktrace(),                                    \n        {'EXIT', {R, Stacktrace}, {R, Stacktrace}};                              \n    exit:R ->                                                                    \n        Stacktrace = erlang:get_stacktrace(),                                    \n        {'EXIT', R, {R, Stacktrace}}                                             \n    end. \n```\n\n## 参考链接\nhttps://github.com/erlang/otp/blob/maint/lib%2Fstdlib%2Fsrc%2Fgen_server.erl\nhttps://github.com/erlang/otp/blob/maint/lib%2Fstdlib%2Fsrc%2Fgen.erl\nhttp://erlang.org/doc/man/erlang.html#monitor-2\n","slug":"erlang_gen_server_call","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5l6005cmcxqkndaq8fn"},{"title":"erlang inline","date":"2015-12-28T16:00:00.000Z","_content":"\n内联是一个性能考虑点\n<!--more-->\n\n## 参考链接\nhttp://www.erlang.org/doc/man/compile.html\nhttp://www.cnblogs.com/me-sa/archive/2012/01/09/erlang0029.html\n\n","source":"_posts/erlang_inline.md","raw":"title: erlang inline\ndate: 2015-12-29\ntags: [erlang]\n---\n\n内联是一个性能考虑点\n<!--more-->\n\n## 参考链接\nhttp://www.erlang.org/doc/man/compile.html\nhttp://www.cnblogs.com/me-sa/archive/2012/01/09/erlang0029.html\n\n","slug":"erlang_inline","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5l7005fmcxq1yexxkc7"},{"title":"erlang graph","date":"2021-07-09T16:00:00.000Z","_content":"\n不常用却很有用的数据结构, erlang 有内建的支持, 即 digraph, 和 digraph_util 这两个模块\n\n<!--more-->\n\ndigraph 模块里只有一些基本函数, new, add_vertex, add_edge, delete 之类的\n\n算法相关的都在 digraph_util 里, 比如求拓扑排序的 :digraph_utils.topsort\n\n\n\n### 需要注意的点\n\n这是我在 erlang 遇到的唯一一个不 pure 的数据结构, \n\n```elixir\n> d = :digraph.new()\n{:digraph, #Reference<0.2230174936.1150418949.31867>,\n #Reference<0.2230174936.1150418949.31868>,\n #Reference<0.2230174936.1150418949.31869>, true}\n```\n\n可以看到用了三个 ets 来存实际的数据\n\n下面我们来看下里面是什么内容, 先放一些数据进去\n\n```elixir\n> :digraph.add_vertex(d)\n[:\"$v\" | 0]\n> :digraph.add_vertex(d)\n[:\"$v\" | 1]\n> :digraph.add_vertex(d)\n[:\"$v\" | 2]\n> :digraph.add_vertex(d)\n[:\"$v\" | 3]\n> :digraph.add_vertex(d, :nimei, [1,2,3])\n:nimei\n> :digraph.add_edge(d, :nimei, [:\"$v\" | 1])\n[:\"$e\" | 1]\n\n> :digraph_utils.topsort(d)\n[[:\"$v\" | 3], [:\"$v\" | 2], [:\"$v\" | 0], :nimei, [:\"$v\" | 1]]\n\n```\n\n下面可以看出来, 一个是顶点数据, 一个是边的数据, \n\n最后一个是元数据(默认顶点名和边名的 counter, 以及为了性能考虑的入度和出度的数据)\n\n```elixir\n> {_, a, b, c, _} = d\n{:digraph, #Reference<0.2230174936.1150418949.31867>,\n #Reference<0.2230174936.1150418949.31868>,\n #Reference<0.2230174936.1150418949.31869>, true}\n> :ets.tab2list(a)\n[\n  {:nimei, [1, 2, 3]},\n  {[:\"$v\" | 1], []},\n  {[:\"$v\" | 0], []},\n  {[:\"$v\" | 2], []},\n  {[:\"$v\" | 3], []}\n]\n> :ets.tab2list(b)\n[{[:\"$e\" | 1], :nimei, [:\"$v\" | 1], []}]\n> :ets.tab2list(c)\n[\n  {:\"$eid\", 2},\n  {:\"$vid\", 4},\n  {{:out, :nimei}, [:\"$e\" | 1]},\n  {{:in, [:\"$v\" | 1]}, [:\"$e\" | 1]}\n]\n```\n\n\n\n### 应用场景\n\nTo Be Continued","source":"_posts/erlang_graph.md","raw":"title: erlang graph\ndate: 2021-07-10\n\ntags: [erlang, elixir, graph]\n---\n\n不常用却很有用的数据结构, erlang 有内建的支持, 即 digraph, 和 digraph_util 这两个模块\n\n<!--more-->\n\ndigraph 模块里只有一些基本函数, new, add_vertex, add_edge, delete 之类的\n\n算法相关的都在 digraph_util 里, 比如求拓扑排序的 :digraph_utils.topsort\n\n\n\n### 需要注意的点\n\n这是我在 erlang 遇到的唯一一个不 pure 的数据结构, \n\n```elixir\n> d = :digraph.new()\n{:digraph, #Reference<0.2230174936.1150418949.31867>,\n #Reference<0.2230174936.1150418949.31868>,\n #Reference<0.2230174936.1150418949.31869>, true}\n```\n\n可以看到用了三个 ets 来存实际的数据\n\n下面我们来看下里面是什么内容, 先放一些数据进去\n\n```elixir\n> :digraph.add_vertex(d)\n[:\"$v\" | 0]\n> :digraph.add_vertex(d)\n[:\"$v\" | 1]\n> :digraph.add_vertex(d)\n[:\"$v\" | 2]\n> :digraph.add_vertex(d)\n[:\"$v\" | 3]\n> :digraph.add_vertex(d, :nimei, [1,2,3])\n:nimei\n> :digraph.add_edge(d, :nimei, [:\"$v\" | 1])\n[:\"$e\" | 1]\n\n> :digraph_utils.topsort(d)\n[[:\"$v\" | 3], [:\"$v\" | 2], [:\"$v\" | 0], :nimei, [:\"$v\" | 1]]\n\n```\n\n下面可以看出来, 一个是顶点数据, 一个是边的数据, \n\n最后一个是元数据(默认顶点名和边名的 counter, 以及为了性能考虑的入度和出度的数据)\n\n```elixir\n> {_, a, b, c, _} = d\n{:digraph, #Reference<0.2230174936.1150418949.31867>,\n #Reference<0.2230174936.1150418949.31868>,\n #Reference<0.2230174936.1150418949.31869>, true}\n> :ets.tab2list(a)\n[\n  {:nimei, [1, 2, 3]},\n  {[:\"$v\" | 1], []},\n  {[:\"$v\" | 0], []},\n  {[:\"$v\" | 2], []},\n  {[:\"$v\" | 3], []}\n]\n> :ets.tab2list(b)\n[{[:\"$e\" | 1], :nimei, [:\"$v\" | 1], []}]\n> :ets.tab2list(c)\n[\n  {:\"$eid\", 2},\n  {:\"$vid\", 4},\n  {{:out, :nimei}, [:\"$e\" | 1]},\n  {{:in, [:\"$v\" | 1]}, [:\"$e\" | 1]}\n]\n```\n\n\n\n### 应用场景\n\nTo Be Continued","slug":"erlang_graph","published":1,"updated":"2021-07-10T13:37:36.561Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5l8005hmcxqsywujiyn"},{"title":"erlang interoperability","date":"2015-09-06T16:00:00.000Z","_content":"erlang跨语言调用\n<!--more-->\n## ports\nerlang的port方式做跨语言调用会启动一个外部的操作系统进程, \n就像后端和前端交互一样与这个进程交互\n\n## erl_interface \n官方自带的例子有点问题,得加上-lpthread才能编译通过,如下\n```bash\ngcc -o extprg -I/usr/local/lib/erlang/lib/erl_interface-3.7.6/include/ -L/usr/local/lib/erlang/lib/erl_interface-3.7.6/lib/ \\\ncomplex.c erl_comm.c ei.c -lerl_interface -lei -lpthread\n```\n\n测试\n```erlang\n> complex2:start(\"extprg\").\n这里根据搜索路径可能需要改成complex2:start(\"./extprg\").\n```\n\n## port driver\nerlang的port driver官方自带的例子有问题\n```bash\n官方: gcc -o exampledrv -fpic -shared complex.c port_driver.c\n正确的应该是: gcc -o example_drv.so -fpic -shared complex.c port_driver.c -I /usr/local/lib/erlang/usr/include/\n```\n\n## c_node\nc node结点名的规则\nIf short node names are used, the plain name of the node will be cN where N is an integer. \nIf long node names are used, there is no such restriction. \nAn example of a C node name using short node names is thus c1@idril, an example using long node names is cnode@idril.ericsson.se.\n\n遇到的问题\n```\ncnode_s.c: In function ‘my_listen’:\ncnode_s.c:87:5: warning: incompatible implicit declaration of built-in function ‘memset’ [enabled by default]\n     memset((void*) &addr, 0, (size_t) sizeof(addr));\n     ^\n/usr/bin/ld: cannot find -lsocket\n```\n解决过程:\n去掉了-lsocket\n\n编译短名称的cserver\n```\ngcc -o cserver -I /usr/local/lib/erlang/lib/erl_interface-3.7.6/include/ -L /usr/local/lib/erlang/lib/erl_interface-3.7.6/lib/ complex.c cnode_s.c -l erl_interface -l ei -l nsl -l pthread\n```\n\n编译长名称的cserver2\n```\ngcc -o cserver2 -I /usr/local/lib/erlang/lib/erl_interface-3.7.6/include/ -L /usr/local/lib/erlang/lib/erl_interface-3.7.6/lib/ complex.c cnode_s2.c -l erl_interface -l ei -l nsl -l pthread\n```\n\n编译cclient\n```\ngcc -o cclient -I /usr/local/lib/erlang/lib/erl_interface-3.7.6/include/ -L /usr/local/lib/erlang/lib/erl_interface-3.7.6/lib/ complex.c cnode_c.c -l erl_interface -l ei -l nsl -l pthread\n```\n\n使用短名称的示例:\n```\n$ ./cserver 3459\nConnected to e1@chenduo-desktop\n\n$ erl -sname e1 -setcookie secretcookie\nErlang R15B (erts-5.9) [source] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9  (abort with ^G)\n(e1@chenduo-desktop)1>\n(e1@chenduo-desktop)1> complex3:foo(3).\n4\n(e1@chenduo-desktop)2> complex3:bar(3).\n6\n```\n\n使用长名称的示例:\n```\n$ ./cserver2 3459\nConnected to e1@192.168.1.113\n\n$ erl -name e1@192.168.1.113 -setcookie secretcookie\nErlang R15B (erts-5.9) [source] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9  (abort with ^G)\n(e1@192.168.1.113)1> complex4:bar(2).\n4\n(e1@192.168.1.113)2> complex4:bar(2).\n4\n(e1@192.168.1.113)3> complex4:foo(3).\n4\n(e1@192.168.1.113)4> complex4:foo(30).\n31\n```\n\n使用cclient的示例\n```\n$ ./cclient\nConnected to ei@chenduo-desktop\n\n$ erl -sname e1 -setcookie secretcookie\nErlang R15B (erts-5.9) [source] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9  (abort with ^G)\n(e1@chenduo-desktop)1> complex3:foo(3).\n4\n(e1@chenduo-desktop)2> complex3:foo(4).\n5\n(e1@chenduo-desktop)3> complex3:bar(4).\n8\n```\n\n## NIF\nNIFs are most suitable for synchronous functions like foo and bar in the example, \nthat does some relatively short calculations without side effects and return the result\n适用于相对简单且无副作用的同步函数调用\n\na crash in a NIF will bring the emulator down\n\nWe use the directive on_load to get function init to be automatically called when the module is loaded. \nIf init returns anything other than ok, such when the loading of the NIF library fails in this example, \nthe module will be unloaded and calls to functions within it will fail.\n\nLoading the NIF library will override the stub implementations and cause calls to foo and bar to be dispatched to the NIF implementations instead.\n\n编译\n```\n$ gcc -o complex6_nif.so -fpic -shared complex.c complex6_nif.c -I /usr/local/lib/erlang/usr/include/\n```\n\n测试\n```\n$ erl\nErlang R15B (erts-5.9) [source] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9  (abort with ^G)\n1> c(complex6).\n{ok,complex6}\n2> complex6:foo(100).\n101\n3> complex6:foo(1000000000000).\n** exception error: bad argument\n     in function  complex6:foo/1\n        called as complex6:foo(1000000000000)\n4> complex6:bar(3000).         \n6000\n```\n\n## 源码下载\n[interoperability](/attachments/interoperability.tar.gz)\n\n## 参考链接\nhttp://www.erlang.org/doc/tutorial/introduction.html\n\n","source":"_posts/erlang_interoperability.md","raw":"title: erlang interoperability\ndate: 2015-09-07\ntags: erlang\n---\nerlang跨语言调用\n<!--more-->\n## ports\nerlang的port方式做跨语言调用会启动一个外部的操作系统进程, \n就像后端和前端交互一样与这个进程交互\n\n## erl_interface \n官方自带的例子有点问题,得加上-lpthread才能编译通过,如下\n```bash\ngcc -o extprg -I/usr/local/lib/erlang/lib/erl_interface-3.7.6/include/ -L/usr/local/lib/erlang/lib/erl_interface-3.7.6/lib/ \\\ncomplex.c erl_comm.c ei.c -lerl_interface -lei -lpthread\n```\n\n测试\n```erlang\n> complex2:start(\"extprg\").\n这里根据搜索路径可能需要改成complex2:start(\"./extprg\").\n```\n\n## port driver\nerlang的port driver官方自带的例子有问题\n```bash\n官方: gcc -o exampledrv -fpic -shared complex.c port_driver.c\n正确的应该是: gcc -o example_drv.so -fpic -shared complex.c port_driver.c -I /usr/local/lib/erlang/usr/include/\n```\n\n## c_node\nc node结点名的规则\nIf short node names are used, the plain name of the node will be cN where N is an integer. \nIf long node names are used, there is no such restriction. \nAn example of a C node name using short node names is thus c1@idril, an example using long node names is cnode@idril.ericsson.se.\n\n遇到的问题\n```\ncnode_s.c: In function ‘my_listen’:\ncnode_s.c:87:5: warning: incompatible implicit declaration of built-in function ‘memset’ [enabled by default]\n     memset((void*) &addr, 0, (size_t) sizeof(addr));\n     ^\n/usr/bin/ld: cannot find -lsocket\n```\n解决过程:\n去掉了-lsocket\n\n编译短名称的cserver\n```\ngcc -o cserver -I /usr/local/lib/erlang/lib/erl_interface-3.7.6/include/ -L /usr/local/lib/erlang/lib/erl_interface-3.7.6/lib/ complex.c cnode_s.c -l erl_interface -l ei -l nsl -l pthread\n```\n\n编译长名称的cserver2\n```\ngcc -o cserver2 -I /usr/local/lib/erlang/lib/erl_interface-3.7.6/include/ -L /usr/local/lib/erlang/lib/erl_interface-3.7.6/lib/ complex.c cnode_s2.c -l erl_interface -l ei -l nsl -l pthread\n```\n\n编译cclient\n```\ngcc -o cclient -I /usr/local/lib/erlang/lib/erl_interface-3.7.6/include/ -L /usr/local/lib/erlang/lib/erl_interface-3.7.6/lib/ complex.c cnode_c.c -l erl_interface -l ei -l nsl -l pthread\n```\n\n使用短名称的示例:\n```\n$ ./cserver 3459\nConnected to e1@chenduo-desktop\n\n$ erl -sname e1 -setcookie secretcookie\nErlang R15B (erts-5.9) [source] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9  (abort with ^G)\n(e1@chenduo-desktop)1>\n(e1@chenduo-desktop)1> complex3:foo(3).\n4\n(e1@chenduo-desktop)2> complex3:bar(3).\n6\n```\n\n使用长名称的示例:\n```\n$ ./cserver2 3459\nConnected to e1@192.168.1.113\n\n$ erl -name e1@192.168.1.113 -setcookie secretcookie\nErlang R15B (erts-5.9) [source] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9  (abort with ^G)\n(e1@192.168.1.113)1> complex4:bar(2).\n4\n(e1@192.168.1.113)2> complex4:bar(2).\n4\n(e1@192.168.1.113)3> complex4:foo(3).\n4\n(e1@192.168.1.113)4> complex4:foo(30).\n31\n```\n\n使用cclient的示例\n```\n$ ./cclient\nConnected to ei@chenduo-desktop\n\n$ erl -sname e1 -setcookie secretcookie\nErlang R15B (erts-5.9) [source] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9  (abort with ^G)\n(e1@chenduo-desktop)1> complex3:foo(3).\n4\n(e1@chenduo-desktop)2> complex3:foo(4).\n5\n(e1@chenduo-desktop)3> complex3:bar(4).\n8\n```\n\n## NIF\nNIFs are most suitable for synchronous functions like foo and bar in the example, \nthat does some relatively short calculations without side effects and return the result\n适用于相对简单且无副作用的同步函数调用\n\na crash in a NIF will bring the emulator down\n\nWe use the directive on_load to get function init to be automatically called when the module is loaded. \nIf init returns anything other than ok, such when the loading of the NIF library fails in this example, \nthe module will be unloaded and calls to functions within it will fail.\n\nLoading the NIF library will override the stub implementations and cause calls to foo and bar to be dispatched to the NIF implementations instead.\n\n编译\n```\n$ gcc -o complex6_nif.so -fpic -shared complex.c complex6_nif.c -I /usr/local/lib/erlang/usr/include/\n```\n\n测试\n```\n$ erl\nErlang R15B (erts-5.9) [source] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9  (abort with ^G)\n1> c(complex6).\n{ok,complex6}\n2> complex6:foo(100).\n101\n3> complex6:foo(1000000000000).\n** exception error: bad argument\n     in function  complex6:foo/1\n        called as complex6:foo(1000000000000)\n4> complex6:bar(3000).         \n6000\n```\n\n## 源码下载\n[interoperability](/attachments/interoperability.tar.gz)\n\n## 参考链接\nhttp://www.erlang.org/doc/tutorial/introduction.html\n\n","slug":"erlang_interoperability","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5la005kmcxq1of0hkem"},{"title":"erlang的io库","date":"2015-09-05T16:00:00.000Z","_content":"file:eval\n可以将一个文件里的erlang代码执行,但是不返回值,所有只能利用这些代码的副作用.\n\n","source":"_posts/erlang_io.md","raw":"title: erlang的io库\ntag: erlang\ndate: 2015-09-06\n---\nfile:eval\n可以将一个文件里的erlang代码执行,但是不返回值,所有只能利用这些代码的副作用.\n\n","slug":"erlang_io","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5lb005mmcxqv4qf5i7r"},{"title":"erlang安装指引","date":"2015-07-16T04:00:00.000Z","_content":"## 安装erlang所依赖的库\n```bash\nsudo apt-get build-dep erlang\n```\n<!--more-->\n## 安装基础开发工具\n```bash\nsudo apt-get install build-essential\nsudo apt-get install libncurses5-dev\n```\n\n## crypto依赖\n```bash\nsudo apt-get install libssl-dev\n```\n## wxWidgets依赖\n```bash\nsudo apt-get install freeglut3-dev libwxgtk2.8-dev libgl1-mesa-dev libglu1-mesa-dev libpng3\n```\n## jinterface依赖\n```bash\nsudo apt-get install default-jdk\n```\n## C++支持\n```bash\nsudo apt-get install g++\n```\n## 旧图形工具(appmon, pman等)依赖\n```bash\nsudo apt-get install tk8.5\n```\n\n# 使用kerl安装更方便, 且能支持多个版本\n## 安装R15B版本\n```bash\ncurl -O https://raw.githubusercontent.com/kerl/kerl/master/kerl\nchmod a+x kerl\nsudo mv kerl /usr/local/bin/\nkerl update releases\nKERL_CONFIGURE_OPTIONS=--enable-hipe kerl build R15B r15b\nkerl install r15b ~/erls/R15B\n```\n## 再安装18.0版本\n```bash\nKERL_CONFIGURE_OPTIONS=--enable-hipe kerl build 18.0 18.0\nkerl install 18.0 ~/erls/18.0\n```\n## 将以下代码加入.bashrc以便切换版本\n```bash\n. ~/erls/R15B/activate\nalias erl15='source /home/chenduo/erls/R15B/activate'\nalias erl18='source /home/chenduo/erls/18.0/activate'\n```\n\n## 解除激活，查看当前激活版本, 查看当前状态\n```\n$ kerl_deactivate\n$ kerl active\n$ kerl status\n```\n\n## centos 7.0 环境下安装\nyum install gcc openssl-devel ncurses-devel autoconf\n之后用kerl安装过程相同\nhttps://docs.basho.com/riak/1.3.1/tutorials/installation/Installing-Erlang/\n\n\n## 曾经遇到的问题\n<pre>\nKERL_CONFIGURE_OPTIONS=--enable-hipe kerl build R15B r15b\nVerifying archive checksum...\nChecksum verified (dd6c2a4807551b4a8a536067bde31d73)\nBuilding Erlang/OTP R15B (r15b), please wait...\nBuild failed.\n class WXDLLIMPEXP_CORE wxMDIClientWindow : public wxMDIClientWindowBase\n                         ^\n                         /usr/include/wx-3.0/wx/gtk/mdi.h:138:24: note:   candidate expects 1 argument, 2 provided\n                         make[3]: *** [x86_64-unknown-linux-gnu/wxePrintout.o] Error 1\n                         make[3]: Leaving directory `/home/chenduo/.kerl/builds/r15b/otp_src_R15B/lib/wx/c_src'\n                         make[2]: *** [opt] Error 2\n                         make[2]: Leaving directory `/home/chenduo/.kerl/builds/r15b/otp_src_R15B/lib/wx'\n                         make[1]: *** [opt] Error 2\n                         make[1]: Leaving directory `/home/chenduo/.kerl/builds/r15b/otp_src_R15B/lib'\n                         make: *** [libs] Error 2\n</pre>\n这是因为R15B是匹配wxWidgets2.8的, 而我机器上装的是3.0\n卸载3.0即可\n\n## mac下提示没有 fop 的问题, 用于生成文档\n```\nbrew install fop\n```\n\n## 21.2 开始要求使用 openssl 1.1.1\nmacos下如下安装依赖\n```\nbrew upgrade openssl@1.1\n```\n\n\n\n### 非完整安装的情形\n\n有时只装了 erlang-base 和一些要用的 package\n\n遇到过这样的报错, 装 exoffice 过程中遇到的, 因为没有parsetools, 然后又没有 hrl 头文件\n\n```shell\nCould not compile \"src/link_text_parser.yrl\" because the application \"parsetools\" could not be found. This may happen if your package manager broke Erlang into multiple packages and may be fixed by installing the missing \"erlang-dev\" and \"erlang-parsetools\" packages\n\n/usr/lib/erlang/lib/parsetools-2.2/include/yeccpre.hrl: no such file or directory\n```\n\napt install erlang-parsetools erlang-dev 就可以了, 视情况可能需要指定版本\n\n# 参考链接:\n\n[otp安装wiki][1]\n[ubuntu下erlang源代码的编译与安装][2]\n[kerl的github][3]\n\n[1]: https://github.com/erlang/otp/wiki/Installation\n[2]: http://cryolite.iteye.com/blog/356419\n[3]: https://github.com/yrashk/kerl\n\n","source":"_posts/erlang_install.md","raw":"title: erlang安装指引\ndate: 2015-07-16 12:00:00\ntags: erlang\n---\n## 安装erlang所依赖的库\n```bash\nsudo apt-get build-dep erlang\n```\n<!--more-->\n## 安装基础开发工具\n```bash\nsudo apt-get install build-essential\nsudo apt-get install libncurses5-dev\n```\n\n## crypto依赖\n```bash\nsudo apt-get install libssl-dev\n```\n## wxWidgets依赖\n```bash\nsudo apt-get install freeglut3-dev libwxgtk2.8-dev libgl1-mesa-dev libglu1-mesa-dev libpng3\n```\n## jinterface依赖\n```bash\nsudo apt-get install default-jdk\n```\n## C++支持\n```bash\nsudo apt-get install g++\n```\n## 旧图形工具(appmon, pman等)依赖\n```bash\nsudo apt-get install tk8.5\n```\n\n# 使用kerl安装更方便, 且能支持多个版本\n## 安装R15B版本\n```bash\ncurl -O https://raw.githubusercontent.com/kerl/kerl/master/kerl\nchmod a+x kerl\nsudo mv kerl /usr/local/bin/\nkerl update releases\nKERL_CONFIGURE_OPTIONS=--enable-hipe kerl build R15B r15b\nkerl install r15b ~/erls/R15B\n```\n## 再安装18.0版本\n```bash\nKERL_CONFIGURE_OPTIONS=--enable-hipe kerl build 18.0 18.0\nkerl install 18.0 ~/erls/18.0\n```\n## 将以下代码加入.bashrc以便切换版本\n```bash\n. ~/erls/R15B/activate\nalias erl15='source /home/chenduo/erls/R15B/activate'\nalias erl18='source /home/chenduo/erls/18.0/activate'\n```\n\n## 解除激活，查看当前激活版本, 查看当前状态\n```\n$ kerl_deactivate\n$ kerl active\n$ kerl status\n```\n\n## centos 7.0 环境下安装\nyum install gcc openssl-devel ncurses-devel autoconf\n之后用kerl安装过程相同\nhttps://docs.basho.com/riak/1.3.1/tutorials/installation/Installing-Erlang/\n\n\n## 曾经遇到的问题\n<pre>\nKERL_CONFIGURE_OPTIONS=--enable-hipe kerl build R15B r15b\nVerifying archive checksum...\nChecksum verified (dd6c2a4807551b4a8a536067bde31d73)\nBuilding Erlang/OTP R15B (r15b), please wait...\nBuild failed.\n class WXDLLIMPEXP_CORE wxMDIClientWindow : public wxMDIClientWindowBase\n                         ^\n                         /usr/include/wx-3.0/wx/gtk/mdi.h:138:24: note:   candidate expects 1 argument, 2 provided\n                         make[3]: *** [x86_64-unknown-linux-gnu/wxePrintout.o] Error 1\n                         make[3]: Leaving directory `/home/chenduo/.kerl/builds/r15b/otp_src_R15B/lib/wx/c_src'\n                         make[2]: *** [opt] Error 2\n                         make[2]: Leaving directory `/home/chenduo/.kerl/builds/r15b/otp_src_R15B/lib/wx'\n                         make[1]: *** [opt] Error 2\n                         make[1]: Leaving directory `/home/chenduo/.kerl/builds/r15b/otp_src_R15B/lib'\n                         make: *** [libs] Error 2\n</pre>\n这是因为R15B是匹配wxWidgets2.8的, 而我机器上装的是3.0\n卸载3.0即可\n\n## mac下提示没有 fop 的问题, 用于生成文档\n```\nbrew install fop\n```\n\n## 21.2 开始要求使用 openssl 1.1.1\nmacos下如下安装依赖\n```\nbrew upgrade openssl@1.1\n```\n\n\n\n### 非完整安装的情形\n\n有时只装了 erlang-base 和一些要用的 package\n\n遇到过这样的报错, 装 exoffice 过程中遇到的, 因为没有parsetools, 然后又没有 hrl 头文件\n\n```shell\nCould not compile \"src/link_text_parser.yrl\" because the application \"parsetools\" could not be found. This may happen if your package manager broke Erlang into multiple packages and may be fixed by installing the missing \"erlang-dev\" and \"erlang-parsetools\" packages\n\n/usr/lib/erlang/lib/parsetools-2.2/include/yeccpre.hrl: no such file or directory\n```\n\napt install erlang-parsetools erlang-dev 就可以了, 视情况可能需要指定版本\n\n# 参考链接:\n\n[otp安装wiki][1]\n[ubuntu下erlang源代码的编译与安装][2]\n[kerl的github][3]\n\n[1]: https://github.com/erlang/otp/wiki/Installation\n[2]: http://cryolite.iteye.com/blog/356419\n[3]: https://github.com/yrashk/kerl\n\n","slug":"erlang_install","published":1,"updated":"2021-07-30T04:37:25.596Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5lc005pmcxqfuut2l91"},{"title":"erlang native array nif","date":"2015-12-24T16:00:00.000Z","_content":"\nerlang nif实现的一个数组\n\n<!--more-->\n\n<pre>\nErlang R15B03 (erts-5.9.3.1) [source] [64-bit] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9.3.1  (abort with ^G)\n1> native_array:new(13, 10000).\nok\n2> native_array:put(13, 345, 103).\nok\n3> native_array:get(13, 345).\n103\n4> native_array:put(13, 6645, 255).\nok\n5> native_array:get(13, 6645).     \n255\n</pre>\n\n### 内存分配在system里, 调用delete后立即释放\n<pre>\n> native_array:new(1, 100000000).\nok\n> memory().\n[{total,116695824},\n {processes,5250144},\n {processes_used,5249120},\n {system,111445680},\n {atom,256313},\n {atom_used,223947},\n {binary,100879232},\n {code,5342662},\n {ets,305112}]\n> native_array:delete(1).\nok\n> memory().              \n[{total,16782792},\n {processes,5251440},\n {processes_used,5250264},\n {system,11531352},\n {atom,256313},\n {atom_used,223947},\n {binary,964896},\n {code,5342662},\n {ets,305112}]\n</pre>\n\n## 源码下载\nhttps://github.com/suexcxine/native_array\n\n## 参考链接\nhttps://github.com/chitika/cberl\nhttps://github.com/davisp/nif-examples\n\n","source":"_posts/erlang_native_array_nif.md","raw":"title: erlang native array nif\ndate: 2015-12-25\ntags: [erlang]\n---\n\nerlang nif实现的一个数组\n\n<!--more-->\n\n<pre>\nErlang R15B03 (erts-5.9.3.1) [source] [64-bit] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9.3.1  (abort with ^G)\n1> native_array:new(13, 10000).\nok\n2> native_array:put(13, 345, 103).\nok\n3> native_array:get(13, 345).\n103\n4> native_array:put(13, 6645, 255).\nok\n5> native_array:get(13, 6645).     \n255\n</pre>\n\n### 内存分配在system里, 调用delete后立即释放\n<pre>\n> native_array:new(1, 100000000).\nok\n> memory().\n[{total,116695824},\n {processes,5250144},\n {processes_used,5249120},\n {system,111445680},\n {atom,256313},\n {atom_used,223947},\n {binary,100879232},\n {code,5342662},\n {ets,305112}]\n> native_array:delete(1).\nok\n> memory().              \n[{total,16782792},\n {processes,5251440},\n {processes_used,5250264},\n {system,11531352},\n {atom,256313},\n {atom_used,223947},\n {binary,964896},\n {code,5342662},\n {ets,305112}]\n</pre>\n\n## 源码下载\nhttps://github.com/suexcxine/native_array\n\n## 参考链接\nhttps://github.com/chitika/cberl\nhttps://github.com/davisp/nif-examples\n\n","slug":"erlang_native_array_nif","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ld005rmcxqv51udp8s"},{"title":"erlang macro","date":"2021-06-23T16:00:00.000Z","_content":"\n宏参数字符串化(Stringifying Macro Arguments)\n这个功能有时候还真挺有用的(虽然 elixir 不需要~), 比如测试用例和打日志的时候.\n语法是: `??Arg`\n\n<!--more-->\n\n例如:\n\n```erlang\n-define(TESTCALL(Call), io:format(\"Call ~s: ~w~n\", [??Call, Call])).\n\n?TESTCALL(myfunction(1,2)),\n?TESTCALL(you:function(2,1)).\n```\n\n上面的 `?TESTCALL` 那两行展开后会变成下面这样:\n\n```erlang\nio:format(\"Call ~s: ~w~n\",[\"myfunction(1,2)\", myfunction(1,2)]),\nio:format(\"Call ~s: ~w~n\",[\"you:function(2,1)\", you:function(2,1)]).\n```\n\n## 参考链接\nhttp://erlang.org/doc/reference_manual/macros.html#stringifying-macro-arguments\n\n","source":"_posts/erlang_macro.md","raw":"title: erlang macro\ndate: 2021-06-24\n\ntags: [erlang, macro]\n---\n\n宏参数字符串化(Stringifying Macro Arguments)\n这个功能有时候还真挺有用的(虽然 elixir 不需要~), 比如测试用例和打日志的时候.\n语法是: `??Arg`\n\n<!--more-->\n\n例如:\n\n```erlang\n-define(TESTCALL(Call), io:format(\"Call ~s: ~w~n\", [??Call, Call])).\n\n?TESTCALL(myfunction(1,2)),\n?TESTCALL(you:function(2,1)).\n```\n\n上面的 `?TESTCALL` 那两行展开后会变成下面这样:\n\n```erlang\nio:format(\"Call ~s: ~w~n\",[\"myfunction(1,2)\", myfunction(1,2)]),\nio:format(\"Call ~s: ~w~n\",[\"you:function(2,1)\", you:function(2,1)]).\n```\n\n## 参考链接\nhttp://erlang.org/doc/reference_manual/macros.html#stringifying-macro-arguments\n\n","slug":"erlang_macro","published":1,"updated":"2021-06-24T11:46:07.096Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5lf005umcxqt7zv10c1"},{"title":"erlang nif","date":"2015-12-27T16:00:00.000Z","_content":"\nNIF(Native Implemented Function)比port driver更简单有效，\n尤其适合编写同步程序, 替Erlang完成一些Erlang不擅长的运算(heavy lifting)\n<!--more-->\n## 环境(ErlNifEnv)\n<pre>\nstruct enif_environment_t /* ErlNifEnv */\n{                                                                                \n    struct erl_module_nif* mod_nif;   \n    Process* proc;                                                               \n    Eterm* hp;                                                                   \n    Eterm* hp_end;                                                               \n    ErlHeapFragment* heap_frag;                                                  \n    int fpe_was_unmasked;                                                        \n    struct enif_tmp_obj_t* tmp_obj_list;                                         \n    int exception_thrown; /* boolean */                                          \n}; \n</pre>\nErlNifEnv表示host erlang term的环境\n所有的erlang term都属于某一个环境\nlist/tuple/map等容器, 都必须和其内部元素在同一个环境内\n\n#### 绑定进程的环境(process bound environment)\n所有NIF的第一个参数都是这种环境, 给NIF的所有参数都属于这个环境, NIF的返回值也必须属于这个环境,\n此类环境仅包含关于调用进程的瞬时信息, 仅在NIF执行期间那一个线程有效, \n所以在这类环境中保存指针给下次NIF使用是无效且危险的行为\n\n#### 非绑定进程的环境(process independent environment)\n使用enif_alloc_env创建, 在enif_free_env或enif_send被调用之前一直有效,\n所以可以用于在多次调用NIF之间保存erlang term\n\n## 源码\nerts/emulator/beam/global.h\nerts/emulator/beam/erl_nif.c\n                                                                                 \n## 参考链接\nhttp://blog.suexcxine.cc/2015/09/07/erlang_interoperability/\nhttp://blog.suexcxine.cc/2015/12/25/erlang_native_array_nif/\n\n","source":"_posts/erlang_nif.md","raw":"title: erlang nif\ndate: 2015-12-28\ntags: [erlang]\n---\n\nNIF(Native Implemented Function)比port driver更简单有效，\n尤其适合编写同步程序, 替Erlang完成一些Erlang不擅长的运算(heavy lifting)\n<!--more-->\n## 环境(ErlNifEnv)\n<pre>\nstruct enif_environment_t /* ErlNifEnv */\n{                                                                                \n    struct erl_module_nif* mod_nif;   \n    Process* proc;                                                               \n    Eterm* hp;                                                                   \n    Eterm* hp_end;                                                               \n    ErlHeapFragment* heap_frag;                                                  \n    int fpe_was_unmasked;                                                        \n    struct enif_tmp_obj_t* tmp_obj_list;                                         \n    int exception_thrown; /* boolean */                                          \n}; \n</pre>\nErlNifEnv表示host erlang term的环境\n所有的erlang term都属于某一个环境\nlist/tuple/map等容器, 都必须和其内部元素在同一个环境内\n\n#### 绑定进程的环境(process bound environment)\n所有NIF的第一个参数都是这种环境, 给NIF的所有参数都属于这个环境, NIF的返回值也必须属于这个环境,\n此类环境仅包含关于调用进程的瞬时信息, 仅在NIF执行期间那一个线程有效, \n所以在这类环境中保存指针给下次NIF使用是无效且危险的行为\n\n#### 非绑定进程的环境(process independent environment)\n使用enif_alloc_env创建, 在enif_free_env或enif_send被调用之前一直有效,\n所以可以用于在多次调用NIF之间保存erlang term\n\n## 源码\nerts/emulator/beam/global.h\nerts/emulator/beam/erl_nif.c\n                                                                                 \n## 参考链接\nhttp://blog.suexcxine.cc/2015/09/07/erlang_interoperability/\nhttp://blog.suexcxine.cc/2015/12/25/erlang_native_array_nif/\n\n","slug":"erlang_nif","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5lg005wmcxq9jk8wxif"},{"title":"如何在shell里好好(pretty)地显示erlang的record","date":"2015-12-06T16:00:00.000Z","_content":"调试的时候\n是否经常觉得record显示成tuple那样很难把值和字段名对上?\n是否经常觉得record如果能好好显示就好了?\n显示成什么样算是好好显示了呢,就像下面这样:\n```\n#person{id = undefined,age = undefined,name = <<>>,\n        gold = undefined,career = undefined}\n```\n<!--more-->\n## 使用erlang未公开的io\\_lib\\_pretty模块好好显示record\n```\npretty_print(Val) ->                                                             \n    io_lib_pretty:print(Val, fun rec_def_fun/2).                                 \n                                                                                 \nrec_def_fun(Tag, N) ->                                                           \n    Ret = recordfields:get(Tag),                                                 \n    case Ret =/= [] andalso length(Ret) =:= N of                                 \n        true -> Ret;                                                             \n        false -> no                                                              \n    end. \n```\n\nrecordfields模块代码(考虑用工具自动生成)\n```    \n-module(recordfields).                                                              \n-export([get/1]).  \n-include(\"xxx.hrl\").                                                              \n-include(\"yyy.hrl\").                                           \n\nget(recordname1) ->                                                                   \n    record_info(fields, recordname1);\nget(recordname2) ->                                                                   \n    record_info(fields, recordname2);  \nget(recordname3) ->                                                                   \n    record_info(fields, recordname3);  \nget(_) ->\n    [].\n```\n\n这样一来使用上面定义的pretty_print函数打印出来的格式就是~好好的~\n\n## 使用user_default模块\nuser\\_default(必须以debug\\_info编译选项编译)里include的头文件里的record会在结点启动时自动加载,\n于是在shell里可以用,即不需要使用shell的rr命令\n效果:如下\n```\n> #person{}.\n#person{id = undefined,age = undefined,name = <<>>,\n        gold = undefined,career = undefined}\n```\n","source":"_posts/erlang_pretty_print.md","raw":"title: 如何在shell里好好(pretty)地显示erlang的record\ndate: 2015-12-07\ntags: [erlang]\n---\n调试的时候\n是否经常觉得record显示成tuple那样很难把值和字段名对上?\n是否经常觉得record如果能好好显示就好了?\n显示成什么样算是好好显示了呢,就像下面这样:\n```\n#person{id = undefined,age = undefined,name = <<>>,\n        gold = undefined,career = undefined}\n```\n<!--more-->\n## 使用erlang未公开的io\\_lib\\_pretty模块好好显示record\n```\npretty_print(Val) ->                                                             \n    io_lib_pretty:print(Val, fun rec_def_fun/2).                                 \n                                                                                 \nrec_def_fun(Tag, N) ->                                                           \n    Ret = recordfields:get(Tag),                                                 \n    case Ret =/= [] andalso length(Ret) =:= N of                                 \n        true -> Ret;                                                             \n        false -> no                                                              \n    end. \n```\n\nrecordfields模块代码(考虑用工具自动生成)\n```    \n-module(recordfields).                                                              \n-export([get/1]).  \n-include(\"xxx.hrl\").                                                              \n-include(\"yyy.hrl\").                                           \n\nget(recordname1) ->                                                                   \n    record_info(fields, recordname1);\nget(recordname2) ->                                                                   \n    record_info(fields, recordname2);  \nget(recordname3) ->                                                                   \n    record_info(fields, recordname3);  \nget(_) ->\n    [].\n```\n\n这样一来使用上面定义的pretty_print函数打印出来的格式就是~好好的~\n\n## 使用user_default模块\nuser\\_default(必须以debug\\_info编译选项编译)里include的头文件里的record会在结点启动时自动加载,\n于是在shell里可以用,即不需要使用shell的rr命令\n效果:如下\n```\n> #person{}.\n#person{id = undefined,age = undefined,name = <<>>,\n        gold = undefined,career = undefined}\n```\n","slug":"erlang_pretty_print","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5lh005ymcxqfmepmdft"},{"title":"erlang rebar","date":"2015-09-13T16:00:00.000Z","_content":"## 获取帮助\n> rebar -c\n> 获取指定命令的帮助如clean\n> rebar help clean\n\n## 新建项目\n> rebar create-app appid=myapp\n\n## 编译\n> rebar compile\n\n## 清理\n> rebar clean\n\n## 单元测试\n在文件头部加上:\n> -ifdef(TEST).\n> -include_lib(\"eunit/include/eunit.hrl\").\n> -endif.\n\n在文件尾部加上类似如下代码:\n> -ifdef(TEST).\n> \n> simple_test() ->\n>     ok = application:start(myapp),\n>     ?assertNot(undefined == whereis(myapp_sup)).\n> \n> -endif.\n\n执行单元测试\n> rebar compile eunit\n\n## 覆盖率测试\n在rebar.config配置文件中加上:\n> {cover_enabled, true}.\n\n执行覆盖率测试\n> $ rebar compile eunit\n> ==> myapp (compile)\n> ==> myapp (eunit)\n>   Test passed.\n> Cover analysis: /Users/dizzyd/tmp/myapp/.eunit/index.html\n\n可以打开.eunit/index.html文件检查覆盖率的分析报告\n\n## Rebar conventions\n* rebar会在test目录中寻找EUnit测试代码\n* c_src文件夹存储用于编译port driver的c代码文件\n\n## Dynamic configuration\n这个功能提供一些定制空间\n\n如果存在rebar.config.script文件(与rebar.config在同一目录),\n那么该文件会被以file:script/2函数读取并执行,最后一个表达式的值会被返回做为结果\n同样的,对其他自定义的rebar.config文件也适用,\n如rebar -C special_config会尝试读取special.config.script文件\n例如:\n> case os:getenv(\"REBAR_DEPS\") of\n>     false -> CONFIG; % env var not defined\n>     []    -> CONFIG; % env var set to empty string\n>     Dir ->\n>     lists:keystore(deps_dir, 1, CONFIG, {deps_dir, Dir})\n> end.\n\n这段代码的功能是,如果想自定义一个依赖目录而不是每次都从github取依赖的话设置REBAR_DEPS环境变量\n反过来,不设置REBAR_DEPS环境变量则会从github取依赖\n\n## 优先编译\n```\n{erl_first_files, [\"src/mymib1.erl\", \"src/mymib2.erl\"]}.\n```\n\n## 条件编译\n可以使用另一个config来做条件编译之用\n如:rebar_ct.config\n> {erl_opts, [debug_info, {d, `'TEST'`, true}]}.\n\n使用-C参数指定config文件(非默认的rebar.config),\n进一步可以使用Makefile\n记得先clean掉之前的编译结果,因为rebar只会编译未编译过的模块,\n如果不clean,那么已编译的模块不会被重新编译\n```bash\n./rebar -C \"rebar_ct.config\" clean compile ct\n```\n\n## lib_dirs配置\nrebar.config:\n```erlang\n{lib_dirs, [\"deps\"]}.\n```\n编译代码时,有时出现Warning: behaviour ranch_protocol undefined这样的错误,\n原因是compile:file执行时无法在搜索路径里找到ranch_protocol:behaviour_info/1函数,\n而对于rebar这样一个escript程序,无法使用-pa,-pz来扩展搜索路径,\n只能在代码里使用code:add_pathsa等来动态添加, 其依据即为lib_dirs配置\n参考链接: http://erlang.2086793.n4.nabble.com/Behavior-undefined-warning-td2088824.html\n\n\n\n\n","source":"_posts/erlang_rebar.md","raw":"title: erlang rebar\ndate: 2015-09-14\ntags: erlang\n---\n## 获取帮助\n> rebar -c\n> 获取指定命令的帮助如clean\n> rebar help clean\n\n## 新建项目\n> rebar create-app appid=myapp\n\n## 编译\n> rebar compile\n\n## 清理\n> rebar clean\n\n## 单元测试\n在文件头部加上:\n> -ifdef(TEST).\n> -include_lib(\"eunit/include/eunit.hrl\").\n> -endif.\n\n在文件尾部加上类似如下代码:\n> -ifdef(TEST).\n> \n> simple_test() ->\n>     ok = application:start(myapp),\n>     ?assertNot(undefined == whereis(myapp_sup)).\n> \n> -endif.\n\n执行单元测试\n> rebar compile eunit\n\n## 覆盖率测试\n在rebar.config配置文件中加上:\n> {cover_enabled, true}.\n\n执行覆盖率测试\n> $ rebar compile eunit\n> ==> myapp (compile)\n> ==> myapp (eunit)\n>   Test passed.\n> Cover analysis: /Users/dizzyd/tmp/myapp/.eunit/index.html\n\n可以打开.eunit/index.html文件检查覆盖率的分析报告\n\n## Rebar conventions\n* rebar会在test目录中寻找EUnit测试代码\n* c_src文件夹存储用于编译port driver的c代码文件\n\n## Dynamic configuration\n这个功能提供一些定制空间\n\n如果存在rebar.config.script文件(与rebar.config在同一目录),\n那么该文件会被以file:script/2函数读取并执行,最后一个表达式的值会被返回做为结果\n同样的,对其他自定义的rebar.config文件也适用,\n如rebar -C special_config会尝试读取special.config.script文件\n例如:\n> case os:getenv(\"REBAR_DEPS\") of\n>     false -> CONFIG; % env var not defined\n>     []    -> CONFIG; % env var set to empty string\n>     Dir ->\n>     lists:keystore(deps_dir, 1, CONFIG, {deps_dir, Dir})\n> end.\n\n这段代码的功能是,如果想自定义一个依赖目录而不是每次都从github取依赖的话设置REBAR_DEPS环境变量\n反过来,不设置REBAR_DEPS环境变量则会从github取依赖\n\n## 优先编译\n```\n{erl_first_files, [\"src/mymib1.erl\", \"src/mymib2.erl\"]}.\n```\n\n## 条件编译\n可以使用另一个config来做条件编译之用\n如:rebar_ct.config\n> {erl_opts, [debug_info, {d, `'TEST'`, true}]}.\n\n使用-C参数指定config文件(非默认的rebar.config),\n进一步可以使用Makefile\n记得先clean掉之前的编译结果,因为rebar只会编译未编译过的模块,\n如果不clean,那么已编译的模块不会被重新编译\n```bash\n./rebar -C \"rebar_ct.config\" clean compile ct\n```\n\n## lib_dirs配置\nrebar.config:\n```erlang\n{lib_dirs, [\"deps\"]}.\n```\n编译代码时,有时出现Warning: behaviour ranch_protocol undefined这样的错误,\n原因是compile:file执行时无法在搜索路径里找到ranch_protocol:behaviour_info/1函数,\n而对于rebar这样一个escript程序,无法使用-pa,-pz来扩展搜索路径,\n只能在代码里使用code:add_pathsa等来动态添加, 其依据即为lib_dirs配置\n参考链接: http://erlang.2086793.n4.nabble.com/Behavior-undefined-warning-td2088824.html\n\n\n\n\n","slug":"erlang_rebar","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5li0061mcxqteo33eoh"},{"title":"erlang receive after infinity时启动timer么","date":"2016-02-15T16:00:00.000Z","_content":"\n找了一段emulator的代码看来是不会启动timer\n<!--more-->\n\n不启动timer的话, 使用infinity确实可以省一个timer\n\n## 参考erlang源码\nbeam_emu.c\n```erlang\n     if (timeout_value != make_small(0)) {\n\n     if (timeout_value == am_infinity)\n         c_p->flags |= F_TIMO;\n     else {\n         int tres = erts_set_proc_timer_term(c_p, timeout_value);\n         if (tres == 0) {\n         /*\n          * The timer routiner will set c_p->i to the value in\n          * c_p->def_arg_reg[0].  Note that it is safe to use this\n          * location because there are no living x registers in\n          * a receive statement.\n          * Note that for the halfword emulator, the two first elements\n          * of the array are used.\n          */\n         BeamInstr** pi = (BeamInstr**) c_p->def_arg_reg;\n         *pi = I+3;\n         }\n         else { /* Wrong time */\n         OpCase(i_wait_error_locked): {\n             erts_smp_proc_unlock(c_p, ERTS_PROC_LOCKS_MSG_RECEIVE);\n             /* Fall through */\n         }\n         OpCase(i_wait_error): {\n             c_p->freason = EXC_TIMEOUT_VALUE;\n             goto find_func_info;\n         }\n         }\n     }\n```\n     \n## 参考链接\nhttps://github.com/erlang/otp/blob/a03b7add86b92d0d7d2d744e5555314bedbc2197/erts/emulator/beam/beam_emu.c\n\n","source":"_posts/erlang_receive_infinity.md","raw":"title: erlang receive after infinity时启动timer么\ndate: 2016-02-16\ntags: [erlang]\n---\n\n找了一段emulator的代码看来是不会启动timer\n<!--more-->\n\n不启动timer的话, 使用infinity确实可以省一个timer\n\n## 参考erlang源码\nbeam_emu.c\n```erlang\n     if (timeout_value != make_small(0)) {\n\n     if (timeout_value == am_infinity)\n         c_p->flags |= F_TIMO;\n     else {\n         int tres = erts_set_proc_timer_term(c_p, timeout_value);\n         if (tres == 0) {\n         /*\n          * The timer routiner will set c_p->i to the value in\n          * c_p->def_arg_reg[0].  Note that it is safe to use this\n          * location because there are no living x registers in\n          * a receive statement.\n          * Note that for the halfword emulator, the two first elements\n          * of the array are used.\n          */\n         BeamInstr** pi = (BeamInstr**) c_p->def_arg_reg;\n         *pi = I+3;\n         }\n         else { /* Wrong time */\n         OpCase(i_wait_error_locked): {\n             erts_smp_proc_unlock(c_p, ERTS_PROC_LOCKS_MSG_RECEIVE);\n             /* Fall through */\n         }\n         OpCase(i_wait_error): {\n             c_p->freason = EXC_TIMEOUT_VALUE;\n             goto find_func_info;\n         }\n         }\n     }\n```\n     \n## 参考链接\nhttps://github.com/erlang/otp/blob/a03b7add86b92d0d7d2d744e5555314bedbc2197/erts/emulator/beam/beam_emu.c\n\n","slug":"erlang_receive_infinity","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5lj0063mcxqicu3n2x9"},{"title":"erlang relx","date":"2015-09-13T16:00:00.000Z","_content":"## 如何在release不包含src代码\nrelx.config里加上配置即可不包含源代码\n> {include_src, false}.\n\n## 怎么不让wx, observer等app一开始就启动但是又包含在release里\n在relx.config里加上就可以了, 如下\n> {release, {suex_1, \"1\"}, [suex, wx, observer]}.","source":"_posts/erlang_relx.md","raw":"title: erlang relx\ndate: 2015-09-14\ntags: erlang\n---\n## 如何在release不包含src代码\nrelx.config里加上配置即可不包含源代码\n> {include_src, false}.\n\n## 怎么不让wx, observer等app一开始就启动但是又包含在release里\n在relx.config里加上就可以了, 如下\n> {release, {suex_1, \"1\"}, [suex, wx, observer]}.","slug":"erlang_relx","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5lk0066mcxq6nrzv1mt"},{"title":"erlang remsh","date":"2016-06-03T16:00:00.000Z","_content":"\n连接erlang remote shell的几种方式方法\n\n<!--more-->\n\n### 启动a shell\n\n```\n$ erl -name a@127.0.0.1 -setcookie abc\nErlang R15B03 (erts-5.9.3.1) [source] [64-bit] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9.3.1  (abort with ^G)\n(a@127.0.0.1)1> \n```\n\n### 启动b shell后通过JCM(Job Control Mode)远程连接a shell\n\n```\n$ erl -name b@127.0.0.1 -setcookie abc\nErlang R15B03 (erts-5.9.3.1) [source] [64-bit] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9.3.1  (abort with ^G)\n(b@127.0.0.1)1> \nUser switch command\n--> h\nc [nn]            - connect to job\ni [nn]            - interrupt job\nk [nn]            - kill job\nj                 - list all jobs\ns [shell]         - start local shell\nr [node [shell]]  - start remote shell\nq        - quit erlang\n? | h             - this message\n--> r 'a@127.0.0.1'\n--> j\n1  {shell,start,[init]}\n2* {'a@127.0.0.1',shell,start,[]}\n--> c \nEshell V5.9.3.1  (abort with ^G)\n(a@127.0.0.1)1> nodes().\n['b@127.0.0.1']\n```\n\n### 通过命令行参数remsh直接连接a shell\n```\n$ erl -name b@127.0.0.1 -setcookie abc -remsh a@127.0.0.1\nErlang R15B03 (erts-5.9.3.1) [source] [64-bit] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9.3.1  (abort with ^G)\n(a@127.0.0.1)1> \nUser switch command\n--> j\n1* {'a@127.0.0.1',shell,start,[]}\n```\n\n### 增加-hidden命令行参数避免出现在nodes()函数的返回值里, 同时避免自动连接到整个集群上\n```\n$ erl -name b@127.0.0.1 -setcookie abc -remsh a@127.0.0.1 -hidden\nErlang R15B03 (erts-5.9.3.1) [source] [64-bit] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9.3.1  (abort with ^G)\n(a@127.0.0.1)1> nodes().\n[]\n```\n\n","source":"_posts/erlang_remsh.md","raw":"title: erlang remsh\ndate: 2016-06-04\ntags: [erlang]\n---\n\n连接erlang remote shell的几种方式方法\n\n<!--more-->\n\n### 启动a shell\n\n```\n$ erl -name a@127.0.0.1 -setcookie abc\nErlang R15B03 (erts-5.9.3.1) [source] [64-bit] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9.3.1  (abort with ^G)\n(a@127.0.0.1)1> \n```\n\n### 启动b shell后通过JCM(Job Control Mode)远程连接a shell\n\n```\n$ erl -name b@127.0.0.1 -setcookie abc\nErlang R15B03 (erts-5.9.3.1) [source] [64-bit] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9.3.1  (abort with ^G)\n(b@127.0.0.1)1> \nUser switch command\n--> h\nc [nn]            - connect to job\ni [nn]            - interrupt job\nk [nn]            - kill job\nj                 - list all jobs\ns [shell]         - start local shell\nr [node [shell]]  - start remote shell\nq        - quit erlang\n? | h             - this message\n--> r 'a@127.0.0.1'\n--> j\n1  {shell,start,[init]}\n2* {'a@127.0.0.1',shell,start,[]}\n--> c \nEshell V5.9.3.1  (abort with ^G)\n(a@127.0.0.1)1> nodes().\n['b@127.0.0.1']\n```\n\n### 通过命令行参数remsh直接连接a shell\n```\n$ erl -name b@127.0.0.1 -setcookie abc -remsh a@127.0.0.1\nErlang R15B03 (erts-5.9.3.1) [source] [64-bit] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9.3.1  (abort with ^G)\n(a@127.0.0.1)1> \nUser switch command\n--> j\n1* {'a@127.0.0.1',shell,start,[]}\n```\n\n### 增加-hidden命令行参数避免出现在nodes()函数的返回值里, 同时避免自动连接到整个集群上\n```\n$ erl -name b@127.0.0.1 -setcookie abc -remsh a@127.0.0.1 -hidden\nErlang R15B03 (erts-5.9.3.1) [source] [64-bit] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n\nEshell V5.9.3.1  (abort with ^G)\n(a@127.0.0.1)1> nodes().\n[]\n```\n\n","slug":"erlang_remsh","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ll0068mcxq643u0uqu"},{"title":"erlang 正则表达式","date":"2018-10-07T16:00:00.000Z","_content":"\n当时打算搞一个校验密码的正则,\n各种特殊符号和转义搞死我了\n\n<!--more-->\n\n最后还是用这种才得救, 不用一个个写允许哪些符号了\n```erlang\nre:run(Password, \"^[\\x21-\\x7E]{6,20}$\")\n```\n6-20位长度, 键盘上看得见的符号都允许\n\n### 参考链接\nhttp://www.asciitable.com/\nhttps://www.regular-expressions.info/posixbrackets.html\n\n","source":"_posts/erlang_regex.md","raw":"title: erlang 正则表达式\ndate: 2018-10-08\ntags: [erlang, regex, re]\n---\n\n当时打算搞一个校验密码的正则,\n各种特殊符号和转义搞死我了\n\n<!--more-->\n\n最后还是用这种才得救, 不用一个个写允许哪些符号了\n```erlang\nre:run(Password, \"^[\\x21-\\x7E]{6,20}$\")\n```\n6-20位长度, 键盘上看得见的符号都允许\n\n### 参考链接\nhttp://www.asciitable.com/\nhttps://www.regular-expressions.info/posixbrackets.html\n\n","slug":"erlang_regex","published":1,"updated":"2018-10-08T06:41:32.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5lm006bmcxq8w2epyyy"},{"title":"关于erlang作用域","date":"2015-12-28T16:00:00.000Z","_content":"\n以下三种情况定义一个作用域:\n* 函数分句\n* fun\n* list comprehension\n<!--more-->\n\n## fun和list comprehension\n\nErlang一开始只有函数分句会定义作用域\nErlang里仅有的嵌套作用域只有后来的fun和list comprehension\n\nlist comprehension里引入的变量在执行期间可能被绑定0次(即未绑定)或多次\n所以加了独立作用域, 如果不加独立作用域的话, 里面的变量在外面也没法用(因为可能未绑定)\n外面也不能重新定义这个变量名(因为可能已经绑定了), 所以还是加个独立作用域的好\n\nfun也是相同的道理, 定义了一个fun之后这个fun可能没有被调用, 也可能被调用多次\n\n## list comprehension\n\n在javascript, ruby, python这样的语言中, list comprehension更像一个做过性能优化的for循环,\n例如Python:\n<pre>\\>>> [x for x in [1,2,3]]\n [1, 2, 3]\n\\>>> x\n 3\n\\>>> [x for x in []]\n[]\n\\>>> x\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'x' is not defined</pre>\n这里说明python的list comprehension没有定义作用域\n\nerlang与这些语言的重要区别是, 它们都有Fortran式的可变变量, 而erlang是变量单次赋值\n\n## case是否是一个scope? \ncase从来也不是一个scope, 在erlang里不是, 在c里(包括if, switch, while, do, for)也不是, c里只有花括号会引入scope\n\n下面这段编译不过(会报variable 'Value' unsafe in 'case'), \n```erlang\nfoo(Dict) ->\n    Value = case orddict:find(foo, Dict) of\n        {ok, Value} -> Value;\n        error -> calculate_very_expensive_default_value()\n    end,\n    ...\n```\n在任何一个变量被使用的地方, \n所以能到达该处的路径上该变量必须绑定一次且只能绑定一次(bind once and only once原则)\n否则会被认为'unsafe'\n这也是因为case不是一个scope, 所以里面的Value还是取一个别的名吧\n\n## 关于warn_export_vars警告\n\n先看这段代码:\n```erlang\nfoo() ->\n    ...\n    V1 = case bar() of\n        {ok, Bar} ->\n            Bar;\n        {error, Reason} ->\n            lager:error(\"SOS ~p\", [Reason]),\n            BarDefault\n    end,\n    V2 = case baz() of\n        {ok, Baz} ->\n            Baz;\n        {error, Reason} ->\n            lager:error(\"SOS ~p\", [Reason]),\n            BazDefault\n    end,\n    ...\n```\n这里两个Reason就匹配上了, 有时就会报badmatch崩掉\nerlang里变量名相同的地方会自动match, 这点太容易出bug\n其实宁愿用when语句明确指定match, Haskell就没有这个问题, 都是明确比较的, 而不像erlang名字相同就会自动match,\n确实经常出bug(有用的情形基本上只有binary pattern, 因为长度信息经常有用)\n\n再看这段代码:\n```erlang\n-module(test).\n-export([test/1]).\ntest(Mode) ->\n    case Mode of\n        r -> {ok, FP} = file:open(\"warn.erl\", [read]);\n        w -> {ok, FP} = file:open(\"warn.erl\", [write])\n    end,\n    file:close(FP).\n```\n会报如下警告:\n<pre>compile:file(\"test.erl\", [report, warn_export_vars]).\ntest.erl:8: Warning: variable 'FP' exported from 'case' (line 4)</pre>\n由于case没有独立的作用域(可能有人以为有), \n所以为了提示潜在的风险, 比如后续代码中相同变量名的匹配, 有了这个warning\n\n另外, 不要为了消除警告而把这种:\n```erlang\ncase foo(...) of \n    {bar,X,Y} -> ...; \n    {ugh,Y,X} -> ...\nend,\nuse(X, Y)\n```\n改成这种:\n```erlang\n{X,Y} = \ncase foo(...) of \n    {bar,X1,Y1} -> ..., {X1,Y1}; \n    {ugh,Y2,X2} -> ..., {X2,Y2}\nend,\nuse(X, Y)\n```\n命名更恶心,也更容易出问题\n\n另外, 虽然第一段较好, 但是后面再用X,Y的话也会有匹配问题, 所以还是把这段抽成一个函数吧\n```erlang\nfoo({bar,X,Y}) -> bar_related_thing({X,Y});\nfoo({ugh,X,Y}) -> ugh_related_thing({X,Y}).\n```\n当一个函数分句中出现多次case且其分支内变量命名都类似的时候, 意味着你应当把这些case抽象成独立的函数\n可读性好, 可复用性好, 还可以加type声明做type检查等, 比较符合erlang的哲学\n\n## 参考链接\nhttp://www.erlang.org/doc/man/compile.html\nhttp://erlang.org/pipermail/erlang-questions/2015-October/086252.html\nhttp://erlang.org/pipermail/erlang-questions/2014-March/078017.html\n\n","source":"_posts/erlang_scope.md","raw":"title: 关于erlang作用域\ndate: 2015-12-29\ntags: [erlang]\n---\n\n以下三种情况定义一个作用域:\n* 函数分句\n* fun\n* list comprehension\n<!--more-->\n\n## fun和list comprehension\n\nErlang一开始只有函数分句会定义作用域\nErlang里仅有的嵌套作用域只有后来的fun和list comprehension\n\nlist comprehension里引入的变量在执行期间可能被绑定0次(即未绑定)或多次\n所以加了独立作用域, 如果不加独立作用域的话, 里面的变量在外面也没法用(因为可能未绑定)\n外面也不能重新定义这个变量名(因为可能已经绑定了), 所以还是加个独立作用域的好\n\nfun也是相同的道理, 定义了一个fun之后这个fun可能没有被调用, 也可能被调用多次\n\n## list comprehension\n\n在javascript, ruby, python这样的语言中, list comprehension更像一个做过性能优化的for循环,\n例如Python:\n<pre>\\>>> [x for x in [1,2,3]]\n [1, 2, 3]\n\\>>> x\n 3\n\\>>> [x for x in []]\n[]\n\\>>> x\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'x' is not defined</pre>\n这里说明python的list comprehension没有定义作用域\n\nerlang与这些语言的重要区别是, 它们都有Fortran式的可变变量, 而erlang是变量单次赋值\n\n## case是否是一个scope? \ncase从来也不是一个scope, 在erlang里不是, 在c里(包括if, switch, while, do, for)也不是, c里只有花括号会引入scope\n\n下面这段编译不过(会报variable 'Value' unsafe in 'case'), \n```erlang\nfoo(Dict) ->\n    Value = case orddict:find(foo, Dict) of\n        {ok, Value} -> Value;\n        error -> calculate_very_expensive_default_value()\n    end,\n    ...\n```\n在任何一个变量被使用的地方, \n所以能到达该处的路径上该变量必须绑定一次且只能绑定一次(bind once and only once原则)\n否则会被认为'unsafe'\n这也是因为case不是一个scope, 所以里面的Value还是取一个别的名吧\n\n## 关于warn_export_vars警告\n\n先看这段代码:\n```erlang\nfoo() ->\n    ...\n    V1 = case bar() of\n        {ok, Bar} ->\n            Bar;\n        {error, Reason} ->\n            lager:error(\"SOS ~p\", [Reason]),\n            BarDefault\n    end,\n    V2 = case baz() of\n        {ok, Baz} ->\n            Baz;\n        {error, Reason} ->\n            lager:error(\"SOS ~p\", [Reason]),\n            BazDefault\n    end,\n    ...\n```\n这里两个Reason就匹配上了, 有时就会报badmatch崩掉\nerlang里变量名相同的地方会自动match, 这点太容易出bug\n其实宁愿用when语句明确指定match, Haskell就没有这个问题, 都是明确比较的, 而不像erlang名字相同就会自动match,\n确实经常出bug(有用的情形基本上只有binary pattern, 因为长度信息经常有用)\n\n再看这段代码:\n```erlang\n-module(test).\n-export([test/1]).\ntest(Mode) ->\n    case Mode of\n        r -> {ok, FP} = file:open(\"warn.erl\", [read]);\n        w -> {ok, FP} = file:open(\"warn.erl\", [write])\n    end,\n    file:close(FP).\n```\n会报如下警告:\n<pre>compile:file(\"test.erl\", [report, warn_export_vars]).\ntest.erl:8: Warning: variable 'FP' exported from 'case' (line 4)</pre>\n由于case没有独立的作用域(可能有人以为有), \n所以为了提示潜在的风险, 比如后续代码中相同变量名的匹配, 有了这个warning\n\n另外, 不要为了消除警告而把这种:\n```erlang\ncase foo(...) of \n    {bar,X,Y} -> ...; \n    {ugh,Y,X} -> ...\nend,\nuse(X, Y)\n```\n改成这种:\n```erlang\n{X,Y} = \ncase foo(...) of \n    {bar,X1,Y1} -> ..., {X1,Y1}; \n    {ugh,Y2,X2} -> ..., {X2,Y2}\nend,\nuse(X, Y)\n```\n命名更恶心,也更容易出问题\n\n另外, 虽然第一段较好, 但是后面再用X,Y的话也会有匹配问题, 所以还是把这段抽成一个函数吧\n```erlang\nfoo({bar,X,Y}) -> bar_related_thing({X,Y});\nfoo({ugh,X,Y}) -> ugh_related_thing({X,Y}).\n```\n当一个函数分句中出现多次case且其分支内变量命名都类似的时候, 意味着你应当把这些case抽象成独立的函数\n可读性好, 可复用性好, 还可以加type声明做type检查等, 比较符合erlang的哲学\n\n## 参考链接\nhttp://www.erlang.org/doc/man/compile.html\nhttp://erlang.org/pipermail/erlang-questions/2015-October/086252.html\nhttp://erlang.org/pipermail/erlang-questions/2014-March/078017.html\n\n","slug":"erlang_scope","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ln006dmcxq2z118k3i"},{"title":"erlang socket","date":"2016-06-28T08:35:00.000Z","_content":"\n### controlling process死了以后, port会回收吗? 不回收的话会有内存泄漏吗?\n根据下面链接的话\nhttps://mitnk.com/wiki/2012/05/programming_with_sockets_in_erlang/\n\n> If the controlling process dies, then the socket will be automatically closed.\n\n有空可以看看代码\n\n","source":"_posts/erlang_socket.md","raw":"title: erlang socket\ndate: 2016-06-28 16:35:00\ntags: erlang\n---\n\n### controlling process死了以后, port会回收吗? 不回收的话会有内存泄漏吗?\n根据下面链接的话\nhttps://mitnk.com/wiki/2012/05/programming_with_sockets_in_erlang/\n\n> If the controlling process dies, then the socket will be automatically closed.\n\n有空可以看看代码\n\n","slug":"erlang_socket","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5lp006gmcxq9y2t2h99"},{"title":"vim erlang tags","date":"2015-10-08T16:00:00.000Z","_content":"\n## 安装\n使用vundle\n在.vimrc中加入\n```\nPlugin 'vim-erlang/vim-erlang-tags' \n```\n\n## 生成tags\n在vim中执行`:ErlangTags`即可\n在当前目录会生成一个tags文件,其中包含了关键单词与位置的对应关系,如下\n> \\#player ./include/player.hrl    /^-\\s\\*record\\s\\*(\\s\\*player\\>/;\"   r\n\n## 生成tags时忽略指定目录\n编辑vimrc, 加入\n```\n\" 使ErlangTags不包含_rel目录里的文件                                             \nlet g:erlang_tags_ignore=[\"_rel\", \"ebin\"]\n```\n\n## 参考链接\nhttps://github.com/vim-erlang/vim-erlang-tags\n","source":"_posts/erlang_tags.md","raw":"title: vim erlang tags\ndate: 2015-10-09\ntags: [erlang, vim]\n---\n\n## 安装\n使用vundle\n在.vimrc中加入\n```\nPlugin 'vim-erlang/vim-erlang-tags' \n```\n\n## 生成tags\n在vim中执行`:ErlangTags`即可\n在当前目录会生成一个tags文件,其中包含了关键单词与位置的对应关系,如下\n> \\#player ./include/player.hrl    /^-\\s\\*record\\s\\*(\\s\\*player\\>/;\"   r\n\n## 生成tags时忽略指定目录\n编辑vimrc, 加入\n```\n\" 使ErlangTags不包含_rel目录里的文件                                             \nlet g:erlang_tags_ignore=[\"_rel\", \"ebin\"]\n```\n\n## 参考链接\nhttps://github.com/vim-erlang/vim-erlang-tags\n","slug":"erlang_tags","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5lq006imcxq4vejxd0a"},{"title":"erlang点滴","date":"2018-05-31T16:00:00.000Z","_content":"这里记录一些点滴知识\n<!--more-->\n\n### PROGRESS REPORT 这种日志怎么关掉\n\nsys.config里加上如下内容\n```\n    {sasl, [\n        {errlog_type, error}\n    ]}\n```\n\n","source":"_posts/erlang_sediment.md","raw":"title: erlang点滴\ndate: 2018-06-01\ntags: [erlang]\n---\n这里记录一些点滴知识\n<!--more-->\n\n### PROGRESS REPORT 这种日志怎么关掉\n\nsys.config里加上如下内容\n```\n    {sasl, [\n        {errlog_type, error}\n    ]}\n```\n\n","slug":"erlang_sediment","published":1,"updated":"2018-06-01T08:35:48.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5lr006lmcxqs5w45ast"},{"title":"erlang体会","date":"2015-10-26T16:00:00.000Z","_content":"\n## 如何保证进程间沟通成功\n信息总是滞后的,就连我们看见的星光,也都是N年前发出来的,\n进程之间通讯同样不能保证对方立即收到,即使立即收到也未必立即处理,..\n这是宇宙的真实模型,只要找到合理的处理方式,一定不会错\n\n### call\n相当于cast之后用receive语句加monitor选择性接收应答消息,\n使用服务的进程可以call提供服务的进程,反过来则不推荐\n\n### cast\n异步发送,可能发的时候对方处于terminate中,虽然进程还活着却不会再处理后面的消息了\n如何应对这种情况?\n1,terminate那里做保障,比如清状态,通知服务方...\n2,下次上线时主动请求当前状态并给反馈或从一个全局的地方取数据\n\n","source":"_posts/erlang_taste.md","raw":"title: erlang体会\ndate: 2015-10-27\ntags: [erlang]\n---\n\n## 如何保证进程间沟通成功\n信息总是滞后的,就连我们看见的星光,也都是N年前发出来的,\n进程之间通讯同样不能保证对方立即收到,即使立即收到也未必立即处理,..\n这是宇宙的真实模型,只要找到合理的处理方式,一定不会错\n\n### call\n相当于cast之后用receive语句加monitor选择性接收应答消息,\n使用服务的进程可以call提供服务的进程,反过来则不推荐\n\n### cast\n异步发送,可能发的时候对方处于terminate中,虽然进程还活着却不会再处理后面的消息了\n如何应对这种情况?\n1,terminate那里做保障,比如清状态,通知服务方...\n2,下次上线时主动请求当前状态并给反馈或从一个全局的地方取数据\n\n","slug":"erlang_taste","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ls006nmcxqes3tazhg"},{"title":"erlang time","date":"2015-09-09T16:00:00.000Z","_content":"erlang 18.0重新实现了time相关功能,性能更好,可伸缩性更好,精度更好\n<!--more-->\n## 取系统时间\n使用erlang:system_time/1取当前系统时间,可能按自己想要的单位取\n使用erlang:timestamp/0可以得到与erlang:now/0相同格式的返回值\n\n## 计算时间差\n使用erlang:monotonic_time/0取时间戳,并用普通减法取差值,结果是native的时间单位,\n可以使用erlang:convert_time_unit/3转换成想要的时间单位\n也可以使用erlang:monotonic_time/1取想要的时间单位并取差值,但是这样会损失精度\n\n## 确定事件发生的顺序\n各事件发生时保存erlang:unique_integer([monotonic])的返回值,\n以此确定事件发生的顺序\n更精确的话可以这样\n```erlang\nTime = erlang:monotonic_time(),\nUMI = erlang:unique_integer([monotonic]),\nEventTag = {Time, UMI}\n```\n如果需要知道事件发生的时间点,可以在元组最后再附加erlang:time_offset/0,\nErlang monotonic time加上time offset就是Erlang系统时间\n\n## 生成一个当前运行时内的唯一值\n使用erlang:unique_integer/0,\n使用erlang:unique_integer([positive])得到正数.\n\n## 生成一个随机值给随机数做seed\n使用erlang:monotonic_time(), erlang:time_offset(), erlang:unique_integer()的组合做seed\n\n## time correction和time warp mode的命令行参数\n```\nerl +c [true|false]\nerl +C [no_time_warp|single_time_warp|multi_time_warp]\n```\n\n## 监控系统时间跳变\nerlang:monitor(time_offset, clock_service).\n当time offset变化时, 监控的进程会收到如下消息:\n{'CHANGE', MonitorReference, time_offset, clock_service, NewTimeOffset}\n\n","source":"_posts/erlang_time.md","raw":"title: erlang time \ndate: 2015-09-10\ntags: [erlang]\n---\nerlang 18.0重新实现了time相关功能,性能更好,可伸缩性更好,精度更好\n<!--more-->\n## 取系统时间\n使用erlang:system_time/1取当前系统时间,可能按自己想要的单位取\n使用erlang:timestamp/0可以得到与erlang:now/0相同格式的返回值\n\n## 计算时间差\n使用erlang:monotonic_time/0取时间戳,并用普通减法取差值,结果是native的时间单位,\n可以使用erlang:convert_time_unit/3转换成想要的时间单位\n也可以使用erlang:monotonic_time/1取想要的时间单位并取差值,但是这样会损失精度\n\n## 确定事件发生的顺序\n各事件发生时保存erlang:unique_integer([monotonic])的返回值,\n以此确定事件发生的顺序\n更精确的话可以这样\n```erlang\nTime = erlang:monotonic_time(),\nUMI = erlang:unique_integer([monotonic]),\nEventTag = {Time, UMI}\n```\n如果需要知道事件发生的时间点,可以在元组最后再附加erlang:time_offset/0,\nErlang monotonic time加上time offset就是Erlang系统时间\n\n## 生成一个当前运行时内的唯一值\n使用erlang:unique_integer/0,\n使用erlang:unique_integer([positive])得到正数.\n\n## 生成一个随机值给随机数做seed\n使用erlang:monotonic_time(), erlang:time_offset(), erlang:unique_integer()的组合做seed\n\n## time correction和time warp mode的命令行参数\n```\nerl +c [true|false]\nerl +C [no_time_warp|single_time_warp|multi_time_warp]\n```\n\n## 监控系统时间跳变\nerlang:monitor(time_offset, clock_service).\n当time offset变化时, 监控的进程会收到如下消息:\n{'CHANGE', MonitorReference, time_offset, clock_service, NewTimeOffset}\n\n","slug":"erlang_time","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5lv006qmcxq2ebyn7yy"},{"title":"erlang tips","date":"2015-09-05T16:00:00.000Z","_content":"零碎的erlang知识\n<!--more-->\n## 关于erlang guard里的,号和;号的注意点\nguard分三级,\n第一级guard sequence, 由;号分隔,第一段guard sequence崩了还会执行第二段guard sequence,成功的话也算匹配成功\n第二级guard, 由,号分隔,是且的关系\n第三级guard expression, 内部可以有各种运算符包括andalso,orelse等,这里的orelse里如果崩了的话,orelse的后半段不会执行了\n\n## 用Fun写递归函数\n```erlang\nFn = fun(F)->\n    receive\n        {echo, Msg} ->\n            io:format(\"~p received.~n\",[Msg]), \n            F(F);\n        stop -> stop \n    end\nend.\n```\n调用时: Fn(Fn).\n\n另一个例子:\n```erlang\nFn = fun(F, X, Y) when Y < 10000 -> F(F, Y, X+Y); (F,X,Y)-> done end.\n```\n调用时: Fn(Fn, 1, 1).\n\nerlang 17.0以后有了命名fun之后就不必这么麻烦地把自己做为参数传给自己了\n\n## 几种函数调用方式之间的性能差异\nfun包含或者间接包含了实现了该方法的指针调用不涉及hash-table的查询,\napply/3必须要在HashTable中查找funtion对应的Code实现，所以通常比直接调用或者fun调用速度要慢.\n另外, 在参数个数确定的时候, apply/3的调用会在编译时被优化为m:f(a)形式的external function call.\n例如:\n\n```erlang\na() ->\n    M=erlang,\n    F=now,\n    apply(M,F,[]).\n\nb(M,F,A) ->\n    apply(M,F,A).\n\nc(M,F) ->\n    apply(M,F,[a,b,c]).\n\nd(M)->\n    apply(M,do_something,[]).\n```\n\n添加to_core参数,看一下编译出来的Core Erlang代码:\n```\n'a'/0 =\n    fun () ->\n        call 'erlang':'now'()\n'b'/3 =\n    fun (_cor2,_cor1,_cor0) ->\n        call 'erlang':'apply'(_cor2, _cor1, _cor0)\n'c'/2 =\n    fun (_cor1,_cor0) ->\n        call _cor1:_cor0('a', 'b', 'c')\n'd'/1 =\n    fun (_cor0) ->\n        call _cor0:'do_something'()\n```\n\n## 根据ets表名获取ets表id,可用但是繁琐一点\n```erlang\nfun(Name) -> [ID || ID <- ets:all(), Name == ets:info(ID,name)] end.\n```\n\n## erlang io重定向 \n如想要把shell里通过io:format输出的内容(比如m()命令返回的已加载模块列表)重定向到文件时,\n用group_leader/2函数重定向到file:open返回的port上\n\n## 传入一段代码,可以得到AST,可用于分析erlang\n```erlang\n> E = fun(Code)-> {_,Tokens,_}=erl_scan:string(Code),rp(erl_parse:parse_exprs(Tokens)) end.\n> E(\"[Item || Item<- [1,2,3,4],Item>2 ].\").\n{ok,[{lc,1,\n    {var,1,'Item'},\n    [{generate,1,\n        {var,1,'Item'},\n        {cons,1,\n            {integer,1,1},\n            {cons,1,\n                {integer,1,2},\n                {cons,1,{integer,1,3},{cons,1,{integer,1,4},{nil,1}}}}}},\n    {op,1,'>',{var,1,'Item'},{integer,1,2}}]}]}\n    ok\n```\n\n## 手动产生crashdump文件的方法\n如下：\n1. erlang:halt(“abort”).\n2. 在erlang shell下输入CTRL C + “大写的A”\n\n## supervior里permanent和transient的区别\nnormal退出的时候permanent会重启而transient不重启？\n\n## erlang bootscript\nerl -boot start_clean(默认)\nerl -boot start_sasl\n\n## 配置sasl的日志\nerl -boot start_sasl -config elog\n\nelog.config\n%% rotating log and errors\n[{sasl, [\n    %% minimise shell error logging\n    {sasl_error_logger, false},\n        %% only report errors\n        {errlog_type, error},\n        %% define the parameters of the rotating log\n        %% the log file directory\n        {error_logger_mf_dir,\"/Users/joe/error_logs\"},\n        %% # bytes per logfile\n        {error_logger_mf_maxbytes,10485760}, % 10 MB\n    %% maximum number of\n    {error_logger_mf_maxfiles, 10}\n    ]}].\n\n## 查erlang安装信息\nerl -version\n\n## 使用user_default加载record定义\nuser_default必须要带debug_info编译\n\n## 根据Pid查注册名\nprocess_info(Pid, registered_name)\n\n## erlang 18 里日志文件可以设为append, 15B不行\n```bash\nerl -sasl sasl_error_logger \\{file,\\\"haha\\\",[append]\\}\n```\n\n## format_error函数\n许多模块都有format_error函数,可以传入其他函数返回的error代码得到详细信息\n\n","source":"_posts/erlang_tips.md","raw":"title: erlang tips\ndate: 2015-09-06\ntags: erlang\n---\n零碎的erlang知识\n<!--more-->\n## 关于erlang guard里的,号和;号的注意点\nguard分三级,\n第一级guard sequence, 由;号分隔,第一段guard sequence崩了还会执行第二段guard sequence,成功的话也算匹配成功\n第二级guard, 由,号分隔,是且的关系\n第三级guard expression, 内部可以有各种运算符包括andalso,orelse等,这里的orelse里如果崩了的话,orelse的后半段不会执行了\n\n## 用Fun写递归函数\n```erlang\nFn = fun(F)->\n    receive\n        {echo, Msg} ->\n            io:format(\"~p received.~n\",[Msg]), \n            F(F);\n        stop -> stop \n    end\nend.\n```\n调用时: Fn(Fn).\n\n另一个例子:\n```erlang\nFn = fun(F, X, Y) when Y < 10000 -> F(F, Y, X+Y); (F,X,Y)-> done end.\n```\n调用时: Fn(Fn, 1, 1).\n\nerlang 17.0以后有了命名fun之后就不必这么麻烦地把自己做为参数传给自己了\n\n## 几种函数调用方式之间的性能差异\nfun包含或者间接包含了实现了该方法的指针调用不涉及hash-table的查询,\napply/3必须要在HashTable中查找funtion对应的Code实现，所以通常比直接调用或者fun调用速度要慢.\n另外, 在参数个数确定的时候, apply/3的调用会在编译时被优化为m:f(a)形式的external function call.\n例如:\n\n```erlang\na() ->\n    M=erlang,\n    F=now,\n    apply(M,F,[]).\n\nb(M,F,A) ->\n    apply(M,F,A).\n\nc(M,F) ->\n    apply(M,F,[a,b,c]).\n\nd(M)->\n    apply(M,do_something,[]).\n```\n\n添加to_core参数,看一下编译出来的Core Erlang代码:\n```\n'a'/0 =\n    fun () ->\n        call 'erlang':'now'()\n'b'/3 =\n    fun (_cor2,_cor1,_cor0) ->\n        call 'erlang':'apply'(_cor2, _cor1, _cor0)\n'c'/2 =\n    fun (_cor1,_cor0) ->\n        call _cor1:_cor0('a', 'b', 'c')\n'd'/1 =\n    fun (_cor0) ->\n        call _cor0:'do_something'()\n```\n\n## 根据ets表名获取ets表id,可用但是繁琐一点\n```erlang\nfun(Name) -> [ID || ID <- ets:all(), Name == ets:info(ID,name)] end.\n```\n\n## erlang io重定向 \n如想要把shell里通过io:format输出的内容(比如m()命令返回的已加载模块列表)重定向到文件时,\n用group_leader/2函数重定向到file:open返回的port上\n\n## 传入一段代码,可以得到AST,可用于分析erlang\n```erlang\n> E = fun(Code)-> {_,Tokens,_}=erl_scan:string(Code),rp(erl_parse:parse_exprs(Tokens)) end.\n> E(\"[Item || Item<- [1,2,3,4],Item>2 ].\").\n{ok,[{lc,1,\n    {var,1,'Item'},\n    [{generate,1,\n        {var,1,'Item'},\n        {cons,1,\n            {integer,1,1},\n            {cons,1,\n                {integer,1,2},\n                {cons,1,{integer,1,3},{cons,1,{integer,1,4},{nil,1}}}}}},\n    {op,1,'>',{var,1,'Item'},{integer,1,2}}]}]}\n    ok\n```\n\n## 手动产生crashdump文件的方法\n如下：\n1. erlang:halt(“abort”).\n2. 在erlang shell下输入CTRL C + “大写的A”\n\n## supervior里permanent和transient的区别\nnormal退出的时候permanent会重启而transient不重启？\n\n## erlang bootscript\nerl -boot start_clean(默认)\nerl -boot start_sasl\n\n## 配置sasl的日志\nerl -boot start_sasl -config elog\n\nelog.config\n%% rotating log and errors\n[{sasl, [\n    %% minimise shell error logging\n    {sasl_error_logger, false},\n        %% only report errors\n        {errlog_type, error},\n        %% define the parameters of the rotating log\n        %% the log file directory\n        {error_logger_mf_dir,\"/Users/joe/error_logs\"},\n        %% # bytes per logfile\n        {error_logger_mf_maxbytes,10485760}, % 10 MB\n    %% maximum number of\n    {error_logger_mf_maxfiles, 10}\n    ]}].\n\n## 查erlang安装信息\nerl -version\n\n## 使用user_default加载record定义\nuser_default必须要带debug_info编译\n\n## 根据Pid查注册名\nprocess_info(Pid, registered_name)\n\n## erlang 18 里日志文件可以设为append, 15B不行\n```bash\nerl -sasl sasl_error_logger \\{file,\\\"haha\\\",[append]\\}\n```\n\n## format_error函数\n许多模块都有format_error函数,可以传入其他函数返回的error代码得到详细信息\n\n","slug":"erlang_tips","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5lw006smcxqwtvws60v"},{"title":"erlang inet&tcp","date":"2020-04-24T16:00:00.000Z","_content":"## gen_tcp:shutdown\n函数配合{exit_on_close, false}选项可以实现tcp半开的效果\n\n## inet_db:lookup_socket\n可以获取socket对应的模块\n> {ok, S} = gen_tcp:listen(10000, []).\n{ok,#Port<0.4423655>}\n> inet_db:lookup_socket(S).\n{ok,inet_tcp}\n> {ok, S2} = gen_udp:open(10001).\n{ok,#Port<0.4429431>}\n> inet_db:lookup_socket(S2).\n{ok,inet_udp}\n\n## inet_db:register_socket\n下面这种做法没有直接调用gen_tcp:accept而是伪装成使用了gen_tcp:accept\n\n> gen_tcp:accept里面也就只是调了lookup_socket和register_socket\n> % patch up the socket so it looks like one we got from\n> % gen_tcp:accept/1\n> {ok, Mod} = inet_db:lookup_socket(LSock),\n> % 内部调用erlang:port_set_data记录信息\n> inet_db:register_socket(Sock, Mod),\n\n## inet:getaddr\n检查是否支持ipv6\n> inet:getaddr(\"localhost\", inet).\n{ok,{127,0,0,1}}\n> inet:getaddr(\"localhost\", inet6).\n{error,nxdomain}\n\n## inet_parse:address\n> inet_parse:address(\"192.168.1.1\").\n{ok,{192,168,1,1}}\n\n## inet:sockname\n## inet:peername\n\n## inet_parse:ntoa\n> inet_parse:ntoa({192,168,1,113}).\n\"192.168.1.113\"\n\n## inet:getstat\n查socket的状态\n\n## inet:getif\n```\n{ok,[{{172,17,42,1},{0,0,0,0},{255,255,0,0}},\n    {{172,16,205,1},{172,16,205,255},{255,255,255,0}},\n    {{192,168,117,1},{192,168,117,255},{255,255,255,0}},\n    {{192,168,1,114},{192,168,1,255},{255,255,255,0}},\n    {{127,0,0,1},{0,0,0,0},{255,0,0,0}}]}\n```\n\n## 如何检查当前环境下的 sndbuf, recbuf, buffer 这些参数的默认值\nOSX sysctl\n```\nsysctl -a | grep space\nnet.local.stream.sendspace: 8192\nnet.local.stream.recvspace: 8192\nnet.local.dgram.recvspace: 4096\nnet.inet.tcp.sendspace: 131072\nnet.inet.tcp.recvspace: 131072\nnet.inet.udp.recvspace: 786896\nnet.inet.raw.recvspace: 8192\nnet.stats.sendspace: 2048\nnet.stats.recvspace: 8192\n```\nOSX default\n```\nErlang/OTP 22 [erts-10.7] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]\n\nEshell V10.7  (abort with ^G)\n1> {ok, LSock} = gen_tcp:listen(12345, []).\n{ok,#Port<0.5>}\n2> spawn(fun() -> {ok, Sock} = gen_tcp:accept(LSock), io:format(\"~p\", [inet:getopts(Sock, [recbuf, sndbuf, buffer])]), receive _ -> ok end end).\n<0.86.0>\n3> inet:getopts(LSock, [recbuf, sndbuf, buffer]).\n{ok,[{recbuf,131072},{sndbuf,131072},{buffer,1460}]}\n4> {ok, S} = gen_tcp:connect(\"127.0.0.1\", 12345, []).\n{ok,#Port<0.7>}\n{ok,[{recbuf,408300},{sndbuf,146988},{buffer,1460}]}\n5> inet:getopts(S, [recbuf, sndbuf, buffer]).\n{ok,[{recbuf,408300},{sndbuf,146988},{buffer,1460}]}\n```\nOSX 4096\n```\nErlang/OTP 22 [erts-10.7] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]\n\nEshell V10.7  (abort with ^G)\n1> {ok, LSock} = gen_tcp:listen(12345, [{sndbuf, 4096}, {recbuf, 4096}]).\n{ok,#Port<0.5>}\n2> spawn(fun() -> {ok, Sock} = gen_tcp:accept(LSock), io:format(\"~p\", [inet:getopts(Sock, [recbuf, sndbuf, buffer])]), receive _ -> ok end end).\n<0.86.0>\n3> inet:getopts(LSock, [recbuf, sndbuf, buffer]).\n{ok,[{recbuf,4096},{sndbuf,4096},{buffer,4096}]}\n4> {ok, S} = gen_tcp:connect(\"127.0.0.1\", 12345, [{sndbuf, 4096}, {recbuf, 4096}]).\n{ok,#Port<0.7>}\n{ok,[{recbuf,326640},{sndbuf,65328},{buffer,4096}]}\n5> inet:getopts(S, [recbuf, sndbuf, buffer]).\n{ok,[{recbuf,326640},{sndbuf,65328},{buffer,4096}]}\n```\nUbuntu\n```\n# cat /proc/sys/net/ipv4/tcp_rmem\n4096    131072  6291456\n# cat /proc/sys/net/ipv4/tcp_wmem\n4096    16384   4194304\n# cat /proc/sys/net/core/rmem_default\n212992\n# cat /proc/sys/net/core/wmem_default\n212992\n```\nUbuntu default\n```\nErlang/OTP 22 [erts-10.7] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]\n\nEshell V10.7  (abort with ^G)\n1> {ok, LSock} = gen_tcp:listen(12345, []).\n{ok,#Port<0.6>}\n2> spawn(fun() -> {ok, Sock} = gen_tcp:accept(LSock), io:format(\"~p\", [inet:getopts(Sock, [recbuf, sndbuf, buffer])]), receive _ -> okend end).\n<0.83.0>\n3> inet:getopts(LSock, [recbuf, sndbuf, buffer]).\n{ok,[{recbuf,131072},{sndbuf,16384},{buffer,1460}]}\n4> {ok, S} = gen_tcp:connect(\"127.0.0.1\", 12345, []).\n{ok,#Port<0.8>}\n{ok,[{recbuf,131072},{sndbuf,2626560},{buffer,1460}]}\n5> inet:getopts(S, [recbuf, sndbuf, buffer]).\n{ok,[{recbuf,131072},{sndbuf,2626560},{buffer,1460}]}\n```\nUbuntu 4096\n```\nErlang/OTP 22 [erts-10.7] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]\n\nEshell V10.7  (abort with ^G)\n1> {ok, LSock} = gen_tcp:listen(12345, [{recbuf,4096},{sndbuf,4096}]).\n{ok,#Port<0.6>}\n2> spawn(fun() -> {ok, Sock} = gen_tcp:accept(LSock), io:format(\"~p\", [inet:getopts(Sock, [recbuf, sndbuf, buffer])]), receive _ -> okend end).\n<0.83.0>\n3> inet:getopts(LSock, [recbuf, sndbuf, buffer]).\n{ok,[{recbuf,8192},{sndbuf,8192},{buffer,4096}]}\n4> {ok, S} = gen_tcp:connect(\"127.0.0.1\", 12345, [{recbuf,4096},{sndbuf,4096}]).\n{ok,#Port<0.8>}\n{ok,[{recbuf,8192},{sndbuf,8192},{buffer,4096}]}\n5> inet:getopts(S, [recbuf, sndbuf, buffer]).\n{ok,[{recbuf,8192},{sndbuf,8192},{buffer,4096}]}\n```\n\n","source":"_posts/erlang_tcp.md","raw":"title: erlang inet&tcp\ndate: 2020-04-25\n\ntags: [erlang, tcp]\n---\n## gen_tcp:shutdown\n函数配合{exit_on_close, false}选项可以实现tcp半开的效果\n\n## inet_db:lookup_socket\n可以获取socket对应的模块\n> {ok, S} = gen_tcp:listen(10000, []).\n{ok,#Port<0.4423655>}\n> inet_db:lookup_socket(S).\n{ok,inet_tcp}\n> {ok, S2} = gen_udp:open(10001).\n{ok,#Port<0.4429431>}\n> inet_db:lookup_socket(S2).\n{ok,inet_udp}\n\n## inet_db:register_socket\n下面这种做法没有直接调用gen_tcp:accept而是伪装成使用了gen_tcp:accept\n\n> gen_tcp:accept里面也就只是调了lookup_socket和register_socket\n> % patch up the socket so it looks like one we got from\n> % gen_tcp:accept/1\n> {ok, Mod} = inet_db:lookup_socket(LSock),\n> % 内部调用erlang:port_set_data记录信息\n> inet_db:register_socket(Sock, Mod),\n\n## inet:getaddr\n检查是否支持ipv6\n> inet:getaddr(\"localhost\", inet).\n{ok,{127,0,0,1}}\n> inet:getaddr(\"localhost\", inet6).\n{error,nxdomain}\n\n## inet_parse:address\n> inet_parse:address(\"192.168.1.1\").\n{ok,{192,168,1,1}}\n\n## inet:sockname\n## inet:peername\n\n## inet_parse:ntoa\n> inet_parse:ntoa({192,168,1,113}).\n\"192.168.1.113\"\n\n## inet:getstat\n查socket的状态\n\n## inet:getif\n```\n{ok,[{{172,17,42,1},{0,0,0,0},{255,255,0,0}},\n    {{172,16,205,1},{172,16,205,255},{255,255,255,0}},\n    {{192,168,117,1},{192,168,117,255},{255,255,255,0}},\n    {{192,168,1,114},{192,168,1,255},{255,255,255,0}},\n    {{127,0,0,1},{0,0,0,0},{255,0,0,0}}]}\n```\n\n## 如何检查当前环境下的 sndbuf, recbuf, buffer 这些参数的默认值\nOSX sysctl\n```\nsysctl -a | grep space\nnet.local.stream.sendspace: 8192\nnet.local.stream.recvspace: 8192\nnet.local.dgram.recvspace: 4096\nnet.inet.tcp.sendspace: 131072\nnet.inet.tcp.recvspace: 131072\nnet.inet.udp.recvspace: 786896\nnet.inet.raw.recvspace: 8192\nnet.stats.sendspace: 2048\nnet.stats.recvspace: 8192\n```\nOSX default\n```\nErlang/OTP 22 [erts-10.7] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]\n\nEshell V10.7  (abort with ^G)\n1> {ok, LSock} = gen_tcp:listen(12345, []).\n{ok,#Port<0.5>}\n2> spawn(fun() -> {ok, Sock} = gen_tcp:accept(LSock), io:format(\"~p\", [inet:getopts(Sock, [recbuf, sndbuf, buffer])]), receive _ -> ok end end).\n<0.86.0>\n3> inet:getopts(LSock, [recbuf, sndbuf, buffer]).\n{ok,[{recbuf,131072},{sndbuf,131072},{buffer,1460}]}\n4> {ok, S} = gen_tcp:connect(\"127.0.0.1\", 12345, []).\n{ok,#Port<0.7>}\n{ok,[{recbuf,408300},{sndbuf,146988},{buffer,1460}]}\n5> inet:getopts(S, [recbuf, sndbuf, buffer]).\n{ok,[{recbuf,408300},{sndbuf,146988},{buffer,1460}]}\n```\nOSX 4096\n```\nErlang/OTP 22 [erts-10.7] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]\n\nEshell V10.7  (abort with ^G)\n1> {ok, LSock} = gen_tcp:listen(12345, [{sndbuf, 4096}, {recbuf, 4096}]).\n{ok,#Port<0.5>}\n2> spawn(fun() -> {ok, Sock} = gen_tcp:accept(LSock), io:format(\"~p\", [inet:getopts(Sock, [recbuf, sndbuf, buffer])]), receive _ -> ok end end).\n<0.86.0>\n3> inet:getopts(LSock, [recbuf, sndbuf, buffer]).\n{ok,[{recbuf,4096},{sndbuf,4096},{buffer,4096}]}\n4> {ok, S} = gen_tcp:connect(\"127.0.0.1\", 12345, [{sndbuf, 4096}, {recbuf, 4096}]).\n{ok,#Port<0.7>}\n{ok,[{recbuf,326640},{sndbuf,65328},{buffer,4096}]}\n5> inet:getopts(S, [recbuf, sndbuf, buffer]).\n{ok,[{recbuf,326640},{sndbuf,65328},{buffer,4096}]}\n```\nUbuntu\n```\n# cat /proc/sys/net/ipv4/tcp_rmem\n4096    131072  6291456\n# cat /proc/sys/net/ipv4/tcp_wmem\n4096    16384   4194304\n# cat /proc/sys/net/core/rmem_default\n212992\n# cat /proc/sys/net/core/wmem_default\n212992\n```\nUbuntu default\n```\nErlang/OTP 22 [erts-10.7] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]\n\nEshell V10.7  (abort with ^G)\n1> {ok, LSock} = gen_tcp:listen(12345, []).\n{ok,#Port<0.6>}\n2> spawn(fun() -> {ok, Sock} = gen_tcp:accept(LSock), io:format(\"~p\", [inet:getopts(Sock, [recbuf, sndbuf, buffer])]), receive _ -> okend end).\n<0.83.0>\n3> inet:getopts(LSock, [recbuf, sndbuf, buffer]).\n{ok,[{recbuf,131072},{sndbuf,16384},{buffer,1460}]}\n4> {ok, S} = gen_tcp:connect(\"127.0.0.1\", 12345, []).\n{ok,#Port<0.8>}\n{ok,[{recbuf,131072},{sndbuf,2626560},{buffer,1460}]}\n5> inet:getopts(S, [recbuf, sndbuf, buffer]).\n{ok,[{recbuf,131072},{sndbuf,2626560},{buffer,1460}]}\n```\nUbuntu 4096\n```\nErlang/OTP 22 [erts-10.7] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]\n\nEshell V10.7  (abort with ^G)\n1> {ok, LSock} = gen_tcp:listen(12345, [{recbuf,4096},{sndbuf,4096}]).\n{ok,#Port<0.6>}\n2> spawn(fun() -> {ok, Sock} = gen_tcp:accept(LSock), io:format(\"~p\", [inet:getopts(Sock, [recbuf, sndbuf, buffer])]), receive _ -> okend end).\n<0.83.0>\n3> inet:getopts(LSock, [recbuf, sndbuf, buffer]).\n{ok,[{recbuf,8192},{sndbuf,8192},{buffer,4096}]}\n4> {ok, S} = gen_tcp:connect(\"127.0.0.1\", 12345, [{recbuf,4096},{sndbuf,4096}]).\n{ok,#Port<0.8>}\n{ok,[{recbuf,8192},{sndbuf,8192},{buffer,4096}]}\n5> inet:getopts(S, [recbuf, sndbuf, buffer]).\n{ok,[{recbuf,8192},{sndbuf,8192},{buffer,4096}]}\n```\n\n","slug":"erlang_tcp","published":1,"updated":"2021-06-13T16:12:41.350Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5lx006vmcxqu6kyfc3m"},{"title":"erlang unicode","date":"2015-09-07T16:00:00.000Z","_content":"## LANG & LC_CTYPE环境变量和encoding\n影响Erlang Shell,告诉终端程序是否要处理unicode\n> \\$ echo $LC_CTYPE\n> \n> \\$ echo $LANG\n> zh_CN.UTF-8\n\n如,下例中encoding是unicode:\n> Erlang R15B (erts-5.9) [source] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n> \n> Eshell V5.9  (abort with ^G)\n> 1> io:getopts().\n> [{expand_fun,#Fun<group.0.33302583>},\n>  {echo,true},\n>  {binary,false},\n>  {encoding,unicode}]\n\n改成latin1看看,显示都成乱码了:\n> LC_CTYPE=en_US.ISO-8859-1 /usr/local/bin/erl\n> Erlang R15B (erts-5.9) [source] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n> \n> Eshell V5.9  (abort with ^G)\n> 1> io:getopts().\n> [{expand_fun,#Fun<group.0.33302583>},\n>  {echo,true},\n>  {binary,false},\n>  {encoding,latin1}]\n> 2> \"\\346\\210\\221\\344\\273\\254\".\n> [230,136,145,228,187,172]\n> 3> io:format(\"~ts\",[lists:seq(20204,20220)]).\n> \\x{4EEC}\\x{4EED}\\x{4EEE}\\x{4EEF}\\x{4EF0}\\x{4EF1}\\x{4EF2}\\x{4EF3}\\x{4EF4}\\x{4EF5}\\x{4EF6}\\x{4EF7}\\x{4EF8}\\x{4EF9}\\x{4EFA}\\x{4EFB}\\x{4EFC}ok\n> 4> io:setopts([{encoding,unicode}]).\n> ok\n> 5> \"我们\".\n> [25105,20204]\n\n输入\"我们\"变成了\"\\346\\210\\221\\344\\273\\254\"\n\n## erl的参数: +pc \n选择Shell可打印字符的范围,可以是erl +pc latin1 或者  erl +pc unicode, 默认情况下,erl启动参数是latin1 \nio:printable_range/0返回可打印的字符集\nio_lib:printable_list/1判断一个List是否可打印\n> $ erl\n> Erlang/OTP 17 [erts-6.2] [source] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]\n> \n> Eshell V6.2  (abort with ^G)\n> 1> io:printable_range().\n> latin1\n> 2> io_lib:printable_list([25105]).\n> false\n> 3> unicode:characters_to_binary(\"我\").\n> <<230,136,145>>\n> 4> file:write_file(\"test\", [unicode:characters_to_binary(\"我\")]).\n> ok\n> 5> file:read_file(\"test\").\n> {ok,<<230,136,145>>}\n> 6> file:write_file(\"test\", [io_lib:format(\"~w.~n\", [unicode:characters_to_binary(\"我\")])]).\n> ok\n> 7> file:consult(\"test\").\n> {ok,[<<230,136,145>>]}\n\n> 17.0 +pc unicode情况下,unicode字符串可以正常显示如下\n> $ erl +pc unicode\n> Erlang/OTP 17 [erts-6.2] [source] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]\n> \n> Eshell V6.2  (abort with ^G)\n> 1> io:printable_range().\n> unicode\n> 2> io_lib:printable_list([25105]).\n> true\n> 3> <<230,136,145,228,187,172,229,173,166,228,185,160,69,114,108,97,110,103>>.\n> <<\"我们学习Erlang\"/utf8>>\n> 4> unicode:characters_to_binary(\"我\").\n> <<\"我\"/utf8>>\n> 5> file:write_file(\"test\", [unicode:characters_to_binary(\"我\")]).\n> ok\n> 6> file:read_file(\"test\").\n> {ok,<<\"我\"/utf8>>}\n> 7> file:write_file(\"test\", [io_lib:format(\"~w.~n\", [unicode:characters_to_binary(\"我\")])]).\n> ok\n> 8> file:consult(\"test\").\n> {ok,[<<\"我\"/utf8>>]}\n\n## epp:default_encoding/0\n返回的是当前OTP版本使用的默认编码方式.R16B是latin1, 17.0是utf8.\n> $ erl\n> Erlang/OTP 17 [erts-6.2] [source] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]\n> \n> Eshell V6.2  (abort with ^G)\n> 1> epp:default_encoding().\n> utf8\n\n文件注释头可以指定编译器使用某种编码来解析,如\n```\n%% -*- coding: utf-8 -*-\n%% -*- coding: latin-1 -*-\n```\n例如:\n```\n%% -*- coding: utf-8 -*-\n-module(test).\n-export([test/0]).\ntest() ->\n        [\"我\", <<\"我\"/utf8>>].     \n```\n> $ erl\n> Erlang/OTP 17 [erts-6.2] [source] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]\n> \n> Eshell V6.2  (abort with ^G)\n> 1> test:test().\n> [[25105],<<230,136,145>>]\n \n## 文件编码带来的差异\nR15B, erlang一律以latin-1编译代码,遇到中文都编译成这种,\n如test模块的函数:\n```\ndata() -> \"中国人\".\ndata2() -> <<\"中国人\">>.\n```\n运行时:\n> 1> test:data().\n> [228,184,173,229,155,189,228,186,186]\n> 2> test:data2().\n> <<228,184,173,229,155,189,228,186,186>>\n\n而erlang 17中,erlang一律默认以unicode编译代码(也可以在文件头指定),遇到中文都编译成这种,\n如test模块的函数:\n```\ndata() -> \"中国人\".\ndata2() -> <<\"中国人\"/utf8>>.  (注意这里需要加utf8类型)\n```\n运行时:\n> 1> test:data().\n> [20013,22269,20154]\n> 2> test:data2().\n> <<228,184,173,229,155,189,228,186,186>>\n\n而这里如果data2()没加utf8类型说明,即写成了这样\n```\ndata2() -> <<\"中国人\">>.\n```\n则会有问题:\n> 1> test:data2().\n> <<\"-ýº\">>\n> 2> io:format(\"~w\", [test:data2()]).\n> <<45,253,186>>ok\n\n或者写成了这样\n```\n%% -*- coding: latin-1 -*-\ndata2() -> <<\"中国人\"/utf8>>.\n```\n即utf8类型说明与latin-1文件编码说明冲突,则也会有问题:\n> 1> test:data2().\n> <<195,164,194,184,194,173,195,165,194,155,194,189,195,164,\n>   194,186,194,186>>\n> 2> io:format(\"~ts\", [v(2)]).\n> ä¸­å½äººok\n> 3> io:format(\"~s\", [v(2)]).\n> Ã¤Â¸Â­Ã¥ÂÂ½Ã¤ÂºÂºok\n\n所以以下这段问题代码\n```\n-module(t).\n-export([test/0]).\ntest() ->\n    [\"我\", <<\"我\">>].\n```\nR17编译后的运行结果为：\n> 1> t:test().\n> [[25105],<<17>>]\n\n字符串是字符串,binary是binary,\n字符串是这样的[25105, 25105, 97]\nbinary是这样的, <<230,136,145,230,136,145,97>>, 二进制这里面一个数字肯定是1个字节的, 要不不叫binary了\n\n<<\"我\">>相当于<<25105>>,而二进制一个数字需要是1个字节,所以截断变成<<17>>\n而加上utf8描述符后就不会被截断\n> <<\"我\"/utf8>>.\n<<230,136,145>>\n\n所以这里把代码改为\n```\n-module(t).\n-export([test/0]).\ntest() ->\n    [\"我\", <<\"我\"/utf8>>].\n```\n即可\n\n## 文件名解析\nerl启动的时候添加不同的flag可以控制解析文件名的方式: \n* +fnl 按照latin去解析文件名 \n* +fnu 按照unicode解析文件名 \n* +fna 是根据环境变量(LC_CTYPE)自动选择,这也是目前的系统默认值.\n\n可以使用file:native_name_encoding检查此参数.\n> $ erl\n> Erlang/OTP 17 [erts-6.2] [source] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]\n> \n> Eshell V6.2  (abort with ^G)\n> 1> file:native_name_encoding().\n> utf8\n> 2> file:read_file(\"test我.erl\").\n> {ok,<<45,109,111,100,117,108,101,40,39,116,101,115,116,230,136,145,39,41,46,32,10,45,101,120,112,111,114,...>>}\n\n+fnl后\n> $ erl +fnl\n> Erlang/OTP 17 [erts-6.2] [source] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]\n> \n> Eshell V6.2  (abort with ^G)\n> 1> file:native_name_encoding().\n> latin1\n> 2> file:read_file(\"test我.erl\").\n> {error,badarg}\n\n## 参考链接\n[Erlang User Conference 2013上patrik分享的BRING UNICODE TO ERLANG!视频](http://www.youtube.com/watch?v=M6hPLCA0F-Y)\n[PDF在这里](http://www.erlang-factory.com/upload/presentations/847/PatrikEUC2013.pdf)\n[官方文档](http://www.erlang.org/doc/apps/stdlib/unicode_usage.html)\n\n","source":"_posts/erlang_unicode.md","raw":"title: erlang unicode\ndate: 2015-09-08\ntags: erlang\n---\n## LANG & LC_CTYPE环境变量和encoding\n影响Erlang Shell,告诉终端程序是否要处理unicode\n> \\$ echo $LC_CTYPE\n> \n> \\$ echo $LANG\n> zh_CN.UTF-8\n\n如,下例中encoding是unicode:\n> Erlang R15B (erts-5.9) [source] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n> \n> Eshell V5.9  (abort with ^G)\n> 1> io:getopts().\n> [{expand_fun,#Fun<group.0.33302583>},\n>  {echo,true},\n>  {binary,false},\n>  {encoding,unicode}]\n\n改成latin1看看,显示都成乱码了:\n> LC_CTYPE=en_US.ISO-8859-1 /usr/local/bin/erl\n> Erlang R15B (erts-5.9) [source] [smp:4:4] [async-threads:0] [hipe] [kernel-poll:false]\n> \n> Eshell V5.9  (abort with ^G)\n> 1> io:getopts().\n> [{expand_fun,#Fun<group.0.33302583>},\n>  {echo,true},\n>  {binary,false},\n>  {encoding,latin1}]\n> 2> \"\\346\\210\\221\\344\\273\\254\".\n> [230,136,145,228,187,172]\n> 3> io:format(\"~ts\",[lists:seq(20204,20220)]).\n> \\x{4EEC}\\x{4EED}\\x{4EEE}\\x{4EEF}\\x{4EF0}\\x{4EF1}\\x{4EF2}\\x{4EF3}\\x{4EF4}\\x{4EF5}\\x{4EF6}\\x{4EF7}\\x{4EF8}\\x{4EF9}\\x{4EFA}\\x{4EFB}\\x{4EFC}ok\n> 4> io:setopts([{encoding,unicode}]).\n> ok\n> 5> \"我们\".\n> [25105,20204]\n\n输入\"我们\"变成了\"\\346\\210\\221\\344\\273\\254\"\n\n## erl的参数: +pc \n选择Shell可打印字符的范围,可以是erl +pc latin1 或者  erl +pc unicode, 默认情况下,erl启动参数是latin1 \nio:printable_range/0返回可打印的字符集\nio_lib:printable_list/1判断一个List是否可打印\n> $ erl\n> Erlang/OTP 17 [erts-6.2] [source] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]\n> \n> Eshell V6.2  (abort with ^G)\n> 1> io:printable_range().\n> latin1\n> 2> io_lib:printable_list([25105]).\n> false\n> 3> unicode:characters_to_binary(\"我\").\n> <<230,136,145>>\n> 4> file:write_file(\"test\", [unicode:characters_to_binary(\"我\")]).\n> ok\n> 5> file:read_file(\"test\").\n> {ok,<<230,136,145>>}\n> 6> file:write_file(\"test\", [io_lib:format(\"~w.~n\", [unicode:characters_to_binary(\"我\")])]).\n> ok\n> 7> file:consult(\"test\").\n> {ok,[<<230,136,145>>]}\n\n> 17.0 +pc unicode情况下,unicode字符串可以正常显示如下\n> $ erl +pc unicode\n> Erlang/OTP 17 [erts-6.2] [source] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]\n> \n> Eshell V6.2  (abort with ^G)\n> 1> io:printable_range().\n> unicode\n> 2> io_lib:printable_list([25105]).\n> true\n> 3> <<230,136,145,228,187,172,229,173,166,228,185,160,69,114,108,97,110,103>>.\n> <<\"我们学习Erlang\"/utf8>>\n> 4> unicode:characters_to_binary(\"我\").\n> <<\"我\"/utf8>>\n> 5> file:write_file(\"test\", [unicode:characters_to_binary(\"我\")]).\n> ok\n> 6> file:read_file(\"test\").\n> {ok,<<\"我\"/utf8>>}\n> 7> file:write_file(\"test\", [io_lib:format(\"~w.~n\", [unicode:characters_to_binary(\"我\")])]).\n> ok\n> 8> file:consult(\"test\").\n> {ok,[<<\"我\"/utf8>>]}\n\n## epp:default_encoding/0\n返回的是当前OTP版本使用的默认编码方式.R16B是latin1, 17.0是utf8.\n> $ erl\n> Erlang/OTP 17 [erts-6.2] [source] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]\n> \n> Eshell V6.2  (abort with ^G)\n> 1> epp:default_encoding().\n> utf8\n\n文件注释头可以指定编译器使用某种编码来解析,如\n```\n%% -*- coding: utf-8 -*-\n%% -*- coding: latin-1 -*-\n```\n例如:\n```\n%% -*- coding: utf-8 -*-\n-module(test).\n-export([test/0]).\ntest() ->\n        [\"我\", <<\"我\"/utf8>>].     \n```\n> $ erl\n> Erlang/OTP 17 [erts-6.2] [source] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]\n> \n> Eshell V6.2  (abort with ^G)\n> 1> test:test().\n> [[25105],<<230,136,145>>]\n \n## 文件编码带来的差异\nR15B, erlang一律以latin-1编译代码,遇到中文都编译成这种,\n如test模块的函数:\n```\ndata() -> \"中国人\".\ndata2() -> <<\"中国人\">>.\n```\n运行时:\n> 1> test:data().\n> [228,184,173,229,155,189,228,186,186]\n> 2> test:data2().\n> <<228,184,173,229,155,189,228,186,186>>\n\n而erlang 17中,erlang一律默认以unicode编译代码(也可以在文件头指定),遇到中文都编译成这种,\n如test模块的函数:\n```\ndata() -> \"中国人\".\ndata2() -> <<\"中国人\"/utf8>>.  (注意这里需要加utf8类型)\n```\n运行时:\n> 1> test:data().\n> [20013,22269,20154]\n> 2> test:data2().\n> <<228,184,173,229,155,189,228,186,186>>\n\n而这里如果data2()没加utf8类型说明,即写成了这样\n```\ndata2() -> <<\"中国人\">>.\n```\n则会有问题:\n> 1> test:data2().\n> <<\"-ýº\">>\n> 2> io:format(\"~w\", [test:data2()]).\n> <<45,253,186>>ok\n\n或者写成了这样\n```\n%% -*- coding: latin-1 -*-\ndata2() -> <<\"中国人\"/utf8>>.\n```\n即utf8类型说明与latin-1文件编码说明冲突,则也会有问题:\n> 1> test:data2().\n> <<195,164,194,184,194,173,195,165,194,155,194,189,195,164,\n>   194,186,194,186>>\n> 2> io:format(\"~ts\", [v(2)]).\n> ä¸­å½äººok\n> 3> io:format(\"~s\", [v(2)]).\n> Ã¤Â¸Â­Ã¥ÂÂ½Ã¤ÂºÂºok\n\n所以以下这段问题代码\n```\n-module(t).\n-export([test/0]).\ntest() ->\n    [\"我\", <<\"我\">>].\n```\nR17编译后的运行结果为：\n> 1> t:test().\n> [[25105],<<17>>]\n\n字符串是字符串,binary是binary,\n字符串是这样的[25105, 25105, 97]\nbinary是这样的, <<230,136,145,230,136,145,97>>, 二进制这里面一个数字肯定是1个字节的, 要不不叫binary了\n\n<<\"我\">>相当于<<25105>>,而二进制一个数字需要是1个字节,所以截断变成<<17>>\n而加上utf8描述符后就不会被截断\n> <<\"我\"/utf8>>.\n<<230,136,145>>\n\n所以这里把代码改为\n```\n-module(t).\n-export([test/0]).\ntest() ->\n    [\"我\", <<\"我\"/utf8>>].\n```\n即可\n\n## 文件名解析\nerl启动的时候添加不同的flag可以控制解析文件名的方式: \n* +fnl 按照latin去解析文件名 \n* +fnu 按照unicode解析文件名 \n* +fna 是根据环境变量(LC_CTYPE)自动选择,这也是目前的系统默认值.\n\n可以使用file:native_name_encoding检查此参数.\n> $ erl\n> Erlang/OTP 17 [erts-6.2] [source] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]\n> \n> Eshell V6.2  (abort with ^G)\n> 1> file:native_name_encoding().\n> utf8\n> 2> file:read_file(\"test我.erl\").\n> {ok,<<45,109,111,100,117,108,101,40,39,116,101,115,116,230,136,145,39,41,46,32,10,45,101,120,112,111,114,...>>}\n\n+fnl后\n> $ erl +fnl\n> Erlang/OTP 17 [erts-6.2] [source] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]\n> \n> Eshell V6.2  (abort with ^G)\n> 1> file:native_name_encoding().\n> latin1\n> 2> file:read_file(\"test我.erl\").\n> {error,badarg}\n\n## 参考链接\n[Erlang User Conference 2013上patrik分享的BRING UNICODE TO ERLANG!视频](http://www.youtube.com/watch?v=M6hPLCA0F-Y)\n[PDF在这里](http://www.erlang-factory.com/upload/presentations/847/PatrikEUC2013.pdf)\n[官方文档](http://www.erlang.org/doc/apps/stdlib/unicode_usage.html)\n\n","slug":"erlang_unicode","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ly006xmcxq52tb75ue"},{"title":"erlang实现websocket简单示例","date":"2015-09-06T16:00:00.000Z","_content":"WebSocket protocol 是HTML5一种新的协议。它实现了浏览器与服务器全双工通信(full-duplex)。\n<!--more-->\n![运行效果](/pics/websocket_demo.png)\n\n本示例仅支持文本消息\n基于websocket版本13\n\n由于joe armstrong的例子:\nhttp://armstrongonsoftware.blogspot.com/2009/12/comet-is-dead-long-live-websockets.html\n已经过时,不符合现在的websocket标准,于是改写了一下\n\n前端使用js发送websocket请求\n\n## 测试\n在erlang shell里执行local_server:start()即可启动服务端,\n此时打开index.html即可看到文首的截图效果\n\n## 源码下载\n[websocket](/attachments/websocket_demo.tar.gz)\n\n## 参考链接\n[cowboy](https://github.com/extend/cowboy)\n[websocket标准](http://blog.csdn.net/fenglibing/article/details/6852497)\n\n","source":"_posts/erlang_websocket.md","raw":"title: erlang实现websocket简单示例\ndate: 2015-09-07\ntags: [erlang, internet]\n---\nWebSocket protocol 是HTML5一种新的协议。它实现了浏览器与服务器全双工通信(full-duplex)。\n<!--more-->\n![运行效果](/pics/websocket_demo.png)\n\n本示例仅支持文本消息\n基于websocket版本13\n\n由于joe armstrong的例子:\nhttp://armstrongonsoftware.blogspot.com/2009/12/comet-is-dead-long-live-websockets.html\n已经过时,不符合现在的websocket标准,于是改写了一下\n\n前端使用js发送websocket请求\n\n## 测试\n在erlang shell里执行local_server:start()即可启动服务端,\n此时打开index.html即可看到文首的截图效果\n\n## 源码下载\n[websocket](/attachments/websocket_demo.tar.gz)\n\n## 参考链接\n[cowboy](https://github.com/extend/cowboy)\n[websocket标准](http://blog.csdn.net/fenglibing/article/details/6852497)\n\n","slug":"erlang_websocket","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5lz0070mcxq9imgtlpm"},{"title":"fcitx","date":"2015-08-05T16:00:00.000Z","_content":"\n## 安装\n```\nsudo apt-get install fcitx\nsudo apt-get install fcitx-table-all\nsudo apt-get install fcitx-mozc // 日语输入法\n```\n\n## 设fcitx为默认\n```\nsudo apt-get install im-config\n进入im-config图形界面设置fcitx为默认输入法\n```\n\n## 添加具体输入法\n将系统设置里的keyboard里的shortcuts里的\"Switch to next source\"和\"Switch to previous source\"disable掉，鼠标点击后按Backspace键即可disable.\n点击右上角任务栏里的键盘样图标，选择Configure Current Input Method，点击左下角的+号，清掉\"Only Show Current Language\"复选框后添加你想要的输入法\n\nLogout或Restart\n\nCtrl+Space开启或关闭输入法， Ctrl+Shift切换输入法\n\nEnjoy!\n\n","source":"_posts/fcitx.md","raw":"title: fcitx\ndate: 2015-08-06\ntags: linux\n---\n\n## 安装\n```\nsudo apt-get install fcitx\nsudo apt-get install fcitx-table-all\nsudo apt-get install fcitx-mozc // 日语输入法\n```\n\n## 设fcitx为默认\n```\nsudo apt-get install im-config\n进入im-config图形界面设置fcitx为默认输入法\n```\n\n## 添加具体输入法\n将系统设置里的keyboard里的shortcuts里的\"Switch to next source\"和\"Switch to previous source\"disable掉，鼠标点击后按Backspace键即可disable.\n点击右上角任务栏里的键盘样图标，选择Configure Current Input Method，点击左下角的+号，清掉\"Only Show Current Language\"复选框后添加你想要的输入法\n\nLogout或Restart\n\nCtrl+Space开启或关闭输入法， Ctrl+Shift切换输入法\n\nEnjoy!\n\n","slug":"fcitx","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5m00072mcxqqat3wunk"},{"title":"erlang vm args","date":"2020-04-17T16:00:00.000Z","_content":"erlang VM(OTP 22.3) 参数调优\n\n<!--more-->\n## 内存\nerlang:memory(total) 报告的内存用量是 active used 用量,\n这个值与操作系统报告(如 htop)的 RES 不同, 有时差异很大\n原因是 erlang VM 从操作系统通过 mmap(mseg_alloc) 或 malloc(sys_alloc) 分配的内存由 VM 自行管理\n\n### mseg_alloc\nmseg_alloc 分配的 carrier(称为 mbc: multi block carrier, 即一大块内存, 如 8 MB, 用于满足大量小块的内存需求),\n当需要使用内存时, 再从 carrier 内部找到一块能够满足需要的内存(称为 block)\n\n### sys_alloc\nsys_alloc 分配的 carrier(称为 sbc: single block carrier, 这种 carrier 内只会有一个 block, 用于满足单个大块内存需求)\n\n## 记一次内存参数调优\nerlang:memory(total) 是 6G\nlinux report 的 RES 竟然是 12G\n分析发现利用率低的原因在于 binary_alloc , erlang:memory(binary) 是 3G,\n\n### 问题\n```\n> {:ok, {_, l}} = :instrument.carriers(%{allocator_types: [:binary_alloc]}); l |> Enum.map(fn i -> elem(i, 1)end) |> Enum.sum\n9147547648\n> l |> Enum.map(fn i -> elem(i, 3) end) |> Enum.sum\n3227022288\n> length(l)\n1086\n> l |> Enum.filter(fn i -> elem(i, 1) == 8388608 end) |> Enum.count\n993\n```\n这里可以看出, 仅 binary_alloc 就从 OS 那里拿了 9G 多, 只使用了 3G 多, 利用率仅 30% 多\n绝大多数 carrier 都是 8M 大小\n\n### recon_alloc:fragmentation\n```\n> for {{:binary_alloc, _}, _} = i <- :recon_alloc.fragmentation(:current), do: i\n[\n   {{:binary_alloc, 1},\n   [\n     sbcs_usage: 1.0,\n     mbcs_usage: 0.11764846584230272,\n     sbcs_block_size: 0,\n     sbcs_carriers_size: 0,\n     mbcs_block_size: 256630480,\n     mbcs_carriers_size: 2181332992\n   ]},\n   ...\n```\n这里的数据和上面的数据相似, 只是按各个 scheduler 分开了, 各个 scheduler 因忙碌程度不同数据有所不同\n这里是无法直视的 0.117 的 usage\n另外各 scheduler 都没有 sbc , 100% mbc\n\n### 惨不忍睹的 cache_hit_rates\n```\n> :recon_alloc.cache_hit_rates\n[\n  {{:instance, 2},\n   [hit_rate: 0.07593661451298644, hits: 198688, calls: 2616498]},\n  {{:instance, 1},\n   [hit_rate: 0.07875297434572018, hits: 206590, calls: 2623266]},\n  {{:instance, 3},\n   [hit_rate: 0.07236038356379897, hits: 178458, calls: 2466239]},\n  {{:instance, 4},\n   [hit_rate: 0.07046272138745954, hits: 146002, calls: 2072046]},\n  {{:instance, 5},\n   [hit_rate: 0.06508099839392721, hits: 103979, calls: 1597686]},\n  {{:instance, 6}, [hit_rate: 0.06482833535152076, hits: 65529, calls: 1010808]},\n  {{:instance, 7}, [hit_rate: 0.04520865314353365, hits: 23943, calls: 529611]},\n  {{:instance, 0}, [hit_rate: 0.5870402814606035, hits: 657744, calls: 1120441]},\n  {{:instance, 8}, [hit_rate: 0.035719675041223455, hits: 13019, calls: 364477]}\n]\n```\n根据该函数的doc来看, 该值应该在 0.80(80%)以上才正常\n\n### instrument:allocations\n```\n> :instrument.allocations\n{:ok,\n {128, 233015472,\n  %{\n    jiffy: %{\n      binary: {0, 71325, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      drv_binary: {56252, 2907, 5212, 6400, 633, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      nif_internal: {128608, 2749, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0}\n    },\n    prim_file: %{\n      drv_binary: {0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}\n    },\n    spawn: %{drv_binary: {0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}},\n    system: %{\n      binary: {0, 251, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      driver: {0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      driver_control_data: {1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0},\n      driver_mutex: {1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      driver_rwlock: {1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      driver_tsd: {2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      drv_binary: {713173, 141795, 4301, 4045, 2001, 104, 1, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0},\n      drv_internal: {0, 0, 64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      microstate_accounting: {1, 29, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0},\n      nif_internal: {12, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      port: {0, 0, 68, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      port_data_lock: {2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}\n    },\n    tcp_inet: %{\n      driver_tid: {8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      driver_tsd: {8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      drv_binary: {2, 260, 3928, 37343, 4713, 575, 2, 0, 0, 0, 3257, 5871, 0, 0, 0, 0, 0, 0},\n      drv_internal: {109, 10, 54143, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0},\n      port: {0, 0, 53852, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}\n    }\n  }}}\n```\n如下写了一个小函数来计算 histogram 里的总内存量\n```\n> f = fn(start, histogram) ->\n  :erlang.tuple_to_list(histogram)\n  |> Enum.reduce({start, 0}, fn(i, {size_level, acc}) -> {size_level * 2, i * size_level + acc}  end)\nend\n> f.(128, {2, 260, 3928, 37343, 4713, 575, 2, 0, 0, 0, 3257, 5871, 0, 0, 0, 0, 0, 0})\n{33554432, 2018289920}\n```\n显示绝大部分都是 tcp_inet 占用的, < 2018289920 (约2G)\n这里看起来是正常的\n\n### 当时使用的内存参数\n```\n> :erlang.system_info(:allocator)\n   ...\n   binary_alloc: [\n     e: true,\n     t: true,\n     atags: true,\n     ramv: false,\n     sbct: 524288,\n     asbcst: 4145152,\n     rsbcst: 20,\n     rsbcmt: 80,\n     rmbcmt: 50,\n     mmbcs: 32768,\n     mmmbc: 18446744073709551615,\n     mmsbc: 256,\n     lmbcs: 5242880,\n     smbcs: 262144,\n     mbcgs: 10,\n     acul: 0,\n     acnl: 0,\n     acfml: 0,\n     as: :aoffcbf\n   ],\n   ...\n```\n\n### 尝试 disable binary_alloc\n```\n+MBe false\n```\ndisable 之后连 erlang:memory 都返回 :notsup 的错误, 看不了了.... :(\n压力测试下来比原参数 RES 占用可能少 20% 多的样子\n但是看不了 erlang:memory 等数据无法接受\n\n### 关于 background gc\n这个 background gc 每 10 分钟自动对几乎所有 process 做一次 fullsweep gc\n```\nfor p <- :erlang.processes(),\n  {:status, :waiting} == :erlang.process_info(p, :status),\n  do: :erlang.garbage_collect(p)\n```\n发现改成 1 天一次以后, memory fragmentation 有逐渐改善(3 天后降下来 2G 左右)\nfullsweep gc 与 memory fragmentation 之间的关系还需要研究\n\n### reference\nerts_alloc, instrument docs by erlang\nhttp://erlang.org/doc/man/erts_alloc.html\nhttp://erlang.org/doc/apps/erts/CarrierMigration.html\nhttp://blog.erlang.org/Memory-instrumentation-in-OTP-21/\nhttps://erlang.org/doc/man/instrument.html\n\nmemory management: battle stories by Lukas Larsson\nhttps://www.youtube.com/watch?v=nuCYL0X-8f4\nhttps://www.erlang-factory.com/static/upload/media/139454517145429lukaslarsson.pdf\nhttps://www.cnblogs.com/zhengsyao/p/erts_allocators_speech_by_lukas_larsson.html\n\nmemory fragmentation case, and recon_alloc tool, erlang-in-anger book written by Fred Hebert\nhttps://blog.heroku.com/archives/2013/11/7/logplex-down-the-rabbit-hole\nhttps://github.com/ferd/recon/blob/master/src/recon_alloc.erl\nhttps://www.erlang-in-anger.com\n\nRabbitMQ default flags\nhttps://www.rabbitmq.com/runtime.html#allocators\nhttps://groups.google.com/forum/#!msg/rabbitmq-users/LSYaac9frYw/LNZDZUlrBAAJ\n\n## CPU\n### reference\n+sbwt\nhttps://stressgrid.com/blog/beam_cpu_usage/\n\n+stbt Rabbit MQ default\nhttps://www.rabbitmq.com/runtime.html#scheduler-bind-type\n\nsomeone says using `+stbt ts` reduced context switching for 4 times\nhttps://github.com/rabbitmq/rabbitmq-server/issues/612\n\nWhatsapp use tnnps\nhttps://www.youtube.com/watch?v=tW49z8HqsNw&feature=youtu.be&t=11m2s\n\n## Inter-node Communication Buffer Size\n+zdbbl\n\nRabbit MQ explain\nhttps://www.rabbitmq.com/runtime.html#distribution-buffer\n\n## 最终选用的参数\n\n经过本地压力测试(10k websocket connections + 10k nsq message consumption per second, send those nsq binary to websocket)\n可能因为时间不够长(30 minutes, 然而根据 ferd 的博客, memory fragmentation 要数周才体现出来), 压力不够大,\n测试结果: 以下参数对比默认参数, RES 减少 10 % 多\n\n```\n+P 1048576\n+Q 1048576\n\n+sbwt none\n+sbwtdcpu none\n+sbwtdio none\n\n+swt very_low\n\n+stbt db\n\n+zdbbl 81920\n\n+MBas ageffcbf\n+MHas ageffcbf\n\n+MBlmbcs 512\n+MBsmbcs 512\n+MHlmbcs 512\n+MHsmbcs 512\n\n+MMmcs 30\n```\n\nerl flags doc\nhttp://erlang.org/doc/man/erl.html\n\n## TODO\n\n* +M<S>ramv <bool>\n* +M<S>acul <utilization>|de\n* carrier pool\n* carrier header size\n","source":"_posts/erlang_vm_flags.md","raw":"title: erlang vm args\ndate: 2020-04-18\ntags: erlang\n---\nerlang VM(OTP 22.3) 参数调优\n\n<!--more-->\n## 内存\nerlang:memory(total) 报告的内存用量是 active used 用量,\n这个值与操作系统报告(如 htop)的 RES 不同, 有时差异很大\n原因是 erlang VM 从操作系统通过 mmap(mseg_alloc) 或 malloc(sys_alloc) 分配的内存由 VM 自行管理\n\n### mseg_alloc\nmseg_alloc 分配的 carrier(称为 mbc: multi block carrier, 即一大块内存, 如 8 MB, 用于满足大量小块的内存需求),\n当需要使用内存时, 再从 carrier 内部找到一块能够满足需要的内存(称为 block)\n\n### sys_alloc\nsys_alloc 分配的 carrier(称为 sbc: single block carrier, 这种 carrier 内只会有一个 block, 用于满足单个大块内存需求)\n\n## 记一次内存参数调优\nerlang:memory(total) 是 6G\nlinux report 的 RES 竟然是 12G\n分析发现利用率低的原因在于 binary_alloc , erlang:memory(binary) 是 3G,\n\n### 问题\n```\n> {:ok, {_, l}} = :instrument.carriers(%{allocator_types: [:binary_alloc]}); l |> Enum.map(fn i -> elem(i, 1)end) |> Enum.sum\n9147547648\n> l |> Enum.map(fn i -> elem(i, 3) end) |> Enum.sum\n3227022288\n> length(l)\n1086\n> l |> Enum.filter(fn i -> elem(i, 1) == 8388608 end) |> Enum.count\n993\n```\n这里可以看出, 仅 binary_alloc 就从 OS 那里拿了 9G 多, 只使用了 3G 多, 利用率仅 30% 多\n绝大多数 carrier 都是 8M 大小\n\n### recon_alloc:fragmentation\n```\n> for {{:binary_alloc, _}, _} = i <- :recon_alloc.fragmentation(:current), do: i\n[\n   {{:binary_alloc, 1},\n   [\n     sbcs_usage: 1.0,\n     mbcs_usage: 0.11764846584230272,\n     sbcs_block_size: 0,\n     sbcs_carriers_size: 0,\n     mbcs_block_size: 256630480,\n     mbcs_carriers_size: 2181332992\n   ]},\n   ...\n```\n这里的数据和上面的数据相似, 只是按各个 scheduler 分开了, 各个 scheduler 因忙碌程度不同数据有所不同\n这里是无法直视的 0.117 的 usage\n另外各 scheduler 都没有 sbc , 100% mbc\n\n### 惨不忍睹的 cache_hit_rates\n```\n> :recon_alloc.cache_hit_rates\n[\n  {{:instance, 2},\n   [hit_rate: 0.07593661451298644, hits: 198688, calls: 2616498]},\n  {{:instance, 1},\n   [hit_rate: 0.07875297434572018, hits: 206590, calls: 2623266]},\n  {{:instance, 3},\n   [hit_rate: 0.07236038356379897, hits: 178458, calls: 2466239]},\n  {{:instance, 4},\n   [hit_rate: 0.07046272138745954, hits: 146002, calls: 2072046]},\n  {{:instance, 5},\n   [hit_rate: 0.06508099839392721, hits: 103979, calls: 1597686]},\n  {{:instance, 6}, [hit_rate: 0.06482833535152076, hits: 65529, calls: 1010808]},\n  {{:instance, 7}, [hit_rate: 0.04520865314353365, hits: 23943, calls: 529611]},\n  {{:instance, 0}, [hit_rate: 0.5870402814606035, hits: 657744, calls: 1120441]},\n  {{:instance, 8}, [hit_rate: 0.035719675041223455, hits: 13019, calls: 364477]}\n]\n```\n根据该函数的doc来看, 该值应该在 0.80(80%)以上才正常\n\n### instrument:allocations\n```\n> :instrument.allocations\n{:ok,\n {128, 233015472,\n  %{\n    jiffy: %{\n      binary: {0, 71325, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      drv_binary: {56252, 2907, 5212, 6400, 633, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      nif_internal: {128608, 2749, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0}\n    },\n    prim_file: %{\n      drv_binary: {0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}\n    },\n    spawn: %{drv_binary: {0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}},\n    system: %{\n      binary: {0, 251, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      driver: {0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      driver_control_data: {1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0},\n      driver_mutex: {1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      driver_rwlock: {1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      driver_tsd: {2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      drv_binary: {713173, 141795, 4301, 4045, 2001, 104, 1, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0},\n      drv_internal: {0, 0, 64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      microstate_accounting: {1, 29, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0},\n      nif_internal: {12, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      port: {0, 0, 68, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      port_data_lock: {2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}\n    },\n    tcp_inet: %{\n      driver_tid: {8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      driver_tsd: {8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n      drv_binary: {2, 260, 3928, 37343, 4713, 575, 2, 0, 0, 0, 3257, 5871, 0, 0, 0, 0, 0, 0},\n      drv_internal: {109, 10, 54143, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0},\n      port: {0, 0, 53852, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}\n    }\n  }}}\n```\n如下写了一个小函数来计算 histogram 里的总内存量\n```\n> f = fn(start, histogram) ->\n  :erlang.tuple_to_list(histogram)\n  |> Enum.reduce({start, 0}, fn(i, {size_level, acc}) -> {size_level * 2, i * size_level + acc}  end)\nend\n> f.(128, {2, 260, 3928, 37343, 4713, 575, 2, 0, 0, 0, 3257, 5871, 0, 0, 0, 0, 0, 0})\n{33554432, 2018289920}\n```\n显示绝大部分都是 tcp_inet 占用的, < 2018289920 (约2G)\n这里看起来是正常的\n\n### 当时使用的内存参数\n```\n> :erlang.system_info(:allocator)\n   ...\n   binary_alloc: [\n     e: true,\n     t: true,\n     atags: true,\n     ramv: false,\n     sbct: 524288,\n     asbcst: 4145152,\n     rsbcst: 20,\n     rsbcmt: 80,\n     rmbcmt: 50,\n     mmbcs: 32768,\n     mmmbc: 18446744073709551615,\n     mmsbc: 256,\n     lmbcs: 5242880,\n     smbcs: 262144,\n     mbcgs: 10,\n     acul: 0,\n     acnl: 0,\n     acfml: 0,\n     as: :aoffcbf\n   ],\n   ...\n```\n\n### 尝试 disable binary_alloc\n```\n+MBe false\n```\ndisable 之后连 erlang:memory 都返回 :notsup 的错误, 看不了了.... :(\n压力测试下来比原参数 RES 占用可能少 20% 多的样子\n但是看不了 erlang:memory 等数据无法接受\n\n### 关于 background gc\n这个 background gc 每 10 分钟自动对几乎所有 process 做一次 fullsweep gc\n```\nfor p <- :erlang.processes(),\n  {:status, :waiting} == :erlang.process_info(p, :status),\n  do: :erlang.garbage_collect(p)\n```\n发现改成 1 天一次以后, memory fragmentation 有逐渐改善(3 天后降下来 2G 左右)\nfullsweep gc 与 memory fragmentation 之间的关系还需要研究\n\n### reference\nerts_alloc, instrument docs by erlang\nhttp://erlang.org/doc/man/erts_alloc.html\nhttp://erlang.org/doc/apps/erts/CarrierMigration.html\nhttp://blog.erlang.org/Memory-instrumentation-in-OTP-21/\nhttps://erlang.org/doc/man/instrument.html\n\nmemory management: battle stories by Lukas Larsson\nhttps://www.youtube.com/watch?v=nuCYL0X-8f4\nhttps://www.erlang-factory.com/static/upload/media/139454517145429lukaslarsson.pdf\nhttps://www.cnblogs.com/zhengsyao/p/erts_allocators_speech_by_lukas_larsson.html\n\nmemory fragmentation case, and recon_alloc tool, erlang-in-anger book written by Fred Hebert\nhttps://blog.heroku.com/archives/2013/11/7/logplex-down-the-rabbit-hole\nhttps://github.com/ferd/recon/blob/master/src/recon_alloc.erl\nhttps://www.erlang-in-anger.com\n\nRabbitMQ default flags\nhttps://www.rabbitmq.com/runtime.html#allocators\nhttps://groups.google.com/forum/#!msg/rabbitmq-users/LSYaac9frYw/LNZDZUlrBAAJ\n\n## CPU\n### reference\n+sbwt\nhttps://stressgrid.com/blog/beam_cpu_usage/\n\n+stbt Rabbit MQ default\nhttps://www.rabbitmq.com/runtime.html#scheduler-bind-type\n\nsomeone says using `+stbt ts` reduced context switching for 4 times\nhttps://github.com/rabbitmq/rabbitmq-server/issues/612\n\nWhatsapp use tnnps\nhttps://www.youtube.com/watch?v=tW49z8HqsNw&feature=youtu.be&t=11m2s\n\n## Inter-node Communication Buffer Size\n+zdbbl\n\nRabbit MQ explain\nhttps://www.rabbitmq.com/runtime.html#distribution-buffer\n\n## 最终选用的参数\n\n经过本地压力测试(10k websocket connections + 10k nsq message consumption per second, send those nsq binary to websocket)\n可能因为时间不够长(30 minutes, 然而根据 ferd 的博客, memory fragmentation 要数周才体现出来), 压力不够大,\n测试结果: 以下参数对比默认参数, RES 减少 10 % 多\n\n```\n+P 1048576\n+Q 1048576\n\n+sbwt none\n+sbwtdcpu none\n+sbwtdio none\n\n+swt very_low\n\n+stbt db\n\n+zdbbl 81920\n\n+MBas ageffcbf\n+MHas ageffcbf\n\n+MBlmbcs 512\n+MBsmbcs 512\n+MHlmbcs 512\n+MHsmbcs 512\n\n+MMmcs 30\n```\n\nerl flags doc\nhttp://erlang.org/doc/man/erl.html\n\n## TODO\n\n* +M<S>ramv <bool>\n* +M<S>acul <utilization>|de\n* carrier pool\n* carrier header size\n","slug":"erlang_vm_flags","published":1,"updated":"2020-04-18T09:43:59.664Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5m10075mcxqvp40d5jv"},{"title":"如何检查当前的atom数量和上限","date":"2015-07-21T16:00:00.000Z","_content":"\n### 在shell里Ctrl+a并选择info, index_table:atom_tab的entries项是当前atom数量,limit是上限\n> BREAK: (a)bort (c)ontinue (p)roc info (i)nfo (l)oaded\n>        (v)ersion (k)ill (D)b-tables (d)istribution\n> i\n> =memory\n> total: 8482456\n> processes: 1109318\n> processes_used: 1109318\n> system: 7373138\n> atom: 194289\n> atom_used: 171350\n> binary: 935568\n> code: 3736765\n> ets: 252896\n> =hash_table:atom_tab\n> size: 4813\n> used: 3599\n> objs: 6751\n> depth: 7\n> =index_table:atom_tab\n> size: 7168\n> limit: 1048576\n> entries: 6751\n> ...\n\n### 另一种方法, 使用erlang:system_info(info)获得上述输出的binary形式\n输出文件\n```erlang\nfile:write_file(\"info\", erlang:system_info(info)).\n```\n只看前20项,不会太长了\n```erlang\nlists:sublist(string:tokens(binary_to_list(erlang:system_info(info)),\"\\n\"), 20).\n```\n\n### 另一种方法, crash_dump文件里也会有上述输出\nCtrl+a并输入A,回车后可以产生crash_dump文件,还有core文件\n\n### 更新: OTP 20.0 新增\nerlang:system_info/1 atom_count and atom_limit\n\n","source":"_posts/erlang查看当前atom数量和上限.md","raw":"title: 如何检查当前的atom数量和上限\ndate: 2015-07-22\ntags: erlang\n---\n\n### 在shell里Ctrl+a并选择info, index_table:atom_tab的entries项是当前atom数量,limit是上限\n> BREAK: (a)bort (c)ontinue (p)roc info (i)nfo (l)oaded\n>        (v)ersion (k)ill (D)b-tables (d)istribution\n> i\n> =memory\n> total: 8482456\n> processes: 1109318\n> processes_used: 1109318\n> system: 7373138\n> atom: 194289\n> atom_used: 171350\n> binary: 935568\n> code: 3736765\n> ets: 252896\n> =hash_table:atom_tab\n> size: 4813\n> used: 3599\n> objs: 6751\n> depth: 7\n> =index_table:atom_tab\n> size: 7168\n> limit: 1048576\n> entries: 6751\n> ...\n\n### 另一种方法, 使用erlang:system_info(info)获得上述输出的binary形式\n输出文件\n```erlang\nfile:write_file(\"info\", erlang:system_info(info)).\n```\n只看前20项,不会太长了\n```erlang\nlists:sublist(string:tokens(binary_to_list(erlang:system_info(info)),\"\\n\"), 20).\n```\n\n### 另一种方法, crash_dump文件里也会有上述输出\nCtrl+a并输入A,回车后可以产生crash_dump文件,还有core文件\n\n### 更新: OTP 20.0 新增\nerlang:system_info/1 atom_count and atom_limit\n\n","slug":"erlang查看当前atom数量和上限","published":1,"updated":"2018-12-12T08:49:56.725Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5m30077mcxq11tod3gc"},{"title":"fdisk","date":"2015-09-05T16:00:00.000Z","_content":"fdisk -l可以查看分区信息\nsudo fdisk -l \nsudo fdisk -l /dev/sda\n\n","source":"_posts/fdisk.md","raw":"title: fdisk\ndate: 2015-09-06\ntags: linux\n---\nfdisk -l可以查看分区信息\nsudo fdisk -l \nsudo fdisk -l /dev/sda\n\n","slug":"fdisk","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5m4007amcxqzqesyjyy"},{"title":"fcm","date":"2018-02-22T16:00:00.000Z","_content":"FCM(firebase cloud messaging)用于推送服务(主要目标是移动设备),\n在app进程被杀死后仍然可以通过android自带的google服务做到推送\n<!--more-->\n首先, 用firebase需要梯子. 用httpc的话, 如下设置http代理(不支持socks5代理, 需要自己把socks5代理转接成http代理):\n```\nhttpc:set_options([{proxy, {{\"localhost\", 8123}, [\"localhost\"]}}]).\n```\n\nfcm client library for erlang\n```\nhttps://github.com/softwarejoint/fcm-erlang\n```\n\n好, 开始使用, 如下提供api key做为初始化参数, 启动一个gen server(干活的进程)\n```\nfcm:start(test2, \"AAAAC53t-ac:APA91bHYDiZFPOYA5jwNedEv7TOCfQQncPtgXCpxpB1WwZ6oSsJu_3SGJ7poaqQpd8o1SQ5YUXpp1E5OWOQmjwKLEKLExcQtyS22bD_SI76OcmSQFYRSnl-NKJxW_QQsW2qbvmxmt7qU\").\n```\n\n给目标注册令牌(registration token, 注意这个东西可能会变)推送一条通知栏消息\n```\nfcm:push(test2, <<\"eLeCIjv0u1Y:APA91bGwRLEOycNjLq5OPpwdIsxdn5aQcMbMu7DuRXU9RirWnofW82YlJFGB4DxhXr30sepd0t99bd6CfGbr5P5x6tdlzUlhNQz6Lq3yYyEZFMtLa7ZmKfavr22d3L9YrkOX75BVuqpv\">>, [{<<\"data\">>, [{<<\"message\">>, <<\"a message\">>}]}, {<<\"notification\">>, [{<<\"title\">>, <<\"Title chenduo\">>}, {<<\"body\">>, <<\"Content chenduo\">>}]}]).\n```\n\n给主题(topic)推送一条通知栏消息\n```\nfcm:push(test2, <<\"/topics/testTopic\">>, [{<<\"data\">>, [{<<\"message\">>, <<\"a message\">>}]}, {<<\"notification\">>, [{<<\"title\">>, <<\"Title chenduo\">>}, {<<\"body\">>, <<\"Content chenduo\">>}]}]).\n```\n\ncurl的示例\n```\ncurl -i -H 'Content-type: application/json' -H 'Authorization: key=AAAAC53t-ac:APA91bHYDiZFPOYA5jwNedEv7TOCfQQncPtgXCpxpB1WwZ6oSsJu_3SGJ7poaqQpd8o1SQ5YUXpp1E5OWOQmjwKLEKLExcQtyS22bD_SI76OcmSQFYRSnl-NKJxW_QQsW2qbvmxmt7qU' -XPOST https://fcm.googleapis.com/fcm/send -d '{\n  \"registration_ids\":[\"eAK6S9KDGNw:APA91bF5sdf70uhCnmrMmV0ThfjhRToMFcbYMAt3HuT1apwUObXAhW4Sz-UG0IakS12brja4ItugGXqZQ9amWVm62-ZBoxeqWobGmR6_DsXa020O9yNWx_2T-SjnPeqsgT6Pagw8eUK-\"],\n  \"notification\": {\n      \"title\":\"Title of your notification\",\n      \"body\":\"content of your notification\"\n  },\n  \"data\": {\n    \"key1\" : \"value1\",\n    \"key2\" : \"value2\",\n    \"key3\" : 23.56565,\n    \"key4\" : true\n  }\n}'\n```\n\n","source":"_posts/fcm.md","raw":"title: fcm\ndate: 2018-02-23\ntags: [push, firebase, android, ios]\n---\nFCM(firebase cloud messaging)用于推送服务(主要目标是移动设备),\n在app进程被杀死后仍然可以通过android自带的google服务做到推送\n<!--more-->\n首先, 用firebase需要梯子. 用httpc的话, 如下设置http代理(不支持socks5代理, 需要自己把socks5代理转接成http代理):\n```\nhttpc:set_options([{proxy, {{\"localhost\", 8123}, [\"localhost\"]}}]).\n```\n\nfcm client library for erlang\n```\nhttps://github.com/softwarejoint/fcm-erlang\n```\n\n好, 开始使用, 如下提供api key做为初始化参数, 启动一个gen server(干活的进程)\n```\nfcm:start(test2, \"AAAAC53t-ac:APA91bHYDiZFPOYA5jwNedEv7TOCfQQncPtgXCpxpB1WwZ6oSsJu_3SGJ7poaqQpd8o1SQ5YUXpp1E5OWOQmjwKLEKLExcQtyS22bD_SI76OcmSQFYRSnl-NKJxW_QQsW2qbvmxmt7qU\").\n```\n\n给目标注册令牌(registration token, 注意这个东西可能会变)推送一条通知栏消息\n```\nfcm:push(test2, <<\"eLeCIjv0u1Y:APA91bGwRLEOycNjLq5OPpwdIsxdn5aQcMbMu7DuRXU9RirWnofW82YlJFGB4DxhXr30sepd0t99bd6CfGbr5P5x6tdlzUlhNQz6Lq3yYyEZFMtLa7ZmKfavr22d3L9YrkOX75BVuqpv\">>, [{<<\"data\">>, [{<<\"message\">>, <<\"a message\">>}]}, {<<\"notification\">>, [{<<\"title\">>, <<\"Title chenduo\">>}, {<<\"body\">>, <<\"Content chenduo\">>}]}]).\n```\n\n给主题(topic)推送一条通知栏消息\n```\nfcm:push(test2, <<\"/topics/testTopic\">>, [{<<\"data\">>, [{<<\"message\">>, <<\"a message\">>}]}, {<<\"notification\">>, [{<<\"title\">>, <<\"Title chenduo\">>}, {<<\"body\">>, <<\"Content chenduo\">>}]}]).\n```\n\ncurl的示例\n```\ncurl -i -H 'Content-type: application/json' -H 'Authorization: key=AAAAC53t-ac:APA91bHYDiZFPOYA5jwNedEv7TOCfQQncPtgXCpxpB1WwZ6oSsJu_3SGJ7poaqQpd8o1SQ5YUXpp1E5OWOQmjwKLEKLExcQtyS22bD_SI76OcmSQFYRSnl-NKJxW_QQsW2qbvmxmt7qU' -XPOST https://fcm.googleapis.com/fcm/send -d '{\n  \"registration_ids\":[\"eAK6S9KDGNw:APA91bF5sdf70uhCnmrMmV0ThfjhRToMFcbYMAt3HuT1apwUObXAhW4Sz-UG0IakS12brja4ItugGXqZQ9amWVm62-ZBoxeqWobGmR6_DsXa020O9yNWx_2T-SjnPeqsgT6Pagw8eUK-\"],\n  \"notification\": {\n      \"title\":\"Title of your notification\",\n      \"body\":\"content of your notification\"\n  },\n  \"data\": {\n    \"key1\" : \"value1\",\n    \"key2\" : \"value2\",\n    \"key3\" : 23.56565,\n    \"key4\" : true\n  }\n}'\n```\n\n","slug":"fcm","published":1,"updated":"2018-02-23T10:52:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5m5007cmcxq9aqv4r3p"},{"title":"firefox","date":"2015-08-05T16:00:00.000Z","_content":"## firefox取消记住密码\n编辑->首选项->安全->已保存的密码\n\n## firefox手势\n附加组件搜索FireGestures\n\n","source":"_posts/firefox.md","raw":"title: firefox\ndate: 2015-08-06\ntags: [internet, linux]\n---\n## firefox取消记住密码\n编辑->首选项->安全->已保存的密码\n\n## firefox手势\n附加组件搜索FireGestures\n\n","slug":"firefox","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5m6007fmcxqrx0ti2wt"},{"title":"firewalld","date":"2016-01-20T16:00:00.000Z","_content":"使用iptables, 与内核负责过滤包的Netfilter交互\nfirewalld的好处:\n* 支持动态更新, 不用重启服务\n* zone概念, 相当于预定义规则, 使用方便\n<!--more-->\n\n## 安装firewalld\nyum install firewalld\nyum install firewall-config\n\n## 启动和关闭firewalld\nsystemctl start firewalld\nsystemctl stop firewalld\n\n## 检测firewalld状态\nsystemctl status firewalld\nfirewall-cmd --state\n\n## 开机自启\nsystemctl enable firewalld\nsystemctl disable firewalld\n\n## zone\nfirewall可以把网络隔离为几个不同的zone, 每个interface都属于一个zone, \n/etc/firewalld/下的zone配置文件里有如下几个预定义的zone,\n* drop 扔掉所有进来的packet, 不发送应答, 只允许出去的网络连接\n* block 所有进来的连接都被拒绝,应答为IPv4: icmp-host-prohibited, IPv6: icmp6-adm-prohibited, 只允许内部发起连接\n* public 适用于公共领域(即警戒姿态, 不相信网络里的其他电脑), 只有选中的进来的连接才能被接受\n* external 适用于外部网络, 对router自动伪装(masquerading), 只有选中的进来的连接才能被接受\n* dmz 适用于可以有限访问内部网络的对外开放的网络, 只有选中的进来的连接才能被接受\n* work 适用于公司的网络, 只有选中的进来的连接才能被接受\t\n* home 适用于家里的网络, 只有选中的进来的连接才能被接受\n* internal 适用于内部网络, 只有选中的进来的连接才能被接受\n* trusted 接受所有连接\n\n## 配置\ngui下拉框选项runtime和permanent\nruntime: 每一个修改都立即生效, 要小心对其他用户的影响\npermanent: 下次(restart, reload)生效\n\n### 查看zone相关信息\nfirewall-cmd --get-active-zones\nfirewall-cmd --get-zones\nfirewall-cmd --get-zone-of-interface=eno16777736\nfirewall-cmd --zone=public --list-interfaces\nfirewall-cmd --zone=public --list-all\n\n### 添加interface到zone\nfirewall-cmd --zone=public --add-interface=em1\n\n### 绑定zone的源地址\nfirewall-cmd --zone=trusted --add-source=192.168.1.114/32\n\n### 配置服务(service)\nPorts and Protocols: 编辑协议类型和端口\nNetfilter helper module:\nDestination: 指定只允许到目标地址和协议类型(IPv4, IPv6)的流量\n\n### 设置zone的service\nfirewall-cmd --zone=work --add-service=smtp\nfirewall-cmd --zone=work --remove-service=smtp\n\n#### 通过编辑xml文件设置zone的service\n如果/etc/firewalld/zones/下没有对应文件, 把默认文件cp过去\ncp /usr/lib/firewalld/zones/work.xml /etc/firewalld/zones/\n编辑/etc/firewalld/zones/work.xml\n添加\n```\n<service name=\"smtp\"/>\n```\n\n### 开放端口\n对所有主机或网络开放指定协议(tcp, udp)的端口或端口范围\nfirewall-cmd --zone=dmz --add-port=8080/tcp\nfirewall-cmd --zone=dmz --add-port=5060-5061/udp\nfirewall-cmd --zone=dmz --remove-port=8080/tcp\nfirewall-cmd --zone=dmz --list-ports\n注意这个命令不会显示以--add-services命令打开的端口\n\n### 启用IP地址masquerade\n将IPv4地址转换为指定的单一外部地址\nfirewall-cmd --zone=external --add-masquerade\nfirewall-cmd --zone=external --remove-masquerade\nfirewall-cmd --zone=external --query-masquerade\n\n### 配置端口转发\n需要启用masquerade, 仅限ipv4\nfirewall-cmd --zone=external --add-forward-port=port=22:proto=tcp:toport=3753\nfirewall-cmd --zone=external --add-forward-port=port=22:proto=tcp:toaddr=192.0.2.55\nfirewall-cmd --zone=external --add-forward-port=port=22:proto=tcp:toport=2055:toaddr=192.0.2.55\n\n### 配置ICMP filter\n选择想要过滤的ICMP消息\n在Permanent模式下可编辑ICMP类型\n\n## 使用命令行工具(CLI)firewall-cmd\n使用--permanent选项持久化(除了--direct的,这种无法持久化), 没有--permanent选项的视为runtime修改,\nruntime修改是临时修改, 在reload或restart后会丢失\n如果需要立即生效又需要持久化, 执行两次命令, 一次带--permanent一次不带, 这样比--permanent然后reload要快\n而且reload期间由于安全原因built-in chains会先被设为DROP,reload完成后再设为ACCEPT, 由此可能造成服务被打断\n\n### 查service列表\n显示/usr/lib/firewalld/services/以及当前加载的自定义服务/etc/firewalld/services/, xml文件名必须是servicename.xml\nfirewall-cmd --get-services\n要包含未加载的自定义服务, 可以\nfirewall-cmd --permanent --get-services\n\n### panic mode\nfirewall-cmd --panic-on\nfirewall-cmd --panic-off\nfirewall-cmd --query-panic\n启用时打印yes返回0,否则打印no返回1\n如果panic模式持续时间不长, 已有的连接可能还可以继续工作\n\n### reload\nfirewall-cmd --reload\n\n如果想要重新加载并打断用户连接, 放弃状态信息, 使用如下命令\n这条命令只应在出现严重的防火墙问题时才使用, 比如防火墙规则没问题但是无法建立连接\nfirewall-cmd --complete-reload\n\n### 修改默认zone\nfirewall-cmd --set-default-zone=public\n不需要reload\n或编辑\n/etc/firewalld/firewalld.conf\n```none\n# default zone\n# The default zone used if an empty zone string is used.\n# Default: public\nDefaultZone=home\n```\n然后reload\nfirewall-cmd --reload\n\n## 使用XML文件配置firewall\nXML文件路径/etc/firewalld/\n/usr/lib/firewalld/zones/下的文件不要编辑,它们只在/etc/firewalld/zones/下没有对应文件时作为默认文件\n可以直接创建和修改xml文件或者使用图形和命令行工具间接创建和修改\n可以使用RPM文件分发配置文件以方便管理和版本控制, Puppet等工具可以用于分发这种配置文件\n\n## --direct选项\n如果不熟悉iptables, 使用--direct选项比较危险, 可能会给firewall打开一个裂口\n该模式用于在运行时添加特殊的防火墙规则\n通过firewall-cmd --permanent --direct命令或修改/etc/firewalld/direct.xml文件可以持久化\n\nfirewall-cmd --direct --add-rule ipv4 filter IN_public_allow 0 -m tcp -p tcp --dport 666 -j ACCEPT\nfirewall-cmd --direct --remove-rule ipv4 filter IN_public_allow 0 -m tcp -p tcp --dport 666 -j ACCEPT\nfirewall-cmd --direct --get-rules ipv4 filter IN_public_allow\n注意--get-rules只能获取通过--add-rule加上的规则, 不会列出既存的通过其他方式添加的iptables规则\n\n## Rich Language\nfirewall-cmd [--zone=zone] --add-rich-rule='rule' [--timeout=timeval]\nfirewall-cmd [--zone=zone] --remove-rich-rule='rule'\nfirewall-cmd [--zone=zone] --query-rich-rule='rule'\ntimeout选项表示仅在指定时间内有效(时间到即自动移除), 单位可以是s(秒), m(分)或h(时), 默认是秒\n```none\nrule [family=\"rule family\"]\n    [ source address=\"address\" [invert=\"True\"] ]\n    [ destination address=\"address\" [invert=\"True\"] ]\n    [ element ]\n    [ log [prefix=\"prefix text\"] [level=\"log level\"] [limit value=\"rate/duration\"] ]\n    [ audit ]\n    [ action ]\n```\n规则与zone关联, 一个zone可以有多条规则, 如果多条规则相关或冲突, 以第一条规则为准\n\n## 获取帮助\nman firewall-cmd 1\nman firewalld.icmptype 5\nman firewalld.service 5\nman firewalld.zone 5\nman firewalld.direct 5\nfirewall-cmd --version\nfirewall-cmd --help\n\n## 参考链接\nhttp://www.centoscn.com/CentOS/help/2015/0208/4667.html\nhttps://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Security_Guide/sec-Using_Firewalls.html\n\n","source":"_posts/firewalld.md","raw":"title: firewalld\ndate: 2016-01-21\ntags: [linux, internet]\n---\n使用iptables, 与内核负责过滤包的Netfilter交互\nfirewalld的好处:\n* 支持动态更新, 不用重启服务\n* zone概念, 相当于预定义规则, 使用方便\n<!--more-->\n\n## 安装firewalld\nyum install firewalld\nyum install firewall-config\n\n## 启动和关闭firewalld\nsystemctl start firewalld\nsystemctl stop firewalld\n\n## 检测firewalld状态\nsystemctl status firewalld\nfirewall-cmd --state\n\n## 开机自启\nsystemctl enable firewalld\nsystemctl disable firewalld\n\n## zone\nfirewall可以把网络隔离为几个不同的zone, 每个interface都属于一个zone, \n/etc/firewalld/下的zone配置文件里有如下几个预定义的zone,\n* drop 扔掉所有进来的packet, 不发送应答, 只允许出去的网络连接\n* block 所有进来的连接都被拒绝,应答为IPv4: icmp-host-prohibited, IPv6: icmp6-adm-prohibited, 只允许内部发起连接\n* public 适用于公共领域(即警戒姿态, 不相信网络里的其他电脑), 只有选中的进来的连接才能被接受\n* external 适用于外部网络, 对router自动伪装(masquerading), 只有选中的进来的连接才能被接受\n* dmz 适用于可以有限访问内部网络的对外开放的网络, 只有选中的进来的连接才能被接受\n* work 适用于公司的网络, 只有选中的进来的连接才能被接受\t\n* home 适用于家里的网络, 只有选中的进来的连接才能被接受\n* internal 适用于内部网络, 只有选中的进来的连接才能被接受\n* trusted 接受所有连接\n\n## 配置\ngui下拉框选项runtime和permanent\nruntime: 每一个修改都立即生效, 要小心对其他用户的影响\npermanent: 下次(restart, reload)生效\n\n### 查看zone相关信息\nfirewall-cmd --get-active-zones\nfirewall-cmd --get-zones\nfirewall-cmd --get-zone-of-interface=eno16777736\nfirewall-cmd --zone=public --list-interfaces\nfirewall-cmd --zone=public --list-all\n\n### 添加interface到zone\nfirewall-cmd --zone=public --add-interface=em1\n\n### 绑定zone的源地址\nfirewall-cmd --zone=trusted --add-source=192.168.1.114/32\n\n### 配置服务(service)\nPorts and Protocols: 编辑协议类型和端口\nNetfilter helper module:\nDestination: 指定只允许到目标地址和协议类型(IPv4, IPv6)的流量\n\n### 设置zone的service\nfirewall-cmd --zone=work --add-service=smtp\nfirewall-cmd --zone=work --remove-service=smtp\n\n#### 通过编辑xml文件设置zone的service\n如果/etc/firewalld/zones/下没有对应文件, 把默认文件cp过去\ncp /usr/lib/firewalld/zones/work.xml /etc/firewalld/zones/\n编辑/etc/firewalld/zones/work.xml\n添加\n```\n<service name=\"smtp\"/>\n```\n\n### 开放端口\n对所有主机或网络开放指定协议(tcp, udp)的端口或端口范围\nfirewall-cmd --zone=dmz --add-port=8080/tcp\nfirewall-cmd --zone=dmz --add-port=5060-5061/udp\nfirewall-cmd --zone=dmz --remove-port=8080/tcp\nfirewall-cmd --zone=dmz --list-ports\n注意这个命令不会显示以--add-services命令打开的端口\n\n### 启用IP地址masquerade\n将IPv4地址转换为指定的单一外部地址\nfirewall-cmd --zone=external --add-masquerade\nfirewall-cmd --zone=external --remove-masquerade\nfirewall-cmd --zone=external --query-masquerade\n\n### 配置端口转发\n需要启用masquerade, 仅限ipv4\nfirewall-cmd --zone=external --add-forward-port=port=22:proto=tcp:toport=3753\nfirewall-cmd --zone=external --add-forward-port=port=22:proto=tcp:toaddr=192.0.2.55\nfirewall-cmd --zone=external --add-forward-port=port=22:proto=tcp:toport=2055:toaddr=192.0.2.55\n\n### 配置ICMP filter\n选择想要过滤的ICMP消息\n在Permanent模式下可编辑ICMP类型\n\n## 使用命令行工具(CLI)firewall-cmd\n使用--permanent选项持久化(除了--direct的,这种无法持久化), 没有--permanent选项的视为runtime修改,\nruntime修改是临时修改, 在reload或restart后会丢失\n如果需要立即生效又需要持久化, 执行两次命令, 一次带--permanent一次不带, 这样比--permanent然后reload要快\n而且reload期间由于安全原因built-in chains会先被设为DROP,reload完成后再设为ACCEPT, 由此可能造成服务被打断\n\n### 查service列表\n显示/usr/lib/firewalld/services/以及当前加载的自定义服务/etc/firewalld/services/, xml文件名必须是servicename.xml\nfirewall-cmd --get-services\n要包含未加载的自定义服务, 可以\nfirewall-cmd --permanent --get-services\n\n### panic mode\nfirewall-cmd --panic-on\nfirewall-cmd --panic-off\nfirewall-cmd --query-panic\n启用时打印yes返回0,否则打印no返回1\n如果panic模式持续时间不长, 已有的连接可能还可以继续工作\n\n### reload\nfirewall-cmd --reload\n\n如果想要重新加载并打断用户连接, 放弃状态信息, 使用如下命令\n这条命令只应在出现严重的防火墙问题时才使用, 比如防火墙规则没问题但是无法建立连接\nfirewall-cmd --complete-reload\n\n### 修改默认zone\nfirewall-cmd --set-default-zone=public\n不需要reload\n或编辑\n/etc/firewalld/firewalld.conf\n```none\n# default zone\n# The default zone used if an empty zone string is used.\n# Default: public\nDefaultZone=home\n```\n然后reload\nfirewall-cmd --reload\n\n## 使用XML文件配置firewall\nXML文件路径/etc/firewalld/\n/usr/lib/firewalld/zones/下的文件不要编辑,它们只在/etc/firewalld/zones/下没有对应文件时作为默认文件\n可以直接创建和修改xml文件或者使用图形和命令行工具间接创建和修改\n可以使用RPM文件分发配置文件以方便管理和版本控制, Puppet等工具可以用于分发这种配置文件\n\n## --direct选项\n如果不熟悉iptables, 使用--direct选项比较危险, 可能会给firewall打开一个裂口\n该模式用于在运行时添加特殊的防火墙规则\n通过firewall-cmd --permanent --direct命令或修改/etc/firewalld/direct.xml文件可以持久化\n\nfirewall-cmd --direct --add-rule ipv4 filter IN_public_allow 0 -m tcp -p tcp --dport 666 -j ACCEPT\nfirewall-cmd --direct --remove-rule ipv4 filter IN_public_allow 0 -m tcp -p tcp --dport 666 -j ACCEPT\nfirewall-cmd --direct --get-rules ipv4 filter IN_public_allow\n注意--get-rules只能获取通过--add-rule加上的规则, 不会列出既存的通过其他方式添加的iptables规则\n\n## Rich Language\nfirewall-cmd [--zone=zone] --add-rich-rule='rule' [--timeout=timeval]\nfirewall-cmd [--zone=zone] --remove-rich-rule='rule'\nfirewall-cmd [--zone=zone] --query-rich-rule='rule'\ntimeout选项表示仅在指定时间内有效(时间到即自动移除), 单位可以是s(秒), m(分)或h(时), 默认是秒\n```none\nrule [family=\"rule family\"]\n    [ source address=\"address\" [invert=\"True\"] ]\n    [ destination address=\"address\" [invert=\"True\"] ]\n    [ element ]\n    [ log [prefix=\"prefix text\"] [level=\"log level\"] [limit value=\"rate/duration\"] ]\n    [ audit ]\n    [ action ]\n```\n规则与zone关联, 一个zone可以有多条规则, 如果多条规则相关或冲突, 以第一条规则为准\n\n## 获取帮助\nman firewall-cmd 1\nman firewalld.icmptype 5\nman firewalld.service 5\nman firewalld.zone 5\nman firewalld.direct 5\nfirewall-cmd --version\nfirewall-cmd --help\n\n## 参考链接\nhttp://www.centoscn.com/CentOS/help/2015/0208/4667.html\nhttps://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Security_Guide/sec-Using_Firewalls.html\n\n","slug":"firewalld","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5m7007hmcxqckpct5he"},{"title":"firewalld与iptables, 记一次问题的解决","date":"2016-06-21T11:04:00.000Z","_content":"\n关掉firewalld之后有一个docker服务起不来了, 报错如下:\n```\n# docker-compose up -d shadowsocks\nCreating ss_server\n\nERROR: for shadowsocks  driver failed programming external connectivity on endpoint ss_server (ee95b8b78a095b2838b8e415a9e52d3807cdcec99f3486d7a9ce47101ee794f9): iptables failed: iptables --wait -t nat -A DOCKER -p tcp -d 0/0 --dport 8388 -j DNAT --to-destination 172.23.0.3:8388 ! -i br-d4333300e60a: iptables: No chain/target/match by that name.\n (exit status 1)\n Traceback (most recent call last):\n   File \"<string>\", line 3, in <module>\n     File \"compose/cli/main.py\", line 63, in main\n     AttributeError: 'ProjectError' object has no attribute 'msg'\n     docker-compose returned -1\n```\n启动firewalld之后问题解决\n\n个中缘由日后再深入挖掘...\n\n","source":"_posts/firewalld_iptables.md","raw":"title: firewalld与iptables, 记一次问题的解决\ndate: 2016-06-21 19:04:00\ntags: [linux, firewalld, iptables]\n---\n\n关掉firewalld之后有一个docker服务起不来了, 报错如下:\n```\n# docker-compose up -d shadowsocks\nCreating ss_server\n\nERROR: for shadowsocks  driver failed programming external connectivity on endpoint ss_server (ee95b8b78a095b2838b8e415a9e52d3807cdcec99f3486d7a9ce47101ee794f9): iptables failed: iptables --wait -t nat -A DOCKER -p tcp -d 0/0 --dport 8388 -j DNAT --to-destination 172.23.0.3:8388 ! -i br-d4333300e60a: iptables: No chain/target/match by that name.\n (exit status 1)\n Traceback (most recent call last):\n   File \"<string>\", line 3, in <module>\n     File \"compose/cli/main.py\", line 63, in main\n     AttributeError: 'ProjectError' object has no attribute 'msg'\n     docker-compose returned -1\n```\n启动firewalld之后问题解决\n\n个中缘由日后再深入挖掘...\n\n","slug":"firewalld_iptables","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5m8007kmcxqffhufwqk"},{"title":"浮点数","date":"2016-08-21T08:34:00.000Z","_content":"\n传说中邪恶的IEEE 754和著名的0.1 + 0.2 = 0.30000000000000004\n\n<!--more-->\n\n与定点数不同,浮点数面临的情形更复杂\n有0.0000000000000000000000001这样的, 也有10000000000000000000000000.0这样的\n取值范围广, 但是计算机资源有限, 想要省怎么办? 于是科学计数法上场\n上面两种情况用科学计数法分别为1.0e-25和1.0e25\n保存指数部分的25即可表示那么大的数和那么小的数\n\n32位(单精度)浮点数由1位符号位S, 8位指数位E和23位有效数字M组成\n64位(双精度)浮点数由1位符号位S,11位指数位E和52位有效数字M组成\n\n0.1 + 0.2 = 0.30000000000000004是因为误差积累,\n由于二进制无法精确表示1/5, 所以0.1和0.2都无法精确表示, 用了一个最接近的近似表示,\n加起来之后误差积累, 超过了可以忽略的误差, 就变成0.30000000000000004了\n想要避免这类误差问题可以使用decimal floating point, 或者fixed-point,\nhttps://en.wikipedia.org/wiki/Decimal_floating_point\n\n## 特殊规定\n\n有效数字M的取值范围是1≤M<2，也就是说，M可以写成1.xxxxxx的形式，其中xxxxxx表示小数部分。\nIEEE 754规定，在计算机内部保存M时，默认这个数的第一位总是1，因此可以被舍去，只保存后面的xxxxxx部分。\n比如保存1.01的时候，只保存01，等到读取的时候，再把第一位的1加上去。\n这样做的目的，是节省1位有效数字。以32位浮点数为例，留给M只有23位，将第一位的1舍去以后，等于可以保存24位有效数字。\n\n指数E为一个无符号整数（unsigned int）。这意味着，\n如果E为8位，它的取值范围为0~255； 如果E为11位，它的取值范围为0~2047。\n但是，我们知道，科学计数法中的E是可以出现负数的，\n所以IEEE 754规定，E的真实值必须再减去一个中间数，对于8位的E，这个中间数是127；对于11位的E，这个中间数是1023。\n比如，2^10的E是10，所以保存成32位浮点数时，必须保存成10+127=137，即10001001。\n然后，指数E还可以再分成三种情况：\n\n* E不全为0且不全为1\n这时浮点数就采用上面的规则表示，即指数E的计算值减去127（或1023），得到真实值，再将有效数字M前加上第一位的1。\n* E全为0\n这时浮点数的指数E等于1-127（或者1-1023），有效数字M不再加上第一位的1，而是还原为0.xxxxxx的小数。这样做是为了表示±0，以及接近于0的很小的数字。\n* E全为1\n这时，如果有效数字M全为0，表示±无穷大（正负取决于符号位s）；如果有效数字M不全为0，表示这个数不是一个数（NaN）。\n\n## 性能\n\nlua不用整型, 只用双精度浮点数, 据说这方面性能不成问题, 甚至还更好\nhttp://lua-users.org/wiki/FloatingPoint\n\n## 参考链接\nhttp://0.30000000000000004.com/\nhttp://www.ruanyifeng.com/blog/2010/06/ieee_floating-point_representation.html\n\n","source":"_posts/float.md","raw":"title: 浮点数\ndate: 2016-08-21 16:34:00\ntags: [cs]\n---\n\n传说中邪恶的IEEE 754和著名的0.1 + 0.2 = 0.30000000000000004\n\n<!--more-->\n\n与定点数不同,浮点数面临的情形更复杂\n有0.0000000000000000000000001这样的, 也有10000000000000000000000000.0这样的\n取值范围广, 但是计算机资源有限, 想要省怎么办? 于是科学计数法上场\n上面两种情况用科学计数法分别为1.0e-25和1.0e25\n保存指数部分的25即可表示那么大的数和那么小的数\n\n32位(单精度)浮点数由1位符号位S, 8位指数位E和23位有效数字M组成\n64位(双精度)浮点数由1位符号位S,11位指数位E和52位有效数字M组成\n\n0.1 + 0.2 = 0.30000000000000004是因为误差积累,\n由于二进制无法精确表示1/5, 所以0.1和0.2都无法精确表示, 用了一个最接近的近似表示,\n加起来之后误差积累, 超过了可以忽略的误差, 就变成0.30000000000000004了\n想要避免这类误差问题可以使用decimal floating point, 或者fixed-point,\nhttps://en.wikipedia.org/wiki/Decimal_floating_point\n\n## 特殊规定\n\n有效数字M的取值范围是1≤M<2，也就是说，M可以写成1.xxxxxx的形式，其中xxxxxx表示小数部分。\nIEEE 754规定，在计算机内部保存M时，默认这个数的第一位总是1，因此可以被舍去，只保存后面的xxxxxx部分。\n比如保存1.01的时候，只保存01，等到读取的时候，再把第一位的1加上去。\n这样做的目的，是节省1位有效数字。以32位浮点数为例，留给M只有23位，将第一位的1舍去以后，等于可以保存24位有效数字。\n\n指数E为一个无符号整数（unsigned int）。这意味着，\n如果E为8位，它的取值范围为0~255； 如果E为11位，它的取值范围为0~2047。\n但是，我们知道，科学计数法中的E是可以出现负数的，\n所以IEEE 754规定，E的真实值必须再减去一个中间数，对于8位的E，这个中间数是127；对于11位的E，这个中间数是1023。\n比如，2^10的E是10，所以保存成32位浮点数时，必须保存成10+127=137，即10001001。\n然后，指数E还可以再分成三种情况：\n\n* E不全为0且不全为1\n这时浮点数就采用上面的规则表示，即指数E的计算值减去127（或1023），得到真实值，再将有效数字M前加上第一位的1。\n* E全为0\n这时浮点数的指数E等于1-127（或者1-1023），有效数字M不再加上第一位的1，而是还原为0.xxxxxx的小数。这样做是为了表示±0，以及接近于0的很小的数字。\n* E全为1\n这时，如果有效数字M全为0，表示±无穷大（正负取决于符号位s）；如果有效数字M不全为0，表示这个数不是一个数（NaN）。\n\n## 性能\n\nlua不用整型, 只用双精度浮点数, 据说这方面性能不成问题, 甚至还更好\nhttp://lua-users.org/wiki/FloatingPoint\n\n## 参考链接\nhttp://0.30000000000000004.com/\nhttp://www.ruanyifeng.com/blog/2010/06/ieee_floating-point_representation.html\n\n","slug":"float","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5m9007mmcxqebxakiol"},{"title":"Functional","date":"2015-12-20T16:00:00.000Z","_content":"\n尽管函数式编程定义尚有争议, 有一些基本一致的观点\n\n<!--more-->\n• First-class函数, 可以接受函数作为参数或返回一个函数\n• 纯函数, 副作用一般指io, 读写全局变量的值这样的纯运算以外的操作, 纯函数更容易测试, 可读性更好\n• Pattern matching, 省去大量的check和取值的代码, 可读性更好\n• 惰性求值, 省去不必要的运算和io等, 其实许多运算都没有必要, 编译时不知道有没有必要, 根据运行时的情况, 有可能就变得没有必要\n• 递归, 许多人认为递归会影响性能并且可能栈溢出, 尾递归解决了这些问题\n• 不可变变量, 变量不可变, 意味着不会存在对外可见的中间状态, 也可以改善全局状态的更新问题, \n  我们知道变量不可变, 那么发现问题变量时就可以断定变量来自哪部分运算或来自参数传递, 这样调试更容易\n\n## Pure Functions\n\nNull为什么不好?\nNull使我们可以表示没有值,但是使用它会导致许多问题.\n比如我们调用函数getCustomerById得到一个返回值Null, \n调用方该怎么做? 这个Null表示出错了? 还是说没有找到值? 该不该有值? 接下去怎么办?\n考虑一下有多少地方需要做Null判定, 漏了一处就会有NullPointerException,\n每每想到这里我就会想到Haskell的Maybe类型, Clojure的Option类型, erlang的速错思想\n另外也有一个做法是返回一个空列表(适用于本来返回值就是列表的情况),\n这样对于上层来说是相同的,都是列表,只是有没有元素的区别\n\n## 消息传递\n减小了进程间的关联性, 收消息做运算, 运算完发完消息就跟本进程没关系了, \n减少了需要使用锁的场合, 于是提高了并发性\n\n## 没有空指针问题\n函数式编程的一点体会, 命令式编程里变量只是个名字,里面是什么值,有没有值都不好说,\n没有值是什么情况?空指针呗,没有分配内存空间才会这样,如果分配内存了就有值\n而函数式编程里变量就是值,不会再变,一定有值,不会是空指针,是什么值也是确定的\n\n","source":"_posts/functional.md","raw":"title: Functional\ndate: 2015-12-21\ntags: [programming]\n---\n\n尽管函数式编程定义尚有争议, 有一些基本一致的观点\n\n<!--more-->\n• First-class函数, 可以接受函数作为参数或返回一个函数\n• 纯函数, 副作用一般指io, 读写全局变量的值这样的纯运算以外的操作, 纯函数更容易测试, 可读性更好\n• Pattern matching, 省去大量的check和取值的代码, 可读性更好\n• 惰性求值, 省去不必要的运算和io等, 其实许多运算都没有必要, 编译时不知道有没有必要, 根据运行时的情况, 有可能就变得没有必要\n• 递归, 许多人认为递归会影响性能并且可能栈溢出, 尾递归解决了这些问题\n• 不可变变量, 变量不可变, 意味着不会存在对外可见的中间状态, 也可以改善全局状态的更新问题, \n  我们知道变量不可变, 那么发现问题变量时就可以断定变量来自哪部分运算或来自参数传递, 这样调试更容易\n\n## Pure Functions\n\nNull为什么不好?\nNull使我们可以表示没有值,但是使用它会导致许多问题.\n比如我们调用函数getCustomerById得到一个返回值Null, \n调用方该怎么做? 这个Null表示出错了? 还是说没有找到值? 该不该有值? 接下去怎么办?\n考虑一下有多少地方需要做Null判定, 漏了一处就会有NullPointerException,\n每每想到这里我就会想到Haskell的Maybe类型, Clojure的Option类型, erlang的速错思想\n另外也有一个做法是返回一个空列表(适用于本来返回值就是列表的情况),\n这样对于上层来说是相同的,都是列表,只是有没有元素的区别\n\n## 消息传递\n减小了进程间的关联性, 收消息做运算, 运算完发完消息就跟本进程没关系了, \n减少了需要使用锁的场合, 于是提高了并发性\n\n## 没有空指针问题\n函数式编程的一点体会, 命令式编程里变量只是个名字,里面是什么值,有没有值都不好说,\n没有值是什么情况?空指针呗,没有分配内存空间才会这样,如果分配内存了就有值\n而函数式编程里变量就是值,不会再变,一定有值,不会是空指针,是什么值也是确定的\n\n","slug":"functional","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5m9007pmcxqsiy8qze7"},{"title":"gcc code gen options","date":"2015-12-27T16:00:00.000Z","_content":"\n生成一个shared library(.so)往往要用到-fPIC, 这是什么意思呢?\n<!--more-->\n例如:\ngcc -fPIC -shared -o niftest.so niftest.c -I $ERL_ROOT/usr/include/\n\n-fPIC表示生成位置(地址)无关代码, 意味着生成的机器码不依赖于特定的位置(地址)\n例如: 跳转会以相对地址生成而不是绝对地址\n<pre>\nPIC:\n\n100: COMPARE REG1, REG2\n101: JUMP_IF_EQUAL CURRENT+10\n...\n111: NOP\n\nNon-PIC:\n\n100: COMPARE REG1, REG2\n101: JUMP_IF_EQUAL 111\n...\n111: NOP\n</pre>\n\n## 参考链接\nhttps://gcc.gnu.org/onlinedocs/gcc/Code-Gen-Options.html#Code-Gen-Options\nhttp://stackoverflow.com/questions/5311515/gcc-fpic-option\n\n","source":"_posts/gcc_code_gen_options.md","raw":"title: gcc code gen options\ndate: 2015-12-28\ntags: [c]\n---\n\n生成一个shared library(.so)往往要用到-fPIC, 这是什么意思呢?\n<!--more-->\n例如:\ngcc -fPIC -shared -o niftest.so niftest.c -I $ERL_ROOT/usr/include/\n\n-fPIC表示生成位置(地址)无关代码, 意味着生成的机器码不依赖于特定的位置(地址)\n例如: 跳转会以相对地址生成而不是绝对地址\n<pre>\nPIC:\n\n100: COMPARE REG1, REG2\n101: JUMP_IF_EQUAL CURRENT+10\n...\n111: NOP\n\nNon-PIC:\n\n100: COMPARE REG1, REG2\n101: JUMP_IF_EQUAL 111\n...\n111: NOP\n</pre>\n\n## 参考链接\nhttps://gcc.gnu.org/onlinedocs/gcc/Code-Gen-Options.html#Code-Gen-Options\nhttp://stackoverflow.com/questions/5311515/gcc-fpic-option\n\n","slug":"gcc_code_gen_options","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ma007rmcxqfjd75gj5"},{"title":"gedit","date":"2015-09-05T16:00:00.000Z","_content":"## 去掉gedit编辑文件时生成的临时文件\ngedit -> 编辑 -> 首选项 -> 编辑器 -> 在保存前创建备份文件\n\n\n","source":"_posts/gedit.md","raw":"title: gedit\ndate: 2015-09-06\ntags: [linux]\n---\n## 去掉gedit编辑文件时生成的临时文件\ngedit -> 编辑 -> 首选项 -> 编辑器 -> 在保存前创建备份文件\n\n\n","slug":"gedit","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mb007umcxq1aj3cxs6"},{"title":"gen_server:cast与erlang:send的区别","date":"2015-11-04T16:00:00.000Z","_content":"在Request前加了一个'$gen_cast'做为Tag,用于handle_cast,handle_info以及print_event时做区分\n在调用erlang:send前使用noconnect,\n如果需要connect,即会被阻塞一小会(连接目标结点),则spawn另一个进程来erlang:send以避免阻塞\nps: 只是noconnect并不是nosuspend,nosuspend会在port busy时放弃\n源码如下:\n```erlang\ncast({global,Name}, Request) ->                                                  \n    catch global:send(Name, cast_msg(Request)),                                  \n    ok;                                                                          \ncast({via, Mod, Name}, Request) ->                                               \n    catch Mod:send(Name, cast_msg(Request)),                                     \n    ok;                                                                          \ncast({Name,Node}=Dest, Request) when is_atom(Name), is_atom(Node) ->             \n    do_cast(Dest, Request);                                                      \ncast(Dest, Request) when is_atom(Dest) ->                                        \n    do_cast(Dest, Request);                                                      \ncast(Dest, Request) when is_pid(Dest) ->                                         \n    do_cast(Dest, Request).                                                      \n                                                                                 \ndo_cast(Dest, Request) ->                                                        \n    do_send(Dest, cast_msg(Request)),                                            \n    ok.                                                                          \n                                                                                 \ncast_msg(Request) -> {'$gen_cast',Request}.  \n\ndo_send(Dest, Msg) ->                                                            \n    case catch erlang:send(Dest, Msg, [noconnect]) of                            \n    noconnect ->                                                                 \n        spawn(erlang, send, [Dest,Msg]);                                         \n    Other ->                                                                     \n        Other                                                                    \n    end. \n```\n","source":"_posts/gen_server_cast.md","raw":"title: gen_server:cast与erlang:send的区别\ndate: 2015-11-05\ntags: [erlang]\n---\n在Request前加了一个'$gen_cast'做为Tag,用于handle_cast,handle_info以及print_event时做区分\n在调用erlang:send前使用noconnect,\n如果需要connect,即会被阻塞一小会(连接目标结点),则spawn另一个进程来erlang:send以避免阻塞\nps: 只是noconnect并不是nosuspend,nosuspend会在port busy时放弃\n源码如下:\n```erlang\ncast({global,Name}, Request) ->                                                  \n    catch global:send(Name, cast_msg(Request)),                                  \n    ok;                                                                          \ncast({via, Mod, Name}, Request) ->                                               \n    catch Mod:send(Name, cast_msg(Request)),                                     \n    ok;                                                                          \ncast({Name,Node}=Dest, Request) when is_atom(Name), is_atom(Node) ->             \n    do_cast(Dest, Request);                                                      \ncast(Dest, Request) when is_atom(Dest) ->                                        \n    do_cast(Dest, Request);                                                      \ncast(Dest, Request) when is_pid(Dest) ->                                         \n    do_cast(Dest, Request).                                                      \n                                                                                 \ndo_cast(Dest, Request) ->                                                        \n    do_send(Dest, cast_msg(Request)),                                            \n    ok.                                                                          \n                                                                                 \ncast_msg(Request) -> {'$gen_cast',Request}.  \n\ndo_send(Dest, Msg) ->                                                            \n    case catch erlang:send(Dest, Msg, [noconnect]) of                            \n    noconnect ->                                                                 \n        spawn(erlang, send, [Dest,Msg]);                                         \n    Other ->                                                                     \n        Other                                                                    \n    end. \n```\n","slug":"gen_server_cast","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mc007wmcxq8irxi6v7"},{"title":"母函数","date":"2016-08-10T16:00:00.000Z","_content":"\n暂时还没有完全明白,先写一半...\n\n<!--more-->\n\n下面这个多项式\n(1+x)^n = 1 + C(n,1)x + C(n,2)x^2 + ... + C(n,n)x^n\n1可以视为x^0, 即\n(x^0+x^1)^n = C(n,0)x^0 + C(n,1)x + C(n,2)x^2 + ... + C(n,n)x^n\n这样可以理解为, 有(x^0)和没有(x^1)这两种情况的n次组合\n\n系数即组合数,有些求组合的问题,就可以转换为求系数的问题,\n如1毛,2毛,5毛,6毛的硬币各一枚,找7毛钱有几种方案?\n(x^0+x^1)(x^0+x^2)(x^0+x^5)(x^0+x^6)\n=x^0 + x^1 + x^2 + x^3 + x^5 + 2x^6 + 2x^7 + 2x^8  + x^9 + x^11 + x^12 + x^13 + x^14\n即这四枚硬币各一枚可以组合成\n0毛有一个方案\n1毛有一个方案\n2毛有一个方案\n3毛有一个方案\n5毛有一个方案\n6毛有两个方案\n...\n1块4有一个方案\n如果是1毛硬币3枚,2毛硬币1枚,5毛硬币2枚,6毛硬币1枚,就可以如下表示\n(x^0+x^1)(x^0+x^1)(x^0+x^1)(x^0+x^2)(x^0+x^5)(x^0+x^5)(x^0+x^6)\n...\n但是这种表示法把3枚1毛硬币当成了不同的硬币处理,出来的方案数偏多..\n于是要把3枚1毛硬币同样处理的话,要这样表示\n(1 + x + x^2 + x^3)(1 + x^2)(1 + x^5 + x^10)(1 + x^6)\n即把内部的系数去掉了\n\n","source":"_posts/generating_function.md","raw":"title: 母函数\ndate: 2016-08-11\ntags: [algorithm]\n---\n\n暂时还没有完全明白,先写一半...\n\n<!--more-->\n\n下面这个多项式\n(1+x)^n = 1 + C(n,1)x + C(n,2)x^2 + ... + C(n,n)x^n\n1可以视为x^0, 即\n(x^0+x^1)^n = C(n,0)x^0 + C(n,1)x + C(n,2)x^2 + ... + C(n,n)x^n\n这样可以理解为, 有(x^0)和没有(x^1)这两种情况的n次组合\n\n系数即组合数,有些求组合的问题,就可以转换为求系数的问题,\n如1毛,2毛,5毛,6毛的硬币各一枚,找7毛钱有几种方案?\n(x^0+x^1)(x^0+x^2)(x^0+x^5)(x^0+x^6)\n=x^0 + x^1 + x^2 + x^3 + x^5 + 2x^6 + 2x^7 + 2x^8  + x^9 + x^11 + x^12 + x^13 + x^14\n即这四枚硬币各一枚可以组合成\n0毛有一个方案\n1毛有一个方案\n2毛有一个方案\n3毛有一个方案\n5毛有一个方案\n6毛有两个方案\n...\n1块4有一个方案\n如果是1毛硬币3枚,2毛硬币1枚,5毛硬币2枚,6毛硬币1枚,就可以如下表示\n(x^0+x^1)(x^0+x^1)(x^0+x^1)(x^0+x^2)(x^0+x^5)(x^0+x^5)(x^0+x^6)\n...\n但是这种表示法把3枚1毛硬币当成了不同的硬币处理,出来的方案数偏多..\n于是要把3枚1毛硬币同样处理的话,要这样表示\n(1 + x + x^2 + x^3)(1 + x^2)(1 + x^5 + x^10)(1 + x^6)\n即把内部的系数去掉了\n\n","slug":"generating_function","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5md007zmcxqi22gav3r"},{"title":"git","date":"2015-09-14T16:00:00.000Z","_content":"\nGit是分布式版本管理, 每个开发者都有代码库的完整copy,包括完整的历史记录\n\n<!--more-->\n\n## 概述\n\n每个Git代码库包含四个部分:\n* The working directory\n* The staging area\n* Committed history\n* Development branches\nstaging area在项目历史和工作目录之间,Git允许在提交修改之前将修改分组\n大多数开发者在专门的分支下工作,主干分支留给public release\n\ngit的每一个commit都保存完整的文件,而不是diff,\n这样读很快,因为具体的文件内容不需要从一开始慢慢按diff上溯\n\n## Stage and Commit\nstaging的意义在于将编码工作与版本控制分离,\n组织代码的变更为一个个有意义的commit, 而不是一个commit里有许多不相关的代码变更\n<pre>\n下面的命令会将删除操作加入stage并停止track该文件,但是不会删除工作区文件\ngit rm --cached <file>\n只显示已经stage的diff\ngit diff --cached\n提交代码时还是不要用-m\ngit commit\n这样会出一个编辑器,在里面多写几行注释\n</pre>\n\n## log\n\ngit log <since>..<until>\ngit log --stat\ngit log --oneline\n\n## tags\n\nTag是到commit的指针, 或者说别名\n<pre>\n新建tag\ngit tag -a v1.0 -m \"Stable release\"\n显示tag列表\ngit tag\n</pre>\n\n## 撤销变更\n\n最近一次提交叫做HEAD\n<pre>\nunstage单个文件\ngit reset HEAD <file>\nunstage全部代码\ngit reset HEAD\n将工作目录的代码恢复到HEAD, 本地的变更都会丢弃\ngit reset --hard HEAD\n强制删除没有纳入git管理的文件\ngit clean -f\n恢复单个文件到过去的某commit, 默认是HEAD\ngit checkout <commit> <file>\n退到HEAD之前一个版本\ngit reset HEAD~1\n删除commit在多人协作时可能会产生严重后果,\n其他人需要从被删除的commit之前开始将他们的commit一一合并过来,过程中很可能有许多冲突,\n所以不要reset公共commit(私人的无所谓)而是用一个新的commit盖掉不想要的commits\ngit revert <commit-id>\n修改最近一次commit\ngit commit --amend\n如果已经push到远程,可以考虑如下覆盖远程,可能会导致远程的commit变成垃圾,需要用git gc回收\ngit push origin +dev:dev\n</pre>\n\n## 分支\n\ngit的branch只是到commit的一个指针,不像svn会把整个目录拷贝一份\n<pre>\n查看本地分支列表及当前分支\ngit branch\n新建分支\ngit branch <name>\n删除分支\ngit branch -d <name>\n强行删除分支\ngit branch -D <name>\n切换分支\ngit checkout <branch>\n在detached HEAD state时(旧commit或远程分支)使用如下命令开辟实验分支\ngit checkout -b <new-branch-name>\n</pre>\n\n## 合并\n\nfast-forward 和 3-way merge\n<pre>\n切换分支并合并some-feature分支的内容\ngit checkout master\ngit merge some-feature\n由于merge会让history变乱,采用rebase是一个好主意,\n把当前分支的变更在现在master的基础上重做一遍\ngit checkout some-feature\ngit rebase maste\n交互式rebase, Interactive Rebasing\ngit rebase –i master\npick 58dec2a First commit for new feature\nsquash 6ac8a9f Second commit for new feature\n可以把多个commit squash(挤压)成一个commit\n</pre>\n由于rebase会把当前分支的这些commits都毁掉,把目标(比如master)的commits同步过来,然后再把刚刚毁掉的commits加上,所以commit的id变了,所以如果已经push到公共版本库,就不要再rebase了,以免影响到别人,就像reset命令一样.\n\n## 远程代码库(Remote Repositories)\n\n<pre>\nremote相当于书签,就是个网络地址,是为了让你少敲点键盘起的别名而已\ngit remote\ngit remote add <name> <path-to-repo>\ngit remote rm <remote-name>\n省略branch名表示所有分支全下载\ngit fetch <remote> <branch>\n显示远程分支列表\ngit branch -r\n可以checkout远程分支,不过是只读的\ngit checkout <remote>/<branch>\n这样看origin/master领先于master的log\ngit log master..origin/master\n将origin master的内容合并到当前分支\ngit merge origin/master\n但是这样会产生一条无意义的merge commit, 所以\ngit rebase origin/master\npull是fetch和merge的快捷方式\ngit pull origin/master\n也可以用--rebase选项表示rebase\ngit pull origin/master --rebase\n更新到远程代码库\ngit push <remote> <branch>\n初始化一个用于当公共代码库的git仓库\ngit init --bare some-repo.git\n这样没有.git目录,.git目录里的内容直接就在some-repo.git目录下\n</pre>\n\n## 中心化流程和分布式流程\n中心化流程下大家都直接在中心库上工作,不fork自己的repository\n这样的主要缺陷是每个人都需要有对中心库的写权限\n而大型开源项目不可能给每个人写权限,所以就走pull request那条路了\n\n## git config\n手动修改.gitconfig文件也行\n`--global`选项使得参数被存储在~/.gitconfig,即全局位置\n\nconfig示例\n\nUser Info\n<pre>\ngit config --global user.name \"John Smith\"\ngit config --global user.email john@example.com\n</pre>\nEditor\n<pre>\ngit config --global core.editor vim\n</pre>\nAliases(命令别名)\n<pre>\ngit config --global alias.st status\ngit config --global alias.ci commit\ngit config --global alias.co checkout\ngit config --global alias.br branch\n</pre>\n\ngit config --global push.default simple\n\n## 初始化\n> git init <path>\n\nGit代码库和普通目录之间的区别仅仅是有无.git目录\n\n## Cloning Repositories\n> git clone ssh://<user>@<host>/path/to/repo.git\n\n### 从https改为使用ssh\n\n这样就不用输密码了\n<pre>\ngit remote set-url origin git@github.com:USERNAME/REPOSITORY.git\n</pre>\n\n### 同步主干分支\n<pre>\ngit remote -v\ngit remote add upstream git@github.com:username/repository.git\ngit fetch upstream\ngit checkout master\ngit merge upstream/master\ngit push\n</pre>\n\n### 编译安装git\nhttps://git-scm.com/book/en/v2/Getting-Started-Installing-Git\n\n## 遇到的问题\n\n### docker container需要用到git功能时, ssh key是个问题吧, 不想把自己的私钥放vps上\ngithub可以绑定多个ssh key, 区分开来用, 可以给hexo专门弄一个, 每个版本库也可以单独绑定key\n叫做deploy key\nhttps://www.zybuluo.com/yangfch3/note/172120\n\n### 子模组(subproject)好坑, git add命令没有效果\n被坑了两次了,想着为什么git add命令无效呢?\n\n### git clone时报错如下:\n<pre>\nFailed to receive SOCKS4 connect request ack\n</pre>\n在用代理且代理挂了? git的代理在哪里设的?\n如下解决\n<pre>\n$ git config --global http.proxy 'socks5://127.0.0.1:1080'\n$ git config --global https.proxy 'socks5://127.0.0.1:1080'\n</pre>\n\n### git push时报错如下:\n<pre>\nerror: src refspec master does not match any.\n</pre>\n应该是没有commit就push了, 如下解决\n<pre>\ngit add .\ngit commit -m 'Initial Commit'\ngit push -u origin master\n</pre>\n\n参考链接\nhttp://stackoverflow.com/questions/4181861/src-refspec-master-does-not-match-any-when-pushing-commits-in-git\n\n","source":"_posts/git.md","raw":"title: git\ndate: 2015-09-15\ntags: versioncontrol\n---\n\nGit是分布式版本管理, 每个开发者都有代码库的完整copy,包括完整的历史记录\n\n<!--more-->\n\n## 概述\n\n每个Git代码库包含四个部分:\n* The working directory\n* The staging area\n* Committed history\n* Development branches\nstaging area在项目历史和工作目录之间,Git允许在提交修改之前将修改分组\n大多数开发者在专门的分支下工作,主干分支留给public release\n\ngit的每一个commit都保存完整的文件,而不是diff,\n这样读很快,因为具体的文件内容不需要从一开始慢慢按diff上溯\n\n## Stage and Commit\nstaging的意义在于将编码工作与版本控制分离,\n组织代码的变更为一个个有意义的commit, 而不是一个commit里有许多不相关的代码变更\n<pre>\n下面的命令会将删除操作加入stage并停止track该文件,但是不会删除工作区文件\ngit rm --cached <file>\n只显示已经stage的diff\ngit diff --cached\n提交代码时还是不要用-m\ngit commit\n这样会出一个编辑器,在里面多写几行注释\n</pre>\n\n## log\n\ngit log <since>..<until>\ngit log --stat\ngit log --oneline\n\n## tags\n\nTag是到commit的指针, 或者说别名\n<pre>\n新建tag\ngit tag -a v1.0 -m \"Stable release\"\n显示tag列表\ngit tag\n</pre>\n\n## 撤销变更\n\n最近一次提交叫做HEAD\n<pre>\nunstage单个文件\ngit reset HEAD <file>\nunstage全部代码\ngit reset HEAD\n将工作目录的代码恢复到HEAD, 本地的变更都会丢弃\ngit reset --hard HEAD\n强制删除没有纳入git管理的文件\ngit clean -f\n恢复单个文件到过去的某commit, 默认是HEAD\ngit checkout <commit> <file>\n退到HEAD之前一个版本\ngit reset HEAD~1\n删除commit在多人协作时可能会产生严重后果,\n其他人需要从被删除的commit之前开始将他们的commit一一合并过来,过程中很可能有许多冲突,\n所以不要reset公共commit(私人的无所谓)而是用一个新的commit盖掉不想要的commits\ngit revert <commit-id>\n修改最近一次commit\ngit commit --amend\n如果已经push到远程,可以考虑如下覆盖远程,可能会导致远程的commit变成垃圾,需要用git gc回收\ngit push origin +dev:dev\n</pre>\n\n## 分支\n\ngit的branch只是到commit的一个指针,不像svn会把整个目录拷贝一份\n<pre>\n查看本地分支列表及当前分支\ngit branch\n新建分支\ngit branch <name>\n删除分支\ngit branch -d <name>\n强行删除分支\ngit branch -D <name>\n切换分支\ngit checkout <branch>\n在detached HEAD state时(旧commit或远程分支)使用如下命令开辟实验分支\ngit checkout -b <new-branch-name>\n</pre>\n\n## 合并\n\nfast-forward 和 3-way merge\n<pre>\n切换分支并合并some-feature分支的内容\ngit checkout master\ngit merge some-feature\n由于merge会让history变乱,采用rebase是一个好主意,\n把当前分支的变更在现在master的基础上重做一遍\ngit checkout some-feature\ngit rebase maste\n交互式rebase, Interactive Rebasing\ngit rebase –i master\npick 58dec2a First commit for new feature\nsquash 6ac8a9f Second commit for new feature\n可以把多个commit squash(挤压)成一个commit\n</pre>\n由于rebase会把当前分支的这些commits都毁掉,把目标(比如master)的commits同步过来,然后再把刚刚毁掉的commits加上,所以commit的id变了,所以如果已经push到公共版本库,就不要再rebase了,以免影响到别人,就像reset命令一样.\n\n## 远程代码库(Remote Repositories)\n\n<pre>\nremote相当于书签,就是个网络地址,是为了让你少敲点键盘起的别名而已\ngit remote\ngit remote add <name> <path-to-repo>\ngit remote rm <remote-name>\n省略branch名表示所有分支全下载\ngit fetch <remote> <branch>\n显示远程分支列表\ngit branch -r\n可以checkout远程分支,不过是只读的\ngit checkout <remote>/<branch>\n这样看origin/master领先于master的log\ngit log master..origin/master\n将origin master的内容合并到当前分支\ngit merge origin/master\n但是这样会产生一条无意义的merge commit, 所以\ngit rebase origin/master\npull是fetch和merge的快捷方式\ngit pull origin/master\n也可以用--rebase选项表示rebase\ngit pull origin/master --rebase\n更新到远程代码库\ngit push <remote> <branch>\n初始化一个用于当公共代码库的git仓库\ngit init --bare some-repo.git\n这样没有.git目录,.git目录里的内容直接就在some-repo.git目录下\n</pre>\n\n## 中心化流程和分布式流程\n中心化流程下大家都直接在中心库上工作,不fork自己的repository\n这样的主要缺陷是每个人都需要有对中心库的写权限\n而大型开源项目不可能给每个人写权限,所以就走pull request那条路了\n\n## git config\n手动修改.gitconfig文件也行\n`--global`选项使得参数被存储在~/.gitconfig,即全局位置\n\nconfig示例\n\nUser Info\n<pre>\ngit config --global user.name \"John Smith\"\ngit config --global user.email john@example.com\n</pre>\nEditor\n<pre>\ngit config --global core.editor vim\n</pre>\nAliases(命令别名)\n<pre>\ngit config --global alias.st status\ngit config --global alias.ci commit\ngit config --global alias.co checkout\ngit config --global alias.br branch\n</pre>\n\ngit config --global push.default simple\n\n## 初始化\n> git init <path>\n\nGit代码库和普通目录之间的区别仅仅是有无.git目录\n\n## Cloning Repositories\n> git clone ssh://<user>@<host>/path/to/repo.git\n\n### 从https改为使用ssh\n\n这样就不用输密码了\n<pre>\ngit remote set-url origin git@github.com:USERNAME/REPOSITORY.git\n</pre>\n\n### 同步主干分支\n<pre>\ngit remote -v\ngit remote add upstream git@github.com:username/repository.git\ngit fetch upstream\ngit checkout master\ngit merge upstream/master\ngit push\n</pre>\n\n### 编译安装git\nhttps://git-scm.com/book/en/v2/Getting-Started-Installing-Git\n\n## 遇到的问题\n\n### docker container需要用到git功能时, ssh key是个问题吧, 不想把自己的私钥放vps上\ngithub可以绑定多个ssh key, 区分开来用, 可以给hexo专门弄一个, 每个版本库也可以单独绑定key\n叫做deploy key\nhttps://www.zybuluo.com/yangfch3/note/172120\n\n### 子模组(subproject)好坑, git add命令没有效果\n被坑了两次了,想着为什么git add命令无效呢?\n\n### git clone时报错如下:\n<pre>\nFailed to receive SOCKS4 connect request ack\n</pre>\n在用代理且代理挂了? git的代理在哪里设的?\n如下解决\n<pre>\n$ git config --global http.proxy 'socks5://127.0.0.1:1080'\n$ git config --global https.proxy 'socks5://127.0.0.1:1080'\n</pre>\n\n### git push时报错如下:\n<pre>\nerror: src refspec master does not match any.\n</pre>\n应该是没有commit就push了, 如下解决\n<pre>\ngit add .\ngit commit -m 'Initial Commit'\ngit push -u origin master\n</pre>\n\n参考链接\nhttp://stackoverflow.com/questions/4181861/src-refspec-master-does-not-match-any-when-pushing-commits-in-git\n\n","slug":"git","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5me0081mcxqb0f0mxqb"},{"title":"go语言槽点","date":"2016-07-19T13:27:00.000Z","_content":"\n想起一条写一条,\n之后尽量补上例子和理想的做法\n\n## 定义类型的地方允许x, y, z int这种写法表示x, y, z均为int型\n可读性不好\n\n## 没有重载\n许多package里看到大片的XXXInt, XXXInt64, XXXUint64, ...\n视觉污染, 写代码麻烦, 改代码也麻烦\n\n## defer\n* 可读性不好, 本身就已经颠覆了一般性的顺序执行思维, 写在前面, 执行却在后面,\n而且多条defer在一起还是LIFO顺序, 真是counter-intuitive,\n还是像其他语言那样try finally比较好, 或者像python, C#那样有with语句更好,\n* 容易引发bug, 因为defer可以修改return语句的值, 使得return语句处具有不确定性,\n使得程序员容易搞错\n\n## var, :=, =\n太容易出错了, 何必整这么多种, 而且a, b := xxx时, a, b中有一个未定义也合法, 简直dirty\n编译后经常报:=前面没有新变量,然后去改成=号,许多时间就浪费在这种事情上\n像python或erlang那样都是=对大家都好\n平白增加程序员需要处理的细节, 与go宣传的简单化背道而驰\n\n## 没有implement这样的关键字\n无意中就实现了某interface{},\n违背了程序员的意志,\n带来意想不到的问题\n\n## closure做得不对\n直接定义一个匿名函数,函数用到的外部变量并不是当时的变量快照,而是一个引用,\n想要真正的closure需要用传参来做.\nhttps://www.goinggo.net/2014/06/pitfalls-with-closures-in-go.html\n\n## 一个package可以对应多个文件\n函数定义还需要到别的文件里去找. import语句也重复了\n\n## 没有泛型\n\n## 返回error\n每一层函数调用都要check一遍,到处都充斥着if err != nil\n中间层函数只是因为调到了返回error的函数,自己的返回值也被迫加上error\n\n## 没有条件表达式\n\n当然这个不是什么致命伤,\n但是需要的时候发现go代码写起来巨麻烦,\n其实希望最好像函数式编程那样一切都是表达式,if或case等都能有一个返回值\n\n# 优点\n\n## gofmt\n虽然别的语言也可以一个插件搞定, 不过go这方面做得不错\n由于是官方提供的, 大家就统一了\n\n","source":"_posts/go_flaws.md","raw":"title: go语言槽点\ndate: 2016-07-19 21:27:00\ntags: go\n---\n\n想起一条写一条,\n之后尽量补上例子和理想的做法\n\n## 定义类型的地方允许x, y, z int这种写法表示x, y, z均为int型\n可读性不好\n\n## 没有重载\n许多package里看到大片的XXXInt, XXXInt64, XXXUint64, ...\n视觉污染, 写代码麻烦, 改代码也麻烦\n\n## defer\n* 可读性不好, 本身就已经颠覆了一般性的顺序执行思维, 写在前面, 执行却在后面,\n而且多条defer在一起还是LIFO顺序, 真是counter-intuitive,\n还是像其他语言那样try finally比较好, 或者像python, C#那样有with语句更好,\n* 容易引发bug, 因为defer可以修改return语句的值, 使得return语句处具有不确定性,\n使得程序员容易搞错\n\n## var, :=, =\n太容易出错了, 何必整这么多种, 而且a, b := xxx时, a, b中有一个未定义也合法, 简直dirty\n编译后经常报:=前面没有新变量,然后去改成=号,许多时间就浪费在这种事情上\n像python或erlang那样都是=对大家都好\n平白增加程序员需要处理的细节, 与go宣传的简单化背道而驰\n\n## 没有implement这样的关键字\n无意中就实现了某interface{},\n违背了程序员的意志,\n带来意想不到的问题\n\n## closure做得不对\n直接定义一个匿名函数,函数用到的外部变量并不是当时的变量快照,而是一个引用,\n想要真正的closure需要用传参来做.\nhttps://www.goinggo.net/2014/06/pitfalls-with-closures-in-go.html\n\n## 一个package可以对应多个文件\n函数定义还需要到别的文件里去找. import语句也重复了\n\n## 没有泛型\n\n## 返回error\n每一层函数调用都要check一遍,到处都充斥着if err != nil\n中间层函数只是因为调到了返回error的函数,自己的返回值也被迫加上error\n\n## 没有条件表达式\n\n当然这个不是什么致命伤,\n但是需要的时候发现go代码写起来巨麻烦,\n其实希望最好像函数式编程那样一切都是表达式,if或case等都能有一个返回值\n\n# 优点\n\n## gofmt\n虽然别的语言也可以一个插件搞定, 不过go这方面做得不错\n由于是官方提供的, 大家就统一了\n\n","slug":"go_flaws","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mf0084mcxqgyo7oinr"},{"title":"gnu screen 修改 tab 名称遇到自动跳回的问题和解决","date":"2019-12-20T03:28:00.000Z","_content":"\n需要在shell执行如下命令避免 tab 名称自动跳回\n```\nexport PROMPT_COMMAND=\n```\n然后再用 screen 快捷键 `Ctrl a A` 修改 tab 名称之后就不再跳回了\n\n","source":"_posts/gnu_screen_change_tab_name.md","raw":"title: gnu screen 修改 tab 名称遇到自动跳回的问题和解决\ndate: 2019-12-20 11:28:00\ntags: [linux, gnu, screen]\n---\n\n需要在shell执行如下命令避免 tab 名称自动跳回\n```\nexport PROMPT_COMMAND=\n```\n然后再用 screen 快捷键 `Ctrl a A` 修改 tab 名称之后就不再跳回了\n\n","slug":"gnu_screen_change_tab_name","published":1,"updated":"2019-12-20T03:32:32.061Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mg0086mcxqtt53gaji"},{"title":"围棋复盘1","date":"2018-10-09T16:00:00.000Z","_content":"\n* 厚势的运用\n* 死活\n* 官子\n* 计算不足导致的废棋\n* 过分\n* 补棋\n* 先手交换\n\n<!--more-->\n\n[sgf下载](/attachments/go_replay_sgf/1.sgf)\n\n![](/pics/go_replay1/1.png)\n厚势不围空\n![](/pics/go_replay1/2.png)\n围太大\n![](/pics/go_replay1/3.png)\n先手交换\n![](/pics/go_replay1/4.png)\n高效补棋\n![](/pics/go_replay1/5.png)\n确保连接\n![](/pics/go_replay1/6.png)\n过分的棋, 没有封到头\n![](/pics/go_replay1/7.png)\n又是过分的棋, 没有封到头\n![](/pics/go_replay1/8.png)\n该补的棋要补\n![](/pics/go_replay1/9.png)\n该补的棋要补\n![](/pics/go_replay1/10.png)\n大的死活没看到\n![](/pics/go_replay1/11.png)\n又是过分的棋, 没有封到头\n![](/pics/go_replay1/12.png)\n单官废棋与大场的交换\n![](/pics/go_replay1/13.png)\n过分\n![](/pics/go_replay1/14.png)\n死活没看到\n![](/pics/go_replay1/15.png)\n废棋\n![](/pics/go_replay1/16.png)\n废棋\n![](/pics/go_replay1/17.png)\n官子\n![](/pics/go_replay1/18.png)\n官子\n![](/pics/go_replay1/19.png)\n官子\n![](/pics/go_replay1/20.png)\n官子\n\n","source":"_posts/go_replay_1.md","raw":"title: 围棋复盘1\ndate: 2018-10-10\ntags: [go]\n---\n\n* 厚势的运用\n* 死活\n* 官子\n* 计算不足导致的废棋\n* 过分\n* 补棋\n* 先手交换\n\n<!--more-->\n\n[sgf下载](/attachments/go_replay_sgf/1.sgf)\n\n![](/pics/go_replay1/1.png)\n厚势不围空\n![](/pics/go_replay1/2.png)\n围太大\n![](/pics/go_replay1/3.png)\n先手交换\n![](/pics/go_replay1/4.png)\n高效补棋\n![](/pics/go_replay1/5.png)\n确保连接\n![](/pics/go_replay1/6.png)\n过分的棋, 没有封到头\n![](/pics/go_replay1/7.png)\n又是过分的棋, 没有封到头\n![](/pics/go_replay1/8.png)\n该补的棋要补\n![](/pics/go_replay1/9.png)\n该补的棋要补\n![](/pics/go_replay1/10.png)\n大的死活没看到\n![](/pics/go_replay1/11.png)\n又是过分的棋, 没有封到头\n![](/pics/go_replay1/12.png)\n单官废棋与大场的交换\n![](/pics/go_replay1/13.png)\n过分\n![](/pics/go_replay1/14.png)\n死活没看到\n![](/pics/go_replay1/15.png)\n废棋\n![](/pics/go_replay1/16.png)\n废棋\n![](/pics/go_replay1/17.png)\n官子\n![](/pics/go_replay1/18.png)\n官子\n![](/pics/go_replay1/19.png)\n官子\n![](/pics/go_replay1/20.png)\n官子\n\n","slug":"go_replay_1","published":1,"updated":"2018-10-11T13:40:43.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mh0089mcxq7dfkcl11"},{"title":"围棋复盘2","date":"2018-10-10T16:00:00.000Z","_content":"\n* 死活计算不足\n* 封头\n\n<!--more-->\n\n[sgf下载](/attachments/go_replay_sgf/2.sgf)\n\n![](/pics/go_replay2/1.png)\n计算力不足, 杀棋手段双方都没看到..\n![](/pics/go_replay2/2.png)\n封头\n![](/pics/go_replay2/3.png)\n封头\n![](/pics/go_replay2/4.png)\n封头\n![](/pics/go_replay2/5.png)\n计算力不足, 不该断, 应该连扳\n\n","source":"_posts/go_replay_2.md","raw":"title: 围棋复盘2\ndate: 2018-10-11\ntags: [go]\n---\n\n* 死活计算不足\n* 封头\n\n<!--more-->\n\n[sgf下载](/attachments/go_replay_sgf/2.sgf)\n\n![](/pics/go_replay2/1.png)\n计算力不足, 杀棋手段双方都没看到..\n![](/pics/go_replay2/2.png)\n封头\n![](/pics/go_replay2/3.png)\n封头\n![](/pics/go_replay2/4.png)\n封头\n![](/pics/go_replay2/5.png)\n计算力不足, 不该断, 应该连扳\n\n","slug":"go_replay_2","published":1,"updated":"2018-10-11T13:40:48.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mi008bmcxqrhonj20s"},{"title":"go语言 array与slice","date":"2016-08-14T13:27:00.000Z","_content":"\n深入看一下这两个家伙...\n\n<!--more-->\n\n### 长度与类型\narray的长度是类型的一部分,即长度不同的array不是一个类型,\nslice的类型则不包含长度\n\n    var a [4]int // 这样就分配了4个int的内存空间,\n    var b []int // 这是个nil的slice类型,没有分配内存\n\narray是immutable值类型\nslice不是\n\n### 字面值\n\narray字面值\n\n    b := [2]string{\"Penn\", \"Teller\"}\n    b := [...]string{\"Penn\", \"Teller\"}\n    s := b[:] // s引用b这个array\n    // 上面相当于s := []string{\"Penn\", \"Teller\"}\n\nslice字面值, 先分配一个array然后再引用这个array\n\n    letters := []string{\"a\", \"b\", \"c\", \"d\"}\n\n### make\n\nmake分配一个数组的内存和一个引用这个数组的slice并返回\n\n    var s []byte\n    s = make([]byte, 5, 5)\n    // 相当于s == []byte{0, 0, 0, 0, 0}\n\n对于nil的slice,len和cap函数都返回0\nvar p []int, 这种写法没有分配内存, 但是对这个p执行append是支持的, 所以推荐先这样定义p, 之后用for之类的赋值,\n如果for一次也没有执行,就省了内存了, 因为p := []int{}这样是要分配内存的\nhttps://github.com/golang/go/wiki/CodeReviewComments#declaring-empty-slices\n\nslice内部包含一个指向array某一个元素的指针和长度\n以及以此元素为起点的cap值. 类似于type Slice struct { p, len, cap }这种感觉\n所以len(slice)不需要遍历,是O(1)的\n\n可以像下面这样将slice扩展到末尾\n\n    s = s[:cap(s)]\n\n### append函数\n\n循环append时要小心,如果次数很多数量很大的话,可能会产生特别多内存碎片并都成为垃圾,\n加重gc负担,并且内存分配也很费,而且*2的扩展逻辑也可能造成最后一次分配了过多的内存.\n所以如果预先知道有多少元素或大概知道,最好在make的时候就指定好,性能差异很大.\n\n    file, err := os.Open(\"itsover.9000\")\n    if err != nil { ..handle .. }\n    defer file.Close()\n    stat, _ := file.Stat()\n    bytes := make([]byte, stat.Size())\n    file.Read(bytes)\n\n### copy函数\n\nappend里用到的copy内建函数\n\n    func copy(dst, src []T) int\n\ncopy函数会考虑长度,不会越界访问,可以安心\n\n### 当slice很小而背后的array很大,觉得浪费内存的时候\n\narray只要还被引用就不会被gc, 所以有时候像下面这样做省点内存\n\n    func CopyDigits(filename string) []byte {\n        b, _ := ioutil.ReadFile(filename)\n        b = digitRegexp.Find(b)\n        // 这种情况下b很小而背后的array(整个文件)很大, 像下面这样弄一个新数组返回\n        return append(make([]byte, 0), b...)\n    }\n","source":"_posts/go_slice.md","raw":"title: go语言 array与slice\ndate: 2016-08-14 21:27:00\ntags: go\n---\n\n深入看一下这两个家伙...\n\n<!--more-->\n\n### 长度与类型\narray的长度是类型的一部分,即长度不同的array不是一个类型,\nslice的类型则不包含长度\n\n    var a [4]int // 这样就分配了4个int的内存空间,\n    var b []int // 这是个nil的slice类型,没有分配内存\n\narray是immutable值类型\nslice不是\n\n### 字面值\n\narray字面值\n\n    b := [2]string{\"Penn\", \"Teller\"}\n    b := [...]string{\"Penn\", \"Teller\"}\n    s := b[:] // s引用b这个array\n    // 上面相当于s := []string{\"Penn\", \"Teller\"}\n\nslice字面值, 先分配一个array然后再引用这个array\n\n    letters := []string{\"a\", \"b\", \"c\", \"d\"}\n\n### make\n\nmake分配一个数组的内存和一个引用这个数组的slice并返回\n\n    var s []byte\n    s = make([]byte, 5, 5)\n    // 相当于s == []byte{0, 0, 0, 0, 0}\n\n对于nil的slice,len和cap函数都返回0\nvar p []int, 这种写法没有分配内存, 但是对这个p执行append是支持的, 所以推荐先这样定义p, 之后用for之类的赋值,\n如果for一次也没有执行,就省了内存了, 因为p := []int{}这样是要分配内存的\nhttps://github.com/golang/go/wiki/CodeReviewComments#declaring-empty-slices\n\nslice内部包含一个指向array某一个元素的指针和长度\n以及以此元素为起点的cap值. 类似于type Slice struct { p, len, cap }这种感觉\n所以len(slice)不需要遍历,是O(1)的\n\n可以像下面这样将slice扩展到末尾\n\n    s = s[:cap(s)]\n\n### append函数\n\n循环append时要小心,如果次数很多数量很大的话,可能会产生特别多内存碎片并都成为垃圾,\n加重gc负担,并且内存分配也很费,而且*2的扩展逻辑也可能造成最后一次分配了过多的内存.\n所以如果预先知道有多少元素或大概知道,最好在make的时候就指定好,性能差异很大.\n\n    file, err := os.Open(\"itsover.9000\")\n    if err != nil { ..handle .. }\n    defer file.Close()\n    stat, _ := file.Stat()\n    bytes := make([]byte, stat.Size())\n    file.Read(bytes)\n\n### copy函数\n\nappend里用到的copy内建函数\n\n    func copy(dst, src []T) int\n\ncopy函数会考虑长度,不会越界访问,可以安心\n\n### 当slice很小而背后的array很大,觉得浪费内存的时候\n\narray只要还被引用就不会被gc, 所以有时候像下面这样做省点内存\n\n    func CopyDigits(filename string) []byte {\n        b, _ := ioutil.ReadFile(filename)\n        b = digitRegexp.Find(b)\n        // 这种情况下b很小而背后的array(整个文件)很大, 像下面这样弄一个新数组返回\n        return append(make([]byte, 0), b...)\n    }\n","slug":"go_slice","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mj008emcxqx3clkyq0"},{"title":"围棋复盘3","date":"2018-10-11T16:00:00.000Z","_content":"\n* 计算力不足\n* 封头\n* 补棋\n* 先手交换\n\n<!--more-->\n\n[sgf下载](/attachments/go_replay_sgf/3.sgf)\n\n![](/pics/go_replay3/1.png)\n缓手\n![](/pics/go_replay3/2.png)\n应该先照顾弱子\n![](/pics/go_replay3/3.png)\n补棋\n![](/pics/go_replay3/4.png)\n补棋\n![](/pics/go_replay3/5.png)\n先手交换\n![](/pics/go_replay3/6.png)\n计算力不足\n![](/pics/go_replay3/7.png)\n计算力不足\n![](/pics/go_replay3/8.png)\n计算力不足\n![](/pics/go_replay3/9.png)\n缓手\n![](/pics/go_replay3/10.png)\n俗手\n![](/pics/go_replay3/11.png)\n先手交换\n![](/pics/go_replay3/12.png)\n恶手, 有接不归\n![](/pics/go_replay3/13.png)\n恶手, 送死一片\n\n","source":"_posts/go_replay_3.md","raw":"title: 围棋复盘3\ndate: 2018-10-12\ntags: [go]\n---\n\n* 计算力不足\n* 封头\n* 补棋\n* 先手交换\n\n<!--more-->\n\n[sgf下载](/attachments/go_replay_sgf/3.sgf)\n\n![](/pics/go_replay3/1.png)\n缓手\n![](/pics/go_replay3/2.png)\n应该先照顾弱子\n![](/pics/go_replay3/3.png)\n补棋\n![](/pics/go_replay3/4.png)\n补棋\n![](/pics/go_replay3/5.png)\n先手交换\n![](/pics/go_replay3/6.png)\n计算力不足\n![](/pics/go_replay3/7.png)\n计算力不足\n![](/pics/go_replay3/8.png)\n计算力不足\n![](/pics/go_replay3/9.png)\n缓手\n![](/pics/go_replay3/10.png)\n俗手\n![](/pics/go_replay3/11.png)\n先手交换\n![](/pics/go_replay3/12.png)\n恶手, 有接不归\n![](/pics/go_replay3/13.png)\n恶手, 送死一片\n\n","slug":"go_replay_3","published":1,"updated":"2018-10-12T14:50:23.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mk008gmcxq9hef4r2q"},{"title":"go语言测试","date":"2016-08-04T14:30:00.000Z","_content":"\n* 使用_test做为包名做黑盒测试, 使用import . xxx导入要测试的包, 有时为了打破循环引用也需要用这种方式\n* t.Skip(), 当检测到有些测试条件不满足时(比如外部依赖,环境变量没设等情况)可以跳过这个case\n* go test -short, TestCase里用testing.Short判断用户使用了-short参数时,可以做判断跳过耗时的case\n* go test -timeout 1s, 指定耗时, 超时就失败\n* go test -run TestNameRegexp 只执行指定的测试用例\n* t.Parallel() 标记为可以并行测试, 在Test case函数体一开始就调用\n\n## 参考链接\nhttps://splice.com/blog/lesser-known-features-go-test/\n\n","source":"_posts/go_test.md","raw":"title: go语言测试\ndate: 2016-08-04 22:30:00\ntags: [go]\n---\n\n* 使用_test做为包名做黑盒测试, 使用import . xxx导入要测试的包, 有时为了打破循环引用也需要用这种方式\n* t.Skip(), 当检测到有些测试条件不满足时(比如外部依赖,环境变量没设等情况)可以跳过这个case\n* go test -short, TestCase里用testing.Short判断用户使用了-short参数时,可以做判断跳过耗时的case\n* go test -timeout 1s, 指定耗时, 超时就失败\n* go test -run TestNameRegexp 只执行指定的测试用例\n* t.Parallel() 标记为可以并行测试, 在Test case函数体一开始就调用\n\n## 参考链接\nhttps://splice.com/blog/lesser-known-features-go-test/\n\n","slug":"go_test","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ml008jmcxqnbdui17v"},{"title":"go语言工具链","date":"2016-10-09T05:27:00.000Z","_content":"\n## 参考链接\nhttps://golang.org/cmd/link/\n\n","source":"_posts/go_tools.md","raw":"title: go语言工具链\ndate: 2016-10-09 13:27:00\ntags: go\n---\n\n## 参考链接\nhttps://golang.org/cmd/link/\n\n","slug":"go_tools","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mm008lmcxq6a5ndary"},{"title":"gogs","date":"2016-06-17T07:09:00.000Z","_content":"\n自己搭一个git server\ngogs与github有点不一样的地方, 坑了我...\n不过总体上gogs还是方便好用的\n<!--more-->\n\n## docker-compose\n```\ngogs:\n  image: gogs/gogs\n  container_name: gogs\n  ports:\n    - \"10022:22\"\n    - \"10080:3000\"\n  volumes:\n    - /root/gogs:/data\n```\n\n## 遇到的问题\n\n如下这样, 从https改到ssh,\n```\ngit remote set-url origin git@suexcxine.cc:10022/suexcxine/gogogo.git\n```\n测试ssh连接:\n```\n$ ssh -T -p 10022 git@suexcxine.cc\nHi there, You've successfully authenticated, but Gogs does not provide shell access.\nIf this is unexpected, please log in with password and setup Gogs under another user.\n```\ngithub这样是可以的, 但是git push时gogs却提示我输入git@suexcxine.cc的密码:\n```\ngit@suexcxine.cc's password: \n```\n无语, 查了许久, 原来要加上ssh://, 但是github确实是不需要的\n```\ngit remote set-url origin ssh://git@suexcxine.cc:10022/suexcxine/gogogo.git\n```\nclone也需要:\n```\ngit clone ssh://git@suexcxine.cc:10022/suexcxine/gogogo.git\n```\n\n","source":"_posts/gogs.md","raw":"title: gogs\ndate: 2016-06-17 15:09:00\ntags: versioncontrol\n---\n\n自己搭一个git server\ngogs与github有点不一样的地方, 坑了我...\n不过总体上gogs还是方便好用的\n<!--more-->\n\n## docker-compose\n```\ngogs:\n  image: gogs/gogs\n  container_name: gogs\n  ports:\n    - \"10022:22\"\n    - \"10080:3000\"\n  volumes:\n    - /root/gogs:/data\n```\n\n## 遇到的问题\n\n如下这样, 从https改到ssh,\n```\ngit remote set-url origin git@suexcxine.cc:10022/suexcxine/gogogo.git\n```\n测试ssh连接:\n```\n$ ssh -T -p 10022 git@suexcxine.cc\nHi there, You've successfully authenticated, but Gogs does not provide shell access.\nIf this is unexpected, please log in with password and setup Gogs under another user.\n```\ngithub这样是可以的, 但是git push时gogs却提示我输入git@suexcxine.cc的密码:\n```\ngit@suexcxine.cc's password: \n```\n无语, 查了许久, 原来要加上ssh://, 但是github确实是不需要的\n```\ngit remote set-url origin ssh://git@suexcxine.cc:10022/suexcxine/gogogo.git\n```\nclone也需要:\n```\ngit clone ssh://git@suexcxine.cc:10022/suexcxine/gogogo.git\n```\n\n","slug":"gogs","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mn008omcxq9gte3k07"},{"title":"graph theory","date":"2016-03-02T16:00:00.000Z","_content":"\n整理了一些图论基础知识和相关算法\n\n<!--more-->\n\n## 基本概念\n顶点,边,\n无向图,有向图,完全图,子图,连通图,非连通图,\n路径,路径长度,简单路径,回路,\n邻接,入度,出度\n\n## 表示法\n* 邻接矩阵, 用一个一维数组存放顶点数据;用一个二维数组存放边的数据，这个二维数组称为邻接矩阵。\n* 邻接表, 是一种顺序分配和链式分配相结合的存储结构。把每个结点的所有相邻结点都存放在一个单向链表里。\n\n## 深度优先搜索(Depth First Search)\n访问当前结点,记当前结点为已访问并递归访问当前结点的未访问邻接结点\n```c\nvoid traverse(int k, void (*visit)(int))\n{\n\t(*visit)(k);\n\tvisited[k] = 1;\n\tlink t;\n\tfor (t = adj[k]; t != NULL; t = t -> next) {\n\t\tif (! visited[t -> v]) traverse(t -> v, visit);\n\t}\n}\n```\n\n## 广度优先搜索(Breadth First Search)\n指定一个顶点,经过一条边进入另一个顶点后,继续进入下一个顶点,直到没有未访问的顶点\n再对其他边也这样做,直到没有未处理的边\n```c\nvoid traverse(int k, void (*visit)(int))\n{\n\tQUEUEinit();\n\tQUEUEput(k);\n\tlink t;\n\twhile(! QUEUEempty()) {\n\t\tif (! visited[k = QUEUEget()]) {\n\t\t\t(*visit)(k);\n\t\t\tvisited[k] = 1;\n\t\t\tfor (t = adj[k]; t != NULL; t = t -> next) {\n\t\t\t\tif (! visited[t -> v]) QUEUEput(t -> v);\n\t\t\t} \n\t\t} \n\t}\n}\n```\n\n## dijikstra算法(单源最短路径算法)\n感觉这个算法和动态规划找零钱的算法本质上相同,\n但是计算找零钱的时候用的是从1-N这样自底向上的遍历法,而dijikstra需要用另一种方式遍历(类似BFS)\n图上连着的结点表示可行,就像1元结点到4元结点有3元硬币这条路径可行而5元硬币不可行,\n即找零钱的问题也可以转换为如下图的最短路径问题, 路径权重均为1(因为都是1枚硬币), \n<pre>\n0元 -> 1元 -> 2元 -> 3元 -> 4元\n |--------------------^     ^\n        |-------------------|\n从0元到4元的单源最短路径为0元到1元再到4元,即一枚1元硬币和一枚3元硬币,路程为2最短\n</pre>\n\n```c\n#include <stdio.h>\n#include <limits.h>\n\n#define V 9\n\n// 找出未处理的结点中路径最短的\nint get_min_vertex(int dist[], int processed[])\n{\n\tint min = INT_MAX;\n\tint min_index;\n\tfor (int v = 0; v < V; v ++) {\n\t\tif (! processed[v] && dist[v] < min) {\n\t\t\tmin = dist[v];\n\t\t\tmin_index = v;\n\t\t}\n\t}\n\treturn min_index;\n}\n\nvoid dijikstra(int graph[V][V])\n{\n\tint dist[V];\n\tint processed[V];\n\t\n\tdist[0] = 0;\n\t\n\tint count;\n\tfor (count = 0; count < V; count ++) {\n\t\tint u = get_min_vertex(dist, processed);\n\t\t\n\t\t// 遍历邻接矩阵\n\t\tfor (int v = 0; v < V; v ++) {\n\t\t\tif (! processed[v] && graph[u][v] && \n\t\t\t\tdist[u] + graph[u][v] < dist[v]) {\n\t\t\t\tdist[v] = dist[u] + graph[u][v];\n\t\t\t}\n\t\t}\n\t\t\n\t\tprocessed[v] = 1;\n\t}\n}\n```\n## Floyd算法\n\n如果要让任意两点(例如从顶点a到顶点b)之间的路程变短，\n只能引入第三个点(顶点k)，并通过这个顶点k中转即a->k->b，才可能缩短原来从顶点a到顶点b的路程。\n```c\nfor (int i = 0; i <= n; i ++) {\n\tfor (int j = 0; j <= n, j ++) {\n\t\tfor (int k = 0; k <= n, k ++) {\n\t\t\tif (e[i][j] > e[i][k] + e[k][j])\n\t\t\t\te[i][j] = e[i][k] + e[k][j];\n\t\t}\t\n\t}\n}\n```\n## 树遍历 \n树是无环图\n\n* 前序preorder遍历, 节点->左子树->右子树\n* 中序inorder遍历, 左子树->节点->右子树\n* 后序postorder遍历, 左子树->右子树->节点\n* 层序levelorder遍历, 类似图的广度优先遍历\n\n#### 递归前序遍历\n```c\nvoid traverse(Node *node, void (*visit)(Node *))\n{\n\tif (node == NULL) return;\n\t(*visit)(node);\n\ttraverse(node -> left, visit);\n\ttraverse(node -> right, visit);\n}\n```\n\n#### 递归中序遍历\n```c\nvoid traverse(Node *node, void (*visit)(Node *))\n{\n\tif (node == NULL) return;\n\ttraverse(node -> left, visit);\n\t(*visit)(node);\n\ttraverse(node -> right, visit);\n}\n```\n#### 递归后序遍历\n```c\nvoid traverse(Node *node, void (*visit)(Node *))\n{\n\tif (node == NULL) return;\n\ttraverse(node -> left, visit);\n\ttraverse(node -> right, visit);\n\t(*visit)(node);\n}\n```\n#### 非递归的前序遍历\n```c\nvoid traverse(Node *node, void (*visit)(Node *))\n{\n\tif (node == NULL) return;\n\tSTACKinit(max);\n\tSTACKpush(node);\n\twhile (! STACKempty())\n\t{\n\t\t(*visit)(node = STACKpop());\n\t\tif (node -> right != NULL) STACKpush(node -> right);\n\t\tif (node -> left != NULL) STACKpush(node -> left);\n\t}\n}\n```\n\n## 拓扑排序\n对一个有向无环图(Directed Acyclic Graph简称DAG)G进行拓扑排序，\n是将G中所有顶点排成一个线性序列，使得图中任意一对顶点u和v，若边(u,v)∈E(G)，则u在线性序列中出现在v之前。\n通常，这样的线性序列称为满足拓扑次序(Topological Order)的序列，简称拓扑序列。\n简单的说，由某个集合上的一个偏序得到该集合上的一个全序，这个操作称之为拓扑排序。\n\n拓扑排序通常用来处理具有依赖关系的任务。\n如有先修课要求的课程,任务A开始之前任务B必须已完成等。\n\n算法思路:\n用一个队列存储返回值\n找出入度为0的结点放入队列\n从队列取出一个,打印出来,并将该结点的邻结点的入度-1,如果-1后为0则放入队列,循环该处理\n \n## 最小生成树(Minimum-Cost Spannning Tree)\n\n遍历的路径就是一个树, 如深度优先生成树, 广度优先生成树\n而最小生成树是指有权重的图中总权重最小的生成树\n\n算法思路:\n将各边按权值从小到大排序,\n只要不会形成环, 就逐一加入边, 直到所有的点都已经连接上\n如何检查环?如果一条边的两个顶点同属于某一个集合(已经连接起来的顶点们),就会形成环,\n即lists:any(fun(Set) -> lists:member(A, Set) andalso lists:member(B, Set) end, sets:to_list(Sets)).\n","source":"_posts/graph_theory.md","raw":"title: graph theory\ndate: 2016-03-03\ntags: [algorithm]\n---\n\n整理了一些图论基础知识和相关算法\n\n<!--more-->\n\n## 基本概念\n顶点,边,\n无向图,有向图,完全图,子图,连通图,非连通图,\n路径,路径长度,简单路径,回路,\n邻接,入度,出度\n\n## 表示法\n* 邻接矩阵, 用一个一维数组存放顶点数据;用一个二维数组存放边的数据，这个二维数组称为邻接矩阵。\n* 邻接表, 是一种顺序分配和链式分配相结合的存储结构。把每个结点的所有相邻结点都存放在一个单向链表里。\n\n## 深度优先搜索(Depth First Search)\n访问当前结点,记当前结点为已访问并递归访问当前结点的未访问邻接结点\n```c\nvoid traverse(int k, void (*visit)(int))\n{\n\t(*visit)(k);\n\tvisited[k] = 1;\n\tlink t;\n\tfor (t = adj[k]; t != NULL; t = t -> next) {\n\t\tif (! visited[t -> v]) traverse(t -> v, visit);\n\t}\n}\n```\n\n## 广度优先搜索(Breadth First Search)\n指定一个顶点,经过一条边进入另一个顶点后,继续进入下一个顶点,直到没有未访问的顶点\n再对其他边也这样做,直到没有未处理的边\n```c\nvoid traverse(int k, void (*visit)(int))\n{\n\tQUEUEinit();\n\tQUEUEput(k);\n\tlink t;\n\twhile(! QUEUEempty()) {\n\t\tif (! visited[k = QUEUEget()]) {\n\t\t\t(*visit)(k);\n\t\t\tvisited[k] = 1;\n\t\t\tfor (t = adj[k]; t != NULL; t = t -> next) {\n\t\t\t\tif (! visited[t -> v]) QUEUEput(t -> v);\n\t\t\t} \n\t\t} \n\t}\n}\n```\n\n## dijikstra算法(单源最短路径算法)\n感觉这个算法和动态规划找零钱的算法本质上相同,\n但是计算找零钱的时候用的是从1-N这样自底向上的遍历法,而dijikstra需要用另一种方式遍历(类似BFS)\n图上连着的结点表示可行,就像1元结点到4元结点有3元硬币这条路径可行而5元硬币不可行,\n即找零钱的问题也可以转换为如下图的最短路径问题, 路径权重均为1(因为都是1枚硬币), \n<pre>\n0元 -> 1元 -> 2元 -> 3元 -> 4元\n |--------------------^     ^\n        |-------------------|\n从0元到4元的单源最短路径为0元到1元再到4元,即一枚1元硬币和一枚3元硬币,路程为2最短\n</pre>\n\n```c\n#include <stdio.h>\n#include <limits.h>\n\n#define V 9\n\n// 找出未处理的结点中路径最短的\nint get_min_vertex(int dist[], int processed[])\n{\n\tint min = INT_MAX;\n\tint min_index;\n\tfor (int v = 0; v < V; v ++) {\n\t\tif (! processed[v] && dist[v] < min) {\n\t\t\tmin = dist[v];\n\t\t\tmin_index = v;\n\t\t}\n\t}\n\treturn min_index;\n}\n\nvoid dijikstra(int graph[V][V])\n{\n\tint dist[V];\n\tint processed[V];\n\t\n\tdist[0] = 0;\n\t\n\tint count;\n\tfor (count = 0; count < V; count ++) {\n\t\tint u = get_min_vertex(dist, processed);\n\t\t\n\t\t// 遍历邻接矩阵\n\t\tfor (int v = 0; v < V; v ++) {\n\t\t\tif (! processed[v] && graph[u][v] && \n\t\t\t\tdist[u] + graph[u][v] < dist[v]) {\n\t\t\t\tdist[v] = dist[u] + graph[u][v];\n\t\t\t}\n\t\t}\n\t\t\n\t\tprocessed[v] = 1;\n\t}\n}\n```\n## Floyd算法\n\n如果要让任意两点(例如从顶点a到顶点b)之间的路程变短，\n只能引入第三个点(顶点k)，并通过这个顶点k中转即a->k->b，才可能缩短原来从顶点a到顶点b的路程。\n```c\nfor (int i = 0; i <= n; i ++) {\n\tfor (int j = 0; j <= n, j ++) {\n\t\tfor (int k = 0; k <= n, k ++) {\n\t\t\tif (e[i][j] > e[i][k] + e[k][j])\n\t\t\t\te[i][j] = e[i][k] + e[k][j];\n\t\t}\t\n\t}\n}\n```\n## 树遍历 \n树是无环图\n\n* 前序preorder遍历, 节点->左子树->右子树\n* 中序inorder遍历, 左子树->节点->右子树\n* 后序postorder遍历, 左子树->右子树->节点\n* 层序levelorder遍历, 类似图的广度优先遍历\n\n#### 递归前序遍历\n```c\nvoid traverse(Node *node, void (*visit)(Node *))\n{\n\tif (node == NULL) return;\n\t(*visit)(node);\n\ttraverse(node -> left, visit);\n\ttraverse(node -> right, visit);\n}\n```\n\n#### 递归中序遍历\n```c\nvoid traverse(Node *node, void (*visit)(Node *))\n{\n\tif (node == NULL) return;\n\ttraverse(node -> left, visit);\n\t(*visit)(node);\n\ttraverse(node -> right, visit);\n}\n```\n#### 递归后序遍历\n```c\nvoid traverse(Node *node, void (*visit)(Node *))\n{\n\tif (node == NULL) return;\n\ttraverse(node -> left, visit);\n\ttraverse(node -> right, visit);\n\t(*visit)(node);\n}\n```\n#### 非递归的前序遍历\n```c\nvoid traverse(Node *node, void (*visit)(Node *))\n{\n\tif (node == NULL) return;\n\tSTACKinit(max);\n\tSTACKpush(node);\n\twhile (! STACKempty())\n\t{\n\t\t(*visit)(node = STACKpop());\n\t\tif (node -> right != NULL) STACKpush(node -> right);\n\t\tif (node -> left != NULL) STACKpush(node -> left);\n\t}\n}\n```\n\n## 拓扑排序\n对一个有向无环图(Directed Acyclic Graph简称DAG)G进行拓扑排序，\n是将G中所有顶点排成一个线性序列，使得图中任意一对顶点u和v，若边(u,v)∈E(G)，则u在线性序列中出现在v之前。\n通常，这样的线性序列称为满足拓扑次序(Topological Order)的序列，简称拓扑序列。\n简单的说，由某个集合上的一个偏序得到该集合上的一个全序，这个操作称之为拓扑排序。\n\n拓扑排序通常用来处理具有依赖关系的任务。\n如有先修课要求的课程,任务A开始之前任务B必须已完成等。\n\n算法思路:\n用一个队列存储返回值\n找出入度为0的结点放入队列\n从队列取出一个,打印出来,并将该结点的邻结点的入度-1,如果-1后为0则放入队列,循环该处理\n \n## 最小生成树(Minimum-Cost Spannning Tree)\n\n遍历的路径就是一个树, 如深度优先生成树, 广度优先生成树\n而最小生成树是指有权重的图中总权重最小的生成树\n\n算法思路:\n将各边按权值从小到大排序,\n只要不会形成环, 就逐一加入边, 直到所有的点都已经连接上\n如何检查环?如果一条边的两个顶点同属于某一个集合(已经连接起来的顶点们),就会形成环,\n即lists:any(fun(Set) -> lists:member(A, Set) andalso lists:member(B, Set) end, sets:to_list(Sets)).\n","slug":"graph_theory","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mn008qmcxqxuvvnx9k"},{"title":"go语言编码规范","date":"2016-08-02T14:30:00.000Z","_content":"\n编码规范统一,很有必要\n\n<!--more-->\n\n* 注释要用完整的句子,以函数名开头,以逗号结束,这样比较好排,可读性也好,也方便grep文档.\n\n* 定义空slice时,用var t []string而不是t := []string{},在这个slice不被append时,前者不占用内存.\n\n* 导出函数均应有注释.\n\n* error string不要以大写开头,除非是缩略词等,且不要以标点结束,以免printf时前面有大写时又出现多余的大写和标点位置不合适等情况.\n\n* import . <packagename> 这种语法除了测试的场景以外不要用.\n\n* 先写异常逻辑,后写正常逻辑,尽量不要让正常逻辑缩进,而让异常逻辑缩进,这样可读性好.方便阅读正常逻辑.\n```\nif err != nil {\n    // error handling\n    return // or continue, etc.\n}\n// normal code\n```\n\n* 尽量不要在if里赋值\n```\nif x, err := f(); err != nil {\n    // error handling\n    return\n} else {\n    // use x\n}\n```\n改为\n```\nx, err := f()\nif err != nil {\n    // error handling\n    return\n}\n// use x\n```\n\n* 缩略词要大小写一致,HTTP或http,不要Http, ServeHTTP而不是ServeHttp.\n\n* 一行不要太长,没有严格标准,稍长一点可读性好时无须强行改短.\n\n* 返回值参数命名,如果有相同类型的,最好命个名可读性好一些.\n\n* 不使用裸return.\n\n* 不大的参数尽量用值传递.\n\n* receive命名,不要使用me,self,this等通用词,可读性不好,用一两字母,如c表示Client.\n\n* receive type,大致上不变类型或基本类型用值类型,否则用指针类型.特殊情况除外.\n\n* Test Case失败应该给出input,output和expect的值,要不然不明不白,先写output再写expect.\n```\nif got != tt.want {\n    t.Errorf(\"Foo(%q) = %d; want %d\", tt.in, got, tt.want)\n}\n```\n\n* 变量名采用驼峰标准，不要使用_来命名变量名.\n\n* 错误处理的原则就是不能丢弃任何有返回err的调用，不要采用_丢弃，必须全部处理.\n\n## 参考链接\nhttps://github.com/golang/go/wiki/CodeReviewComments\n\n","source":"_posts/go_style.md","raw":"title: go语言编码规范\ndate: 2016-08-02 22:30:00\ntags: [go]\n---\n\n编码规范统一,很有必要\n\n<!--more-->\n\n* 注释要用完整的句子,以函数名开头,以逗号结束,这样比较好排,可读性也好,也方便grep文档.\n\n* 定义空slice时,用var t []string而不是t := []string{},在这个slice不被append时,前者不占用内存.\n\n* 导出函数均应有注释.\n\n* error string不要以大写开头,除非是缩略词等,且不要以标点结束,以免printf时前面有大写时又出现多余的大写和标点位置不合适等情况.\n\n* import . <packagename> 这种语法除了测试的场景以外不要用.\n\n* 先写异常逻辑,后写正常逻辑,尽量不要让正常逻辑缩进,而让异常逻辑缩进,这样可读性好.方便阅读正常逻辑.\n```\nif err != nil {\n    // error handling\n    return // or continue, etc.\n}\n// normal code\n```\n\n* 尽量不要在if里赋值\n```\nif x, err := f(); err != nil {\n    // error handling\n    return\n} else {\n    // use x\n}\n```\n改为\n```\nx, err := f()\nif err != nil {\n    // error handling\n    return\n}\n// use x\n```\n\n* 缩略词要大小写一致,HTTP或http,不要Http, ServeHTTP而不是ServeHttp.\n\n* 一行不要太长,没有严格标准,稍长一点可读性好时无须强行改短.\n\n* 返回值参数命名,如果有相同类型的,最好命个名可读性好一些.\n\n* 不使用裸return.\n\n* 不大的参数尽量用值传递.\n\n* receive命名,不要使用me,self,this等通用词,可读性不好,用一两字母,如c表示Client.\n\n* receive type,大致上不变类型或基本类型用值类型,否则用指针类型.特殊情况除外.\n\n* Test Case失败应该给出input,output和expect的值,要不然不明不白,先写output再写expect.\n```\nif got != tt.want {\n    t.Errorf(\"Foo(%q) = %d; want %d\", tt.in, got, tt.want)\n}\n```\n\n* 变量名采用驼峰标准，不要使用_来命名变量名.\n\n* 错误处理的原则就是不能丢弃任何有返回err的调用，不要采用_丢弃，必须全部处理.\n\n## 参考链接\nhttps://github.com/golang/go/wiki/CodeReviewComments\n\n","slug":"go_style","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mo008smcxq4kxg7zxu"},{"title":"grep","date":"2015-09-05T16:00:00.000Z","_content":"## 开发目录下写一个脚本叫g, 用起grep来方便一点\ngrep -rn $@ . --exclude=tags --exclude-dir=.svn | grep -v \"匹配到二进制文件\"\n\n","source":"_posts/grep.md","raw":"title: grep \ndate: 2015-09-06\ntags: linux\n---\n## 开发目录下写一个脚本叫g, 用起grep来方便一点\ngrep -rn $@ . --exclude=tags --exclude-dir=.svn | grep -v \"匹配到二进制文件\"\n\n","slug":"grep","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mp008vmcxqg3cuady3"},{"title":"grub","date":"2015-08-05T16:00:00.000Z","_content":"sudo update-grub\n\n","source":"_posts/grub.md","raw":"title: grub\ndate: 2015-08-06\ntags: linux\n---\nsudo update-grub\n\n","slug":"grub","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mq008xmcxq49o4d0k4"},{"title":"坎坷之路 Hasee和linux的内核","date":"2016-09-03T06:01:00.000Z","_content":"\n今天弹出一个升级框，天真地点了下去。悲剧发生了。电脑启动不了了。\n本来都打算换电脑了。试了一下grub里显示的ubuntu的其他选项。\n里面有各种内核版本的普通mode和safe mode。\n于是选了旧的3.19版本，\n启动成功！喜悦！\n\n<!--more-->\n\n这次是升级到了ubuntu 14.04.5, 看来换4.4内核(linux-headers-4.4.0-36-generic)了\n之前装16.04装不了也是相同的症状, 看来就是我手里这台Hasee的硬件问题了。\n另外为了避免以后每次启动都要从其他选项里进ubuntu，下面记录怎么删不要的内核版本。\n\n```\nuname -r # 查看当前使用的内核版本, 这个版本不要删哦\ndpkg --list | grep linux-image # 查看已经安装的内核版本\nsudo apt-get purge linux-image-x.x.x.x-generic\nsudo update-grub2 # 更新grub2\n```\n\n## 参考链接\nhttp://askubuntu.com/questions/2793/how-do-i-remove-old-kernel-versions-to-clean-up-the-boot-menu\n\n","source":"_posts/hasee_linux_kernel_problem.md","raw":"title: 坎坷之路 Hasee和linux的内核\ndate: 2016-09-03 14:01:00\ntags: linux\n---\n\n今天弹出一个升级框，天真地点了下去。悲剧发生了。电脑启动不了了。\n本来都打算换电脑了。试了一下grub里显示的ubuntu的其他选项。\n里面有各种内核版本的普通mode和safe mode。\n于是选了旧的3.19版本，\n启动成功！喜悦！\n\n<!--more-->\n\n这次是升级到了ubuntu 14.04.5, 看来换4.4内核(linux-headers-4.4.0-36-generic)了\n之前装16.04装不了也是相同的症状, 看来就是我手里这台Hasee的硬件问题了。\n另外为了避免以后每次启动都要从其他选项里进ubuntu，下面记录怎么删不要的内核版本。\n\n```\nuname -r # 查看当前使用的内核版本, 这个版本不要删哦\ndpkg --list | grep linux-image # 查看已经安装的内核版本\nsudo apt-get purge linux-image-x.x.x.x-generic\nsudo update-grub2 # 更新grub2\n```\n\n## 参考链接\nhttp://askubuntu.com/questions/2793/how-do-i-remove-old-kernel-versions-to-clean-up-the-boot-menu\n\n","slug":"hasee_linux_kernel_problem","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mr0090mcxqqf4o949b"},{"title":"Haskell Applicative","date":"2016-01-21T16:00:00.000Z","_content":"\nApplicative Functor允许Functor的链式调用\n<!--more-->\n\n## Applicative Functor\nControl.Applicative模块\n```haskell\nclass (Functor f) => Applicative f where\n    pure :: a -> f a\n    (<*>) :: f (a -> b) -> f a -> f b\n```\npure将一个值包装到一个最简单的(默认或者说最小)环境里\n<*>可以使用环境里的函数处理另一个环境\n\n### Maybe\n```haskell\ninstance Applicative Maybe where\n    pure = Just\n    Nothing <*> _ = Nothing\n    (Just f) <*> something = fmap f something\n```\n\n### Maybe Applicative 链式调用\n```haskell\n(<$>) :: (Functor f) => (a -> b) -> f a -> f b\nf <$> x = fmap f x\n\nghci> pure (+) <*> Just 3 <*> Just 5\nghci> fmap (+) Just 3 <*> Just 5\nghci> (+) <$> Just 3 <*> Just 5\nJust 8\n```\n这种方式使我们不需要理会环境,直接处理环境内的值\n\n### List\n```haskell\ninstance Applicative [] where\n    pure x = [x]\n    fs <*> xs = [f x | f <- fs, x <- xs] 笛卡尔积\n```\n```haskell\nghci> [(+),(*)] <*> [1,2] <*> [3,4]\n[4,5,5,6,3,4,6,8]\nghci> (++) <$> [\"ha\",\"heh\",\"hmm\"] <*> [\"?\",\"!\",\".\"]\n[\"ha?\",\"ha!\",\"ha.\",\"heh?\",\"heh!\",\"heh.\",\"hmm?\",\"hmm!\",\"hmm.\"]\n```\n\n使用applicative style取代list comprehension\n```haskell\nghci> [ x*y | x <- [2,5,10], y <- [8,10,11]]\n[16,20,22,40,50,55,80,100,110]\nghci> (*) <$> [2,5,10] <*> [8,10,11]\n[16,20,22,40,50,55,80,100,110]\n```\n这里好像可以得出这样一个结论,\n那就是Haskell在尽可能地消除变量\n上面的例子里x,y都没有了,只有行为和数据\n\n### IO也是applicative functor\n\n### function也是applicative functor\n```haskell\ninstance Applicative ((->) r) where\n    pure x = (\\_ -> x)\n    f <*> g = \\x -> f x (g x)\n```\n\n```haskell\nghci> (+) <$> (+3) <*> (*100) $ 5\nghci> fmap (+) (+3) <*> (*100) $ 5\nghci> ((+) . (+3)) <*> (*100) $ 5\n((+) . (+3)) $ 5 即(\\x -> (+(x+3))) $ 5的结果是 (+8)\n按照<*>的定义, 继续化简为\nghci> (\\x -> ((+) . (+3)) x ((*100) x)) $ 5\nghci> (+8) (5*100)\nghci> (+8)  500\n508\n```\n```haskell\nghci> (\\x y z -> [x,y,z]) <$> (+3) <*> (*2) <*> (/2) $ 5\nghci> (\\x y z -> [x+3,y,z]) <*> (*2) <*> (/2) $ 5\n按照<*>的定义,第一元不变,将第二元改为使用第一元调用(*2),即\nghci> (\\x z -> [x+3,x*2,z]) <*> (/2) $ 5\nghci> (\\x -> [x+3,x*2,x/2]) $ 5\n[8.0,10.0,2.5]\n```\n\n<\\$\\>左边的得是一个二(N,右边有N个一元函数的情况)元函数,即函数的函数,即函数在一个环境(这个环境恰好也是一个函数)里\n每执行一个<$>或<*>就减一元,到最后只剩一元(即前面的几个函数合成成的新函数,根据curry化,一元就是N元)\n最后接受一个参数可得结果,\n所以function使用applicative的效果依然是类似function composition\n\n本以为函数的applicative会定义成这样\n```haskell\ninstance Applicative ((->) r) where\n    pure x = (\\_ -> x)\n    f <*> g = \\x y -> f x (g y)\n```\n这样元数不会减少, 但是就只对二元函数有用了,\n不如官方的定义有用吧\n<*>的意义是将f这个functor(恰好也是个function)里的function取出来修饰g这个一元函数(也是functor)\n到此为止吧,我也没完全明白\n\n## ZipList as Applicative Functor\n```haskell\ninstance Applicative ZipList where\n    pure x = ZipList (repeat x)\n    ZipList fs <*> ZipList xs = ZipList (zipWith (\\f x -> f x) fs xs)\n\nghci> getZipList $ (+) <$> ZipList [1,2,3] <*> ZipList [100,100,100]\n[101,102,103]\nghci> getZipList $ (+) <$> ZipList [1,2,3] <*> ZipList [100,100..]\n[101,102,103]\nghci> getZipList $ max <$> ZipList [1,2,3,4,5,3] <*> ZipList [5,3,1,2]\n[5,3,3,4]\nghci> getZipList $ (,,) <$> ZipList \"dog\" <*> ZipList \"cat\" <*> ZipList \"rat\"\n[('d','c','r'),('o','a','a'),('g','t','t')]\n```\n这里的ZipList可以取代zipWithN函数\ngetZipList函数用来从ZipList取出List\n\n## Applicative法则\n```haskell\npure f <*> x = fmap f x\npure id <*> v = v\npure (.) <*> u <*> v <*> w = u <*> (v <*> w)\npure f <*> pure x = pure (f x)\nu <*> pure y = pure ($ y) <*> u\n```\n\n## liftA2\n```haskell\nliftA2 :: (Applicative f) => (a -> b -> c) -> f a -> f b -> f c\nliftA2 f a b = f <$> a <*> b\n```\nWith ordinary functors, we can just map functions over one functor value. \nWith applicative functors, we can apply a function between several functor values.\n\n我们可以实现这样一个函数,把Applicative值都拼到一个List里\n```haskell\nsequenceA :: (Applicative f) => [f a] -> f [a]\nsequenceA [] = pure []\nsequenceA (x:xs) = (:) <$> x <*> sequenceA xs\n\nghci> sequenceA [(+3),(+2),(+1)] 3\nghci> (\\x y z -> [x,y,z]) <$> (+3) <*> (+2) <*> (+1) $ 3\n[6,5,4]\n\nghci> map (\\f -> f 7) [(>4),(<10),odd]\n[True,True,True]\nghci> and $ map (\\f -> f 7) [(>4),(<10),odd]\nTrue\n可以改写成\nghci> sequenceA [(>4),(<10),odd] 7\n[True,True,True]\nghci> and $ sequenceA [(>4),(<10),odd] 7\nTrue\n```\n\n","source":"_posts/haskell_applicative.md","raw":"title: Haskell Applicative\ndate: 2016-01-22\ntags: [haskell]\n---\n\nApplicative Functor允许Functor的链式调用\n<!--more-->\n\n## Applicative Functor\nControl.Applicative模块\n```haskell\nclass (Functor f) => Applicative f where\n    pure :: a -> f a\n    (<*>) :: f (a -> b) -> f a -> f b\n```\npure将一个值包装到一个最简单的(默认或者说最小)环境里\n<*>可以使用环境里的函数处理另一个环境\n\n### Maybe\n```haskell\ninstance Applicative Maybe where\n    pure = Just\n    Nothing <*> _ = Nothing\n    (Just f) <*> something = fmap f something\n```\n\n### Maybe Applicative 链式调用\n```haskell\n(<$>) :: (Functor f) => (a -> b) -> f a -> f b\nf <$> x = fmap f x\n\nghci> pure (+) <*> Just 3 <*> Just 5\nghci> fmap (+) Just 3 <*> Just 5\nghci> (+) <$> Just 3 <*> Just 5\nJust 8\n```\n这种方式使我们不需要理会环境,直接处理环境内的值\n\n### List\n```haskell\ninstance Applicative [] where\n    pure x = [x]\n    fs <*> xs = [f x | f <- fs, x <- xs] 笛卡尔积\n```\n```haskell\nghci> [(+),(*)] <*> [1,2] <*> [3,4]\n[4,5,5,6,3,4,6,8]\nghci> (++) <$> [\"ha\",\"heh\",\"hmm\"] <*> [\"?\",\"!\",\".\"]\n[\"ha?\",\"ha!\",\"ha.\",\"heh?\",\"heh!\",\"heh.\",\"hmm?\",\"hmm!\",\"hmm.\"]\n```\n\n使用applicative style取代list comprehension\n```haskell\nghci> [ x*y | x <- [2,5,10], y <- [8,10,11]]\n[16,20,22,40,50,55,80,100,110]\nghci> (*) <$> [2,5,10] <*> [8,10,11]\n[16,20,22,40,50,55,80,100,110]\n```\n这里好像可以得出这样一个结论,\n那就是Haskell在尽可能地消除变量\n上面的例子里x,y都没有了,只有行为和数据\n\n### IO也是applicative functor\n\n### function也是applicative functor\n```haskell\ninstance Applicative ((->) r) where\n    pure x = (\\_ -> x)\n    f <*> g = \\x -> f x (g x)\n```\n\n```haskell\nghci> (+) <$> (+3) <*> (*100) $ 5\nghci> fmap (+) (+3) <*> (*100) $ 5\nghci> ((+) . (+3)) <*> (*100) $ 5\n((+) . (+3)) $ 5 即(\\x -> (+(x+3))) $ 5的结果是 (+8)\n按照<*>的定义, 继续化简为\nghci> (\\x -> ((+) . (+3)) x ((*100) x)) $ 5\nghci> (+8) (5*100)\nghci> (+8)  500\n508\n```\n```haskell\nghci> (\\x y z -> [x,y,z]) <$> (+3) <*> (*2) <*> (/2) $ 5\nghci> (\\x y z -> [x+3,y,z]) <*> (*2) <*> (/2) $ 5\n按照<*>的定义,第一元不变,将第二元改为使用第一元调用(*2),即\nghci> (\\x z -> [x+3,x*2,z]) <*> (/2) $ 5\nghci> (\\x -> [x+3,x*2,x/2]) $ 5\n[8.0,10.0,2.5]\n```\n\n<\\$\\>左边的得是一个二(N,右边有N个一元函数的情况)元函数,即函数的函数,即函数在一个环境(这个环境恰好也是一个函数)里\n每执行一个<$>或<*>就减一元,到最后只剩一元(即前面的几个函数合成成的新函数,根据curry化,一元就是N元)\n最后接受一个参数可得结果,\n所以function使用applicative的效果依然是类似function composition\n\n本以为函数的applicative会定义成这样\n```haskell\ninstance Applicative ((->) r) where\n    pure x = (\\_ -> x)\n    f <*> g = \\x y -> f x (g y)\n```\n这样元数不会减少, 但是就只对二元函数有用了,\n不如官方的定义有用吧\n<*>的意义是将f这个functor(恰好也是个function)里的function取出来修饰g这个一元函数(也是functor)\n到此为止吧,我也没完全明白\n\n## ZipList as Applicative Functor\n```haskell\ninstance Applicative ZipList where\n    pure x = ZipList (repeat x)\n    ZipList fs <*> ZipList xs = ZipList (zipWith (\\f x -> f x) fs xs)\n\nghci> getZipList $ (+) <$> ZipList [1,2,3] <*> ZipList [100,100,100]\n[101,102,103]\nghci> getZipList $ (+) <$> ZipList [1,2,3] <*> ZipList [100,100..]\n[101,102,103]\nghci> getZipList $ max <$> ZipList [1,2,3,4,5,3] <*> ZipList [5,3,1,2]\n[5,3,3,4]\nghci> getZipList $ (,,) <$> ZipList \"dog\" <*> ZipList \"cat\" <*> ZipList \"rat\"\n[('d','c','r'),('o','a','a'),('g','t','t')]\n```\n这里的ZipList可以取代zipWithN函数\ngetZipList函数用来从ZipList取出List\n\n## Applicative法则\n```haskell\npure f <*> x = fmap f x\npure id <*> v = v\npure (.) <*> u <*> v <*> w = u <*> (v <*> w)\npure f <*> pure x = pure (f x)\nu <*> pure y = pure ($ y) <*> u\n```\n\n## liftA2\n```haskell\nliftA2 :: (Applicative f) => (a -> b -> c) -> f a -> f b -> f c\nliftA2 f a b = f <$> a <*> b\n```\nWith ordinary functors, we can just map functions over one functor value. \nWith applicative functors, we can apply a function between several functor values.\n\n我们可以实现这样一个函数,把Applicative值都拼到一个List里\n```haskell\nsequenceA :: (Applicative f) => [f a] -> f [a]\nsequenceA [] = pure []\nsequenceA (x:xs) = (:) <$> x <*> sequenceA xs\n\nghci> sequenceA [(+3),(+2),(+1)] 3\nghci> (\\x y z -> [x,y,z]) <$> (+3) <*> (+2) <*> (+1) $ 3\n[6,5,4]\n\nghci> map (\\f -> f 7) [(>4),(<10),odd]\n[True,True,True]\nghci> and $ map (\\f -> f 7) [(>4),(<10),odd]\nTrue\n可以改写成\nghci> sequenceA [(>4),(<10),odd] 7\n[True,True,True]\nghci> and $ sequenceA [(>4),(<10),odd] 7\nTrue\n```\n\n","slug":"haskell_applicative","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mr0092mcxqyf9wrnug"},{"title":"Haskell基础","date":"2015-11-19T16:00:00.000Z","_content":"\n## 简介\n静态,纯函数式通用编程语言                                                        \n命名源自美国逻辑学家Haskell Brooks Curry，他在数学逻辑方面的工作使得函数式编程语言有了广泛的基础。\nHaskell语言是1990年在编程语言Miranda的基础上标准化的，并且以λ演算（Lambda-Calculus)为基础发展而来。\n具有“证明即程序、结论公式即程序类型”的特征。这也是Haskell语言以希腊字母「λ」（Lambda）作为自己标志的原因。\nHaskell语言的最主要的执行环境是GHC。\n\n<!--more-->\n                                                                                 \n发音为: /ˈheskəl/ \n\n## 引用透明 referential transparency     \n\n一个函数以同样的参数调用两次,得到的结果一定相同,这种性质称为引用透明.            \n组合使用多个这样的函数得到的函数仍然可以保持引用透明.\n这有助于写出容易测试,容易复用,可读性更好的程序,还能支持惰性求值\n                        \n## 什么是副作用\n\n## 惰性求值 Lazy Evaluation                                                      \n大多数语言是热情求值 Eager Evaluation\n不到要使用值的时候不求值,引用透明使这一点成为可能.                               \n如果明确了函数的执行结果仅与参数相关,那么早执行或晚执行都是一样的.               \nHaskell利用这一点省去了不必要的运算.                                             \n所有的代码在执行之前都只是定义,最后需要用值(比如io)的时候才运算.                 \n如                                                                               \nxs = [1,2,3,4,5,6,7,8]                                                           \nprint (take 1 (doubleMe(xs)))\n只会把第一个元素*2                                                               \n\n另如无限列表,                                                                      \ncycle函数,无限循环一个列表的元素从而生成一个无限列表                             \n```                                                                              \nghci> take 10 (cycle [1,2,3])                                                    \n[1,2,3,1,2,3,1,2,3,1]                                                            \nghci> take 12 (cycle \"LOL \")                                                     \n\"LOL LOL LOL \"                                                                   \n```\n\nrepeat函数,生成单个元素的无限列表                                                \n```\nghci> take 10 (repeat 5)                                                         \n[5,5,5,5,5,5,5,5,5,5]\n```\n\n## 静态类型                                                                      \n使编译器能够做更多的编译检查                                                     \n                                                                                 \n## 类型推导                                                                      \n多数时候不需要程序员在代码里注明类型信息                                         \n如一个函数定义是                                                                 \nadd x y = x + y                                                                  \n能够推导出是可以+的类型                                                          \n                                                                                 \n## 前缀和中缀                                                                    \n1 + 2这样的函数调用,+函数是中缀形式                                              \nadd(1, 2)或 (+ 1 2)这样的是前缀形式                                              \nlisp语言大家族的函数是前缀的,包括像+这样的函数                                   \nhaskell默认前缀,也可以中缀,调用时加两反引号即可                                  \n假如我们自定义一个div函数表示除法                                                \nghci> div 92 10                                                                  \n9                                                                                \nghci> 92 \\`div\\` 10                                                                \n9                                                                                \n\n### 函数名可以用字符'\n就像数学里那样,一般用来表示与原来的函数有一点区别的版本\n```\ndoubleSmallNumber' x = (if x > 100 then x else x*2) + 1\n```\n\n### list\n与erlang类似\n经典示例:\n```\nghci> let rightTriangles' = [ (a,b,c) | c <- [1..10], a <- [1..c], b <- [1..a], a^2 + b^2 == c^2, a+b+c == 24]\nghci> rightTriangles'\n[(6,8,10)]\n```\n不同点:\n* list内的元素必须类型相同\n* 取元素时下标从0开始\n* zip, 两个列表长度不同时erlang会报错,haskell以短的list为准,所以允许和无限列表zip(估计这才是目的)\n```\nghci> zip [5,3,2,6,2,7,2,5,4,6,6] [\"im\",\"a\",\"turtle\"]\n[(5,\"im\"),(3,\"a\"),(2,\"turtle\")]\nghci> zip [1..] [\"apple\", \"orange\", \"cherry\", \"mango\"]\n[(1,\"apple\"),(2,\"orange\"),(3,\"cherry\"),(4,\"mango\")]\n```\n\n### tuple\n> (1,3)\n> (3,'a',\"hello\")\n> (50,50.4,\"hello\",'b')\n\n元组的类型由长度和每一个元素的类型决定,\n如下形式都会报错,因为list不允许不同类型的元素共存\n[(1,2),(8,11,5),(4,5)]\n[(1,2),(\"One\",2)]\n\n## type\n```\naddThree :: Int -> Int -> Int -> Int\naddThree x y z = x + y + z\n```\n\n## type variable\n```\nghci> :t head\nhead :: [a] -> a\n```\na表示可以为任意类型,a只是与后续可能出现的b相区别\n这里用类型变量实现了多态\n```\nghci> let add' x y = x + y\nghci> :t add'\nadd' :: Num a => a -> a -> a\n```\n这里表示add'的x和y的参数类型可以是任意一个符合Num要求的类型\n于是Float也可以Int也可以,Integer也可以\n\n## type class\n```\nghci> :t (==)\n(==) :: (Eq a) => a -> a -> Bool\n```\n\n函数名仅由符号组成的函数默认中缀,加上一对括号变成前缀形式\n(Eq a) =>这部分是类型约束,表示a类型符合Eq这个type class\n\nEq表示支持检测是否相等,对应的需要实现的函数是==和/=,\n即一个type要支持Eq这个type class,需要实现==和/=,有点像jave里的interface\n下述数值的类型都符合Eq类型约束\n> ghci> 5 == 5\n> True\n> ghci> 5 /= 5\n> False\n> ghci> 'a' == 'a'\n> True\n> ghci> \"Ho Ho\" == \"Ho Ho\"\n> True\n> ghci> 3.432 == 3.432\n> True\n\n### 其他常见type class\n* Ord 允许比大小, 即支持>, >=, <, <=, 需要实现compare函数\n* Show 允许转换为字符串, 需要实现show函数, 相当于java的toString()\n* Read Show的逆操作,将字符串转换成值,如\"1\" -> 1\n* Enum 允许取上一个和下一个元素和range,如3的上一个是2,下一个是4, succ 'b'返回'c', [3..5]返回[3,4,5]\n* Bounded 允许取边界, 如Int的边界是minBound返回-2147483648\n* Num 表示数值类型\n* Floating 表示符点型\n* Integral 表示整型 \n\n类型class也有前提关系,Ord的前提是Eq,即要实现Ord必须先实现Eq\n\n### type annotation 类型声明\n```\nPrelude> read \"5\" \n\n<interactive>:36:1:\n    No instance for (Read a0) arising from a use of `read'\n    The type variable `a0' is ambiguous\n    Possible fix: add a type signature that fixes these type variable(s)\n    Note: there are several potential instances:\n      instance Read () -- Defined in `GHC.Read'\n      instance (Read a, Read b) => Read (a, b) -- Defined in `GHC.Read'\n      instance (Read a, Read b, Read c) => Read (a, b, c)\n        -- Defined in `GHC.Read'\n      ...plus 25 others\n    In the expression: read \"5\"\n    In an equation for `it': it = read \"5\"\n```\n报错了,因为read \"5\"返回的值的类型不知道具体是Int还是Integer还是Float还是Double还是什么??\n所以此时要使用类型声明\nPrelude> read \"5\":: Double\n5.0\n此时因为是REPL模式立即要显示所以才会报错,代码中如果环境里能推断出来类型也不会报错了\n\n\n## Curried Functions\nHaskell的所有函数都只有一个参数,\n多个参数的函数实际上接受一个参数然后返回一个接受两个参数的函数,然后再接受一个参数, ...\n\n```\nghci> max 4 5\n5\nghci> (max 4) 5\n5\n```\n以上两个实际上相同,(max 4)返回一个一参的函数,叫做partially applied function\n看类型:\n```\nghci> :t max\nmax :: (Ord a) => a -> a -> a\n```\n可以理解为\n```\nmax :: (Ord a) => a -> (a -> a)\n```\n即接受一个函数返回一个函数\n\n这是一个制造函数的好办法,我们可以把partially applied function传到别的地方去\n\n### sections\n```\nisUpperAlphanum :: Char -> Bool\nisUpperAlphanum = (`elem` ['A'..'Z'])\n```\n这里(\\`elem\\` ['A'..'Z'])是一个partially applied function\n```\nPrelude> (`elem` ['A'..'Z']) 'B'\nTrue\nPrelude> (`elem` ['A'..'Z']) 'a'\nFalse\nPrelude> let isUpperAlphanum = (`elem` ['A'..'Z'])\nPrelude> isUpperAlphanum 'a'\nFalse\n```\n\n(-4)表示负4,想要减4的函数要用(subtract 4)\n\n## high order function\n```\napplyTwice :: (a -> a) -> a -> a\napplyTwice f x = f (f x)\n```\n```\nghci> applyTwice (+3) 10\n16\nghci> applyTwice (++ \" HAHA\") \"HEY\"\n\"HEY HAHA HAHA\"\nghci> applyTwice (\"HAHA \" ++) \"HEY\"\n\"HAHA HAHA HEY\"\nghci> applyTwice (multThree 2 2) 9\n144\nghci> applyTwice (3:) [1]\n[3,3,1]\nghci> map (map (^2)) [[1,2],[3,4,5,6],[7,8]]\n[[1,4],[9,16,25,36],[49,64]]\n```\n这里可以看到Curry化的好处, 在需要传入一个函数的时候,可以根据需要传入不同元数的Curry化函数\n\n### lambda\n```\n\\xs -> length xs > 15\n```\n相当于\n```\nfun(L) -> length(L) > 15 end\n```\n比较简洁\n\n```haskell\naddThree :: Int -> Int -> Int -> Int\naddThree x y z = x + y + z\n\naddThree :: Int -> Int -> Int -> Int\naddThree' = \\x -> \\y -> \\z -> x + y + z\n```\n\n### fold\nfoldl和foldr的函数里参数顺序不同, 一个是acc x,另一个是x acc\n```haskell\nfoldl (\\acc x -> (x+1):acc) [] [1,2,3]\n[4,3,2]\nfoldr (\\x acc -> (x+1):acc) [] [1,2,3]\n[2,3,4]\n```\nfoldr可以对无限列表操作,而foldl不可以\n\nfoldl1和foldr1不需要提供初始值, 以第一个元素的值为初始值, 空列表会报错\n\nfoldl'是strict的版本, 如果List较大使用foldl可能导致stack overflow, \n此时使用foldl'可以少占用内存, 类似尾递归\n\n### scan\n\n与fold不同的是,每一步的结果都会放到返回值的List里\n```haskell\nghci> scanl (+) 0 [3,5,2,1]\n[0,3,8,10,11]\n```\n\n### Function Application with $\n\n定义: <pre>($) :: (a -> b) -> a -> b\nf $ x = f x </pre> 由于函数调用(即函数后面跟一个空格)的优先级非常高,f x就相当于f(x),\n于是x如果是一个复杂结构的话,一定是先将x内部的运算算完才后调用f,\n事实上做到了($)的优先级最低\n\n函数调用是左结合: f a b c 相当于((f a) b) c)\n于是: \n<pre>f $ g $ h x\n即 f(g $ h x)\n即 f(g(h x)) </pre> 事实上做到了右结合\n\n例如:\n```haskell\nsum $ map sqrt [1..130] 相当于\nsum (map sqrt [1..130]) \n```\n这样就省去了括号\n\n又如:\n```haskell\nghci> sum $ filter (> 10) $ map (*2) [2..10]\nghci> sum(filter (> 10) $ map (*2) [2..10])\nghci> sum(filter (> 10) (map (*2) [2..10]))\n80\n```\n\n\\$还能允许我们把参数包装成函数, 如(\\$ 3), 这样就可以在map中使用了\n```haskell\nghci> map ($ 3) [(4+), (10*), (^2), sqrt]\nghci> [($ 3) (4+), ($ 3) (10*), ($ 3) (^2), ($ 3) sqrt]\nghci> [(4+) $ 3, (10*) $ 3, (^2) $ 3, sqrt $ 3]\nghci> [(4+) 3, (10*) 3, (^2) 3, sqrt 3]\n[7.0,30.0,9.0,1.7320508075688772]\n```\n\n## Function Composition\n\n```\n(.) :: (b -> c) -> (a -> b) -> a -> c\nf . g = \\x -> f (g x)\n```\nf g x是((f g) x), 这可能不是你想要的, \n所以想要先执行g再执行f的话就得写成\\x -> f (g x),\n那么定义了(.)函数后就可以不用写\\x -> f (g x)这么麻烦,直接用f . g就可以了\n如下:\n```\nghci> map (\\x -> negate (abs x)) [5,-3,-6,7,-3,2,-19,24]\n[-5,-3,-6,-7,-3,-2,-19,-24]\nghci> map (negate . abs) [5,-3,-6,7,-3,2,-19,24]\n[-5,-3,-6,-7,-3,-2,-19,-24]\nghci> map (\\xs -> negate (sum (tail xs))) [[1..5],[3..6],[1..7]]\n[-14,-15,-27]\nghci> map (negate . sum . tail) [[1..5],[3..6],[1..7]]\n[-14,-15,-27]\n```\n```\nsum (replicate 5 (max 6.7 8.9))\n(sum . replicate 5) max 6.7 8.9\nsum . replicate 5 $ max 6.7 8.9\n```\n\nFunction Composition是右结合(f . g . h即\\x -> f((g . h) x)),\n可以使代码更清晰更简洁,相当于用一些函数生成了新的函数,与惰性求值结合将多遍求值化为一遍求值,\n如list的处理\n\n#### Point-Free Style\n```haskell\nsum' :: (Num a) => [a] -> a\nsum' xs = foldl (+) 0 xs\n```\n可以把xs约掉,化简为\n```haskell\nsum' :: (Num a) => [a] -> a\nsum' = foldl (+) 0\n```\n另例\nfn x = ceiling (negate (tan (cos (max 50 x))))\n化简为:\nfn = ceiling . negate . tan . cos . max 50\nFunction Composition改变了我们的思维方式\n从围绕数据转变为围绕函数\n\n## 副作用都封装在IO类型里\n\n分离副作用的代码和纯粹的代码\n不是告诉计算机第一步做什么第二步做什么,而是告诉计算机各种定义和规则\n函数不允许有副作用,无法想像一个加法的函数里嵌入了一个打开洗衣机的api调用,不知道的人以为只是加法,调了几次之后发现家养的猫死在洗衣机里\n\n## random\nerlang在进程字典里记了random状态\n每次调用random:uniform()返回值都不同,这当然违反了函数式的要旨引用透明\n\nSystem.Random库里的\nrandom :: (RandomGen g, Random a) => g -> (a, g)\nRandomGen: 随机种子\nRandom: 随机值,可以是Bool, Int, String等\n\nmkStdGen函数用于手动得到一个随机种子\n```\nghci> random (mkStdGen 100) :: (Int, StdGen)\n(-1352021624,651872571 1655838864)\nghci> random (mkStdGen 100) :: (Int, StdGen)\n(-1352021624,651872571 1655838864)\n两次执行结果是一样的\nghci> random (mkStdGen 949494) :: (Int, StdGen)\n(539963926,466647808 1655838864)\n换一个随机种子结果变化\nghci> random (mkStdGen 949488) :: (Float, StdGen)\n(0.8938442,1597344447 1655838864)\nghci> random (mkStdGen 949488) :: (Bool, StdGen)\n(False,1485632275 40692)\n```\n帅呆了,可以直接获得各种类型的随机值\n\n取指定范围的随机数并返回新的随机种子\n```\nghci> randomR (1,6) (mkStdGen 359353)\n(6,149428957840692)\nghci> randomR (1,6) (mkStdGen 35935335)\n(3,125003105740692)\n```\n\nSystem.Random库的函数getStdGen, 类型IO StdGen, 从全局变量里取随机种子\nnewStdGen函数更新全局变量的随机种子\n\n取a-z范围内的20个随机值\n```\nimport System.Random\nmain = do\n    gen <- getStdGen\n    putStrLn $ take 20 (randomRs ('a','z') gen)\n```\n```\n$ ./random_string\npybphhzzhuepknbykxhe\n```\nhaskell生成随机数都要求以参数形式传入种子,\n这样有利于测试,得到与当时相同的随机结果以重现问题,同时不违背引用透明\n\n## lazy io\n\n## pattern matching 模式匹配\n\n### As-pattern\n```\nfirstLetter :: String -> String\nfirstLetter \"\" = \"Empty string, whoops!\"\nfirstLetter all@(x:xs) = \"The first letter of \" ++ all ++ \" is \" ++ [x]\n```\n类似于erlang的\n```\nfirstLetter([]) -> \"Empty string, whoops!\"\nfirstLetter([H|T] = All) -> \"The first letter of \" ++ All ++ \" is \" ++ [H]\n```\n\n## Guards\n```\nbmiTell :: Double -> Double -> String\nbmiTell weight height\n    | bmi <= skinny = \"You're underweight, you emo, you!\"\n    | bmi <= normal = \"You're supposedly normal. Pffft, I bet you're ugly!\"\n    | bmi <= fat = \"You're fat! Lose some weight, fatty!\"\n    | otherwise = \"You're a whale, congratulations!\"\n    where bmi = weight / height ^ 2\n          skinny = 18.5\n          normal = 25.0\n          fat = 30.0\n```\n\n### where子句里定义函数\n```\ncalcBmis :: [(Double, Double)] -> [Double]\ncalcBmis xs = [bmi w h | (w, h) <- xs]\n    where bmi weight height = weight / height ^ 2\n```\nwhere子句不是表达式\n\n### let\n\nlet内定义的变量, 其作用域只在let表达式内, 不包含guard\n```haskell\ncylinder :: Double -> Double -> Double\ncylinder r h =\n    let sideArea = 2 * pi * r * h\n        topArea = pi * r ^ 2\n    in sideArea + 2 * topArea\n```\nlet语句是表达式, 例如\n```haskell\nghci> 4 * (let a = 9 in a + 1) + 2\n42\nghci> (let a = 100; b = 200; c = 300 in a*b*c, let foo=\"Hey \"; bar = \"there!\" in foo ++ bar)\n(6000000,\"Hey there!\")\n```\n```haskell\ncalcBmis :: [(Double, Double)] -> [Double]\ncalcBmis xs = [bmi | (w, h) <- xs, let bmi = w / h ^ 2]\n```\n\n### if\nif是表达式(expression),必须有返回值,而不是语句(statement)\n所以必须有else\n```haskell\ndoubleSmallNumber x = if x > 100\n                      then x\n                      else x*2\n```\n\n### case\n```haskell\ncase expression of pattern -> result\n                   pattern -> result\n                   pattern -> result\n                   ...\n```\n\n### recursive 递归\n类似erlang\n\n## 与erlang的不同                                                                \n没有原子\n元组最多62元素,erlang无此限制\n有Bool类型,不像erlang用两个原子做 \n有Char类型,表示一个Unicode字符,erlang没有\n提供有边界的Int类型(机器字长度),另有Integer与erlang的int相同\nguards等语法有缩进要求\n\n## 总结\nHaskell程序通常会比其他语言短,                                                   \n程序短的程序可读性强,可维护性会好,bug也会少    \n\n## 业界\nConcurrent Haskell, 借鉴erlang                                                   \nYesod, 做网站                                                                    \nIndustrial Haskell网站                                                               \n金融系统\n\n","source":"_posts/haskell_basics.md","raw":"title: Haskell基础\ndate: 2015-11-20\ntags: [haskell]\n---\n\n## 简介\n静态,纯函数式通用编程语言                                                        \n命名源自美国逻辑学家Haskell Brooks Curry，他在数学逻辑方面的工作使得函数式编程语言有了广泛的基础。\nHaskell语言是1990年在编程语言Miranda的基础上标准化的，并且以λ演算（Lambda-Calculus)为基础发展而来。\n具有“证明即程序、结论公式即程序类型”的特征。这也是Haskell语言以希腊字母「λ」（Lambda）作为自己标志的原因。\nHaskell语言的最主要的执行环境是GHC。\n\n<!--more-->\n                                                                                 \n发音为: /ˈheskəl/ \n\n## 引用透明 referential transparency     \n\n一个函数以同样的参数调用两次,得到的结果一定相同,这种性质称为引用透明.            \n组合使用多个这样的函数得到的函数仍然可以保持引用透明.\n这有助于写出容易测试,容易复用,可读性更好的程序,还能支持惰性求值\n                        \n## 什么是副作用\n\n## 惰性求值 Lazy Evaluation                                                      \n大多数语言是热情求值 Eager Evaluation\n不到要使用值的时候不求值,引用透明使这一点成为可能.                               \n如果明确了函数的执行结果仅与参数相关,那么早执行或晚执行都是一样的.               \nHaskell利用这一点省去了不必要的运算.                                             \n所有的代码在执行之前都只是定义,最后需要用值(比如io)的时候才运算.                 \n如                                                                               \nxs = [1,2,3,4,5,6,7,8]                                                           \nprint (take 1 (doubleMe(xs)))\n只会把第一个元素*2                                                               \n\n另如无限列表,                                                                      \ncycle函数,无限循环一个列表的元素从而生成一个无限列表                             \n```                                                                              \nghci> take 10 (cycle [1,2,3])                                                    \n[1,2,3,1,2,3,1,2,3,1]                                                            \nghci> take 12 (cycle \"LOL \")                                                     \n\"LOL LOL LOL \"                                                                   \n```\n\nrepeat函数,生成单个元素的无限列表                                                \n```\nghci> take 10 (repeat 5)                                                         \n[5,5,5,5,5,5,5,5,5,5]\n```\n\n## 静态类型                                                                      \n使编译器能够做更多的编译检查                                                     \n                                                                                 \n## 类型推导                                                                      \n多数时候不需要程序员在代码里注明类型信息                                         \n如一个函数定义是                                                                 \nadd x y = x + y                                                                  \n能够推导出是可以+的类型                                                          \n                                                                                 \n## 前缀和中缀                                                                    \n1 + 2这样的函数调用,+函数是中缀形式                                              \nadd(1, 2)或 (+ 1 2)这样的是前缀形式                                              \nlisp语言大家族的函数是前缀的,包括像+这样的函数                                   \nhaskell默认前缀,也可以中缀,调用时加两反引号即可                                  \n假如我们自定义一个div函数表示除法                                                \nghci> div 92 10                                                                  \n9                                                                                \nghci> 92 \\`div\\` 10                                                                \n9                                                                                \n\n### 函数名可以用字符'\n就像数学里那样,一般用来表示与原来的函数有一点区别的版本\n```\ndoubleSmallNumber' x = (if x > 100 then x else x*2) + 1\n```\n\n### list\n与erlang类似\n经典示例:\n```\nghci> let rightTriangles' = [ (a,b,c) | c <- [1..10], a <- [1..c], b <- [1..a], a^2 + b^2 == c^2, a+b+c == 24]\nghci> rightTriangles'\n[(6,8,10)]\n```\n不同点:\n* list内的元素必须类型相同\n* 取元素时下标从0开始\n* zip, 两个列表长度不同时erlang会报错,haskell以短的list为准,所以允许和无限列表zip(估计这才是目的)\n```\nghci> zip [5,3,2,6,2,7,2,5,4,6,6] [\"im\",\"a\",\"turtle\"]\n[(5,\"im\"),(3,\"a\"),(2,\"turtle\")]\nghci> zip [1..] [\"apple\", \"orange\", \"cherry\", \"mango\"]\n[(1,\"apple\"),(2,\"orange\"),(3,\"cherry\"),(4,\"mango\")]\n```\n\n### tuple\n> (1,3)\n> (3,'a',\"hello\")\n> (50,50.4,\"hello\",'b')\n\n元组的类型由长度和每一个元素的类型决定,\n如下形式都会报错,因为list不允许不同类型的元素共存\n[(1,2),(8,11,5),(4,5)]\n[(1,2),(\"One\",2)]\n\n## type\n```\naddThree :: Int -> Int -> Int -> Int\naddThree x y z = x + y + z\n```\n\n## type variable\n```\nghci> :t head\nhead :: [a] -> a\n```\na表示可以为任意类型,a只是与后续可能出现的b相区别\n这里用类型变量实现了多态\n```\nghci> let add' x y = x + y\nghci> :t add'\nadd' :: Num a => a -> a -> a\n```\n这里表示add'的x和y的参数类型可以是任意一个符合Num要求的类型\n于是Float也可以Int也可以,Integer也可以\n\n## type class\n```\nghci> :t (==)\n(==) :: (Eq a) => a -> a -> Bool\n```\n\n函数名仅由符号组成的函数默认中缀,加上一对括号变成前缀形式\n(Eq a) =>这部分是类型约束,表示a类型符合Eq这个type class\n\nEq表示支持检测是否相等,对应的需要实现的函数是==和/=,\n即一个type要支持Eq这个type class,需要实现==和/=,有点像jave里的interface\n下述数值的类型都符合Eq类型约束\n> ghci> 5 == 5\n> True\n> ghci> 5 /= 5\n> False\n> ghci> 'a' == 'a'\n> True\n> ghci> \"Ho Ho\" == \"Ho Ho\"\n> True\n> ghci> 3.432 == 3.432\n> True\n\n### 其他常见type class\n* Ord 允许比大小, 即支持>, >=, <, <=, 需要实现compare函数\n* Show 允许转换为字符串, 需要实现show函数, 相当于java的toString()\n* Read Show的逆操作,将字符串转换成值,如\"1\" -> 1\n* Enum 允许取上一个和下一个元素和range,如3的上一个是2,下一个是4, succ 'b'返回'c', [3..5]返回[3,4,5]\n* Bounded 允许取边界, 如Int的边界是minBound返回-2147483648\n* Num 表示数值类型\n* Floating 表示符点型\n* Integral 表示整型 \n\n类型class也有前提关系,Ord的前提是Eq,即要实现Ord必须先实现Eq\n\n### type annotation 类型声明\n```\nPrelude> read \"5\" \n\n<interactive>:36:1:\n    No instance for (Read a0) arising from a use of `read'\n    The type variable `a0' is ambiguous\n    Possible fix: add a type signature that fixes these type variable(s)\n    Note: there are several potential instances:\n      instance Read () -- Defined in `GHC.Read'\n      instance (Read a, Read b) => Read (a, b) -- Defined in `GHC.Read'\n      instance (Read a, Read b, Read c) => Read (a, b, c)\n        -- Defined in `GHC.Read'\n      ...plus 25 others\n    In the expression: read \"5\"\n    In an equation for `it': it = read \"5\"\n```\n报错了,因为read \"5\"返回的值的类型不知道具体是Int还是Integer还是Float还是Double还是什么??\n所以此时要使用类型声明\nPrelude> read \"5\":: Double\n5.0\n此时因为是REPL模式立即要显示所以才会报错,代码中如果环境里能推断出来类型也不会报错了\n\n\n## Curried Functions\nHaskell的所有函数都只有一个参数,\n多个参数的函数实际上接受一个参数然后返回一个接受两个参数的函数,然后再接受一个参数, ...\n\n```\nghci> max 4 5\n5\nghci> (max 4) 5\n5\n```\n以上两个实际上相同,(max 4)返回一个一参的函数,叫做partially applied function\n看类型:\n```\nghci> :t max\nmax :: (Ord a) => a -> a -> a\n```\n可以理解为\n```\nmax :: (Ord a) => a -> (a -> a)\n```\n即接受一个函数返回一个函数\n\n这是一个制造函数的好办法,我们可以把partially applied function传到别的地方去\n\n### sections\n```\nisUpperAlphanum :: Char -> Bool\nisUpperAlphanum = (`elem` ['A'..'Z'])\n```\n这里(\\`elem\\` ['A'..'Z'])是一个partially applied function\n```\nPrelude> (`elem` ['A'..'Z']) 'B'\nTrue\nPrelude> (`elem` ['A'..'Z']) 'a'\nFalse\nPrelude> let isUpperAlphanum = (`elem` ['A'..'Z'])\nPrelude> isUpperAlphanum 'a'\nFalse\n```\n\n(-4)表示负4,想要减4的函数要用(subtract 4)\n\n## high order function\n```\napplyTwice :: (a -> a) -> a -> a\napplyTwice f x = f (f x)\n```\n```\nghci> applyTwice (+3) 10\n16\nghci> applyTwice (++ \" HAHA\") \"HEY\"\n\"HEY HAHA HAHA\"\nghci> applyTwice (\"HAHA \" ++) \"HEY\"\n\"HAHA HAHA HEY\"\nghci> applyTwice (multThree 2 2) 9\n144\nghci> applyTwice (3:) [1]\n[3,3,1]\nghci> map (map (^2)) [[1,2],[3,4,5,6],[7,8]]\n[[1,4],[9,16,25,36],[49,64]]\n```\n这里可以看到Curry化的好处, 在需要传入一个函数的时候,可以根据需要传入不同元数的Curry化函数\n\n### lambda\n```\n\\xs -> length xs > 15\n```\n相当于\n```\nfun(L) -> length(L) > 15 end\n```\n比较简洁\n\n```haskell\naddThree :: Int -> Int -> Int -> Int\naddThree x y z = x + y + z\n\naddThree :: Int -> Int -> Int -> Int\naddThree' = \\x -> \\y -> \\z -> x + y + z\n```\n\n### fold\nfoldl和foldr的函数里参数顺序不同, 一个是acc x,另一个是x acc\n```haskell\nfoldl (\\acc x -> (x+1):acc) [] [1,2,3]\n[4,3,2]\nfoldr (\\x acc -> (x+1):acc) [] [1,2,3]\n[2,3,4]\n```\nfoldr可以对无限列表操作,而foldl不可以\n\nfoldl1和foldr1不需要提供初始值, 以第一个元素的值为初始值, 空列表会报错\n\nfoldl'是strict的版本, 如果List较大使用foldl可能导致stack overflow, \n此时使用foldl'可以少占用内存, 类似尾递归\n\n### scan\n\n与fold不同的是,每一步的结果都会放到返回值的List里\n```haskell\nghci> scanl (+) 0 [3,5,2,1]\n[0,3,8,10,11]\n```\n\n### Function Application with $\n\n定义: <pre>($) :: (a -> b) -> a -> b\nf $ x = f x </pre> 由于函数调用(即函数后面跟一个空格)的优先级非常高,f x就相当于f(x),\n于是x如果是一个复杂结构的话,一定是先将x内部的运算算完才后调用f,\n事实上做到了($)的优先级最低\n\n函数调用是左结合: f a b c 相当于((f a) b) c)\n于是: \n<pre>f $ g $ h x\n即 f(g $ h x)\n即 f(g(h x)) </pre> 事实上做到了右结合\n\n例如:\n```haskell\nsum $ map sqrt [1..130] 相当于\nsum (map sqrt [1..130]) \n```\n这样就省去了括号\n\n又如:\n```haskell\nghci> sum $ filter (> 10) $ map (*2) [2..10]\nghci> sum(filter (> 10) $ map (*2) [2..10])\nghci> sum(filter (> 10) (map (*2) [2..10]))\n80\n```\n\n\\$还能允许我们把参数包装成函数, 如(\\$ 3), 这样就可以在map中使用了\n```haskell\nghci> map ($ 3) [(4+), (10*), (^2), sqrt]\nghci> [($ 3) (4+), ($ 3) (10*), ($ 3) (^2), ($ 3) sqrt]\nghci> [(4+) $ 3, (10*) $ 3, (^2) $ 3, sqrt $ 3]\nghci> [(4+) 3, (10*) 3, (^2) 3, sqrt 3]\n[7.0,30.0,9.0,1.7320508075688772]\n```\n\n## Function Composition\n\n```\n(.) :: (b -> c) -> (a -> b) -> a -> c\nf . g = \\x -> f (g x)\n```\nf g x是((f g) x), 这可能不是你想要的, \n所以想要先执行g再执行f的话就得写成\\x -> f (g x),\n那么定义了(.)函数后就可以不用写\\x -> f (g x)这么麻烦,直接用f . g就可以了\n如下:\n```\nghci> map (\\x -> negate (abs x)) [5,-3,-6,7,-3,2,-19,24]\n[-5,-3,-6,-7,-3,-2,-19,-24]\nghci> map (negate . abs) [5,-3,-6,7,-3,2,-19,24]\n[-5,-3,-6,-7,-3,-2,-19,-24]\nghci> map (\\xs -> negate (sum (tail xs))) [[1..5],[3..6],[1..7]]\n[-14,-15,-27]\nghci> map (negate . sum . tail) [[1..5],[3..6],[1..7]]\n[-14,-15,-27]\n```\n```\nsum (replicate 5 (max 6.7 8.9))\n(sum . replicate 5) max 6.7 8.9\nsum . replicate 5 $ max 6.7 8.9\n```\n\nFunction Composition是右结合(f . g . h即\\x -> f((g . h) x)),\n可以使代码更清晰更简洁,相当于用一些函数生成了新的函数,与惰性求值结合将多遍求值化为一遍求值,\n如list的处理\n\n#### Point-Free Style\n```haskell\nsum' :: (Num a) => [a] -> a\nsum' xs = foldl (+) 0 xs\n```\n可以把xs约掉,化简为\n```haskell\nsum' :: (Num a) => [a] -> a\nsum' = foldl (+) 0\n```\n另例\nfn x = ceiling (negate (tan (cos (max 50 x))))\n化简为:\nfn = ceiling . negate . tan . cos . max 50\nFunction Composition改变了我们的思维方式\n从围绕数据转变为围绕函数\n\n## 副作用都封装在IO类型里\n\n分离副作用的代码和纯粹的代码\n不是告诉计算机第一步做什么第二步做什么,而是告诉计算机各种定义和规则\n函数不允许有副作用,无法想像一个加法的函数里嵌入了一个打开洗衣机的api调用,不知道的人以为只是加法,调了几次之后发现家养的猫死在洗衣机里\n\n## random\nerlang在进程字典里记了random状态\n每次调用random:uniform()返回值都不同,这当然违反了函数式的要旨引用透明\n\nSystem.Random库里的\nrandom :: (RandomGen g, Random a) => g -> (a, g)\nRandomGen: 随机种子\nRandom: 随机值,可以是Bool, Int, String等\n\nmkStdGen函数用于手动得到一个随机种子\n```\nghci> random (mkStdGen 100) :: (Int, StdGen)\n(-1352021624,651872571 1655838864)\nghci> random (mkStdGen 100) :: (Int, StdGen)\n(-1352021624,651872571 1655838864)\n两次执行结果是一样的\nghci> random (mkStdGen 949494) :: (Int, StdGen)\n(539963926,466647808 1655838864)\n换一个随机种子结果变化\nghci> random (mkStdGen 949488) :: (Float, StdGen)\n(0.8938442,1597344447 1655838864)\nghci> random (mkStdGen 949488) :: (Bool, StdGen)\n(False,1485632275 40692)\n```\n帅呆了,可以直接获得各种类型的随机值\n\n取指定范围的随机数并返回新的随机种子\n```\nghci> randomR (1,6) (mkStdGen 359353)\n(6,149428957840692)\nghci> randomR (1,6) (mkStdGen 35935335)\n(3,125003105740692)\n```\n\nSystem.Random库的函数getStdGen, 类型IO StdGen, 从全局变量里取随机种子\nnewStdGen函数更新全局变量的随机种子\n\n取a-z范围内的20个随机值\n```\nimport System.Random\nmain = do\n    gen <- getStdGen\n    putStrLn $ take 20 (randomRs ('a','z') gen)\n```\n```\n$ ./random_string\npybphhzzhuepknbykxhe\n```\nhaskell生成随机数都要求以参数形式传入种子,\n这样有利于测试,得到与当时相同的随机结果以重现问题,同时不违背引用透明\n\n## lazy io\n\n## pattern matching 模式匹配\n\n### As-pattern\n```\nfirstLetter :: String -> String\nfirstLetter \"\" = \"Empty string, whoops!\"\nfirstLetter all@(x:xs) = \"The first letter of \" ++ all ++ \" is \" ++ [x]\n```\n类似于erlang的\n```\nfirstLetter([]) -> \"Empty string, whoops!\"\nfirstLetter([H|T] = All) -> \"The first letter of \" ++ All ++ \" is \" ++ [H]\n```\n\n## Guards\n```\nbmiTell :: Double -> Double -> String\nbmiTell weight height\n    | bmi <= skinny = \"You're underweight, you emo, you!\"\n    | bmi <= normal = \"You're supposedly normal. Pffft, I bet you're ugly!\"\n    | bmi <= fat = \"You're fat! Lose some weight, fatty!\"\n    | otherwise = \"You're a whale, congratulations!\"\n    where bmi = weight / height ^ 2\n          skinny = 18.5\n          normal = 25.0\n          fat = 30.0\n```\n\n### where子句里定义函数\n```\ncalcBmis :: [(Double, Double)] -> [Double]\ncalcBmis xs = [bmi w h | (w, h) <- xs]\n    where bmi weight height = weight / height ^ 2\n```\nwhere子句不是表达式\n\n### let\n\nlet内定义的变量, 其作用域只在let表达式内, 不包含guard\n```haskell\ncylinder :: Double -> Double -> Double\ncylinder r h =\n    let sideArea = 2 * pi * r * h\n        topArea = pi * r ^ 2\n    in sideArea + 2 * topArea\n```\nlet语句是表达式, 例如\n```haskell\nghci> 4 * (let a = 9 in a + 1) + 2\n42\nghci> (let a = 100; b = 200; c = 300 in a*b*c, let foo=\"Hey \"; bar = \"there!\" in foo ++ bar)\n(6000000,\"Hey there!\")\n```\n```haskell\ncalcBmis :: [(Double, Double)] -> [Double]\ncalcBmis xs = [bmi | (w, h) <- xs, let bmi = w / h ^ 2]\n```\n\n### if\nif是表达式(expression),必须有返回值,而不是语句(statement)\n所以必须有else\n```haskell\ndoubleSmallNumber x = if x > 100\n                      then x\n                      else x*2\n```\n\n### case\n```haskell\ncase expression of pattern -> result\n                   pattern -> result\n                   pattern -> result\n                   ...\n```\n\n### recursive 递归\n类似erlang\n\n## 与erlang的不同                                                                \n没有原子\n元组最多62元素,erlang无此限制\n有Bool类型,不像erlang用两个原子做 \n有Char类型,表示一个Unicode字符,erlang没有\n提供有边界的Int类型(机器字长度),另有Integer与erlang的int相同\nguards等语法有缩进要求\n\n## 总结\nHaskell程序通常会比其他语言短,                                                   \n程序短的程序可读性强,可维护性会好,bug也会少    \n\n## 业界\nConcurrent Haskell, 借鉴erlang                                                   \nYesod, 做网站                                                                    \nIndustrial Haskell网站                                                               \n金融系统\n\n","slug":"haskell_basics","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mt0095mcxqbv7fleuo"},{"title":"Parallel and Concurrent Programming in Haskell 1","date":"2016-02-01T16:00:00.000Z","_content":"\n## parallel和concurrent\nparallel是在多个计算硬件上同时计算\nconcurrent则是一个逻辑概念,使用多个逻辑线程,不一定需要多个计算硬件\n\n<!--more-->\n\n## 确定性的编程模型和非确定性的编程模型\ndeterministic programming model: each program can give only one result(执行多次结果都一样)\nnondeterministic programming model: admits programs that may have different results, depending on some aspect of the execution(执行多次结果可能不一样).\nConcurrent programming models are necessarily nondeterministic because they must interact with\nexternal agents that cause events at unpredictable times. Nondeterminism has some\nnotable drawbacks, however: Programs become significantly harder to test and reason about.\n\nIn Haskell, most parallel programming models are deterministic.\n\n## 安装threadscope\nsudo apt-get install threadscope\n\n## 下载示例代码\ncabal unpack parconc-examples\ncd parconc-examples\ncabal install --only-dependencies\ncabal configure\ncabal build\n\n## 编译器能否自动为我们代码做并行化\nYou might wonder whether the compiler could automatically parallelize programs for us. \nAfter all, it should be easier to do this in a purely functional language, \nwhere the only dependencies between computations are data dependencies, \nwhich are mostly perspicuous and thus readily analyzed. However, even in a purely functional language,\nautomatic parallelization is thwarted by an age-old problem: To make the program faster, \nwe have to gain more from parallelism than we lose due to the overhead of adding it, \nand compile-time analysis cannot make good judgments in this area. \nAn alternative approach is to use runtime profiling to find good candidates for parallelization and \nto feed this information back into the compiler. \nEven this, however, has not been terribly successful in practice.\n\n## weak head normal form\nweak head normal form, 即未完全求值的形式, 完全求值的形式叫做normal form\nhaskell的求值顺序与eager evaluation的语言(先对参数求值, 再对函数求值)相反, \n即从外向里, 先对函数求值, 再对参数求值, 于是参数有可能因为不需要而被省掉求值运算\n\n下面这一段说明了haskell的求值顺序\n```haskell\nPrelude> let xs = map (+1) [1..10] :: [Int]\nPrelude> :sprint xs\nxs = _\nPrelude> seq xs ()\n()\nPrelude> :sprint xs\nxs = _ : _\nPrelude> length xs\n10\nPrelude> :sprint xs\nxs = [_,_,_,_,_,_,_,_,_,_]\nPrelude> sum xs\n65\nPrelude> :sprint xs\nxs = [2,3,4,5,6,7,8,9,10,11]\n```\n可见, 执行length并不需要完全求值, 诸如此类的情况节约了计算资源\n\n## The Eval Monad, rpar, and rseq\nControl.Parallel.Strategies\n\n几种模式\n```haskell\nrunEval $ do\n    a <- rpar (f x)\n    b <- rpar (f y)\n    return (a,b)\n\nrunEval $ do\n    a <- rpar (f x)\n    b <- rseq (f y)\n    return (a,b)\n\nrunEval $ do\n    a <- rpar (f x)\n    b <- rseq (f y)\n    rseq a\n    return (a,b)\n    \nrunEval $ do\n    a <- rpar (f x)\n    b <- rpar (f y)\n    rseq a\n    rseq b\n    return (a,b)\n```\n执行示例代码\n```\nghc -O2 rpar.hs -threaded\n./rpar 1 +RTS -N2\nghc -O2 sudoku1.hs -rtsopts\n./sudoku1 sudoku17.1000.txt\n./sudoku1 sudoku17.1000.txt +RTS -s\nThe argument +RTS -s instructs the GHC runtime system to emit the statistics shown.\nghc -O2 sudoku2.hs -rtsopts -threaded\n./sudoku2 sudoku17.1000.txt +RTS -N2 -s\nrm sudoku2; ghc -O2 sudoku2.hs -threaded -rtsopts -eventlog\n./sudoku2 sudoku17.1000.txt +RTS -N2 -l\nthreadscope sudoku2.eventlog\n```\n\n## 动态分配任务\nspark的概念\noverflowed\ndud\nGC’d\nfizzled\n\n## Amdahl's law\n1 / ((1 - P) + P/N)\n其中P/N在N为无穷大时为零, 所以串行部分即1 - P的值决定了并行效率的上限为1 / (1 - P)\n\n## NFData类型\n```haskell\nforce :: NFData a => a -> a\nclass NFData a where\n    rnf :: a -> ()\n    rnf a = a `seq` ()\n```\n自定义的类型可能需要自己实现NFData类\n如:\n```haskell\ninstance NFData a => NFData (Tree a) where\n    rnf Empty = ()\n    rnf (Branch l a r) = rnf l `seq` rnf a `seq` rnf r\n```\n\n## Evaluation Strategies\n\n目的是将业务逻辑与并行策略分离开, 就像下面这样\n(fib 35, fib 36) `using` parPair -- 使用并行\n(fib 35, fib 36)                 -- 不使用并行\n注意: the Strategys must obey the identity property\ntype Strategy a = a -> Eval a\n\n## Parameterized Strategies\n\nwe can write a Strategy over a pair of pairs that evaluates the first component (only) of both pairs in parallel.\nevalPair (evalPair rpar r0) (evalPair rpar r0) :: Strategy ((a,b),(c,d))\n\n## A Strategy for Evaluating a List in Parallel\n\n对一个列表的每一个元素使用指定的并发策略\nlet solutions = map solve puzzles `using` parList rseq\n\n## Example: The K-Means Problem\n\n## Parallelizing Lazy Streams with parBuffer\n\nA common pattern in Haskell programming is to use a lazy list as a stream so that the\nprogram can consume input while simultaneously producing output and consequently\nrun in constant space.\n此时并发如果实现得不好,可能会破坏这种lazy流属性导致消耗大量的内存\n\n## Chunking Strategies\n\n","source":"_posts/haskell_concurrent.md","raw":"title: Parallel and Concurrent Programming in Haskell 1\ndate: 2016-02-02\ntags: [haskell]\n---\n\n## parallel和concurrent\nparallel是在多个计算硬件上同时计算\nconcurrent则是一个逻辑概念,使用多个逻辑线程,不一定需要多个计算硬件\n\n<!--more-->\n\n## 确定性的编程模型和非确定性的编程模型\ndeterministic programming model: each program can give only one result(执行多次结果都一样)\nnondeterministic programming model: admits programs that may have different results, depending on some aspect of the execution(执行多次结果可能不一样).\nConcurrent programming models are necessarily nondeterministic because they must interact with\nexternal agents that cause events at unpredictable times. Nondeterminism has some\nnotable drawbacks, however: Programs become significantly harder to test and reason about.\n\nIn Haskell, most parallel programming models are deterministic.\n\n## 安装threadscope\nsudo apt-get install threadscope\n\n## 下载示例代码\ncabal unpack parconc-examples\ncd parconc-examples\ncabal install --only-dependencies\ncabal configure\ncabal build\n\n## 编译器能否自动为我们代码做并行化\nYou might wonder whether the compiler could automatically parallelize programs for us. \nAfter all, it should be easier to do this in a purely functional language, \nwhere the only dependencies between computations are data dependencies, \nwhich are mostly perspicuous and thus readily analyzed. However, even in a purely functional language,\nautomatic parallelization is thwarted by an age-old problem: To make the program faster, \nwe have to gain more from parallelism than we lose due to the overhead of adding it, \nand compile-time analysis cannot make good judgments in this area. \nAn alternative approach is to use runtime profiling to find good candidates for parallelization and \nto feed this information back into the compiler. \nEven this, however, has not been terribly successful in practice.\n\n## weak head normal form\nweak head normal form, 即未完全求值的形式, 完全求值的形式叫做normal form\nhaskell的求值顺序与eager evaluation的语言(先对参数求值, 再对函数求值)相反, \n即从外向里, 先对函数求值, 再对参数求值, 于是参数有可能因为不需要而被省掉求值运算\n\n下面这一段说明了haskell的求值顺序\n```haskell\nPrelude> let xs = map (+1) [1..10] :: [Int]\nPrelude> :sprint xs\nxs = _\nPrelude> seq xs ()\n()\nPrelude> :sprint xs\nxs = _ : _\nPrelude> length xs\n10\nPrelude> :sprint xs\nxs = [_,_,_,_,_,_,_,_,_,_]\nPrelude> sum xs\n65\nPrelude> :sprint xs\nxs = [2,3,4,5,6,7,8,9,10,11]\n```\n可见, 执行length并不需要完全求值, 诸如此类的情况节约了计算资源\n\n## The Eval Monad, rpar, and rseq\nControl.Parallel.Strategies\n\n几种模式\n```haskell\nrunEval $ do\n    a <- rpar (f x)\n    b <- rpar (f y)\n    return (a,b)\n\nrunEval $ do\n    a <- rpar (f x)\n    b <- rseq (f y)\n    return (a,b)\n\nrunEval $ do\n    a <- rpar (f x)\n    b <- rseq (f y)\n    rseq a\n    return (a,b)\n    \nrunEval $ do\n    a <- rpar (f x)\n    b <- rpar (f y)\n    rseq a\n    rseq b\n    return (a,b)\n```\n执行示例代码\n```\nghc -O2 rpar.hs -threaded\n./rpar 1 +RTS -N2\nghc -O2 sudoku1.hs -rtsopts\n./sudoku1 sudoku17.1000.txt\n./sudoku1 sudoku17.1000.txt +RTS -s\nThe argument +RTS -s instructs the GHC runtime system to emit the statistics shown.\nghc -O2 sudoku2.hs -rtsopts -threaded\n./sudoku2 sudoku17.1000.txt +RTS -N2 -s\nrm sudoku2; ghc -O2 sudoku2.hs -threaded -rtsopts -eventlog\n./sudoku2 sudoku17.1000.txt +RTS -N2 -l\nthreadscope sudoku2.eventlog\n```\n\n## 动态分配任务\nspark的概念\noverflowed\ndud\nGC’d\nfizzled\n\n## Amdahl's law\n1 / ((1 - P) + P/N)\n其中P/N在N为无穷大时为零, 所以串行部分即1 - P的值决定了并行效率的上限为1 / (1 - P)\n\n## NFData类型\n```haskell\nforce :: NFData a => a -> a\nclass NFData a where\n    rnf :: a -> ()\n    rnf a = a `seq` ()\n```\n自定义的类型可能需要自己实现NFData类\n如:\n```haskell\ninstance NFData a => NFData (Tree a) where\n    rnf Empty = ()\n    rnf (Branch l a r) = rnf l `seq` rnf a `seq` rnf r\n```\n\n## Evaluation Strategies\n\n目的是将业务逻辑与并行策略分离开, 就像下面这样\n(fib 35, fib 36) `using` parPair -- 使用并行\n(fib 35, fib 36)                 -- 不使用并行\n注意: the Strategys must obey the identity property\ntype Strategy a = a -> Eval a\n\n## Parameterized Strategies\n\nwe can write a Strategy over a pair of pairs that evaluates the first component (only) of both pairs in parallel.\nevalPair (evalPair rpar r0) (evalPair rpar r0) :: Strategy ((a,b),(c,d))\n\n## A Strategy for Evaluating a List in Parallel\n\n对一个列表的每一个元素使用指定的并发策略\nlet solutions = map solve puzzles `using` parList rseq\n\n## Example: The K-Means Problem\n\n## Parallelizing Lazy Streams with parBuffer\n\nA common pattern in Haskell programming is to use a lazy list as a stream so that the\nprogram can consume input while simultaneously producing output and consequently\nrun in constant space.\n此时并发如果实现得不好,可能会破坏这种lazy流属性导致消耗大量的内存\n\n## Chunking Strategies\n\n","slug":"haskell_concurrent","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mu0097mcxqeq1gq9js"},{"title":"Parallel and Concurrent Programming in Haskell 2","date":"2016-02-02T16:00:00.000Z","_content":"\n大数组怎么并行\n使用GPU并行 \n\n<!--more-->\n\nThere is nothing in the types to stop you from returning an IVar from\nrunPar and passing it to another call of runPar . This is a Very Bad\nIdea; don’t do it. The implementation of the Par monad assumes that\nIVar s are created and used within the same runPar , and breaking this\nassumption could lead to a runtime error, deadlock, or worse.\n\nrunPar $ do\n    i <- new\n    j <- new\n    fork (put i (fib n))\n    fork (put j (fib m))\n    a <- get i\n    b <- get j\n    return (a+b)\n\n## Data Parallel Programming with Repa\n\n大数组怎么并行呢 \nimport Data.Array.Repa as Repa\n\n## GPU Programming with Accelerate\nGPU有大量并行计算单元\nthe processors of a GPU all run exactly the same code in lockstep, \nso they are suitable only for data-parallel tasks where the operations to perform on each data item are identical.\n\nGPU与CPU指令集不同,需要专门的编译器为GPU编译代码,源码一般也类似受限制的C(CUDA和OpenCL)\nAccelerate库是一个EDSL(嵌入的领域专门语言),使我们不需要写CUDA或OpenCL也可以使用GPU的计算能力\n\ncabal install accelerate\ncabal install accelerate-cuda\n\n","source":"_posts/haskell_concurrent2.md","raw":"title: Parallel and Concurrent Programming in Haskell 2\ndate: 2016-02-03\ntags: [haskell]\n---\n\n大数组怎么并行\n使用GPU并行 \n\n<!--more-->\n\nThere is nothing in the types to stop you from returning an IVar from\nrunPar and passing it to another call of runPar . This is a Very Bad\nIdea; don’t do it. The implementation of the Par monad assumes that\nIVar s are created and used within the same runPar , and breaking this\nassumption could lead to a runtime error, deadlock, or worse.\n\nrunPar $ do\n    i <- new\n    j <- new\n    fork (put i (fib n))\n    fork (put j (fib m))\n    a <- get i\n    b <- get j\n    return (a+b)\n\n## Data Parallel Programming with Repa\n\n大数组怎么并行呢 \nimport Data.Array.Repa as Repa\n\n## GPU Programming with Accelerate\nGPU有大量并行计算单元\nthe processors of a GPU all run exactly the same code in lockstep, \nso they are suitable only for data-parallel tasks where the operations to perform on each data item are identical.\n\nGPU与CPU指令集不同,需要专门的编译器为GPU编译代码,源码一般也类似受限制的C(CUDA和OpenCL)\nAccelerate库是一个EDSL(嵌入的领域专门语言),使我们不需要写CUDA或OpenCL也可以使用GPU的计算能力\n\ncabal install accelerate\ncabal install accelerate-cuda\n\n","slug":"haskell_concurrent2","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mv009amcxq95h4g7dk"},{"title":"Parallel and Concurrent Programming in Haskell 2","date":"2016-02-02T16:00:00.000Z","_content":"\n\n","source":"_posts/haskell_concurrent3.md","raw":"title: Parallel and Concurrent Programming in Haskell 2\ndate: 2016-02-03\ntags: [haskell]\n---\n\n\n","slug":"haskell_concurrent3","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mw009cmcxq1246type"},{"title":"Haskell Functor","date":"2015-12-20T16:00:00.000Z","_content":"\nHaskell没有继承关系(做得太对了!), 都是interface的感觉, 一个type class就是一个interface, 以此实现多态\nfunctor, 也是一个type class, 指内容允许被maped over, 如list, 内部元素可以被map, 从而得到另一个list\n<!--more-->\n## Functor定义\n```haskell\nclass Functor f where\n    fmap :: (a -> b) -> f a -> f b\n```\nfunctor修饰了a(如Int)这样的类型变成了f a(如lists Int)这种,这才是一个具体的类型\n这里的f 也叫 type constructor, a 也叫 type parameter, f a才是一个concrete type\n另例: Maybe String里的Maybe 也是 type constructor, String 是 type parameter, Maybe String是concrete type\nfunctor实质上定义了一个盒子(box),只有一个fmap函数,该函数可以把盒子里的内容转换成别的内容,而盒子不变\n\n## list对functor的实现\n```haskell\nmap :: (a -> b) -> [a] -> [b]\n\ninstance Functor [] where\nfmap = map\n```\n\n<pre>\nghci> fmap (*2) [1..3]\n[2,4,6]\nghci> map (*2) [1..3]\n[2,4,6]\n</pre>\n\n## 其他例子\nTree 也是 functor\n```haskell\ninstance Functor Tree where\n    fmap f EmptyTree = EmptyTree\n    fmap f (Node x left right) = Node (f x) (fmap f left) (fmap f right)\n```\nMaybe 也是 functor\n```haskell\ninstance Functor Maybe where\n    fmap f (Just x) = Just (f x)\n    fmap f Nothing = Nothing\n```\nEither a 也是 functor, 注意这里有一个a, 因为Either本身有两个类型参数, 而fmap只能带一个, \n```haskell\ninstance Functor (Either a) where\n    fmap f (Right x) = Right (f x)\n    fmap f (Left x) = Left x\n```\nMap k 同理也是一个functor, 因为Map也有两个类型参数(Map k v)\n\n### IO也是functor\n```haskell\ninstance Functor IO where\n    fmap f action = do\n        result <- action\n        return (f result)\n```\n\n### function也是functor\nThe function type r -> a can be rewritten as (->) r a , much like we can write 2 + 3 as (+) 2 3 .\n(->) r, 即(r ->), 也是一个functor\n```haskell\ninstance Functor ((->) r) where\n    fmap f g = (\\x -> f (g x))\n推导过程:\n   fmap :: (a -> b) -> f a -> f b\n将(->) r代入f\n即 fmap :: (a -> b) -> ((->) r a) -> ((->) r b)\n即 fmap :: (a -> b) -> (r -> a) -> (r -> b)\n```\n其实这就是(.), function composition\n\nfmap一个function会得到另一个function,就像fmap一个Maybe会得到另一个Maybe, fmap一个List会得到另一个List\n(->)的第二个type parameter被fmap从a换成b,于是原来的函数从r -> a变成了r -> b\n函数也被认为是值和其环境, functor是环境\n\n我们可以以另一个角度看fmap的定义\n将fmap :: (a -> b) -> f a -> f b\n看成fmap :: (a -> b) -> (f a -> f b) \n可以理解为fmap接受一个函数返回另一个函数(这叫做lifting),\n这个函数接受一个f环境a类型值返回f环境b类型值\n即fmap把(a -> b)这样一个函数升格(lift)成了处理functor的函数(f a -> f b)\n\n### Functor法则\n在实现一个functor时应当遵守以下两点\n* fmap id = id, id即\\x -> x\n* fmap (f . g) = fmap f . fmap g\n不符合法则的一个例子\n```haskell\ninstance Functor CMaybe where\nfmap f CNothing = CNothing\nfmap f (CJust counter x) = CJust (counter+1) (f x)\n\nghci> fmap id (CJust 0 \"haha\")\nCJust 1 \"haha\"\nghci> id (CJust 0 \"haha\")\nCJust 0 \"haha\"\n```\n\n","source":"_posts/haskell_functor.md","raw":"title: Haskell Functor\ndate: 2015-12-21\ntags: [haskell]\n---\n\nHaskell没有继承关系(做得太对了!), 都是interface的感觉, 一个type class就是一个interface, 以此实现多态\nfunctor, 也是一个type class, 指内容允许被maped over, 如list, 内部元素可以被map, 从而得到另一个list\n<!--more-->\n## Functor定义\n```haskell\nclass Functor f where\n    fmap :: (a -> b) -> f a -> f b\n```\nfunctor修饰了a(如Int)这样的类型变成了f a(如lists Int)这种,这才是一个具体的类型\n这里的f 也叫 type constructor, a 也叫 type parameter, f a才是一个concrete type\n另例: Maybe String里的Maybe 也是 type constructor, String 是 type parameter, Maybe String是concrete type\nfunctor实质上定义了一个盒子(box),只有一个fmap函数,该函数可以把盒子里的内容转换成别的内容,而盒子不变\n\n## list对functor的实现\n```haskell\nmap :: (a -> b) -> [a] -> [b]\n\ninstance Functor [] where\nfmap = map\n```\n\n<pre>\nghci> fmap (*2) [1..3]\n[2,4,6]\nghci> map (*2) [1..3]\n[2,4,6]\n</pre>\n\n## 其他例子\nTree 也是 functor\n```haskell\ninstance Functor Tree where\n    fmap f EmptyTree = EmptyTree\n    fmap f (Node x left right) = Node (f x) (fmap f left) (fmap f right)\n```\nMaybe 也是 functor\n```haskell\ninstance Functor Maybe where\n    fmap f (Just x) = Just (f x)\n    fmap f Nothing = Nothing\n```\nEither a 也是 functor, 注意这里有一个a, 因为Either本身有两个类型参数, 而fmap只能带一个, \n```haskell\ninstance Functor (Either a) where\n    fmap f (Right x) = Right (f x)\n    fmap f (Left x) = Left x\n```\nMap k 同理也是一个functor, 因为Map也有两个类型参数(Map k v)\n\n### IO也是functor\n```haskell\ninstance Functor IO where\n    fmap f action = do\n        result <- action\n        return (f result)\n```\n\n### function也是functor\nThe function type r -> a can be rewritten as (->) r a , much like we can write 2 + 3 as (+) 2 3 .\n(->) r, 即(r ->), 也是一个functor\n```haskell\ninstance Functor ((->) r) where\n    fmap f g = (\\x -> f (g x))\n推导过程:\n   fmap :: (a -> b) -> f a -> f b\n将(->) r代入f\n即 fmap :: (a -> b) -> ((->) r a) -> ((->) r b)\n即 fmap :: (a -> b) -> (r -> a) -> (r -> b)\n```\n其实这就是(.), function composition\n\nfmap一个function会得到另一个function,就像fmap一个Maybe会得到另一个Maybe, fmap一个List会得到另一个List\n(->)的第二个type parameter被fmap从a换成b,于是原来的函数从r -> a变成了r -> b\n函数也被认为是值和其环境, functor是环境\n\n我们可以以另一个角度看fmap的定义\n将fmap :: (a -> b) -> f a -> f b\n看成fmap :: (a -> b) -> (f a -> f b) \n可以理解为fmap接受一个函数返回另一个函数(这叫做lifting),\n这个函数接受一个f环境a类型值返回f环境b类型值\n即fmap把(a -> b)这样一个函数升格(lift)成了处理functor的函数(f a -> f b)\n\n### Functor法则\n在实现一个functor时应当遵守以下两点\n* fmap id = id, id即\\x -> x\n* fmap (f . g) = fmap f . fmap g\n不符合法则的一个例子\n```haskell\ninstance Functor CMaybe where\nfmap f CNothing = CNothing\nfmap f (CJust counter x) = CJust (counter+1) (f x)\n\nghci> fmap id (CJust 0 \"haha\")\nCJust 1 \"haha\"\nghci> id (CJust 0 \"haha\")\nCJust 0 \"haha\"\n```\n\n","slug":"haskell_functor","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5my009fmcxq7f9d13je"},{"title":"Haskell Module","date":"2016-01-22T16:00:00.000Z","_content":"\n```haskell\nmodule Geometry\n( sphereVolume\n, sphereArea\n, cubeVolume\n, cubeArea\n, cuboidArea\n, cuboidVolume\n) where\n\nsphereVolume :: Float -> Float\nsphereVolume radius = (4.0 / 3.0) * pi * (radius ^ 3)\n\nsphereArea :: Float -> Float\nsphereArea radius = 4 * pi * (radius ^ 2)\n\ncubeVolume :: Float -> Float\ncubeVolume side = cuboidVolume side side side\n\ncubeArea :: Float -> Float\ncubeArea side = cuboidArea side side side\n\ncuboidVolume :: Float -> Float -> Float -> Float\ncuboidVolume a b c = rectArea a b * c\n\ncuboidArea :: Float -> Float -> Float -> Float\ncuboidArea a b c = rectArea a b * 2 + rectArea a c * 2 + rectArea c b * 2\n\nrectArea :: Float -> Float -> Float\nrectArea a b = a * b\n```\n\n","source":"_posts/haskell_module.md","raw":"title: Haskell Module\ndate: 2016-01-23\ntags: [haskell]\n---\n\n```haskell\nmodule Geometry\n( sphereVolume\n, sphereArea\n, cubeVolume\n, cubeArea\n, cuboidArea\n, cuboidVolume\n) where\n\nsphereVolume :: Float -> Float\nsphereVolume radius = (4.0 / 3.0) * pi * (radius ^ 3)\n\nsphereArea :: Float -> Float\nsphereArea radius = 4 * pi * (radius ^ 2)\n\ncubeVolume :: Float -> Float\ncubeVolume side = cuboidVolume side side side\n\ncubeArea :: Float -> Float\ncubeArea side = cuboidArea side side side\n\ncuboidVolume :: Float -> Float -> Float -> Float\ncuboidVolume a b c = rectArea a b * c\n\ncuboidArea :: Float -> Float -> Float -> Float\ncuboidArea a b c = rectArea a b * 2 + rectArea a c * 2 + rectArea c b * 2\n\nrectArea :: Float -> Float -> Float\nrectArea a b = a * b\n```\n\n","slug":"haskell_module","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5mz009hmcxq3bu5cylg"},{"title":"Haskell Monad","date":"2016-01-21T16:00:00.000Z","_content":"\n如果我们有一个环境和值m a, 还有一个函数a -> m b, \n怎样才能调用这个函数呢?\n我们需要monad, 它是对Applicative Functor的补充\n<!--more-->\n\n## monad\n```haskell\nclass Monad m where\n    return :: a -> m a\n    (>>=) :: m a -> (a -> m b) -> m b\n    (>>) :: m a -> m b -> m b\n    x >> y = x >>= \\_ -> y\n    fail :: String -> m a\n    fail msg = error msg\n```\n感觉class定义里应该有Applicative m, 但是没有, \n这是因为早期haskell并不认为Applicative Functor适合Haskell\n但是现在证明适合, 并且所有的Monad都是Applicative Functor, 虽然class定义里没有说\n```haskell\ninstance Monad Maybe where\n    return x = Just x\n    Nothing >>= f = Nothing\n    Just x >>= f = f x\n    fail _ = Nothing\n```\n\n原来Monad提供了类似F#的从左向右调用的功能, 就是\\>>=\n\n### 一个Monad应用实例\n```haskell\ntype Birds = Int\ntype Pole = (Birds, Birds)\n\nlandLeft :: Birds -> Pole -> Maybe Pole\nlandLeft n (left, right)\n    | abs ((left + n) - right) < 4 = Just (left + n, right)\n    | otherwise = Nothing\nlandRight :: Birds -> Pole -> Maybe Pole\nlandRight n (left, right)\n    | abs (left - (right + n)) < 4 = Just (left, right + n)\n    | otherwise = Nothing\n\nghci> return (0, 0) >>= landRight 2 >>= landLeft 2 >>= landRight 2\nJust (2,4)\nghci> return (0, 0) >>= landLeft 1 >> Nothing >>= landRight 1\nNothing\n```\n\n当每一步都有可能失败的时候,好的做法是允许每一步的调用返回Maybe类型\n反例, 如果不使用Monad代码可能像这样\n```haskell\nroutine :: Maybe Pole\nroutine = case landLeft 1 (0, 0) of\n    Nothing -> Nothing\n    Just pole1 -> case landRight 4 pole1 of\n        Nothing -> Nothing\n        Just pole2 -> case landLeft 2 pole2 of\n            Nothing -> Nothing\n            Just pole3 -> landLeft 1 pole3\n```\nMonad展示了错误处理的境界\n\n## do\n```haskell\n  Just 3 >>= (\\x -> Just (show x ++ \"!\"))\n即Just 3 >>= (\\x -> Just \"!\" >>= (\\y -> Just (show x ++ y)))\n像let x = 3; y = \"!\" in show x ++ y\n```\n\n加换行以求清晰一些\n```haskell\nfoo :: Maybe String\nfoo = Just 3 >>= (\\x ->\n      Just \"!\" >>= (\\y ->\n      Just (show x ++ y)))\n```\n干脆发明一个do语法\n```haskell\nfoo :: Maybe String\nfoo = do\n    x <- Just 3\n    y <- Just \"!\"\n    Just (show x ++ y)\n```\n\n前例也可以使用do语法改写为:\n```haskell\nroutine :: Maybe Pole\nroutine = do\n    start <- return (0, 0)\n    first <- landLeft 2 start\n    Nothing\n    second <- landRight 2 first\n    landLeft 1 second\n```\n明显不如原版可读性好\n\ndo语法里可以使用pattern match\n```haskell\njustH :: Maybe Char\njustH = do\n    (x:xs) <- Just \"hello\"\n    return x\n```\n\nWhen pattern matching fails in a do expression, the fail function (part of the Monad type class) enables it to \nresult in a failure in the context of the current monad, instead of making the program crash.\n\n### List Monad\n\n```haskell\ninstance Monad [] where\n    return x = [x]\n    xs >>= f = concat (map f xs)\n    fail _ = []\n    \nghci> [1,2] >>= \\n -> ['a','b'] >>= \\ch -> return (n, ch)\n[(1,'a'),(1,'b'),(2,'a'),(2,'b')]\n\nlistOfTuples :: [(Int, Char)]\nlistOfTuples = do\n    n <- [1,2]\n    ch <- ['a','b']\n    return (n, ch)\n\nghci> [ (n, ch) | n <- [1,2], ch <- ['a','b'] ]\n[(1,'a'),(1,'b'),(2,'a'),(2,'b')]\n```\nIn fact, list comprehensions are just syntactic sugar for using lists as monads.\n\n### MonadPlus and the guard Function\n```haskell\nghci> [ x | x <- [1..50], '7' `elem` show x ]\n[7,17,27,37,47]\n\nclass Monad m => MonadPlus m where\n    mzero :: m a\n    mplus :: m a -> m a -> m a\n```\nThe MonadPlus type class is for monads that can also act as monoids.\nmzero is synonymous with mempty from the Monoid type class, and mplus corresponds to mappend.\n\n```haskell\ninstance MonadPlus [] where\n    mzero = []\n    mplus = (++)\n    \nguard :: (MonadPlus m) => Bool -> m ()\nguard True = return ()\nguard False = mzero\n\nghci> [1..50] >>= (\\x -> guard ('7' `elem` show x) >> return x)\n[7,17,27,37,47]\n\nsevensOnly :: [Int]\nsevensOnly = do\n    x <- [1..50]\n    guard ('7' `elem` show x)\n    return x\n```\n\n## Monad Laws\nLeft Identity\n```haskell\nreturn x >>= f 即 f x\n```\nRight Identity\n```haskell\nm >>= return 即 m\n```\nAssociativity\n```haskell\n(m >>= f) >>= g 即 m >>= (\\x -> f x >>= g)\n```\n\n### the mtl package\n\nghc-pkg list\n\n### Writer Monad\n```haskell\nnewtype Writer w a = Writer { runWriter :: (a, w) }\n\ninstance (Monoid w) => Monad (Writer w) where\n    return x = Writer (x, mempty)\n    (Writer (x, v)) >>= f = let (Writer (y, v')) = f x in Writer (y, v `mappend` v')\n```\n附加数据, 往往做日志有用\n\n### Difference List\n保证效率连接List(即总是在List头部++而不是尾部++)的一个类型\n```haskell\nnewtype DiffList a = DiffList { getDiffList :: [a] -> [a] }\ninstance Monoid (DiffList a) where\n    mempty = DiffList (\\xs -> [] ++ xs)\n    (DiffList f) `mappend` (DiffList g) = DiffList (\\xs -> f (g xs))\n```\n结果DiffList就是一个function composition, 相当于把++的顺序倒了过来\n这样原来慢的变成快的,原来快的变成慢的\n\n### Function as Monad(Reader)\n```haskell\ninstance Monad ((->) r) where\n    return x = \\_ -> x\n    h >>= f = \\w -> f (h w) w\n```\n函数的环境是,还缺一个值,我们需要对这个值调用这个函数来取得返回值\n\n```haskell\naddStuff :: Int -> Int\naddStuff = do\n    a <- (*2)\n    b <- (+10)\n    return (a+b)\n```\n\n函数的Monad也叫Reader, 所有的函数都从同一个数据源取值\n当我们有许多操作针对同样的值, 就可以考虑使用Reader\n\n### State\n把状态封装在Monad的环境里\n```haskell\nnewtype State s a = State { runState :: s -> (a, s) }\n\ninstance Monad (State s) where\n    return x = State $ \\s -> (x, s)\n    (State h) >>= f = State $ \\s -> let (a, newState) = h s (State g) = f a in g newState\n```\nreturn x返回一个一元函数,该函数接受一个状态返回一个State Monad,该Monad的值是x,环境是这个状态\n\\>>= 里This lambda will be our new stateful computation.\n\n()基本上当void或erlang的ok来用\n\n### type class MonadState\n\n### Maybe的Nothing只告诉我们失败了, 却没有失败的原因\nControl.Monad.Error\n```haskell\ninstance (Error e) => Monad (Either e) where\n    return x = Right x\n    Right x >>= f = f x\n    Left err >>= f = Left err\n    fail msg = Left (strMsg msg)\n```\n其中e必须符合Error这个type class\n\n### liftM\n有了liftM,我们可以不必实现Functor type class, liftM类似fmap, 就像return和pure是一样的\n```haskell\nliftM :: (Monad m) => (a -> b) -> m a -> m b\nliftM f m = m >>= (\\x -> return (f x))\n```\n函数ap类似<*>\n```haskell\nap :: (Monad m) => m (a -> b) -> m a -> m b\nap mf m = do\n    f <- mf\n    x <- m\n    return (f x)\n```\n\n```haskell\nliftA2 :: (Applicative f) => (a -> b -> c) -> f a -> f b -> f c\nliftA2 f x y = f <$> x <*> y\n```\n这是一个方便的函数\nliftM2至liftM5做的事情相同, 只不过类型要求是Monad\n\n可以直接定义Applicative Functor的pure为return, <*>为ap\n\n### join\n```haskell\njoin :: (Monad m) => m (m a) -> m a\njoin mm = do\n    m <- mm\n    m\n```\n\n```haskell\nghci> join [[1,2,3],[4,5,6]]\n[1,2,3,4,5,6]\nghci> join (Just (Just 9))\nJust 9\nghci> join (Just Nothing)\nNothing\nghci> join Nothing\nNothing\nghci> runWriter $ join (Writer (Writer (1, \"aaa\"), \"bbb\"))\n(1,\"bbbaaa\")\n```\n\nm >>= f 即 join (fmap f m)\n\n### filterM\n```haskell\nfilterM :: (Monad m) => (a -> m Bool) -> [a] -> m [a]\nfilterM _ []     =  return []\nfilterM p (x:xs) =  do\n   flg <- p x\n   ys  <- filterM p xs\n   return (if flg then x:ys else ys)\n```\nfilterM过滤后不仅返回Bool, 还带一个环境(可能包含原因等信息)\n\n例子:\n```haskell\nkeepSmall :: Int -> Writer [String] Bool\nkeepSmall x\n    | x < 4 = do\n        tell [\"Keeping \" ++ show x]\n        return True\n    | otherwise = do\n        tell [show x ++ \" is too large, throwing it away\"]\n        return False\n```\n```haskell\nghci> fst $ runWriter $ filterM keepSmall [9,1,5,2,10,3]\n[1,2,3]\nghci> mapM_ putStrLn $ snd $ runWriter $ filterM keepSmall [9,1,5,2,10,3]\n9 is too large, throwing it away\nKeeping 1\n5 is too large, throwing it away\nKeeping 2\n10 is too large, throwing it away\nKeeping 3\n```\n\n```haskell\npowerset :: [a] -> [[a]]\npowerset xs = filterM (\\x -> [True, False]) xs\n```\n```haskell\nghci> powerset [1,2,3]\n[a] -> [m a]的结果是: [[[1], []], [[2], []], [[3], []]]\n下一步[m a] -> m [a]应该是:\n[x `mappend` y `mappend` z | x <- [[1], []], y <- [[2], []], z <- [[3], []]]\n即: [[1,2,3],[1,2],[1,3],[1],[2,3],[2],[3],[]]\n```\n\n### foldM\n```haskell\nfoldM :: (Monad m) => (a -> b -> m a) -> a -> [b] -> m a\n```\n\n### Composing Monadic Functions\n```haskell\nghci> let f = (+1) . (*100)\nghci> f 4\n401\nghci> let g = (\\x -> return (x+1)) <=< (\\x -> return (x*100))\nghci> Just 4 >>= g\nJust 401\n```\n这是Monad与非Monad的类比,其实操作都很像,换几个符号而已\n\n```haskell\nghci> let f = foldr (.) id [(+1),(*100),(+1)]\nghci> f 1\n201\n```\n\nRational类似与Float不同, 不会丢失精度\n\n","source":"_posts/haskell_monad.md","raw":"title: Haskell Monad\ndate: 2016-01-22\ntags: [haskell]\n---\n\n如果我们有一个环境和值m a, 还有一个函数a -> m b, \n怎样才能调用这个函数呢?\n我们需要monad, 它是对Applicative Functor的补充\n<!--more-->\n\n## monad\n```haskell\nclass Monad m where\n    return :: a -> m a\n    (>>=) :: m a -> (a -> m b) -> m b\n    (>>) :: m a -> m b -> m b\n    x >> y = x >>= \\_ -> y\n    fail :: String -> m a\n    fail msg = error msg\n```\n感觉class定义里应该有Applicative m, 但是没有, \n这是因为早期haskell并不认为Applicative Functor适合Haskell\n但是现在证明适合, 并且所有的Monad都是Applicative Functor, 虽然class定义里没有说\n```haskell\ninstance Monad Maybe where\n    return x = Just x\n    Nothing >>= f = Nothing\n    Just x >>= f = f x\n    fail _ = Nothing\n```\n\n原来Monad提供了类似F#的从左向右调用的功能, 就是\\>>=\n\n### 一个Monad应用实例\n```haskell\ntype Birds = Int\ntype Pole = (Birds, Birds)\n\nlandLeft :: Birds -> Pole -> Maybe Pole\nlandLeft n (left, right)\n    | abs ((left + n) - right) < 4 = Just (left + n, right)\n    | otherwise = Nothing\nlandRight :: Birds -> Pole -> Maybe Pole\nlandRight n (left, right)\n    | abs (left - (right + n)) < 4 = Just (left, right + n)\n    | otherwise = Nothing\n\nghci> return (0, 0) >>= landRight 2 >>= landLeft 2 >>= landRight 2\nJust (2,4)\nghci> return (0, 0) >>= landLeft 1 >> Nothing >>= landRight 1\nNothing\n```\n\n当每一步都有可能失败的时候,好的做法是允许每一步的调用返回Maybe类型\n反例, 如果不使用Monad代码可能像这样\n```haskell\nroutine :: Maybe Pole\nroutine = case landLeft 1 (0, 0) of\n    Nothing -> Nothing\n    Just pole1 -> case landRight 4 pole1 of\n        Nothing -> Nothing\n        Just pole2 -> case landLeft 2 pole2 of\n            Nothing -> Nothing\n            Just pole3 -> landLeft 1 pole3\n```\nMonad展示了错误处理的境界\n\n## do\n```haskell\n  Just 3 >>= (\\x -> Just (show x ++ \"!\"))\n即Just 3 >>= (\\x -> Just \"!\" >>= (\\y -> Just (show x ++ y)))\n像let x = 3; y = \"!\" in show x ++ y\n```\n\n加换行以求清晰一些\n```haskell\nfoo :: Maybe String\nfoo = Just 3 >>= (\\x ->\n      Just \"!\" >>= (\\y ->\n      Just (show x ++ y)))\n```\n干脆发明一个do语法\n```haskell\nfoo :: Maybe String\nfoo = do\n    x <- Just 3\n    y <- Just \"!\"\n    Just (show x ++ y)\n```\n\n前例也可以使用do语法改写为:\n```haskell\nroutine :: Maybe Pole\nroutine = do\n    start <- return (0, 0)\n    first <- landLeft 2 start\n    Nothing\n    second <- landRight 2 first\n    landLeft 1 second\n```\n明显不如原版可读性好\n\ndo语法里可以使用pattern match\n```haskell\njustH :: Maybe Char\njustH = do\n    (x:xs) <- Just \"hello\"\n    return x\n```\n\nWhen pattern matching fails in a do expression, the fail function (part of the Monad type class) enables it to \nresult in a failure in the context of the current monad, instead of making the program crash.\n\n### List Monad\n\n```haskell\ninstance Monad [] where\n    return x = [x]\n    xs >>= f = concat (map f xs)\n    fail _ = []\n    \nghci> [1,2] >>= \\n -> ['a','b'] >>= \\ch -> return (n, ch)\n[(1,'a'),(1,'b'),(2,'a'),(2,'b')]\n\nlistOfTuples :: [(Int, Char)]\nlistOfTuples = do\n    n <- [1,2]\n    ch <- ['a','b']\n    return (n, ch)\n\nghci> [ (n, ch) | n <- [1,2], ch <- ['a','b'] ]\n[(1,'a'),(1,'b'),(2,'a'),(2,'b')]\n```\nIn fact, list comprehensions are just syntactic sugar for using lists as monads.\n\n### MonadPlus and the guard Function\n```haskell\nghci> [ x | x <- [1..50], '7' `elem` show x ]\n[7,17,27,37,47]\n\nclass Monad m => MonadPlus m where\n    mzero :: m a\n    mplus :: m a -> m a -> m a\n```\nThe MonadPlus type class is for monads that can also act as monoids.\nmzero is synonymous with mempty from the Monoid type class, and mplus corresponds to mappend.\n\n```haskell\ninstance MonadPlus [] where\n    mzero = []\n    mplus = (++)\n    \nguard :: (MonadPlus m) => Bool -> m ()\nguard True = return ()\nguard False = mzero\n\nghci> [1..50] >>= (\\x -> guard ('7' `elem` show x) >> return x)\n[7,17,27,37,47]\n\nsevensOnly :: [Int]\nsevensOnly = do\n    x <- [1..50]\n    guard ('7' `elem` show x)\n    return x\n```\n\n## Monad Laws\nLeft Identity\n```haskell\nreturn x >>= f 即 f x\n```\nRight Identity\n```haskell\nm >>= return 即 m\n```\nAssociativity\n```haskell\n(m >>= f) >>= g 即 m >>= (\\x -> f x >>= g)\n```\n\n### the mtl package\n\nghc-pkg list\n\n### Writer Monad\n```haskell\nnewtype Writer w a = Writer { runWriter :: (a, w) }\n\ninstance (Monoid w) => Monad (Writer w) where\n    return x = Writer (x, mempty)\n    (Writer (x, v)) >>= f = let (Writer (y, v')) = f x in Writer (y, v `mappend` v')\n```\n附加数据, 往往做日志有用\n\n### Difference List\n保证效率连接List(即总是在List头部++而不是尾部++)的一个类型\n```haskell\nnewtype DiffList a = DiffList { getDiffList :: [a] -> [a] }\ninstance Monoid (DiffList a) where\n    mempty = DiffList (\\xs -> [] ++ xs)\n    (DiffList f) `mappend` (DiffList g) = DiffList (\\xs -> f (g xs))\n```\n结果DiffList就是一个function composition, 相当于把++的顺序倒了过来\n这样原来慢的变成快的,原来快的变成慢的\n\n### Function as Monad(Reader)\n```haskell\ninstance Monad ((->) r) where\n    return x = \\_ -> x\n    h >>= f = \\w -> f (h w) w\n```\n函数的环境是,还缺一个值,我们需要对这个值调用这个函数来取得返回值\n\n```haskell\naddStuff :: Int -> Int\naddStuff = do\n    a <- (*2)\n    b <- (+10)\n    return (a+b)\n```\n\n函数的Monad也叫Reader, 所有的函数都从同一个数据源取值\n当我们有许多操作针对同样的值, 就可以考虑使用Reader\n\n### State\n把状态封装在Monad的环境里\n```haskell\nnewtype State s a = State { runState :: s -> (a, s) }\n\ninstance Monad (State s) where\n    return x = State $ \\s -> (x, s)\n    (State h) >>= f = State $ \\s -> let (a, newState) = h s (State g) = f a in g newState\n```\nreturn x返回一个一元函数,该函数接受一个状态返回一个State Monad,该Monad的值是x,环境是这个状态\n\\>>= 里This lambda will be our new stateful computation.\n\n()基本上当void或erlang的ok来用\n\n### type class MonadState\n\n### Maybe的Nothing只告诉我们失败了, 却没有失败的原因\nControl.Monad.Error\n```haskell\ninstance (Error e) => Monad (Either e) where\n    return x = Right x\n    Right x >>= f = f x\n    Left err >>= f = Left err\n    fail msg = Left (strMsg msg)\n```\n其中e必须符合Error这个type class\n\n### liftM\n有了liftM,我们可以不必实现Functor type class, liftM类似fmap, 就像return和pure是一样的\n```haskell\nliftM :: (Monad m) => (a -> b) -> m a -> m b\nliftM f m = m >>= (\\x -> return (f x))\n```\n函数ap类似<*>\n```haskell\nap :: (Monad m) => m (a -> b) -> m a -> m b\nap mf m = do\n    f <- mf\n    x <- m\n    return (f x)\n```\n\n```haskell\nliftA2 :: (Applicative f) => (a -> b -> c) -> f a -> f b -> f c\nliftA2 f x y = f <$> x <*> y\n```\n这是一个方便的函数\nliftM2至liftM5做的事情相同, 只不过类型要求是Monad\n\n可以直接定义Applicative Functor的pure为return, <*>为ap\n\n### join\n```haskell\njoin :: (Monad m) => m (m a) -> m a\njoin mm = do\n    m <- mm\n    m\n```\n\n```haskell\nghci> join [[1,2,3],[4,5,6]]\n[1,2,3,4,5,6]\nghci> join (Just (Just 9))\nJust 9\nghci> join (Just Nothing)\nNothing\nghci> join Nothing\nNothing\nghci> runWriter $ join (Writer (Writer (1, \"aaa\"), \"bbb\"))\n(1,\"bbbaaa\")\n```\n\nm >>= f 即 join (fmap f m)\n\n### filterM\n```haskell\nfilterM :: (Monad m) => (a -> m Bool) -> [a] -> m [a]\nfilterM _ []     =  return []\nfilterM p (x:xs) =  do\n   flg <- p x\n   ys  <- filterM p xs\n   return (if flg then x:ys else ys)\n```\nfilterM过滤后不仅返回Bool, 还带一个环境(可能包含原因等信息)\n\n例子:\n```haskell\nkeepSmall :: Int -> Writer [String] Bool\nkeepSmall x\n    | x < 4 = do\n        tell [\"Keeping \" ++ show x]\n        return True\n    | otherwise = do\n        tell [show x ++ \" is too large, throwing it away\"]\n        return False\n```\n```haskell\nghci> fst $ runWriter $ filterM keepSmall [9,1,5,2,10,3]\n[1,2,3]\nghci> mapM_ putStrLn $ snd $ runWriter $ filterM keepSmall [9,1,5,2,10,3]\n9 is too large, throwing it away\nKeeping 1\n5 is too large, throwing it away\nKeeping 2\n10 is too large, throwing it away\nKeeping 3\n```\n\n```haskell\npowerset :: [a] -> [[a]]\npowerset xs = filterM (\\x -> [True, False]) xs\n```\n```haskell\nghci> powerset [1,2,3]\n[a] -> [m a]的结果是: [[[1], []], [[2], []], [[3], []]]\n下一步[m a] -> m [a]应该是:\n[x `mappend` y `mappend` z | x <- [[1], []], y <- [[2], []], z <- [[3], []]]\n即: [[1,2,3],[1,2],[1,3],[1],[2,3],[2],[3],[]]\n```\n\n### foldM\n```haskell\nfoldM :: (Monad m) => (a -> b -> m a) -> a -> [b] -> m a\n```\n\n### Composing Monadic Functions\n```haskell\nghci> let f = (+1) . (*100)\nghci> f 4\n401\nghci> let g = (\\x -> return (x+1)) <=< (\\x -> return (x*100))\nghci> Just 4 >>= g\nJust 401\n```\n这是Monad与非Monad的类比,其实操作都很像,换几个符号而已\n\n```haskell\nghci> let f = foldr (.) id [(+1),(*100),(+1)]\nghci> f 1\n201\n```\n\nRational类似与Float不同, 不会丢失精度\n\n","slug":"haskell_monad","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5n0009kmcxqml1geqxh"},{"title":"Haskell Monoid","date":"2016-01-21T16:00:00.000Z","_content":"\n二元函数的共性, 参数与返回值类型相同, 且存在一个值在操作前后不变如\n```\n1 * N = N, N * 1 = N\n[] ++ List = List, List ++ [] = List\n```\n\n<!--more-->\n\n## monoid定义\n\nMonoid是一个type class\n```haskell\nclass Monoid m where\n    mempty :: m\n    mappend :: m -> m -> m\n    mconcat :: [m] -> m\n    mconcat = foldr mappend mempty\n```\n\nmappend,命名来自++这种append,但是像乘法*这样的,并不是append,理解为参数与返回值类型的二元函数就可以    \nmconcat函数可以重写(某些情况下效率比默认的实现好),但大多数情况下用默认的实现就很好.\n\n## monoid法则\n```haskell\nmempty `mappend` x = x\nx `mappend` mempty = x\n(x `mappend` y) `mappend` z = x `mappend` (y `mappend` z)\n```\n\n## newtype\n```haskell\nnewtype ZipList a = ZipList { getZipList :: [a] }\n```\n\n使用现有类型定义一个新类型\nnewtype会比用data包装旧类型的性能要好\n\n另外,举例说明,如果我们想把tuple定义成符合functor, \n且fmap (+3) (1, 1)的结果是(4, 1),\n由于functor都是对后一个type parameter做处理(如Either a b)\n想让tuple的第一个元素被fmap作用就有点难\n看newtype怎么解决这个问题:\n```haskell\nnewtype Pair b a = Pair { getPair :: (a, b) }\n```\n\n### newtype Laziness\nbecause Haskell knows that types made with the newtype keyword can have only one constructor, \nit doesn’t need to evaluate the value passed to the function to \nmake sure that the value conforms to the (CoolBool _) pattern,\nbecause newtype types can have only one possible value constructor and one field\n\nPattern matching on newtype values isn’t like taking something out of a box (as it is with data ), \nbut more about making a direct conversion from one type to another.\n\n## ghci\n导入package\nimport Data.Monoid\n\n## 一些monoid的例子\n#### List\n```haskell\ninstance Monoid [a] where\n    mempty = []\n    mappend = (++)\n    \nghci> \"one\" `mappend` (\"two\" `mappend` \"tree\")\n\"onetwotree\"\n```\n\n#### Num\n由于数字有加法和乘法均满足monoid, 此处就可以使用newtype分别实现Monoid type class\n```haskell\nnewtype Product a = Product { getProduct :: a }\n    deriving (Eq, Ord, Read, Show, Bounded)\n    \ninstance Num a => Monoid (Product a) where\n    mempty = Product 1\n    Product x `mappend` Product y = Product (x * y)\n\nghci> getProduct $ Product 3 `mappend` Product 4 `mappend` Product 2\n24\n```\n\n加法类似\n```haskell\nghci> getSum . mconcat . map Sum $ [1,2,3]\n6\n```\n\n#### Bool\n\n```haskell\nnewtype Any = Any { getAny :: Bool }\n    deriving (Eq, Ord, Read, Show, Bounded)\n    \ninstance Monoid Any where\n    mempty = Any False\n    Any x `mappend` Any y = Any (x || y)\n\nnewtype All = All { getAll :: Bool }\n    deriving (Eq, Ord, Read, Show, Bounded)\n\ninstance Monoid All where\n    mempty = All True\n    All x `mappend` All y = All (x && y)\n\nghci> getAny . mconcat . map Any $ [False, False, False, True]\nTrue\nghci> getAll . mconcat . map All $ [True, True, False]\nFalse\n```\n\n#### Ordering\n```haskell\ninstance Monoid Ordering where\n    mempty = EQ\n    LT `mappend` _ = LT\n    EQ `mappend` y = y\n    GT `mappend` _ = GT\n\n```\n```haskell\nlengthCompare :: String -> String -> Ordering\nlengthCompare x y = let a = length x `compare` length y\n                        b = x `compare` y\n                    in if a == EQ then b else a\n```\n可以改写为    \n```haskell\nlengthCompare :: String -> String -> Ordering\nlengthCompare x y = (length x `compare` length y) `mappend`\n                    (x `compare` y)\n```\n比第一种写法省一个if,且省a, b变量定义\n且带有自动短路功能\n\n#### Maybe\n```haskell\ninstance Monoid a => Monoid (Maybe a) where\n    mempty = Nothing\n    Nothing `mappend` m = m\n    m `mappend` Nothing = m\n    Just m1 `mappend` Just m2 = Just (m1 `mappend` m2)\n```\n\n```haskell\nghci> Just (Sum 3) `mappend` Just (Sum 4)\nJust (Sum {getSum = 7})\n```\n考虑到Maybe的内容的类型不是monoid的情况(Maybe的mappend定义要求m1和m2都是monoid类型),\n于是有了First类型\n```haskell\nnewtype First a = First { getFirst :: Maybe a }\n    deriving (Eq, Ord, Read, Show)\ninstance Monoid (First a) where\n    mempty = First Nothing\n    First (Just x) `mappend` _ = First (Just x)\n    First Nothing `mappend` x = x\n\nghci> getFirst $ First (Just 'a') `mappend` First (Just 'b')\nJust 'a'\n```\n\nFirst is useful when we have a bunch of Maybe values and we just want to know if any of them is a Just.\n\n与First相应的,还有一个Last类型\n\n### Folding with Monoids\n```haskell\nFoldable type class\nfoldMap :: (Monoid m, Foldable t) => (a -> m) -> t a -> m\n```\n\n以Tree为例\n```haskell\ndata Tree a = EmptyTree | Node a (Tree a) (Tree a) deriving (Show)\n\ninstance F.Foldable Tree where\n    foldMap f EmptyTree = mempty\n    foldMap f (Node x l r) = F.foldMap f l `mappend`\n                                       f x `mappend`\n                             F.foldMap f r\nghci> getAny $ F.foldMap (\\x -> Any $ x == 3) testTree\nTrue\nghci> F.foldMap (\\x -> [x]) testTree\n[1,3,6,5,8,9,10]\n```\n\n","source":"_posts/haskell_monoid.md","raw":"title: Haskell Monoid\ndate: 2016-01-22\ntags: [haskell]\n---\n\n二元函数的共性, 参数与返回值类型相同, 且存在一个值在操作前后不变如\n```\n1 * N = N, N * 1 = N\n[] ++ List = List, List ++ [] = List\n```\n\n<!--more-->\n\n## monoid定义\n\nMonoid是一个type class\n```haskell\nclass Monoid m where\n    mempty :: m\n    mappend :: m -> m -> m\n    mconcat :: [m] -> m\n    mconcat = foldr mappend mempty\n```\n\nmappend,命名来自++这种append,但是像乘法*这样的,并不是append,理解为参数与返回值类型的二元函数就可以    \nmconcat函数可以重写(某些情况下效率比默认的实现好),但大多数情况下用默认的实现就很好.\n\n## monoid法则\n```haskell\nmempty `mappend` x = x\nx `mappend` mempty = x\n(x `mappend` y) `mappend` z = x `mappend` (y `mappend` z)\n```\n\n## newtype\n```haskell\nnewtype ZipList a = ZipList { getZipList :: [a] }\n```\n\n使用现有类型定义一个新类型\nnewtype会比用data包装旧类型的性能要好\n\n另外,举例说明,如果我们想把tuple定义成符合functor, \n且fmap (+3) (1, 1)的结果是(4, 1),\n由于functor都是对后一个type parameter做处理(如Either a b)\n想让tuple的第一个元素被fmap作用就有点难\n看newtype怎么解决这个问题:\n```haskell\nnewtype Pair b a = Pair { getPair :: (a, b) }\n```\n\n### newtype Laziness\nbecause Haskell knows that types made with the newtype keyword can have only one constructor, \nit doesn’t need to evaluate the value passed to the function to \nmake sure that the value conforms to the (CoolBool _) pattern,\nbecause newtype types can have only one possible value constructor and one field\n\nPattern matching on newtype values isn’t like taking something out of a box (as it is with data ), \nbut more about making a direct conversion from one type to another.\n\n## ghci\n导入package\nimport Data.Monoid\n\n## 一些monoid的例子\n#### List\n```haskell\ninstance Monoid [a] where\n    mempty = []\n    mappend = (++)\n    \nghci> \"one\" `mappend` (\"two\" `mappend` \"tree\")\n\"onetwotree\"\n```\n\n#### Num\n由于数字有加法和乘法均满足monoid, 此处就可以使用newtype分别实现Monoid type class\n```haskell\nnewtype Product a = Product { getProduct :: a }\n    deriving (Eq, Ord, Read, Show, Bounded)\n    \ninstance Num a => Monoid (Product a) where\n    mempty = Product 1\n    Product x `mappend` Product y = Product (x * y)\n\nghci> getProduct $ Product 3 `mappend` Product 4 `mappend` Product 2\n24\n```\n\n加法类似\n```haskell\nghci> getSum . mconcat . map Sum $ [1,2,3]\n6\n```\n\n#### Bool\n\n```haskell\nnewtype Any = Any { getAny :: Bool }\n    deriving (Eq, Ord, Read, Show, Bounded)\n    \ninstance Monoid Any where\n    mempty = Any False\n    Any x `mappend` Any y = Any (x || y)\n\nnewtype All = All { getAll :: Bool }\n    deriving (Eq, Ord, Read, Show, Bounded)\n\ninstance Monoid All where\n    mempty = All True\n    All x `mappend` All y = All (x && y)\n\nghci> getAny . mconcat . map Any $ [False, False, False, True]\nTrue\nghci> getAll . mconcat . map All $ [True, True, False]\nFalse\n```\n\n#### Ordering\n```haskell\ninstance Monoid Ordering where\n    mempty = EQ\n    LT `mappend` _ = LT\n    EQ `mappend` y = y\n    GT `mappend` _ = GT\n\n```\n```haskell\nlengthCompare :: String -> String -> Ordering\nlengthCompare x y = let a = length x `compare` length y\n                        b = x `compare` y\n                    in if a == EQ then b else a\n```\n可以改写为    \n```haskell\nlengthCompare :: String -> String -> Ordering\nlengthCompare x y = (length x `compare` length y) `mappend`\n                    (x `compare` y)\n```\n比第一种写法省一个if,且省a, b变量定义\n且带有自动短路功能\n\n#### Maybe\n```haskell\ninstance Monoid a => Monoid (Maybe a) where\n    mempty = Nothing\n    Nothing `mappend` m = m\n    m `mappend` Nothing = m\n    Just m1 `mappend` Just m2 = Just (m1 `mappend` m2)\n```\n\n```haskell\nghci> Just (Sum 3) `mappend` Just (Sum 4)\nJust (Sum {getSum = 7})\n```\n考虑到Maybe的内容的类型不是monoid的情况(Maybe的mappend定义要求m1和m2都是monoid类型),\n于是有了First类型\n```haskell\nnewtype First a = First { getFirst :: Maybe a }\n    deriving (Eq, Ord, Read, Show)\ninstance Monoid (First a) where\n    mempty = First Nothing\n    First (Just x) `mappend` _ = First (Just x)\n    First Nothing `mappend` x = x\n\nghci> getFirst $ First (Just 'a') `mappend` First (Just 'b')\nJust 'a'\n```\n\nFirst is useful when we have a bunch of Maybe values and we just want to know if any of them is a Just.\n\n与First相应的,还有一个Last类型\n\n### Folding with Monoids\n```haskell\nFoldable type class\nfoldMap :: (Monoid m, Foldable t) => (a -> m) -> t a -> m\n```\n\n以Tree为例\n```haskell\ndata Tree a = EmptyTree | Node a (Tree a) (Tree a) deriving (Show)\n\ninstance F.Foldable Tree where\n    foldMap f EmptyTree = mempty\n    foldMap f (Node x l r) = F.foldMap f l `mappend`\n                                       f x `mappend`\n                             F.foldMap f r\nghci> getAny $ F.foldMap (\\x -> Any $ x == 3) testTree\nTrue\nghci> F.foldMap (\\x -> [x]) testTree\n[1,3,6,5,8,9,10]\n```\n\n","slug":"haskell_monoid","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5n2009mmcxquumegr8c"},{"title":"Haskell Zipper","date":"2016-01-21T16:00:00.000Z","_content":"\n修改数据结构(如树)内部的值,除了遍历之外有没有什么比较好的办法\n记录下路径?每次都从树根开始的话比较浪费,有没有更好的办法?\n\n<!--more-->\n\n## Zipper\nA pair that contains a focused part of a data structure and its surroundings is called a zipper\n\n```haskell\ndata Crumb a = LeftCrumb a (Tree a) | RightCrumb a (Tree a) deriving (Show)\n\ntype Breadcrumbs a = [Crumb a]\n\ntype Zipper a = (Tree a, Breadcrumbs a)\n\ngoUp :: (Tree a, Breadcrumbs a) -> (Tree a, Breadcrumbs a)\ngoUp (t, LeftCrumb x r:bs) = (Node x t r, bs)\ngoUp (t, RightCrumb x l:bs) = (Node x l t, bs)\n\ngoLeft :: Zipper a -> Maybe (Zipper a)\ngoLeft (Node x l r, bs) = Just (l, LeftCrumb x r:bs)\ngoLeft (Empty, _) = Nothing\n\ngoRight :: Zipper a -> Maybe (Zipper a)\ngoRight (Node x l r, bs) = Just (r, RightCrumb x l:bs)\ngoRight (Empty, _) = Nothing\n\nmodify :: (a -> a) -> Zipper a -> Zipper a\nmodify f (Node x l r, bs) = (Node (f x) l r, bs)\nmodify f (Empty, bs) = (Empty, bs)\n\nattach :: Tree a -> Zipper a -> Zipper a\nattach t (_, bs) = (t, bs)\n\ntopMost :: Zipper a -> Zipper a\ntopMost (t, []) = (t, [])\ntopMost z = topMost (goUp z)\n\nghci> let coolTree = Node 1 Empty (Node 3 Empty Empty)\nghci> return (coolTree, []) >>= goRight\nJust (Node 3 Empty Empty,[RightCrumb 1 Empty])\nghci> return (coolTree, []) >>= goRight >>= goRight\nJust (Empty,[RightCrumb 3 Empty,RightCrumb 1 Empty])\nghci> return (coolTree, []) >>= goRight >>= goRight >>= goRight\nNothing\n```\n\n","source":"_posts/haskell_zipper.md","raw":"title: Haskell Zipper\ndate: 2016-01-22\ntags: [haskell]\n---\n\n修改数据结构(如树)内部的值,除了遍历之外有没有什么比较好的办法\n记录下路径?每次都从树根开始的话比较浪费,有没有更好的办法?\n\n<!--more-->\n\n## Zipper\nA pair that contains a focused part of a data structure and its surroundings is called a zipper\n\n```haskell\ndata Crumb a = LeftCrumb a (Tree a) | RightCrumb a (Tree a) deriving (Show)\n\ntype Breadcrumbs a = [Crumb a]\n\ntype Zipper a = (Tree a, Breadcrumbs a)\n\ngoUp :: (Tree a, Breadcrumbs a) -> (Tree a, Breadcrumbs a)\ngoUp (t, LeftCrumb x r:bs) = (Node x t r, bs)\ngoUp (t, RightCrumb x l:bs) = (Node x l t, bs)\n\ngoLeft :: Zipper a -> Maybe (Zipper a)\ngoLeft (Node x l r, bs) = Just (l, LeftCrumb x r:bs)\ngoLeft (Empty, _) = Nothing\n\ngoRight :: Zipper a -> Maybe (Zipper a)\ngoRight (Node x l r, bs) = Just (r, RightCrumb x l:bs)\ngoRight (Empty, _) = Nothing\n\nmodify :: (a -> a) -> Zipper a -> Zipper a\nmodify f (Node x l r, bs) = (Node (f x) l r, bs)\nmodify f (Empty, bs) = (Empty, bs)\n\nattach :: Tree a -> Zipper a -> Zipper a\nattach t (_, bs) = (t, bs)\n\ntopMost :: Zipper a -> Zipper a\ntopMost (t, []) = (t, [])\ntopMost z = topMost (goUp z)\n\nghci> let coolTree = Node 1 Empty (Node 3 Empty Empty)\nghci> return (coolTree, []) >>= goRight\nJust (Node 3 Empty Empty,[RightCrumb 1 Empty])\nghci> return (coolTree, []) >>= goRight >>= goRight\nJust (Empty,[RightCrumb 3 Empty,RightCrumb 1 Empty])\nghci> return (coolTree, []) >>= goRight >>= goRight >>= goRight\nNothing\n```\n\n","slug":"haskell_zipper","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5n3009pmcxqontwaann"},{"title":"hexo in docker","date":"2016-05-29T16:00:00.000Z","_content":"\n最近有点迷上docker, 打算把电脑里的服务一个个地都做成docker image..\n<!--more-->\n\n### 思路\n\nhexo做为把markdown转换成html的工具而存在\n博客的markdown放github, 包括Dockerfile, _config.yml, package.json, source目录和themes目录即整套环境\n博客的html放vps上, 用nginx做静态服务器\n即创作在自己电脑上,其他都交给docker\n\n### 写博客流程\n\n在自己电脑上写markdown(最好是带预览的那种编辑器如atom), 提交github, \nssh vps执行\n```\ndocker start hexo && docker exec hexo sh -c 'git pull' && docker exec hexo hexo g\n```\n刷新自己的网站即可看到更新\n\n### docker image设计\n\n基于node image来做, \n首先clone git仓库, 由于仓库里需要的目录和文件都有, 故不需要执行hexo init,\n安装hexo和依赖项即可\n```\nnpm install hexo-cli -g\nnpm install\n```\n\n### vps上的部署\n\n使用Dockerfile build一个image\n\n","source":"_posts/hexo_docker.md","raw":"title: hexo in docker\ndate: 2016-05-30\ntags: [hexo, docker]\n---\n\n最近有点迷上docker, 打算把电脑里的服务一个个地都做成docker image..\n<!--more-->\n\n### 思路\n\nhexo做为把markdown转换成html的工具而存在\n博客的markdown放github, 包括Dockerfile, _config.yml, package.json, source目录和themes目录即整套环境\n博客的html放vps上, 用nginx做静态服务器\n即创作在自己电脑上,其他都交给docker\n\n### 写博客流程\n\n在自己电脑上写markdown(最好是带预览的那种编辑器如atom), 提交github, \nssh vps执行\n```\ndocker start hexo && docker exec hexo sh -c 'git pull' && docker exec hexo hexo g\n```\n刷新自己的网站即可看到更新\n\n### docker image设计\n\n基于node image来做, \n首先clone git仓库, 由于仓库里需要的目录和文件都有, 故不需要执行hexo init,\n安装hexo和依赖项即可\n```\nnpm install hexo-cli -g\nnpm install\n```\n\n### vps上的部署\n\n使用Dockerfile build一个image\n\n","slug":"hexo_docker","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5n4009rmcxqqjvlfpbf"},{"title":"hexo写博客指南","date":"2015-07-16T16:00:00.000Z","_content":"github pages + node.js + hexo 写博客\n<!--more-->\n### 安装node.js\n```bash\ncurl https://raw.githubusercontent.com/creationix/nvm/v0.16.1/install.sh | bash\nnvm ls-remote\nnvm install 0.12\n```\n\n### 安装hexo\n```bash\nnpm install hexo-cli -g\nhexo init blog\ncd blog/\nnpm install\nnpm install hexo-deployer-git --save\n```\n\n### 配置_config.yml\n```\ndeploy:\n  type: git\n  repository: http://github.com/suexcxine/suexcxine.github.io.git\n  branch: master\n```\n\n### 写博客\n```bash\nhexo new \"Hello Hexo\" 或 hexo n \"Hello Hexo\" 生成一个markdown文件骨架用于填写内容\n```\n\n### markdown文件头部, 支持多标签\n```\ntitle: Ubuntu下安装phpmyadmin\ndate: 2015-07-17\ntags: [ubuntu, phpmyadmin]\n---\n```\n\n### 发布博客\n```bash\nhexo generate 或 hexo g 写完博客后, 生成静态内容\nhexo server 或 hexo s 启动本地服务器可以先看一下效果\nhexo deploy 或 hexo d 发布到外网\n```\n\n### 怎样将域名绑定到github pages博客上\n在source目录下添加一个CNAME文件,没有后缀名,里面内容为你的域名(如test.com),不需要添加http/www等前缀\n到域名解析服务商如DNSPod里添加相应的DNS CNAME记录\n\n### 每次重启电脑都需要nvm use启动\n```bash\nnvm use 0.12\n```\n\n### 解决半角引号变成全角引号,--变成全角的问题\nhexo使用的markdown parser是marked,\n在_config.yml中加入一行(空格不能省略)\n```\nmarked: {smartypants: false}\n```\n即可\n\n## 参考链接\nhttp://ibruce.info/2013/11/22/hexo-your-blog/\nhttp://blog.maxwi.com/2014/02/22/first-post/\nhttps://zespia.tw/blog/2012/10/11/hexo-debut/\nhttps://hexo.io/\nhttps://github.com/creationix/nvm/\nhttps://github.com/hexojs/hexo\nhttps://github.com/hexojs/hexo/wiki\nhttps://github.com/hexojs/hexo/issues/1492\nhttps://github.com/chjj/marked#smartypants\n\n","source":"_posts/hexo写博客指南.md","raw":"title: hexo写博客指南\ndate: 2015-07-17\ntags: [internet]\n---\ngithub pages + node.js + hexo 写博客\n<!--more-->\n### 安装node.js\n```bash\ncurl https://raw.githubusercontent.com/creationix/nvm/v0.16.1/install.sh | bash\nnvm ls-remote\nnvm install 0.12\n```\n\n### 安装hexo\n```bash\nnpm install hexo-cli -g\nhexo init blog\ncd blog/\nnpm install\nnpm install hexo-deployer-git --save\n```\n\n### 配置_config.yml\n```\ndeploy:\n  type: git\n  repository: http://github.com/suexcxine/suexcxine.github.io.git\n  branch: master\n```\n\n### 写博客\n```bash\nhexo new \"Hello Hexo\" 或 hexo n \"Hello Hexo\" 生成一个markdown文件骨架用于填写内容\n```\n\n### markdown文件头部, 支持多标签\n```\ntitle: Ubuntu下安装phpmyadmin\ndate: 2015-07-17\ntags: [ubuntu, phpmyadmin]\n---\n```\n\n### 发布博客\n```bash\nhexo generate 或 hexo g 写完博客后, 生成静态内容\nhexo server 或 hexo s 启动本地服务器可以先看一下效果\nhexo deploy 或 hexo d 发布到外网\n```\n\n### 怎样将域名绑定到github pages博客上\n在source目录下添加一个CNAME文件,没有后缀名,里面内容为你的域名(如test.com),不需要添加http/www等前缀\n到域名解析服务商如DNSPod里添加相应的DNS CNAME记录\n\n### 每次重启电脑都需要nvm use启动\n```bash\nnvm use 0.12\n```\n\n### 解决半角引号变成全角引号,--变成全角的问题\nhexo使用的markdown parser是marked,\n在_config.yml中加入一行(空格不能省略)\n```\nmarked: {smartypants: false}\n```\n即可\n\n## 参考链接\nhttp://ibruce.info/2013/11/22/hexo-your-blog/\nhttp://blog.maxwi.com/2014/02/22/first-post/\nhttps://zespia.tw/blog/2012/10/11/hexo-debut/\nhttps://hexo.io/\nhttps://github.com/creationix/nvm/\nhttps://github.com/hexojs/hexo\nhttps://github.com/hexojs/hexo/wiki\nhttps://github.com/hexojs/hexo/issues/1492\nhttps://github.com/chjj/marked#smartypants\n\n","slug":"hexo写博客指南","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5n5009tmcxqviyy2zdj"},{"title":"High Order Function","date":"2015-12-20T16:00:00.000Z","_content":"高阶函数可以提高代码的可复用性\n<!--more-->\n下例有许多重复的代码\n```java\nimport java.util.ArrayList;                                                      \nimport java.util.List;                                                           \npublic class Customer {                                                          \n    static public ArrayList<Customer> allCustomers = new ArrayList<Customer>();  \n    public Integer id = 0;                                                       \n    public String name = \"\";                                                     \n    public String address = \"\";                                                  \n    public String state = \"\";                                                    \n    public String primaryContact = \"\";                                           \n    public String domain = \"\";                                                   \n    public Boolean enabled = true;                                               \n    public Customer() {}                                                         \n                                                                                 \n    public static List<String> getEnabledCustomerNames() {                       \n        ArrayList<String> outList = new ArrayList<String>();                     \n        for(Customer customer : Customer.allCustomers) {                         \n            if(customer.enabled) {                                               \n                outList.add(customer.name);                                      \n            }                                                                    \n        }                                                                        \n        return outList;                                                          \n    }                                                                            \n                                                                                 \n    public static List<String> getEnabledCustomerStates() {                      \n        ArrayList<String> outList = new ArrayList<String>();                     \n        for(Customer customer : Customer.allCustomers) {                         \n            if(customer.enabled) {                                               \n                outList.add(customer.state);                                     \n            }                                                                    \n        }                                                                        \n        return outList;                                                          \n    }                                                                            \n                                                                                 \n    public static List<String> getEnabledCustomerPrimaryContacts() {\n        ArrayList<String> outList = new ArrayList<String>();\n        for(Customer customer : Customer.allCustomers) {\n            if(customer.enabled) {\n                outList.add(customer.primaryContact);\n            }\n        }\n        return outList;\n    }\n    public static List<String> getEnabledCustomerDomains() {\n        ArrayList<String> outList = new ArrayList<String>();\n        for(Customer customer : Customer.allCustomers) {\n            if(customer.enabled) {\n                outList.add(customer.domain);\n            }\n        }\n        return outList;\n    }\n\n    /* TODO: functions getting other fields */\n}                 \n```\n上面的代码,有许多重复的行,如\n```java\nArrayList<String> outList = new ArrayList<String>();                     \nfor(Customer customer : Customer.allCustomers) { \n    ...\n}\nreturn outList; \n```\n如果可以传递函数,那么...的部分就可以通过调用一个函数参数来做,这部分代码就不需要重复了\n用函数式编程语言下面这样的代码相当于上面的函数getEnabledCustomerNames,其中就传递了两个匿名函数\n实现了lists:map和lists:filter这两个函数的复用\n```erlang\nlists:map(fun(#customer{name = Name}) -> Name end, \n    lists:filter(fun(#customer{enabled = E}) -> E end, L)).\n```\n或者更简洁的方式\n```erlang\n[Name || #customer{enabled = true, name = Name} <- L].\n```\n\n","source":"_posts/highorder_function.md","raw":"title: High Order Function\ndate: 2015-12-21\ntags: programming\n---\n高阶函数可以提高代码的可复用性\n<!--more-->\n下例有许多重复的代码\n```java\nimport java.util.ArrayList;                                                      \nimport java.util.List;                                                           \npublic class Customer {                                                          \n    static public ArrayList<Customer> allCustomers = new ArrayList<Customer>();  \n    public Integer id = 0;                                                       \n    public String name = \"\";                                                     \n    public String address = \"\";                                                  \n    public String state = \"\";                                                    \n    public String primaryContact = \"\";                                           \n    public String domain = \"\";                                                   \n    public Boolean enabled = true;                                               \n    public Customer() {}                                                         \n                                                                                 \n    public static List<String> getEnabledCustomerNames() {                       \n        ArrayList<String> outList = new ArrayList<String>();                     \n        for(Customer customer : Customer.allCustomers) {                         \n            if(customer.enabled) {                                               \n                outList.add(customer.name);                                      \n            }                                                                    \n        }                                                                        \n        return outList;                                                          \n    }                                                                            \n                                                                                 \n    public static List<String> getEnabledCustomerStates() {                      \n        ArrayList<String> outList = new ArrayList<String>();                     \n        for(Customer customer : Customer.allCustomers) {                         \n            if(customer.enabled) {                                               \n                outList.add(customer.state);                                     \n            }                                                                    \n        }                                                                        \n        return outList;                                                          \n    }                                                                            \n                                                                                 \n    public static List<String> getEnabledCustomerPrimaryContacts() {\n        ArrayList<String> outList = new ArrayList<String>();\n        for(Customer customer : Customer.allCustomers) {\n            if(customer.enabled) {\n                outList.add(customer.primaryContact);\n            }\n        }\n        return outList;\n    }\n    public static List<String> getEnabledCustomerDomains() {\n        ArrayList<String> outList = new ArrayList<String>();\n        for(Customer customer : Customer.allCustomers) {\n            if(customer.enabled) {\n                outList.add(customer.domain);\n            }\n        }\n        return outList;\n    }\n\n    /* TODO: functions getting other fields */\n}                 \n```\n上面的代码,有许多重复的行,如\n```java\nArrayList<String> outList = new ArrayList<String>();                     \nfor(Customer customer : Customer.allCustomers) { \n    ...\n}\nreturn outList; \n```\n如果可以传递函数,那么...的部分就可以通过调用一个函数参数来做,这部分代码就不需要重复了\n用函数式编程语言下面这样的代码相当于上面的函数getEnabledCustomerNames,其中就传递了两个匿名函数\n实现了lists:map和lists:filter这两个函数的复用\n```erlang\nlists:map(fun(#customer{name = Name}) -> Name end, \n    lists:filter(fun(#customer{enabled = E}) -> E end, L)).\n```\n或者更简洁的方式\n```erlang\n[Name || #customer{enabled = true, name = Name} <- L].\n```\n\n","slug":"highorder_function","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5n6009wmcxqcm88i4o1"},{"title":"如何 publish 自己的项目到 hex package manager","date":"2021-06-19T16:00:00.000Z","_content":"\n背景: 由于在中国众所周知的原因, 下载依赖一直是一个麻烦事 \n\n而发布到 hex , 就可以通过又拍云(点赞!)提供的 mirror 在国内比较方便快速地拉取到依赖\n\n另一个选项是: [自己 host 一个 hex server](https://hex.pm/docs/self_hosting)\n\n<!--more-->\n\n### 使用 mix 的情况\n\n按照[hex官方文档](https://hex.pm/docs/publish) 的要求, 把 mix.exs 里的必要信息填上\n\n然后如下操作即可\n\n```elixir\nmix hex.publish package\n# 需要文档的话 mix hex.publish\n# 如果发现搞错了要撤回, 可以 revert\nmix hex.publish --revert 1.3.0\n# 然后再重发\n```\n\n> 注意: 有时我们需要改变 package 的 name, 原因是 upstream 没人维护了, \n>\n> 那么我们需要把 mix.exs 里的 app 名和 package.name 都改成新的名称才可以, \n>\n> 如果只改了 package.name, app 名没改, 那么包下载下来编译过不了\n>\n\n包上传好了, 现在在 mix.exs 用上, 然后用上又拍云的 mirror, 如下:\n\n`HEX_MIRROR=https://hexpm.upyun.com mix deps.get`\n\nEnjoy!\n\n\n\n### 使用 rebar3 的情况\n\n参见[hex官方文档reber3的情况]https://hex.pm/docs/mirrors\n\nTo Be Continued\n\n\n\n### 如何 self-host\n\nhttps://hex.pm/docs/self_hosting\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/hex_publish.md","raw":"title: 如何 publish 自己的项目到 hex package manager\ndate: 2021-06-20\n\ntags: [erlang, elixir, mix, rebar, hex]\n---\n\n背景: 由于在中国众所周知的原因, 下载依赖一直是一个麻烦事 \n\n而发布到 hex , 就可以通过又拍云(点赞!)提供的 mirror 在国内比较方便快速地拉取到依赖\n\n另一个选项是: [自己 host 一个 hex server](https://hex.pm/docs/self_hosting)\n\n<!--more-->\n\n### 使用 mix 的情况\n\n按照[hex官方文档](https://hex.pm/docs/publish) 的要求, 把 mix.exs 里的必要信息填上\n\n然后如下操作即可\n\n```elixir\nmix hex.publish package\n# 需要文档的话 mix hex.publish\n# 如果发现搞错了要撤回, 可以 revert\nmix hex.publish --revert 1.3.0\n# 然后再重发\n```\n\n> 注意: 有时我们需要改变 package 的 name, 原因是 upstream 没人维护了, \n>\n> 那么我们需要把 mix.exs 里的 app 名和 package.name 都改成新的名称才可以, \n>\n> 如果只改了 package.name, app 名没改, 那么包下载下来编译过不了\n>\n\n包上传好了, 现在在 mix.exs 用上, 然后用上又拍云的 mirror, 如下:\n\n`HEX_MIRROR=https://hexpm.upyun.com mix deps.get`\n\nEnjoy!\n\n\n\n### 使用 rebar3 的情况\n\n参见[hex官方文档reber3的情况]https://hex.pm/docs/mirrors\n\nTo Be Continued\n\n\n\n### 如何 self-host\n\nhttps://hex.pm/docs/self_hosting\n\n\n\n\n\n\n\n\n\n\n\n","slug":"hex_publish","published":1,"updated":"2021-06-20T07:52:40.313Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5n7009ymcxq2s0r0r16"},{"title":"/etc/hosts配置文件","date":"2015-07-22T16:00:00.000Z","_content":"\nHosts - The static table lookup for host name（主机名查询静态表）\n<!--more-->\nhosts文件的每行由三部份组成\n* IP地址\n* 主机名或域名\n* 主机名别名\n\n### 主机名(hostname)和域名(Domain）的区别\n主机名通常在局域网内使用，通过hosts文件，主机名就被解析到对应ip；\n域名通常在internet上使用，但如果不想使用internet上的域名解析，就可以更改hosts文件，加入自己的域名解析。\n\n### hostname命令\nhostname - show or set the system’s host name\n\n$ hostname            查看主机名\nchenduo-desktop\n\n$ hostname test100    修改主机名,需要root权限\ntest100\n\n$ hostname -i         查看ip\n192.168.1.100\n\n$ hostname -f         查看FQDN\nchenduo-desktop.localdomain\n\n通过hostname命令设置主机名是临时的，重启系统后此主机名不会存在\n\n","source":"_posts/hosts.md","raw":"title: /etc/hosts配置文件\ndate: 2015-07-23\ntags: linux\n---\n\nHosts - The static table lookup for host name（主机名查询静态表）\n<!--more-->\nhosts文件的每行由三部份组成\n* IP地址\n* 主机名或域名\n* 主机名别名\n\n### 主机名(hostname)和域名(Domain）的区别\n主机名通常在局域网内使用，通过hosts文件，主机名就被解析到对应ip；\n域名通常在internet上使用，但如果不想使用internet上的域名解析，就可以更改hosts文件，加入自己的域名解析。\n\n### hostname命令\nhostname - show or set the system’s host name\n\n$ hostname            查看主机名\nchenduo-desktop\n\n$ hostname test100    修改主机名,需要root权限\ntest100\n\n$ hostname -i         查看ip\n192.168.1.100\n\n$ hostname -f         查看FQDN\nchenduo-desktop.localdomain\n\n通过hostname命令设置主机名是临时的，重启系统后此主机名不会存在\n\n","slug":"hosts","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5na00a1mcxqmqc334yy"},{"title":"icmp协议","date":"2016-06-06T12:55:00.000Z","_content":"\nICMP是（Internet Control Message Protocol）Internet控制报文协议。\n它是TCP/IP协议族的一个子协议，属于网络层，用于在IP主机、路由器之间传递控制消息。\n控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。\n\n常用的ping命令就使用ICMP协议。\n\n","source":"_posts/icmp.md","raw":"title: icmp协议\ndate: 2016-06-06 20:55:00\ntags: [internet]\n---\n\nICMP是（Internet Control Message Protocol）Internet控制报文协议。\n它是TCP/IP协议族的一个子协议，属于网络层，用于在IP主机、路由器之间传递控制消息。\n控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。\n\n常用的ping命令就使用ICMP协议。\n\n","slug":"icmp","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5nb00a3mcxqr0ftn199"},{"title":"Immutable","date":"2015-12-20T16:00:00.000Z","_content":"\n抢占式操作系统并发编程中有利的做法, 可以减少需要锁的情况, 减少串行代码占比\n\n<pre>\nAmdahl定律: S=1/(1-a+a/n)\n其中，a为并行计算部分所占比例，n为并行处理结点个数。\n当1-a=0时，(即没有串行，只有并行)最大加速比s=n；\n当a=0时（即只有串行，没有并行），最小加速比s=1；\n当n→∞时，极限加速比s→ 1/（1-a），这也就是加速比的上限。\n例如，若串行代码占整个代码的25%，则并行处理的总体性能不可能超过4。\n这一公式已被学术界所接受，并被称做“阿姆达尔定律”，也称为“安达尔定理”(Amdahl law)。\n</pre>\n\n<!--more-->\n\n## Immutable variables\n\n为的是保证状态一致性,比如一个数据结构,日期{Year, Month, Day}\n如果它不是Immutable的话,\n例如:\n```\nDate date = new Date(2015, 1, 31);\ndate.setYear(2015);\ndate.setMonth(2);\ndate.setDay(29);\n```\n那么,当CPU执行到date.setMonth(2);之后进程被抢先,\n其他进程读这个date变量的时候就会读到一个非法的值{2015, 2, 31}\n即中间状态被暴露给了外部,产生了bug\n所以现在C#,Java等语言的Date或DateTime类型都是Immutable的,\n\nJava好像曾经有过setMonth之类的函数,现在虽然还有,\n但是改到了Calendar里,Calendar里根据日历信息保证日期是合法的,返回一个Immutable的新DateTime\n关键还是Immutable,如果只是放到Calendar里把2月31日改成3月1日的话,还是有中间状态被外部看到\n\n即任何对Date的更新都必须返回一个正确的Date,\n如果只是直接更新一个内部值如月份得到的值可能就不正确(不一致),\n即使后面还有一个setDay函数,执行后可以得到正确的值,但是过程中不正确的值可能被并发进程读到所以不行\n而如果不想让不正确的中间状态对其他进程可见,一个好的做法就是用Immutable变量,\n这样就像数据库的事务一样,其他进程能看到的要么是之前的{2015,1,31},要么是最后的正确结果{2015,2,29}\n\n---\n\nerlang的消息机制把一个erlang进程封装成一个类似Date这样的Immutable数据结构,\n其他进程看不到消息处理过程中的数据中间状态,\n因为消息是按队列一个一个地顺序处理的,想要取值的消息(同步调用,call)也是按消息队列的\n例子是Date内部的值出现冲突(2月和31日的冲突)问题,\n而视野放到一个更大的范围就会发现Date之上的数据结构里,可能也有相同的问题,\n比如某产品的出厂日期按业务来说不可能是这个日子,但是更新了产品Id之后更新日期之前这个时间窗里,暴露给其他进程的整体信息就是这样一个冲突了的信息\n所以我们需要把整个状态(可能很大,很多字段)都做成Immutable的?\n改一点点都要把所有字段全都copy一遍?引发巨大的性能的问题?\n其实不需要全部copy, 假如数据结构是State: {A, B, C, Date}这样的,\n更新的那一点点假如是Date,那么重新创建一个Date,\n然后A, B, C与这个新的Date的引用串起来得到一个新State引用,ok\n另外, String类也是Immutable的, String类的对象完全可能很大很大, 但是不影响它成为Immutable对象.\n\n---\n\n那么小到比如一个Int(往往Long, Double就已经不保证原子性了)呢,不像Date这样有内部数据结构了,需要变量不可变吗?\nint a = 1;\na = a + 1;\n这样有问题吗?\n临时计算变量(函数内用完就扔)没问题,业务状态变量(即可以被外部看到)就有问题了\n\n曾经出过一个这样的问题,有一个购买物品的功能,\n扣钱的操作是通过更新gen_server的state来做的,而给物品奖励是通过更新进程字典的值来做的,\n结果有一次出了bug,物品奖励给完之后扣钱之前erlang进程崩掉了\n(或被catch住后面的扣钱代码没有执行也是一样的结果),\n于是在进程terminate时将物品奖励写到了DB里,而扣钱的操作没有成功(因为state没有更新,相当于rollback了)\n即给了玩家物品却没扣钱\n\n如果物品奖励不是通过进程字典而和扣钱一样是通过state的话,物品奖励也不会给,就不会有这个问题出现,\n这就是事务逻辑的好处\n从本质上讲,进程字典的操作跳过了事务的逻辑,相当于实时commit,\n然而其他数据因为异常都rollback了, 这就是问题所在\n上例的\nint a = 1;\na = a + 1;\n如果a是业务状态变量(比如说酒店住宿天数,直接关系到收费),那么也等同于此处的进程字典更新\n\n归根结底是不能出现不一致的状态\n无论是外部逻辑看到不正确的中间状态还是自毁长城实时commit导致不一致的状态\n\n更新前的状态a,在更新完成的状态b出现之前,外部能看见的应该一直是a\n(更严格的做法是,状态a-状态b的变化过程中外部想要取值只能等,因为变化过程中取旧值相当于插队了)\n\n#### 插队什么情况下会引发什么后果,能举个例子吗?\n\n总有人说写的时候用一个进程统一写ets，读的时候从外面读ets没问题\n但是\n如果读出来的数据只是print看一下，那么没问题\n如果读出来的数据还要用于判断或计算，那么用ets可能会有问题\n举例,ets里存了一个counter\n两个进程读出来都是0，都+1，得到结果1，把1发给一个单独的进程（写该ets的专用进程），写进入一个1,bug了\n所以说用一个进程统一写也不一定ok\n至少更新也得在本进程处理,此时不应对外开放一个单独的写接口，\n比如信箱里堆了好多+1的消息\n另一个进程直接ets读了个0，然后通过写接口，把那N个+1的消息更新出来的N又给覆盖成了1\n所以进程暴露出来的写接口,都必须是保证一致性的写接口\n\n---\n\n另例,排行榜如果读ets的话,\n假如有一个活动,结束时(timer驱动)发奖,读ets取到第一名给奖励,\n然而此时排行榜进程(所谓唯一专门写ets的进程)有一条消息正在处理,处理完写完ets第一名应该是另一个人,\n怎么办?奖励发错人了,而且往往排行榜有查看功能,此时明明白白可以看到第一名是谁,错得无可辩驳\n\n另例,打BOSS,\n如果直接读ets觉得有BOSS,进去以后发现没有BOSS(管理进程里攒着掉血的消息,处理完的时候BOSS已经死了)\n如果不想遇见这种情况(根据业务不同,可能会有问题,比如进去这件事本身有代价如需要买票),就得call管理进程,\n否则管理进程一时忙的话,多卖出去N多票,引发许多麻烦\n\n所以用于重要判断的地方,还是不能插队读ets,而要call进程\n\n---\n\n另例说明别的问题\n比如ets存玩家Id对应的团队Id\n玩家进程读自己是哪个队的，如果玩家进程更新自己的团队Id都是call调用的话，\n这样能保证玩家进程自己看不到自己对应的旧的团队Id\n因为call会阻塞玩家进程，等阻塞解除后，那边的ets也已经更新完了\n但是这个保证并不容易, 比如被团长踢出团队就保证不了\n(此时玩家可能不在线, 即无法通过玩家进程修改, 只能由玩家进程以外的进程更新玩家id对应的团队id),\n根本原因是ets里玩家id对应的记录并不是只有玩家进程会更新,即本质上一条数据不止一个进程写,\n而且玩家进程以外的其他进程还是可以插队ets看到旧的团队Id\n\n---\n\n当我报名参加一个活动时取ets告诉活动进程我的团队Id，但是团队进程信箱里有一条踢我的消息，\n辛辛苦苦打完之后，活动进程通知团队进程发奖，这时没有我的奖，辛苦了一场为什么没有奖，\n但是如果用call取也有可能刚call完就被踢了，结果也一样\n那怎么办，世界好复杂\n那么，被踢不能就这么算了，要通知活动进程，团队解散更要通知\n也许报名时把人员对应的团队id存上才是正解，发奖的时候按照报名时的名单给奖励, \n但同时也要考虑团队解散的情况, 可能发奖时要取团队名称什么的,取不到也有问题\n也许正确做法就是，代码写成奖励尽量给，实在给不了就算了\n\n---\n\n当ets的数据间或两(多)个ets间存在一致性关联时,\n专门的进程统一更新这个(这些)ets也保证不了其他进程读到一致的数据,\n因为更新了一个还没更新另一个的时候会被外面看到,这就不仅仅是插队的问题了\n仍然是中间状态被外面看见的大问题\n\n感觉进程间以及进程和ets间的复杂关系必须画图，加文字说明特殊情况以及特殊考虑\n\n## Immutable variables again\n\n考虑下例:\n```\nvoid Safe(string s)\n{\n    if (!SecurityCheck(s)) { throw new SecurityException(); }\n    Dangerous(s);\n}\n```\n\nSafe函数检查字符串s是否安全(比如用户是否允许访问该表或有没有注入式攻击的代码等),\n如果字符串不是Immutable的,聪明的攻击者先传一个安全的字符串,检查过了以后,将字符串s改成一个不安全的就得手了\n(怎么改?由于s只是一个地址,而且是别的地方传过来的全局变量,找到其他并发赋值的地方给一个不安全的值即可)\n于是Immutable的\n第一个好处是: 对一个值,**以前得出的结论未来仍然正确**,这样写代码才有自信\n第二个好处是: 可以复用, \n当需要构造多个大对象时,里面可以都用同一个小对象(即复用),\n以后某一处要改的话,另创建一个对象换掉就可以了,不影响其他大对象\n而如果不是Immutable的话就不能复用,因为万一一处被改了,所有的地方都变掉了(引用类型只是记了一个地址而已嘛),\n所以如果不是Immutable的话就得copy多份\n考虑这一点,Immutable并不比Mutable性能差\n\n## 原子性\n\n什么是原子性,即不可分割,即没有中间状态,\n要么全完成,要么都不完成,没有中间状态(不正确的状态,比如ATM扣了余额没出钱).\n\n## 加锁方案的缺点\n\n* 加锁导致代码串行化,存在Amdahl定律提示的性能问题\n* 解锁之前出bug,解锁的代码没有执行到,锁一辈子死锁\n* 需要加锁的地方可能很多处,一处漏掉就会有bug,防不胜防\n\n## 参考链接\n书: OReilly.Becoming.Functional\nhttps://blogs.msdn.microsoft.com/ericlippert/2011/05/26/atomicity-volatility-and-immutability-are-different-part-one/\nhttps://blogs.msdn.microsoft.com/ericlippert/2011/05/31/atomicity-volatility-and-immutability-are-different-part-two/\nhttps://blogs.msdn.microsoft.com/ericlippert/2011/06/16/atomicity-volatility-and-immutability-are-different-part-three/\n\n","source":"_posts/immutable.md","raw":"title: Immutable\ndate: 2015-12-21\ntags: [programming]\n---\n\n抢占式操作系统并发编程中有利的做法, 可以减少需要锁的情况, 减少串行代码占比\n\n<pre>\nAmdahl定律: S=1/(1-a+a/n)\n其中，a为并行计算部分所占比例，n为并行处理结点个数。\n当1-a=0时，(即没有串行，只有并行)最大加速比s=n；\n当a=0时（即只有串行，没有并行），最小加速比s=1；\n当n→∞时，极限加速比s→ 1/（1-a），这也就是加速比的上限。\n例如，若串行代码占整个代码的25%，则并行处理的总体性能不可能超过4。\n这一公式已被学术界所接受，并被称做“阿姆达尔定律”，也称为“安达尔定理”(Amdahl law)。\n</pre>\n\n<!--more-->\n\n## Immutable variables\n\n为的是保证状态一致性,比如一个数据结构,日期{Year, Month, Day}\n如果它不是Immutable的话,\n例如:\n```\nDate date = new Date(2015, 1, 31);\ndate.setYear(2015);\ndate.setMonth(2);\ndate.setDay(29);\n```\n那么,当CPU执行到date.setMonth(2);之后进程被抢先,\n其他进程读这个date变量的时候就会读到一个非法的值{2015, 2, 31}\n即中间状态被暴露给了外部,产生了bug\n所以现在C#,Java等语言的Date或DateTime类型都是Immutable的,\n\nJava好像曾经有过setMonth之类的函数,现在虽然还有,\n但是改到了Calendar里,Calendar里根据日历信息保证日期是合法的,返回一个Immutable的新DateTime\n关键还是Immutable,如果只是放到Calendar里把2月31日改成3月1日的话,还是有中间状态被外部看到\n\n即任何对Date的更新都必须返回一个正确的Date,\n如果只是直接更新一个内部值如月份得到的值可能就不正确(不一致),\n即使后面还有一个setDay函数,执行后可以得到正确的值,但是过程中不正确的值可能被并发进程读到所以不行\n而如果不想让不正确的中间状态对其他进程可见,一个好的做法就是用Immutable变量,\n这样就像数据库的事务一样,其他进程能看到的要么是之前的{2015,1,31},要么是最后的正确结果{2015,2,29}\n\n---\n\nerlang的消息机制把一个erlang进程封装成一个类似Date这样的Immutable数据结构,\n其他进程看不到消息处理过程中的数据中间状态,\n因为消息是按队列一个一个地顺序处理的,想要取值的消息(同步调用,call)也是按消息队列的\n例子是Date内部的值出现冲突(2月和31日的冲突)问题,\n而视野放到一个更大的范围就会发现Date之上的数据结构里,可能也有相同的问题,\n比如某产品的出厂日期按业务来说不可能是这个日子,但是更新了产品Id之后更新日期之前这个时间窗里,暴露给其他进程的整体信息就是这样一个冲突了的信息\n所以我们需要把整个状态(可能很大,很多字段)都做成Immutable的?\n改一点点都要把所有字段全都copy一遍?引发巨大的性能的问题?\n其实不需要全部copy, 假如数据结构是State: {A, B, C, Date}这样的,\n更新的那一点点假如是Date,那么重新创建一个Date,\n然后A, B, C与这个新的Date的引用串起来得到一个新State引用,ok\n另外, String类也是Immutable的, String类的对象完全可能很大很大, 但是不影响它成为Immutable对象.\n\n---\n\n那么小到比如一个Int(往往Long, Double就已经不保证原子性了)呢,不像Date这样有内部数据结构了,需要变量不可变吗?\nint a = 1;\na = a + 1;\n这样有问题吗?\n临时计算变量(函数内用完就扔)没问题,业务状态变量(即可以被外部看到)就有问题了\n\n曾经出过一个这样的问题,有一个购买物品的功能,\n扣钱的操作是通过更新gen_server的state来做的,而给物品奖励是通过更新进程字典的值来做的,\n结果有一次出了bug,物品奖励给完之后扣钱之前erlang进程崩掉了\n(或被catch住后面的扣钱代码没有执行也是一样的结果),\n于是在进程terminate时将物品奖励写到了DB里,而扣钱的操作没有成功(因为state没有更新,相当于rollback了)\n即给了玩家物品却没扣钱\n\n如果物品奖励不是通过进程字典而和扣钱一样是通过state的话,物品奖励也不会给,就不会有这个问题出现,\n这就是事务逻辑的好处\n从本质上讲,进程字典的操作跳过了事务的逻辑,相当于实时commit,\n然而其他数据因为异常都rollback了, 这就是问题所在\n上例的\nint a = 1;\na = a + 1;\n如果a是业务状态变量(比如说酒店住宿天数,直接关系到收费),那么也等同于此处的进程字典更新\n\n归根结底是不能出现不一致的状态\n无论是外部逻辑看到不正确的中间状态还是自毁长城实时commit导致不一致的状态\n\n更新前的状态a,在更新完成的状态b出现之前,外部能看见的应该一直是a\n(更严格的做法是,状态a-状态b的变化过程中外部想要取值只能等,因为变化过程中取旧值相当于插队了)\n\n#### 插队什么情况下会引发什么后果,能举个例子吗?\n\n总有人说写的时候用一个进程统一写ets，读的时候从外面读ets没问题\n但是\n如果读出来的数据只是print看一下，那么没问题\n如果读出来的数据还要用于判断或计算，那么用ets可能会有问题\n举例,ets里存了一个counter\n两个进程读出来都是0，都+1，得到结果1，把1发给一个单独的进程（写该ets的专用进程），写进入一个1,bug了\n所以说用一个进程统一写也不一定ok\n至少更新也得在本进程处理,此时不应对外开放一个单独的写接口，\n比如信箱里堆了好多+1的消息\n另一个进程直接ets读了个0，然后通过写接口，把那N个+1的消息更新出来的N又给覆盖成了1\n所以进程暴露出来的写接口,都必须是保证一致性的写接口\n\n---\n\n另例,排行榜如果读ets的话,\n假如有一个活动,结束时(timer驱动)发奖,读ets取到第一名给奖励,\n然而此时排行榜进程(所谓唯一专门写ets的进程)有一条消息正在处理,处理完写完ets第一名应该是另一个人,\n怎么办?奖励发错人了,而且往往排行榜有查看功能,此时明明白白可以看到第一名是谁,错得无可辩驳\n\n另例,打BOSS,\n如果直接读ets觉得有BOSS,进去以后发现没有BOSS(管理进程里攒着掉血的消息,处理完的时候BOSS已经死了)\n如果不想遇见这种情况(根据业务不同,可能会有问题,比如进去这件事本身有代价如需要买票),就得call管理进程,\n否则管理进程一时忙的话,多卖出去N多票,引发许多麻烦\n\n所以用于重要判断的地方,还是不能插队读ets,而要call进程\n\n---\n\n另例说明别的问题\n比如ets存玩家Id对应的团队Id\n玩家进程读自己是哪个队的，如果玩家进程更新自己的团队Id都是call调用的话，\n这样能保证玩家进程自己看不到自己对应的旧的团队Id\n因为call会阻塞玩家进程，等阻塞解除后，那边的ets也已经更新完了\n但是这个保证并不容易, 比如被团长踢出团队就保证不了\n(此时玩家可能不在线, 即无法通过玩家进程修改, 只能由玩家进程以外的进程更新玩家id对应的团队id),\n根本原因是ets里玩家id对应的记录并不是只有玩家进程会更新,即本质上一条数据不止一个进程写,\n而且玩家进程以外的其他进程还是可以插队ets看到旧的团队Id\n\n---\n\n当我报名参加一个活动时取ets告诉活动进程我的团队Id，但是团队进程信箱里有一条踢我的消息，\n辛辛苦苦打完之后，活动进程通知团队进程发奖，这时没有我的奖，辛苦了一场为什么没有奖，\n但是如果用call取也有可能刚call完就被踢了，结果也一样\n那怎么办，世界好复杂\n那么，被踢不能就这么算了，要通知活动进程，团队解散更要通知\n也许报名时把人员对应的团队id存上才是正解，发奖的时候按照报名时的名单给奖励, \n但同时也要考虑团队解散的情况, 可能发奖时要取团队名称什么的,取不到也有问题\n也许正确做法就是，代码写成奖励尽量给，实在给不了就算了\n\n---\n\n当ets的数据间或两(多)个ets间存在一致性关联时,\n专门的进程统一更新这个(这些)ets也保证不了其他进程读到一致的数据,\n因为更新了一个还没更新另一个的时候会被外面看到,这就不仅仅是插队的问题了\n仍然是中间状态被外面看见的大问题\n\n感觉进程间以及进程和ets间的复杂关系必须画图，加文字说明特殊情况以及特殊考虑\n\n## Immutable variables again\n\n考虑下例:\n```\nvoid Safe(string s)\n{\n    if (!SecurityCheck(s)) { throw new SecurityException(); }\n    Dangerous(s);\n}\n```\n\nSafe函数检查字符串s是否安全(比如用户是否允许访问该表或有没有注入式攻击的代码等),\n如果字符串不是Immutable的,聪明的攻击者先传一个安全的字符串,检查过了以后,将字符串s改成一个不安全的就得手了\n(怎么改?由于s只是一个地址,而且是别的地方传过来的全局变量,找到其他并发赋值的地方给一个不安全的值即可)\n于是Immutable的\n第一个好处是: 对一个值,**以前得出的结论未来仍然正确**,这样写代码才有自信\n第二个好处是: 可以复用, \n当需要构造多个大对象时,里面可以都用同一个小对象(即复用),\n以后某一处要改的话,另创建一个对象换掉就可以了,不影响其他大对象\n而如果不是Immutable的话就不能复用,因为万一一处被改了,所有的地方都变掉了(引用类型只是记了一个地址而已嘛),\n所以如果不是Immutable的话就得copy多份\n考虑这一点,Immutable并不比Mutable性能差\n\n## 原子性\n\n什么是原子性,即不可分割,即没有中间状态,\n要么全完成,要么都不完成,没有中间状态(不正确的状态,比如ATM扣了余额没出钱).\n\n## 加锁方案的缺点\n\n* 加锁导致代码串行化,存在Amdahl定律提示的性能问题\n* 解锁之前出bug,解锁的代码没有执行到,锁一辈子死锁\n* 需要加锁的地方可能很多处,一处漏掉就会有bug,防不胜防\n\n## 参考链接\n书: OReilly.Becoming.Functional\nhttps://blogs.msdn.microsoft.com/ericlippert/2011/05/26/atomicity-volatility-and-immutability-are-different-part-one/\nhttps://blogs.msdn.microsoft.com/ericlippert/2011/05/31/atomicity-volatility-and-immutability-are-different-part-two/\nhttps://blogs.msdn.microsoft.com/ericlippert/2011/06/16/atomicity-volatility-and-immutability-are-different-part-three/\n\n","slug":"immutable","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5nc00a6mcxq5sslmtt1"},{"title":"inode","date":"2015-10-14T16:00:00.000Z","_content":"储存文件元信息的区域叫做inode, 每一个文件都有对应的inode\n<!--more-->\n## inode包含的文件元信息\n\n    * 文件的字节数\n    * 文件数据block的位置\n    * 链接数，即有多少文件名指向这个inode\n    * 文件的读、写、执行权限\n    * 文件拥有者的User ID\n    * 文件的Group ID\n    * 文件的时间戳，共有三个：ctime创建时间，mtime修改时间，atime访问时间。\n\n可以用stat命令，查看某个文件的inode信息：\nstat example.txt\n\n## inode号码\n\n每个inode都有一个唯一号码，用来识别不同的文件。\n这里值得重复一遍，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。\n对于系统来说，文件名只是inode号码便于识别的别名。\n\n表面上，用户通过文件名，打开文件。 实际上，系统内部这个过程分成三步：\n1. 系统找到这个文件名对应的inode号码；\n2. 通过inode号码，获取inode信息；\n3. 根据inode信息，找到文件数据所在的block，读出数据。\n\n使用ls -i命令，可以看到文件名对应的inode号码：\nls -i example.txt\n\n## inode的大小\n\n硬盘格式化的时候，操作系统自动将硬盘分成两个区域。\n一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。\n\n每个inode节点的大小，一般是128字节或256字节。\ninode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。\n假定在一个1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，\n那么inode table的大小就会达到128MB，占整个硬盘的12.8%。\n\n由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。\n这时，就无法在硬盘上创建新文件。\n\n查看每个硬盘分区的inode总数和已经使用的数量，可以使用df命令。\ndf -i\n查看每个inode节点的大小，可以用如下命令：\nsudo dumpe2fs -h /dev/sda | grep \"Inode size\"\n\n## 硬链接\n\n一般情况下，文件名和inode号码是\"一一对应\"的关系，每个inode号码对应一个文件名。\n但是，Unix/Linux系统允许，多个文件名指向同一个inode号码。\n\n这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；\n但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为\"硬链接\"（hard link）。\n\n反过来，删除一个文件名，就会使得inode节点中的\"链接数\"减1。\n当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。\n\n## 软链接\n\n文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。\n读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。\n这时，文件A就称为文件B的\"软链接\"（soft link）或者\"符号链接（symbolic link）。\n\n这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错：\"No such file or directory\"。\n这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，\n文件B的inode\"链接数\"不会因此发生变化。\n\n## 目录文件\n\nUnix/Linux系统中，目录（directory）也是一种文件。打开目录，实际上就是打开目录文件。\n\n目录文件的内容是一系列目录项（dirent）的列表。\n每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。\nls -i命令列出整个目录文件，即文件名和inode号码：\nls -i /etc\n\n### 关于目录文件的\"链接数\"\n\n创建目录时，默认会生成两个目录项：\".\"和\"..\"。\n前者的inode号码就是当前目录的inode号码，等同于当前目录的\"硬链接\"；\n后者的inode号码就是当前目录的父目录的inode号码，等同于父目录的\"硬链接\"。\n所以，任何一个目录的\"硬链接\"总数，总是等于2加上它的子目录总数（含隐藏目录）。\n","source":"_posts/inode.md","raw":"title: inode\ndate: 2015-10-15\ntags: [linux]\n---\n储存文件元信息的区域叫做inode, 每一个文件都有对应的inode\n<!--more-->\n## inode包含的文件元信息\n\n    * 文件的字节数\n    * 文件数据block的位置\n    * 链接数，即有多少文件名指向这个inode\n    * 文件的读、写、执行权限\n    * 文件拥有者的User ID\n    * 文件的Group ID\n    * 文件的时间戳，共有三个：ctime创建时间，mtime修改时间，atime访问时间。\n\n可以用stat命令，查看某个文件的inode信息：\nstat example.txt\n\n## inode号码\n\n每个inode都有一个唯一号码，用来识别不同的文件。\n这里值得重复一遍，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。\n对于系统来说，文件名只是inode号码便于识别的别名。\n\n表面上，用户通过文件名，打开文件。 实际上，系统内部这个过程分成三步：\n1. 系统找到这个文件名对应的inode号码；\n2. 通过inode号码，获取inode信息；\n3. 根据inode信息，找到文件数据所在的block，读出数据。\n\n使用ls -i命令，可以看到文件名对应的inode号码：\nls -i example.txt\n\n## inode的大小\n\n硬盘格式化的时候，操作系统自动将硬盘分成两个区域。\n一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。\n\n每个inode节点的大小，一般是128字节或256字节。\ninode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。\n假定在一个1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，\n那么inode table的大小就会达到128MB，占整个硬盘的12.8%。\n\n由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。\n这时，就无法在硬盘上创建新文件。\n\n查看每个硬盘分区的inode总数和已经使用的数量，可以使用df命令。\ndf -i\n查看每个inode节点的大小，可以用如下命令：\nsudo dumpe2fs -h /dev/sda | grep \"Inode size\"\n\n## 硬链接\n\n一般情况下，文件名和inode号码是\"一一对应\"的关系，每个inode号码对应一个文件名。\n但是，Unix/Linux系统允许，多个文件名指向同一个inode号码。\n\n这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；\n但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为\"硬链接\"（hard link）。\n\n反过来，删除一个文件名，就会使得inode节点中的\"链接数\"减1。\n当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。\n\n## 软链接\n\n文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。\n读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。\n这时，文件A就称为文件B的\"软链接\"（soft link）或者\"符号链接（symbolic link）。\n\n这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错：\"No such file or directory\"。\n这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，\n文件B的inode\"链接数\"不会因此发生变化。\n\n## 目录文件\n\nUnix/Linux系统中，目录（directory）也是一种文件。打开目录，实际上就是打开目录文件。\n\n目录文件的内容是一系列目录项（dirent）的列表。\n每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。\nls -i命令列出整个目录文件，即文件名和inode号码：\nls -i /etc\n\n### 关于目录文件的\"链接数\"\n\n创建目录时，默认会生成两个目录项：\".\"和\"..\"。\n前者的inode号码就是当前目录的inode号码，等同于当前目录的\"硬链接\"；\n后者的inode号码就是当前目录的父目录的inode号码，等同于父目录的\"硬链接\"。\n所以，任何一个目录的\"硬链接\"总数，总是等于2加上它的子目录总数（含隐藏目录）。\n","slug":"inode","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5nd00a8mcxqv55v1ldp"},{"title":"interrupt 中断","date":"2016-09-06T14:09:00.000Z","_content":"\n回顾一下大学里学过然而早已忘却的人类的好朋友\"中断\"。。\n\n<!--more-->\n\n中断类似事件机制，不是轮询，而是push，所以效率高\n\n让硬件在需要的时候再向内核发出信号（变内核主动为硬件主动），这就是中断机制。\n\n中断绝不是硬件代替软件去轮询，而是硬件的结构决定了，当那个管脚电平变低（或者变高）的时候，cpu就会被打断，并从特定地址开始执行。\n中断来的时候，芯片是马上打断的，然后操作系统的中断处理程序记录中断事件，加入到一个待处理的中断链表里，然后回去继续进行刚才的工作。\n等有空闲时间，来查这个链表，根据中断类型，地址啥的，找到之前注册过得驱动程序，看谁该来处理这个中断，调用相应的函数。\n\n软中断是实现系统调用的手段\n函数调用时将返回地址和CPU状态寄存器内容压栈，函数执行完毕后出栈返回断点继续执行。\n软中断调用时将返回地址和CPU状态寄存器内容压栈，修改特权级，根据中断号查找中断向量表，找到ISR中断服务例程地址，跳转执行。\n\n","source":"_posts/interrupt.md","raw":"title: interrupt 中断\ndate: 2016-09-06 22:09:00\ntags: [linux, os]\n---\n\n回顾一下大学里学过然而早已忘却的人类的好朋友\"中断\"。。\n\n<!--more-->\n\n中断类似事件机制，不是轮询，而是push，所以效率高\n\n让硬件在需要的时候再向内核发出信号（变内核主动为硬件主动），这就是中断机制。\n\n中断绝不是硬件代替软件去轮询，而是硬件的结构决定了，当那个管脚电平变低（或者变高）的时候，cpu就会被打断，并从特定地址开始执行。\n中断来的时候，芯片是马上打断的，然后操作系统的中断处理程序记录中断事件，加入到一个待处理的中断链表里，然后回去继续进行刚才的工作。\n等有空闲时间，来查这个链表，根据中断类型，地址啥的，找到之前注册过得驱动程序，看谁该来处理这个中断，调用相应的函数。\n\n软中断是实现系统调用的手段\n函数调用时将返回地址和CPU状态寄存器内容压栈，函数执行完毕后出栈返回断点继续执行。\n软中断调用时将返回地址和CPU状态寄存器内容压栈，修改特权级，根据中断号查找中断向量表，找到ISR中断服务例程地址，跳转执行。\n\n","slug":"interrupt","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ne00abmcxq748srtnk"},{"title":"iostat","date":"2016-08-13T09:20:00.000Z","_content":"\n## iostat\n\nsudo apt-get install sysstat\nyum install sysstat\n\n<pre>\niostat\nLinux 3.19.0-66-generic (chenduo)   2016年08月13日  _x86_64_    (8 CPU)\n\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n          28.30    0.06   11.32    1.43    0.00   58.88\n\nDevice:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn\nsda               3.44        21.71        99.34    6225040   28490308\n</pre>\n\nuser: 用户级时间比例\nnice: nice优先级时间比例\nsystem: 系统级时间比例\niowait: 等待io的时间比例,相当于top里的wa\nsteal: 虚拟环境下等待物理CPU周期的时间比例\nidle: 空闲时间比例, 相当于top里的id\n\ntps: transfer per second, 一次transfer就是一次io\n\n### steal\n\n如果你使用Amazon EC2等虚拟环境,就要考虑这个steal值了,因为虚拟机之间并不是均等分配CPU,\n比如一台物理机器上有四个虚拟机,并不是说每个虚拟机平均占用25%的CPU周期\n\n这个值持续20分钟以上超过10%就有问题\n\n如何判断原因是否host超卖? 如果自己的每台VM都高,则是自己的软件占用CPU过高,如果只是一部分VM的steal高,可能是物理主机host超卖\n\nXen和KVM支持这个值,貌似vmware和virtualbox都不支持\n\n## 参考链接\nhttp://blog.scoutapp.com/articles/2013/07/25/understanding-cpu-steal-time-when-should-you-be-worried\nhttp://linuxcommand.org/man_pages/iostat1.html\n\n","source":"_posts/iostat.md","raw":"title: iostat\ndate: 2016-08-13 17:20:00\ntags: [linux, monitoring]\n---\n\n## iostat\n\nsudo apt-get install sysstat\nyum install sysstat\n\n<pre>\niostat\nLinux 3.19.0-66-generic (chenduo)   2016年08月13日  _x86_64_    (8 CPU)\n\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n          28.30    0.06   11.32    1.43    0.00   58.88\n\nDevice:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn\nsda               3.44        21.71        99.34    6225040   28490308\n</pre>\n\nuser: 用户级时间比例\nnice: nice优先级时间比例\nsystem: 系统级时间比例\niowait: 等待io的时间比例,相当于top里的wa\nsteal: 虚拟环境下等待物理CPU周期的时间比例\nidle: 空闲时间比例, 相当于top里的id\n\ntps: transfer per second, 一次transfer就是一次io\n\n### steal\n\n如果你使用Amazon EC2等虚拟环境,就要考虑这个steal值了,因为虚拟机之间并不是均等分配CPU,\n比如一台物理机器上有四个虚拟机,并不是说每个虚拟机平均占用25%的CPU周期\n\n这个值持续20分钟以上超过10%就有问题\n\n如何判断原因是否host超卖? 如果自己的每台VM都高,则是自己的软件占用CPU过高,如果只是一部分VM的steal高,可能是物理主机host超卖\n\nXen和KVM支持这个值,貌似vmware和virtualbox都不支持\n\n## 参考链接\nhttp://blog.scoutapp.com/articles/2013/07/25/understanding-cpu-steal-time-when-should-you-be-worried\nhttp://linuxcommand.org/man_pages/iostat1.html\n\n","slug":"iostat","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5nf00admcxqnwgll9ie"},{"title":"jinterface","date":"2021-08-01T04:00:00.000Z","_content":"\n今天试一把传说中的 jinterface 是什么感觉\n\n能让 Java 模拟一个 erlang 结点与 erlang 结点用 erlang 的模式通信\n\n<!--more-->\n\n## 效果展示\n\n先启动 java 侧(使用 -DOtpConnection.trace=4 开启了最高级别的调试日志)\n\n```shell\n$ java -DOtpConnection.trace=4 -cp .:/Users/chenduo/erls/23.3/lib/jinterface-1.11.1/priv/OtpErlang.jar JNodeServer.java\n-> PUBLISH (r4) j1@127.0.0.1 port=49304\n<- OK\nStarted node: #Pid<j1@127.0.0.1.1.0>\n```\n\n再启动 erlang 侧并发出请求消息, 可以看到顺利拿到了结果\n\n```shell\n$ erlc jcomplex.erl\n$ erl -name haha@127.0.0.1 -setcookie secret\nErlang/OTP 23 [erts-11.2] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]\n\nEshell V11.2  (abort with ^G)\n(haha@127.0.0.1)1> jcomplex:foo(100).\n{<9266.1.0>,101}\nok\n(haha@127.0.0.1)2> jcomplex:bar(100).\n{<9266.1.0>,200}\nok\n```\n\njava 侧也显示收到了消息 {call,#Pid<haha@127.0.0.1.90.0>,{foo,100}}, 并返回了{#Pid<j1@127.0.0.1.1.0>,200}, 如下\n\n```\n<- ACCEPT FROM com.ericsson.otp.erlang.OtpSocketTransport@1bec2ee2\n<- HANDSHAKE ntype=110 dist=6 remote=haha@127.0.0.1\n-> HANDSHAKE sendStatus status=ok local=j1@127.0.0.1\n-> HANDSHAKE sendChallenge flags=50794388 challenge=1299681012 local=j1@127.0.0.1\n<- HANDSHAKE recvChallengeReply from=haha@127.0.0.1 challenge=-618201795 digest=5197602eb7b83cf9c68dabe1c56db99c local=j1@127.0.0.1\n-> HANDSHAKE sendChallengeAck digest=4db9c4ba35afc84d6eb858074681d700 local=j1@127.0.0.1\n<- MD5 ACCEPTED 127.0.0.1\n<- REG_SEND {6,#Pid<haha@127.0.0.1.90.0>,'',java}\n   {call,#Pid<haha@127.0.0.1.90.0>,{foo,100}}\nmessage: {#Pid<haha@127.0.0.1.90.0>, {foo, 100}}\n-> SEND {2,'',#Pid<haha@127.0.0.1.90.0>}\n   {#Pid<j1@127.0.0.1.1.0>,101}\n<- REG_SEND {6,#Pid<haha@127.0.0.1.90.0>,'',java}\n   {call,#Pid<haha@127.0.0.1.90.0>,{bar,100}}\nmessage: {#Pid<haha@127.0.0.1.90.0>, {bar, 100}}\n-> SEND {2,'',#Pid<haha@127.0.0.1.90.0>}\n   {#Pid<j1@127.0.0.1.1.0>,200}\n```\n\n\n\n## 源码\n\nJNodeServer.java\n\n```java\nimport com.ericsson.otp.erlang.*;\n\npublic class JNodeServer {\n    private OtpNode node;\n    private OtpMbox mbox;\n\n    public JNodeServer() throws Exception {\n        node = new OtpNode(\"j1@127.0.0.1\", \"secret\");\n        mbox = node.createMbox(\"java\");\n        OtpErlangPid pid = mbox.self();\n        System.out.println(\"Started node: \" + pid.toString());\n    }\n\n    public void process() {\n        while (true) {\n            try {\n                OtpErlangTuple msg = (OtpErlangTuple) mbox.receive();\n                OtpErlangPid from = (OtpErlangPid) msg.elementAt(1);\n                OtpErlangTuple tuple = (OtpErlangTuple) msg.elementAt(2);\n                String fn = ((OtpErlangAtom) tuple.elementAt(0)).atomValue();\n                int arg = (int) ((OtpErlangLong) tuple.elementAt(1)).longValue();\n                System.out.println(\"message: {\" + from.toString() + \", {\" + fn + \", \" + arg + \"}}\");\n                JComplexCalculation complexCalc = new JComplexCalculation();\n                Integer result = null;\n                switch (fn) {\n                case \"foo\":\n                    result = complexCalc.foo(arg);\n                    break;\n                case \"bar\":\n                    result = complexCalc.bar(arg);\n                    break;\n                default:\n                }\n\n                OtpErlangTuple reply = null;\n                if (result == null) {\n                    reply = new OtpErlangTuple(new OtpErlangObject[] { mbox.self(), new OtpErlangString(\"error\") });\n                } else {\n                    reply = new OtpErlangTuple(new OtpErlangObject[] { mbox.self(), new OtpErlangInt(result) });\n                }\n\n                mbox.send(from, reply);\n            } catch (OtpErlangExit | OtpErlangDecodeException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        JNodeServer server = new JNodeServer();\n        server.process();\n    }\n}\n```\n\njcomplex.erl\n\n```erlang\n-module(jcomplex).\n-export([foo/1, bar/1]).\n\nfoo(X) ->\n  call_jnode({foo, X}).\nbar(Y) ->\n  call_jnode({bar, Y}).\n\ncall_jnode(Msg) ->\n  {java, 'j1@127.0.0.1'} ! {call, self(), Msg},\n  receive\n    Any ->\n      io:format(\"~p~n\", [Any])\n  end.\n```\n\n\n\n## 参考链接\n\nhttp://erlang.org/doc/apps/jinterface/jinterface_users_guide.html\n\n","source":"_posts/jinterface.md","raw":"title: jinterface\ndate: 2021-08-01 12:00:00\n\ntags: [java, jinterface, erlang]\n---\n\n今天试一把传说中的 jinterface 是什么感觉\n\n能让 Java 模拟一个 erlang 结点与 erlang 结点用 erlang 的模式通信\n\n<!--more-->\n\n## 效果展示\n\n先启动 java 侧(使用 -DOtpConnection.trace=4 开启了最高级别的调试日志)\n\n```shell\n$ java -DOtpConnection.trace=4 -cp .:/Users/chenduo/erls/23.3/lib/jinterface-1.11.1/priv/OtpErlang.jar JNodeServer.java\n-> PUBLISH (r4) j1@127.0.0.1 port=49304\n<- OK\nStarted node: #Pid<j1@127.0.0.1.1.0>\n```\n\n再启动 erlang 侧并发出请求消息, 可以看到顺利拿到了结果\n\n```shell\n$ erlc jcomplex.erl\n$ erl -name haha@127.0.0.1 -setcookie secret\nErlang/OTP 23 [erts-11.2] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]\n\nEshell V11.2  (abort with ^G)\n(haha@127.0.0.1)1> jcomplex:foo(100).\n{<9266.1.0>,101}\nok\n(haha@127.0.0.1)2> jcomplex:bar(100).\n{<9266.1.0>,200}\nok\n```\n\njava 侧也显示收到了消息 {call,#Pid<haha@127.0.0.1.90.0>,{foo,100}}, 并返回了{#Pid<j1@127.0.0.1.1.0>,200}, 如下\n\n```\n<- ACCEPT FROM com.ericsson.otp.erlang.OtpSocketTransport@1bec2ee2\n<- HANDSHAKE ntype=110 dist=6 remote=haha@127.0.0.1\n-> HANDSHAKE sendStatus status=ok local=j1@127.0.0.1\n-> HANDSHAKE sendChallenge flags=50794388 challenge=1299681012 local=j1@127.0.0.1\n<- HANDSHAKE recvChallengeReply from=haha@127.0.0.1 challenge=-618201795 digest=5197602eb7b83cf9c68dabe1c56db99c local=j1@127.0.0.1\n-> HANDSHAKE sendChallengeAck digest=4db9c4ba35afc84d6eb858074681d700 local=j1@127.0.0.1\n<- MD5 ACCEPTED 127.0.0.1\n<- REG_SEND {6,#Pid<haha@127.0.0.1.90.0>,'',java}\n   {call,#Pid<haha@127.0.0.1.90.0>,{foo,100}}\nmessage: {#Pid<haha@127.0.0.1.90.0>, {foo, 100}}\n-> SEND {2,'',#Pid<haha@127.0.0.1.90.0>}\n   {#Pid<j1@127.0.0.1.1.0>,101}\n<- REG_SEND {6,#Pid<haha@127.0.0.1.90.0>,'',java}\n   {call,#Pid<haha@127.0.0.1.90.0>,{bar,100}}\nmessage: {#Pid<haha@127.0.0.1.90.0>, {bar, 100}}\n-> SEND {2,'',#Pid<haha@127.0.0.1.90.0>}\n   {#Pid<j1@127.0.0.1.1.0>,200}\n```\n\n\n\n## 源码\n\nJNodeServer.java\n\n```java\nimport com.ericsson.otp.erlang.*;\n\npublic class JNodeServer {\n    private OtpNode node;\n    private OtpMbox mbox;\n\n    public JNodeServer() throws Exception {\n        node = new OtpNode(\"j1@127.0.0.1\", \"secret\");\n        mbox = node.createMbox(\"java\");\n        OtpErlangPid pid = mbox.self();\n        System.out.println(\"Started node: \" + pid.toString());\n    }\n\n    public void process() {\n        while (true) {\n            try {\n                OtpErlangTuple msg = (OtpErlangTuple) mbox.receive();\n                OtpErlangPid from = (OtpErlangPid) msg.elementAt(1);\n                OtpErlangTuple tuple = (OtpErlangTuple) msg.elementAt(2);\n                String fn = ((OtpErlangAtom) tuple.elementAt(0)).atomValue();\n                int arg = (int) ((OtpErlangLong) tuple.elementAt(1)).longValue();\n                System.out.println(\"message: {\" + from.toString() + \", {\" + fn + \", \" + arg + \"}}\");\n                JComplexCalculation complexCalc = new JComplexCalculation();\n                Integer result = null;\n                switch (fn) {\n                case \"foo\":\n                    result = complexCalc.foo(arg);\n                    break;\n                case \"bar\":\n                    result = complexCalc.bar(arg);\n                    break;\n                default:\n                }\n\n                OtpErlangTuple reply = null;\n                if (result == null) {\n                    reply = new OtpErlangTuple(new OtpErlangObject[] { mbox.self(), new OtpErlangString(\"error\") });\n                } else {\n                    reply = new OtpErlangTuple(new OtpErlangObject[] { mbox.self(), new OtpErlangInt(result) });\n                }\n\n                mbox.send(from, reply);\n            } catch (OtpErlangExit | OtpErlangDecodeException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        JNodeServer server = new JNodeServer();\n        server.process();\n    }\n}\n```\n\njcomplex.erl\n\n```erlang\n-module(jcomplex).\n-export([foo/1, bar/1]).\n\nfoo(X) ->\n  call_jnode({foo, X}).\nbar(Y) ->\n  call_jnode({bar, Y}).\n\ncall_jnode(Msg) ->\n  {java, 'j1@127.0.0.1'} ! {call, self(), Msg},\n  receive\n    Any ->\n      io:format(\"~p~n\", [Any])\n  end.\n```\n\n\n\n## 参考链接\n\nhttp://erlang.org/doc/apps/jinterface/jinterface_users_guide.html\n\n","slug":"jinterface","published":1,"updated":"2021-08-01T15:08:18.924Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ng00agmcxqj0lzkpfa"},{"title":"ip地址分类","date":"2016-06-07T04:11:00.000Z","_content":"\n大学计算机网络课学的东西全忘光了...\n\n分类网络（Classful network）或称“分级式定址”，\n是在1981(RFC 791)-1993(CIDR出现, RFC 1518, RFC 1519)间使用的network addressing architecture。\n\n<!--more-->\n\n## 分类之前\n一开始，32位的IPv4地址只由8位的网络地址和“剩下的”主机位组成。\n这种格式用在局域网出现之前。在那时，只有一些很少很大的的网络，例如ARPANET。\n这使独立的网络的数量不能太多（最多254个），这在局域网出现的早期，就已经显得不足够了。\n\n## 分类\n* A类, 最高位0, 地址范围0.0.0.0/8 - 127.0.0.0/8\n* B类, 最高位10, 地址范围128.0.0.0/16 - 191.255.0.0/16\n* C类, 最高位110, 地址范围192.0.0.0/24 - 223.255.255.0/24\n* D类, 最高位1110, 地址范围224.0.0.0/4\n* E类, 最高位1111, 地址范围240.0.0.0/4\n\nD类地址用于多点广播（Multicast）。\n\nE类地址保留，仅作实验和开发用。\n\n全零（0.0.0.0）地址指当前主机。全“1”的IP地址（255.255.255.255）是当前子网的广播地址。\n\n## 无类别域间路由(Classless Inter-Domain Routing、CIDR)\n在之前的分类网络中，IP地址的分配把IP地址的32位按每8位为一段分开。这使得前缀必须为8，16或者24位。\n遵从CIDR规则的地址有一个后缀说明前缀的位数，例如：208.130.28.0/22。这使得对日益缺乏的IPv4地址的使用更加有效。\n\n## 关于子网的第一个和最后一个地址\n一般来说, 子网的第一个地址表示子网本身, 最后一个是广播地址\n即这两个地址不用于表示主机, 其它地址可以分配给各个主机\n注意, 子网的第一个和最后一个地址不一定是0和255, 这取决于子网掩码\n如10.6.43.0/22不是第一个地址, 这个子网的第一个地址是10.6.40.0\n\n## 私有地址(RFC 1918)\n在IP地址3种主要类型里，各保留了1个区域作为私有地址，如下：\n\nA类地址：10.0.0.0～10.255.255.255\nB类地址：172.16.0.0～172.31.255.255\nC类地址：192.168.0.0～192.168.255.255\n\n这些地址在网络上不被路由, 即无法连接公网\n\n## 特殊地址\nA,B,C类地址的最低和最高的网段,\n如0.0.0.0/8, 127.0.0.0/8, 128.0.0.0/16, 191.255.0.0/16, 192.0.0.0/24, 223.255.255.0/24,\n根据RFC 3330, 都是IANA保留的, 其中,\n0.0.0.0/8段的说明如下:\n\n> 0.0.0.0/8 - Addresses in this block refer to source hosts on \"this\"\n>   network.  Address 0.0.0.0/32 may be used as a source address for this\n>   host on this network; other addresses within 0.0.0.0/8 may be used to\n>   refer to specified hosts on this network [RFC1700, page 4].\n\n127.0.0.0/8都是环回地址(loopback)\n\n128.0.0.0/16, 191.255.0.0/16, 192.0.0.0/24, 223.255.255.0/24貌似现在已经可以使用\n\n> was initially and is still reserved by\n> the IANA.  Given the present classless nature of the IP address\n> space, the basis for the reservation no longer applies and addresses\n> in this block are subject to future allocation to a Regional Internet\n> Registry for assignment in the normal manner.\n\nRFC 3330还有其他特殊地址, 参见\nhttp://www.rfc-base.org/txt/rfc-3330.txt\n\n","source":"_posts/ip_addr_class.md","raw":"title: ip地址分类\ndate: 2016-06-07 12:11:00\ntags: [internet]\n---\n\n大学计算机网络课学的东西全忘光了...\n\n分类网络（Classful network）或称“分级式定址”，\n是在1981(RFC 791)-1993(CIDR出现, RFC 1518, RFC 1519)间使用的network addressing architecture。\n\n<!--more-->\n\n## 分类之前\n一开始，32位的IPv4地址只由8位的网络地址和“剩下的”主机位组成。\n这种格式用在局域网出现之前。在那时，只有一些很少很大的的网络，例如ARPANET。\n这使独立的网络的数量不能太多（最多254个），这在局域网出现的早期，就已经显得不足够了。\n\n## 分类\n* A类, 最高位0, 地址范围0.0.0.0/8 - 127.0.0.0/8\n* B类, 最高位10, 地址范围128.0.0.0/16 - 191.255.0.0/16\n* C类, 最高位110, 地址范围192.0.0.0/24 - 223.255.255.0/24\n* D类, 最高位1110, 地址范围224.0.0.0/4\n* E类, 最高位1111, 地址范围240.0.0.0/4\n\nD类地址用于多点广播（Multicast）。\n\nE类地址保留，仅作实验和开发用。\n\n全零（0.0.0.0）地址指当前主机。全“1”的IP地址（255.255.255.255）是当前子网的广播地址。\n\n## 无类别域间路由(Classless Inter-Domain Routing、CIDR)\n在之前的分类网络中，IP地址的分配把IP地址的32位按每8位为一段分开。这使得前缀必须为8，16或者24位。\n遵从CIDR规则的地址有一个后缀说明前缀的位数，例如：208.130.28.0/22。这使得对日益缺乏的IPv4地址的使用更加有效。\n\n## 关于子网的第一个和最后一个地址\n一般来说, 子网的第一个地址表示子网本身, 最后一个是广播地址\n即这两个地址不用于表示主机, 其它地址可以分配给各个主机\n注意, 子网的第一个和最后一个地址不一定是0和255, 这取决于子网掩码\n如10.6.43.0/22不是第一个地址, 这个子网的第一个地址是10.6.40.0\n\n## 私有地址(RFC 1918)\n在IP地址3种主要类型里，各保留了1个区域作为私有地址，如下：\n\nA类地址：10.0.0.0～10.255.255.255\nB类地址：172.16.0.0～172.31.255.255\nC类地址：192.168.0.0～192.168.255.255\n\n这些地址在网络上不被路由, 即无法连接公网\n\n## 特殊地址\nA,B,C类地址的最低和最高的网段,\n如0.0.0.0/8, 127.0.0.0/8, 128.0.0.0/16, 191.255.0.0/16, 192.0.0.0/24, 223.255.255.0/24,\n根据RFC 3330, 都是IANA保留的, 其中,\n0.0.0.0/8段的说明如下:\n\n> 0.0.0.0/8 - Addresses in this block refer to source hosts on \"this\"\n>   network.  Address 0.0.0.0/32 may be used as a source address for this\n>   host on this network; other addresses within 0.0.0.0/8 may be used to\n>   refer to specified hosts on this network [RFC1700, page 4].\n\n127.0.0.0/8都是环回地址(loopback)\n\n128.0.0.0/16, 191.255.0.0/16, 192.0.0.0/24, 223.255.255.0/24貌似现在已经可以使用\n\n> was initially and is still reserved by\n> the IANA.  Given the present classless nature of the IP address\n> space, the basis for the reservation no longer applies and addresses\n> in this block are subject to future allocation to a Regional Internet\n> Registry for assignment in the normal manner.\n\nRFC 3330还有其他特殊地址, 参见\nhttp://www.rfc-base.org/txt/rfc-3330.txt\n\n","slug":"ip_addr_class","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5nh00aimcxquym5e18s"},{"title":"JIT","date":"2016-07-05T08:28:00.000Z","_content":"\nJIT 是 just in time 的缩写, 也就是即时编译编译器。\n在运行时 JIT 会把翻译过的机器码保存起来，以备下次使用，\n因此从理论上来说，采用该 JIT 技术可以接近以前纯编译技术。\n\n<!--more-->\n\n## 相对于传统解释和编译的优势\n\nJIT编译一个函数时并不一定编译整个函数,如一个if和else语句,如果判断else语句不会执行到,\n那么else语句块内的代码并不会被编译,这样节省了资源.\n\n另一方面,已经编译过的代码会驻留在内存里,这样下次就不用再编译了.\n\n最后, 传统编译由于不知晓执行时的具体环境,只能做最大限度的通用优化,\nJIT因为把编译推迟到了执行前(所以叫just in time, 再晚就来不及了),\n此时具体的软硬件信息均已知晓, 有哪些具体的优化选项都知道了, 可以做传统编译做不到的优化.\n\n## 参考链接\nhttp://stackoverflow.com/questions/5589409/c-sharp-jit-compiling-and-net\n\n","source":"_posts/jit.md","raw":"title: JIT\ndate: 2016-07-5 16:28:00\ntags: [compiler]\n---\n\nJIT 是 just in time 的缩写, 也就是即时编译编译器。\n在运行时 JIT 会把翻译过的机器码保存起来，以备下次使用，\n因此从理论上来说，采用该 JIT 技术可以接近以前纯编译技术。\n\n<!--more-->\n\n## 相对于传统解释和编译的优势\n\nJIT编译一个函数时并不一定编译整个函数,如一个if和else语句,如果判断else语句不会执行到,\n那么else语句块内的代码并不会被编译,这样节省了资源.\n\n另一方面,已经编译过的代码会驻留在内存里,这样下次就不用再编译了.\n\n最后, 传统编译由于不知晓执行时的具体环境,只能做最大限度的通用优化,\nJIT因为把编译推迟到了执行前(所以叫just in time, 再晚就来不及了),\n此时具体的软硬件信息均已知晓, 有哪些具体的优化选项都知道了, 可以做传统编译做不到的优化.\n\n## 参考链接\nhttp://stackoverflow.com/questions/5589409/c-sharp-jit-compiling-and-net\n\n","slug":"jit","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ni00almcxqdyk3jkan"},{"title":"linux命令env","date":"2016-06-04T09:17:00.000Z","_content":"\nenv命令, 以前只知道可以看环境变量, 没想到还能设置或移除\n<!--more-->\n\n## 查看环境变量\n```\n$ env\n```\n\n## 设置环境变量(允许多个), 并执行指定的命令\n```\n$ env TERM=a COLORTERM=b bash\n$ env | grep TERM\nTERM=a\nCOLORTERM=b\n```\n\n## 移除环境变量(允许多个), 并执行指定的命令\n参数-u\n```\n$ env -u TERM -u HOME -u COLORTERM bash\n$ env | grep TERM\n$ env | grep HOME\n```\n\n","source":"_posts/linux_cmd_env.md","raw":"title: linux命令env\ndate: 2016-06-04 17:17:00\ntags: linux\n---\n\nenv命令, 以前只知道可以看环境变量, 没想到还能设置或移除\n<!--more-->\n\n## 查看环境变量\n```\n$ env\n```\n\n## 设置环境变量(允许多个), 并执行指定的命令\n```\n$ env TERM=a COLORTERM=b bash\n$ env | grep TERM\nTERM=a\nCOLORTERM=b\n```\n\n## 移除环境变量(允许多个), 并执行指定的命令\n参数-u\n```\n$ env -u TERM -u HOME -u COLORTERM bash\n$ env | grep TERM\n$ env | grep HOME\n```\n\n","slug":"linux_cmd_env","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5nj00anmcxq6690dgyy"},{"title":"linux命令hostname","date":"2016-06-04T11:25:00.000Z","_content":"\n取本机ip地址, 比ifconfig或ip addr干净\n```\n$ hostname -i\n127.0.1.1 192.168.1.114\n\n$ hostname -I\n192.168.1.114 192.168.117.1 172.16.205.1 172.17.0.1 \n```\n\n","source":"_posts/linux_cmd_hostname.md","raw":"title: linux命令hostname\ndate: 2016-06-04 19:25:00\ntags: linux\n---\n\n取本机ip地址, 比ifconfig或ip addr干净\n```\n$ hostname -i\n127.0.1.1 192.168.1.114\n\n$ hostname -I\n192.168.1.114 192.168.117.1 172.16.205.1 172.17.0.1 \n```\n\n","slug":"linux_cmd_hostname","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5nk00aqmcxqpcqmiusu"},{"title":"json整型最大值","date":"2018-09-26T16:00:00.000Z","_content":"遇到 json 整型最大值的问题, 发现我发的 1537955357010001012 变成了1537955357010001000,\n即最后 3 位数字变成了 0,\n原来 json 支持不了 long 型\n\n<!--more-->\n超过 Number.MAX_SAFE_INTEGER 的值都无法正常表示\n\n```javascript\nNumber.MAX_SAFE_INTEGER\n9007199254740991\n```\n这个值是 2 ^ 52 - 1\n\n貌似根源是 javascript 的 Number 类型用的是 double , 用 double 表示整型要保证精度\n就只能到这个数\n\n解决方案大概只能是先用字符串传, 到了对面再想办法\n\n## 参考链接\nhttps://stackoverflow.com/questions/47188449/json-max-int-number/47188576\nhttps://stackoverflow.com/questions/13502398/json-integers-limit-on-size\n\n","source":"_posts/json.md","raw":"title: json整型最大值\ndate: 2018-09-27\ntags: [json]\n---\n遇到 json 整型最大值的问题, 发现我发的 1537955357010001012 变成了1537955357010001000,\n即最后 3 位数字变成了 0,\n原来 json 支持不了 long 型\n\n<!--more-->\n超过 Number.MAX_SAFE_INTEGER 的值都无法正常表示\n\n```javascript\nNumber.MAX_SAFE_INTEGER\n9007199254740991\n```\n这个值是 2 ^ 52 - 1\n\n貌似根源是 javascript 的 Number 类型用的是 double , 用 double 表示整型要保证精度\n就只能到这个数\n\n解决方案大概只能是先用字符串传, 到了对面再想办法\n\n## 参考链接\nhttps://stackoverflow.com/questions/47188449/json-max-int-number/47188576\nhttps://stackoverflow.com/questions/13502398/json-integers-limit-on-size\n\n","slug":"json","published":1,"updated":"2018-09-27T08:49:39.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5nl00asmcxqcc2bppg5"},{"title":"linux系统如何添加sudoer","date":"2018-09-11T16:00:00.000Z","_content":"\n```\n$ usermod -aG wheel [username]\n$ vim /etc/sudoers, 在root下面加一条一样的，改一下username即可\n```\n\n## 参考链接\nhttps://www.digitalocean.com/community/tutorials/how-to-create-a-sudo-user-on-centos-quickstart\n\n","source":"_posts/linux_add_sudoer.md","raw":"title: linux系统如何添加sudoer\ndate: 2018-09-12\ntags: [linux, root]\n---\n\n```\n$ usermod -aG wheel [username]\n$ vim /etc/sudoers, 在root下面加一条一样的，改一下username即可\n```\n\n## 参考链接\nhttps://www.digitalocean.com/community/tutorials/how-to-create-a-sudo-user-on-centos-quickstart\n\n","slug":"linux_add_sudoer","published":1,"updated":"2018-09-12T03:14:28.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5nm00aumcxqm6wzqk34"},{"title":"linux_history","date":"2016-01-04T16:00:00.000Z","_content":"\n## 清空history\nhistory -c\n删除用户目录下的.bash_history文件\n\n## 设置history记录条数\n修改/etc/profile\n设置环境变量HISTSIZE\n\n","source":"_posts/linux_history.md","raw":"title: linux_history\ndate: 2016-01-05\ntags: [linux]\n---\n\n## 清空history\nhistory -c\n删除用户目录下的.bash_history文件\n\n## 设置history记录条数\n修改/etc/profile\n设置环境变量HISTSIZE\n\n","slug":"linux_history","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5no00axmcxqajrm2s5v"},{"title":"linux storage","date":"2015-09-05T16:00:00.000Z","_content":"## 关于磁盘第一个分割区前面预留的1MiB空间\n1. 以前的硬盘分割MBR常常说MBR是512bytes,这是早期的规格,就是指第1個分割区前面的空白是512 bytes = 1 sector\n现在Ubuntu预设,第1個分割区前面的空白是1048576 bytes = 1 MiB = 2048 sectors = 0 ~ 2047 sector\n所以gparted第一個分割区前面预留1 MiB空白空间\nfdisk 指令\nparted 指令\ngdisk 指令\n....\n第一个分区都是从第2048个sector开始\n\n2. 这1 MiB的用途\n除了前面512 bytes还是存放MBR信息以外 (0~445放开机引导信息446~511放分区信息)\n后面还有2047个512 sectors留给其它程序使用,例如RAID LVM等等\n\n## 检查某分区的block size\nsudo blockdev --getbsz /dev/sda1\n\n\n","source":"_posts/linux_storage.md","raw":"title: linux storage\ndate: 2015-09-06\ntags: linux\n---\n## 关于磁盘第一个分割区前面预留的1MiB空间\n1. 以前的硬盘分割MBR常常说MBR是512bytes,这是早期的规格,就是指第1個分割区前面的空白是512 bytes = 1 sector\n现在Ubuntu预设,第1個分割区前面的空白是1048576 bytes = 1 MiB = 2048 sectors = 0 ~ 2047 sector\n所以gparted第一個分割区前面预留1 MiB空白空间\nfdisk 指令\nparted 指令\ngdisk 指令\n....\n第一个分区都是从第2048个sector开始\n\n2. 这1 MiB的用途\n除了前面512 bytes还是存放MBR信息以外 (0~445放开机引导信息446~511放分区信息)\n后面还有2047个512 sectors留给其它程序使用,例如RAID LVM等等\n\n## 检查某分区的block size\nsudo blockdev --getbsz /dev/sda1\n\n\n","slug":"linux_storage","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5np00azmcxqmdmy57qz"},{"title":"linux terminal","date":"2016-06-03T16:00:00.000Z","_content":"\nterminal还是有挺多内容的...\n\n<!--more-->\n## Ubuntu终端Terminal常用快捷键\nF11全屏\n\n### 各种term type的区别\n如xterm支持颜色,而vt220不支持颜色, 在shell里执行top, 按z键可以看到颜色, 而 TERM=vt220 top再按z键就没有颜色\n使用命令infocmp, 如: `infocmp xterm vt220`, 可以查看具体区别\n\n### 查看所有的terminfo\n```\ntoe -a\n或\ntoe /usr/share/terminfo\n```\n\n### 查看当前terminfo的信息\n```\ninfocmp\n```\n\n### 常见terminfo\n\n* xterm: X Window System上的标准虚拟终端\n* linux: Ctrl+Alt+F1这种情况时\n* screen: 在GNU screen中 \n* dumb: 字符终端, 只有最基本的输入输出功能, 不能执行删行,清屏,控制光标位置等特殊换码顺序操作\n\n## 参考链接\nhttp://unix.stackexchange.com/questions/43945/whats-the-difference-between-various-term-variables\n\n","source":"_posts/linux_terminal.md","raw":"title: linux terminal\ndate: 2016-06-04\ntags: linux\n---\n\nterminal还是有挺多内容的...\n\n<!--more-->\n## Ubuntu终端Terminal常用快捷键\nF11全屏\n\n### 各种term type的区别\n如xterm支持颜色,而vt220不支持颜色, 在shell里执行top, 按z键可以看到颜色, 而 TERM=vt220 top再按z键就没有颜色\n使用命令infocmp, 如: `infocmp xterm vt220`, 可以查看具体区别\n\n### 查看所有的terminfo\n```\ntoe -a\n或\ntoe /usr/share/terminfo\n```\n\n### 查看当前terminfo的信息\n```\ninfocmp\n```\n\n### 常见terminfo\n\n* xterm: X Window System上的标准虚拟终端\n* linux: Ctrl+Alt+F1这种情况时\n* screen: 在GNU screen中 \n* dumb: 字符终端, 只有最基本的输入输出功能, 不能执行删行,清屏,控制光标位置等特殊换码顺序操作\n\n## 参考链接\nhttp://unix.stackexchange.com/questions/43945/whats-the-difference-between-various-term-variables\n\n","slug":"linux_terminal","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5nq00b2mcxq6pvk1ts6"},{"title":"linux tips","date":"2015-09-05T16:00:00.000Z","_content":"零碎的linux知识\n<!--more-->\n## 查看显卡所支持的OpenGL版本\nsudo apt-get install mesa-utils\nglxinfo | grep OpenGL\n\n## ulimit -c 999999999\n用于产生core文件,否则产生不了\n\n## linux上的office解决方案\n在线的Google Docs和Office Web Apps可以在一定程序上替代本地Office套件\n这样本地不用装那么臃肿的Office\nhttps://www.google.com/docs/about/\nhttps://office.live.com/start/default.aspx\n\n使用金山WPS\n可以从源里安装, 官网上的beta版本不稳定\n\n## 把当前目录放到PATH中有安全风险\n因为当前目录中可能有与/bin等目录里的文件重名的恶意脚本等情况\n\n## 内核空间 用户空间\n每个进程有4GB的进程地址空间(虚拟内存空间),\n多数情况下内核占用其中的1GB,用户空间获得剩余的3GB,64位系统这些数字可能不同\n\n","source":"_posts/linux_tips.md","raw":"title: linux tips\ndate: 2015-09-06\ntags: linux\n---\n零碎的linux知识\n<!--more-->\n## 查看显卡所支持的OpenGL版本\nsudo apt-get install mesa-utils\nglxinfo | grep OpenGL\n\n## ulimit -c 999999999\n用于产生core文件,否则产生不了\n\n## linux上的office解决方案\n在线的Google Docs和Office Web Apps可以在一定程序上替代本地Office套件\n这样本地不用装那么臃肿的Office\nhttps://www.google.com/docs/about/\nhttps://office.live.com/start/default.aspx\n\n使用金山WPS\n可以从源里安装, 官网上的beta版本不稳定\n\n## 把当前目录放到PATH中有安全风险\n因为当前目录中可能有与/bin等目录里的文件重名的恶意脚本等情况\n\n## 内核空间 用户空间\n每个进程有4GB的进程地址空间(虚拟内存空间),\n多数情况下内核占用其中的1GB,用户空间获得剩余的3GB,64位系统这些数字可能不同\n\n","slug":"linux_tips","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5nr00b4mcxquj5p9bpg"},{"title":"logrotate","date":"2016-09-06T13:09:00.000Z","_content":"\nlinux自带的日志滚动工具, 依赖crond定时调用\n\n<!--more-->\n\n## 相关文件\n\n/etc/cron.daily/logrotate # 告诉crontab每天调用logrotate\n/usr/sbin/logrotate # logrotate的可执行文件\n/etc/logrotate.conf 和 /etc/logrotate.d # logrotate自己的配置文件\n\n## 与supervisor结合使用\n\n禁用supervisor的log backup而使用logrotate\n```\nstdout_logfile_maxbytes=0\nstderr_logfile_maxbytes=0\n\nstdout_logfile_backups=0\nstderr_logfile_backups=0\n```\n\n每天rotate, 保存60份, 压缩\n```\n/var/log/supervisor/my_app_*.log {\n daily\n rotate 60\n copytruncate\n compress\n missingok\n notifempty\n}\n```\n\ncopytruncate\n有些程序你无法让他关闭原日志文件，于是只能这样，即通过先copy再truncate原日志文件来实现滚动，\ncopy和truncate之间有一小段时间差，这时的日志会丢失\n\nmissingok\n如果找不到日志文件，跳过，不报错\n\nnotifempty\n如果日志文件是空的，不要滚动\n\n## 参考链接\nhttps://www.rounds.com/blog/easy-logging-with-logrotate-and-supervisord/\nhttp://www.thegeekstuff.com/2010/07/logrotate-examples/\n\n","source":"_posts/logrotate.md","raw":"title: logrotate\ndate: 2016-09-06 21:09:00\ntags: [linux, log]\n---\n\nlinux自带的日志滚动工具, 依赖crond定时调用\n\n<!--more-->\n\n## 相关文件\n\n/etc/cron.daily/logrotate # 告诉crontab每天调用logrotate\n/usr/sbin/logrotate # logrotate的可执行文件\n/etc/logrotate.conf 和 /etc/logrotate.d # logrotate自己的配置文件\n\n## 与supervisor结合使用\n\n禁用supervisor的log backup而使用logrotate\n```\nstdout_logfile_maxbytes=0\nstderr_logfile_maxbytes=0\n\nstdout_logfile_backups=0\nstderr_logfile_backups=0\n```\n\n每天rotate, 保存60份, 压缩\n```\n/var/log/supervisor/my_app_*.log {\n daily\n rotate 60\n copytruncate\n compress\n missingok\n notifempty\n}\n```\n\ncopytruncate\n有些程序你无法让他关闭原日志文件，于是只能这样，即通过先copy再truncate原日志文件来实现滚动，\ncopy和truncate之间有一小段时间差，这时的日志会丢失\n\nmissingok\n如果找不到日志文件，跳过，不报错\n\nnotifempty\n如果日志文件是空的，不要滚动\n\n## 参考链接\nhttps://www.rounds.com/blog/easy-logging-with-logrotate-and-supervisord/\nhttp://www.thegeekstuff.com/2010/07/logrotate-examples/\n\n","slug":"logrotate","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ns00b7mcxqw6q4pshd"},{"title":"lsmod命令","date":"2015-07-30T16:00:00.000Z","_content":"显示已载入系统的模块\n<!--more-->\n## 输出详解\n| Module(模块的名称)| Size(单位字节)| Used by(依赖该模块的模块个数和模块名列表)|\n| -----------------------------------------------------------------------------|\n| ip_tables         | 27240         | 2 iptable_filter,iptable_nat             |\n| vsock             | 34903         | 1 vmw_vsock_vmci_transport               |\n...\n","source":"_posts/lsmod命令.md","raw":"title: lsmod命令\ndate: 2015-07-31\ntags: linux\n---\n显示已载入系统的模块\n<!--more-->\n## 输出详解\n| Module(模块的名称)| Size(单位字节)| Used by(依赖该模块的模块个数和模块名列表)|\n| -----------------------------------------------------------------------------|\n| ip_tables         | 27240         | 2 iptable_filter,iptable_nat             |\n| vsock             | 34903         | 1 vmw_vsock_vmci_transport               |\n...\n","slug":"lsmod命令","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5nt00b9mcxq5803rge7"},{"title":"locale","date":"2018-10-19T16:00:00.000Z","_content":"\n今天登录阿里云时发现如下 warning :\n\n```\nWelcome to Alibaba Cloud Elastic Compute Service !\n\n-bash: warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory\n```\n<!--more-->\n\n原因是 ssh 会把 locale 相关的环境变量 forward 到远端,\n而本地 mac 没有设置所以 LC_CTYPE 的值为 UTF-8, 而这个值在远端系统没有,\n所以有如上警告\n\n解决方案是在 .zshrc 里加入如下\n```\nexport LC_ALL=en_US.UTF-8\nexport LANG=en_US.UTF-8\n```\n\n## 参考链接\nhttps://www.jianshu.com/p/2b24861be987\nhttp://www.cnblogs.com/xlmeng1988/archive/2013/01/16/locale.html\n\n","source":"_posts/locale.md","raw":"title: locale\ndate: 2018-10-20\ntags: [linux, locale, terminal]\n---\n\n今天登录阿里云时发现如下 warning :\n\n```\nWelcome to Alibaba Cloud Elastic Compute Service !\n\n-bash: warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory\n```\n<!--more-->\n\n原因是 ssh 会把 locale 相关的环境变量 forward 到远端,\n而本地 mac 没有设置所以 LC_CTYPE 的值为 UTF-8, 而这个值在远端系统没有,\n所以有如上警告\n\n解决方案是在 .zshrc 里加入如下\n```\nexport LC_ALL=en_US.UTF-8\nexport LANG=en_US.UTF-8\n```\n\n## 参考链接\nhttps://www.jianshu.com/p/2b24861be987\nhttp://www.cnblogs.com/xlmeng1988/archive/2013/01/16/locale.html\n\n","slug":"locale","published":1,"updated":"2018-10-20T11:58:30.214Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5nu00bcmcxqyqyfbzxv"},{"title":"内存墙(memory wall)","date":"2015-10-12T16:00:00.000Z","_content":"内存墙，指的是内存性能严重限制CPU性能发挥的现象。\n内存的性能指标主要有“带宽”(Bandwidth)和“等待时间”(Latency)。\n<!--more-->\n在过去的20多年中，处理器的性能以每年大约55%速度快速提升，而内存性能的提升速度则只有每年10%左右。\n长期累积下来，不均衡的发展速度造成了当前内存的存取速度严重滞后于处理器的计算速度，\n内存瓶颈导致高性能处理器难以发挥出应有的功效\n![内存墙](/pics/memory_wall.png)\n\n# 参考链接\nhttps://en.wikipedia.org/wiki/Random-access_memory#Memory_wall\nhttp://baike.baidu.com/view/4230085.htm\n\n","source":"_posts/memory_wall.md","raw":"title: 内存墙(memory wall)\ndate: 2015-10-13\ntags: [computer]\n---\n内存墙，指的是内存性能严重限制CPU性能发挥的现象。\n内存的性能指标主要有“带宽”(Bandwidth)和“等待时间”(Latency)。\n<!--more-->\n在过去的20多年中，处理器的性能以每年大约55%速度快速提升，而内存性能的提升速度则只有每年10%左右。\n长期累积下来，不均衡的发展速度造成了当前内存的存取速度严重滞后于处理器的计算速度，\n内存瓶颈导致高性能处理器难以发挥出应有的功效\n![内存墙](/pics/memory_wall.png)\n\n# 参考链接\nhttps://en.wikipedia.org/wiki/Random-access_memory#Memory_wall\nhttp://baike.baidu.com/view/4230085.htm\n\n","slug":"memory_wall","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5nv00bemcxqt1oarwi5"},{"title":"mac 点滴","date":"2018-10-11T16:00:00.000Z","_content":"\n点滴积累\n\n* mac读取txt中文乱码问题解决\n* mac如何输入emoji\n\n<!--more-->\n\n## mac读取txt中文乱码问题解决\nmac貌似只认unicode, 有些txt文件是GB2312或GB18030之类的, 需要转码\n\n```\niconv -c -f GB2312 -t UTF-8 [你要看的文件] >> [新文件的名称]\n```\n\n## mac如何输入emoji\ncontrol-command+space\n\n### 参考链接\nhttps://www.zhihu.com/question/20353626\n\n","source":"_posts/mac_chinese.md","raw":"title: mac 点滴\ndate: 2018-10-12\ntags: [mac,乱码,unicode,encoding,emoji]\n---\n\n点滴积累\n\n* mac读取txt中文乱码问题解决\n* mac如何输入emoji\n\n<!--more-->\n\n## mac读取txt中文乱码问题解决\nmac貌似只认unicode, 有些txt文件是GB2312或GB18030之类的, 需要转码\n\n```\niconv -c -f GB2312 -t UTF-8 [你要看的文件] >> [新文件的名称]\n```\n\n## mac如何输入emoji\ncontrol-command+space\n\n### 参考链接\nhttps://www.zhihu.com/question/20353626\n\n","slug":"mac_chinese","published":1,"updated":"2018-10-21T10:23:49.664Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5nw00bgmcxqe9h1o7oz"},{"title":"mysql命令行","date":"2015-12-03T16:00:00.000Z","_content":"\nmysql, mysqladmin, mysqldump\n<!--more-->\n\n## 登录sql\nmysql -u ben -p -h myserver -P 9999\n默认端口3306\n\n## mysql命令\n* show databases; 显示数据库列表\n* use databasename; 选择数据库\n* show tables; 显示数据表列表\n* desc tablename; 显示表tablename的详细信息\n* show columns from tablename; 与desc tablename命令相同\n* show status; 显示服务器状态信息\n* show grants; 显示权限信息\n* show errors; 显示错误信息\n* show warnings; 显示警告信息\n* help commandname; 显示commandname如show, use, desc的帮助信息\n* \\G  显示从横排变成竖排,有时会清晰很多\n\n## mysqladmin\n创建数据库\nmysqladmin -u root -p create newdatabase\n\n删除数据库\nmysqladmin -u root -p drop testdatabase\n\n修改用户密码\nmysqladmin -u root -p password \"new password\"\n\n## 附1: 命令行帮助1\n<pre>\nmysql> help\n\nFor information about MySQL products and services, visit:\n   http://www.mysql.com/\nFor developer information, including the MySQL Reference Manual, visit:\n   http://dev.mysql.com/\nTo buy MySQL Enterprise support, training, or other products, visit:\n   https://shop.mysql.com/\n\nList of all MySQL commands:\nNote that all text commands must be first on line and end with ';'\n?         (\\?) Synonym for `help'.\nclear     (\\c) Clear the current input statement.\nconnect   (\\r) Reconnect to the server. Optional arguments are db and host.\ndelimiter (\\d) Set statement delimiter.\nedit      (\\e) Edit command with $EDITOR.\nego       (\\G) Send command to mysql server, display result vertically.\nexit      (\\q) Exit mysql. Same as quit.\ngo        (\\g) Send command to mysql server.\nhelp      (\\h) Display this help.\nnopager   (\\n) Disable pager, print to stdout.\nnotee     (\\t) Don't write into outfile.\npager     (\\P) Set PAGER [to_pager]. Print the query results via PAGER.\nprint     (\\p) Print current command.\nprompt    (\\R) Change your mysql prompt.\nquit      (\\q) Quit mysql.\nrehash    (\\#) Rebuild completion hash.\nsource    (\\.) Execute an SQL script file. Takes a file name as an argument.\nstatus    (\\s) Get status information from the server.\nsystem    (\\!) Execute a system shell command.\ntee       (\\T) Set outfile [to_outfile]. Append everything into given outfile.\nuse       (\\u) Use another database. Takes database name as argument.\ncharset   (\\C) Switch to another charset. Might be needed for processing binlog with multi-byte charsets.\nwarnings  (\\W) Show warnings after every statement.\nnowarning (\\w) Don't show warnings after every statement.\n\nFor server side help, type 'help contents'\n</pre>\n\n## 附2: 命令行帮助2\n<pre>\n$ mysql --help\nmysql  Ver 14.14 Distrib 5.5.44, for debian-linux-gnu (x86_64) using readline 6.3\nCopyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nUsage: mysql [OPTIONS] [database]\n  -?, --help          Display this help and exit.\n  -I, --help          Synonym for -?\n  --auto-rehash       Enable automatic rehashing. One doesn't need to use\n                      'rehash' to get table and field completion, but startup\n                      and reconnecting may take a longer time. Disable with\n                      --disable-auto-rehash.\n                      (Defaults to on; use --skip-auto-rehash to disable.)\n  -A, --no-auto-rehash \n                      No automatic rehashing. One has to use 'rehash' to get\n                      table and field completion. This gives a quicker start of\n                      mysql and disables rehashing on reconnect.\n  --auto-vertical-output \n                      Automatically switch to vertical output mode if the\n                      result is wider than the terminal width.\n  -B, --batch         Don't use history file. Disable interactive behavior.\n                      (Enables --silent.)\n  --character-sets-dir=name \n                      Directory for character set files.\n  --column-type-info  Display column type information.\n  -c, --comments      Preserve comments. Send comments to the server. The\n                      default is --skip-comments (discard comments), enable\n                      with --comments.\n  -C, --compress      Use compression in server/client protocol.\n  -#, --debug[=#]     This is a non-debug version. Catch this and exit.\n  --debug-check       Check memory and open file usage at exit.\n  -T, --debug-info    Print some debug info at exit.\n  -D, --database=name Database to use.\n  --default-character-set=name \n                      Set the default character set.\n  --delimiter=name    Delimiter to be used.\n  --enable-cleartext-plugin \n                      Enable/disable the clear text authentication plugin.\n  -e, --execute=name  Execute command and quit. (Disables --force and history\n                      file.)\n  -E, --vertical      Print the output of a query (rows) vertically.\n  -f, --force         Continue even if we get an SQL error.\n  -G, --named-commands \n                      Enable named commands. Named commands mean this program's\n                      internal commands; see mysql> help . When enabled, the\n                      named commands can be used from any line of the query,\n                      otherwise only from the first line, before an enter.\n                      Disable with --disable-named-commands. This option is\n                      disabled by default.\n  -i, --ignore-spaces Ignore space after function names.\n  --init-command=name SQL Command to execute when connecting to MySQL server.\n                      Will automatically be re-executed when reconnecting.\n  --local-infile      Enable/disable LOAD DATA LOCAL INFILE.\n  -b, --no-beep       Turn off beep on error.\n  -h, --host=name     Connect to host.\n  -H, --html          Produce HTML output.\n  -X, --xml           Produce XML output.\n  --line-numbers      Write line numbers for errors.\n                      (Defaults to on; use --skip-line-numbers to disable.)\n  -L, --skip-line-numbers \n                      Don't write line number for errors.\n  -n, --unbuffered    Flush buffer after each query.\n  --column-names      Write column names in results.\n                      (Defaults to on; use --skip-column-names to disable.)\n  -N, --skip-column-names \n                      Don't write column names in results.\n  --sigint-ignore     Ignore SIGINT (CTRL-C).\n  -o, --one-database  Ignore statements except those that occur while the\n                      default database is the one named at the command line.\n  --pager[=name]      Pager to use to display results. If you don't supply an\n                      option, the default pager is taken from your ENV variable\n                      PAGER. Valid pagers are less, more, cat [> filename],\n                      etc. See interactive help (\\h) also. This option does not\n                      work in batch mode. Disable with --disable-pager. This\n                      option is disabled by default.\n  -p, --password[=name] \n                      Password to use when connecting to server. If password is\n                      not given it's asked from the tty.\n  -P, --port=#        Port number to use for connection or 0 for default to, in\n                      order of preference, my.cnf, $MYSQL_TCP_PORT,\n                      /etc/services, built-in default (3306).\n  --prompt=name       Set the mysql prompt to this value.\n  --protocol=name     The protocol to use for connection (tcp, socket, pipe,\n                      memory).\n  -q, --quick         Don't cache result, print it row by row. This may slow\n                      down the server if the output is suspended. Doesn't use\n                      history file.\n  -r, --raw           Write fields without conversion. Used with --batch.\n  --reconnect         Reconnect if the connection is lost. Disable with\n                      --disable-reconnect. This option is enabled by default.\n                      (Defaults to on; use --skip-reconnect to disable.)\n  -s, --silent        Be more silent. Print results with a tab as separator,\n                      each row on new line.\n  -S, --socket=name   The socket file to use for connection.\n  --ssl               Enable SSL for connection (automatically enabled with\n                      other flags).\n  --ssl-ca=name       CA file in PEM format (check OpenSSL docs, implies\n                      --ssl).\n  --ssl-capath=name   CA directory (check OpenSSL docs, implies --ssl).\n  --ssl-cert=name     X509 cert in PEM format (implies --ssl).\n  --ssl-cipher=name   SSL cipher to use (implies --ssl).\n  --ssl-key=name      X509 key in PEM format (implies --ssl).\n  --ssl-verify-server-cert \n                      Verify server's \"Common Name\" in its cert against\n                      hostname used when connecting. This option is disabled by\n                      default.\n  -t, --table         Output in table format.\n  --tee=name          Append everything into outfile. See interactive help (\\h)\n                      also. Does not work in batch mode. Disable with\n                      --disable-tee. This option is disabled by default.\n  -u, --user=name     User for login if not current user.\n  -U, --safe-updates  Only allow UPDATE and DELETE that uses keys.\n  -U, --i-am-a-dummy  Synonym for option --safe-updates, -U.\n  -v, --verbose       Write more. (-v -v -v gives the table output format).\n  -V, --version       Output version information and exit.\n  -w, --wait          Wait and retry if connection is down.\n  --connect-timeout=# Number of seconds before connection timeout.\n  --max-allowed-packet=# \n                      The maximum packet length to send to or receive from\n                      server.\n  --net-buffer-length=# \n                      The buffer size for TCP/IP and socket communication.\n  --select-limit=#    Automatic limit for SELECT when using --safe-updates.\n  --max-join-size=#   Automatic limit for rows in a join when using\n                      --safe-updates.\n  --secure-auth       Refuse client connecting to server if it uses old\n                      (pre-4.1.1) protocol.\n  --server-arg=name   Send embedded server this as a parameter.\n  --show-warnings     Show warnings after every statement.\n  --plugin-dir=name   Directory for client-side plugins.\n  --default-auth=name Default authentication client-side plugin to use.\n\nDefault options are read from the following files in the given order:\n/etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf \nThe following groups are read: mysql client\nThe following options may be given as the first argument:\n--print-defaults        Print the program argument list and exit.\n--no-defaults           Don't read default options from any option file.\n--defaults-file=#       Only read default options from the given file #.\n--defaults-extra-file=# Read this file after the global files are read.\n\nVariables (--variable-name=value)\nand boolean options {FALSE|TRUE}  Value (after reading options)\n--------------------------------- ----------------------------------------\nauto-rehash                       TRUE\nauto-vertical-output              FALSE\ncharacter-sets-dir                (No default value)\ncolumn-type-info                  FALSE\ncomments                          FALSE\ncompress                          FALSE\ndebug-check                       FALSE\ndebug-info                        FALSE\ndatabase                          (No default value)\ndefault-character-set             auto\ndelimiter                         ;\nenable-cleartext-plugin           FALSE\nvertical                          FALSE\nforce                             FALSE\nnamed-commands                    FALSE\nignore-spaces                     FALSE\ninit-command                      (No default value)\nlocal-infile                      FALSE\nno-beep                           FALSE\nhost                              (No default value)\nhtml                              FALSE\nxml                               FALSE\nline-numbers                      TRUE\nunbuffered                        FALSE\ncolumn-names                      TRUE\nsigint-ignore                     FALSE\nport                              3306\nprompt                            mysql> \nquick                             FALSE\nraw                               FALSE\nreconnect                         TRUE\nsocket                            /var/run/mysqld/mysqld.sock\nssl                               FALSE\nssl-ca                            (No default value)\nssl-capath                        (No default value)\nssl-cert                          (No default value)\nssl-cipher                        (No default value)\nssl-key                           (No default value)\nssl-verify-server-cert            FALSE\ntable                             FALSE\nuser                              (No default value)\nsafe-updates                      FALSE\ni-am-a-dummy                      FALSE\nconnect-timeout                   0\nmax-allowed-packet                16777216\nnet-buffer-length                 16384\nselect-limit                      1000\nmax-join-size                     1000000\nsecure-auth                       FALSE\nshow-warnings                     FALSE\nplugin-dir                        (No default value)\ndefault-auth                      (No default value)\n</pre>\n","source":"_posts/mysql_cmd.md","raw":"title: mysql命令行\ndate: 2015-12-04\ntags: [db]\n---\n\nmysql, mysqladmin, mysqldump\n<!--more-->\n\n## 登录sql\nmysql -u ben -p -h myserver -P 9999\n默认端口3306\n\n## mysql命令\n* show databases; 显示数据库列表\n* use databasename; 选择数据库\n* show tables; 显示数据表列表\n* desc tablename; 显示表tablename的详细信息\n* show columns from tablename; 与desc tablename命令相同\n* show status; 显示服务器状态信息\n* show grants; 显示权限信息\n* show errors; 显示错误信息\n* show warnings; 显示警告信息\n* help commandname; 显示commandname如show, use, desc的帮助信息\n* \\G  显示从横排变成竖排,有时会清晰很多\n\n## mysqladmin\n创建数据库\nmysqladmin -u root -p create newdatabase\n\n删除数据库\nmysqladmin -u root -p drop testdatabase\n\n修改用户密码\nmysqladmin -u root -p password \"new password\"\n\n## 附1: 命令行帮助1\n<pre>\nmysql> help\n\nFor information about MySQL products and services, visit:\n   http://www.mysql.com/\nFor developer information, including the MySQL Reference Manual, visit:\n   http://dev.mysql.com/\nTo buy MySQL Enterprise support, training, or other products, visit:\n   https://shop.mysql.com/\n\nList of all MySQL commands:\nNote that all text commands must be first on line and end with ';'\n?         (\\?) Synonym for `help'.\nclear     (\\c) Clear the current input statement.\nconnect   (\\r) Reconnect to the server. Optional arguments are db and host.\ndelimiter (\\d) Set statement delimiter.\nedit      (\\e) Edit command with $EDITOR.\nego       (\\G) Send command to mysql server, display result vertically.\nexit      (\\q) Exit mysql. Same as quit.\ngo        (\\g) Send command to mysql server.\nhelp      (\\h) Display this help.\nnopager   (\\n) Disable pager, print to stdout.\nnotee     (\\t) Don't write into outfile.\npager     (\\P) Set PAGER [to_pager]. Print the query results via PAGER.\nprint     (\\p) Print current command.\nprompt    (\\R) Change your mysql prompt.\nquit      (\\q) Quit mysql.\nrehash    (\\#) Rebuild completion hash.\nsource    (\\.) Execute an SQL script file. Takes a file name as an argument.\nstatus    (\\s) Get status information from the server.\nsystem    (\\!) Execute a system shell command.\ntee       (\\T) Set outfile [to_outfile]. Append everything into given outfile.\nuse       (\\u) Use another database. Takes database name as argument.\ncharset   (\\C) Switch to another charset. Might be needed for processing binlog with multi-byte charsets.\nwarnings  (\\W) Show warnings after every statement.\nnowarning (\\w) Don't show warnings after every statement.\n\nFor server side help, type 'help contents'\n</pre>\n\n## 附2: 命令行帮助2\n<pre>\n$ mysql --help\nmysql  Ver 14.14 Distrib 5.5.44, for debian-linux-gnu (x86_64) using readline 6.3\nCopyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nUsage: mysql [OPTIONS] [database]\n  -?, --help          Display this help and exit.\n  -I, --help          Synonym for -?\n  --auto-rehash       Enable automatic rehashing. One doesn't need to use\n                      'rehash' to get table and field completion, but startup\n                      and reconnecting may take a longer time. Disable with\n                      --disable-auto-rehash.\n                      (Defaults to on; use --skip-auto-rehash to disable.)\n  -A, --no-auto-rehash \n                      No automatic rehashing. One has to use 'rehash' to get\n                      table and field completion. This gives a quicker start of\n                      mysql and disables rehashing on reconnect.\n  --auto-vertical-output \n                      Automatically switch to vertical output mode if the\n                      result is wider than the terminal width.\n  -B, --batch         Don't use history file. Disable interactive behavior.\n                      (Enables --silent.)\n  --character-sets-dir=name \n                      Directory for character set files.\n  --column-type-info  Display column type information.\n  -c, --comments      Preserve comments. Send comments to the server. The\n                      default is --skip-comments (discard comments), enable\n                      with --comments.\n  -C, --compress      Use compression in server/client protocol.\n  -#, --debug[=#]     This is a non-debug version. Catch this and exit.\n  --debug-check       Check memory and open file usage at exit.\n  -T, --debug-info    Print some debug info at exit.\n  -D, --database=name Database to use.\n  --default-character-set=name \n                      Set the default character set.\n  --delimiter=name    Delimiter to be used.\n  --enable-cleartext-plugin \n                      Enable/disable the clear text authentication plugin.\n  -e, --execute=name  Execute command and quit. (Disables --force and history\n                      file.)\n  -E, --vertical      Print the output of a query (rows) vertically.\n  -f, --force         Continue even if we get an SQL error.\n  -G, --named-commands \n                      Enable named commands. Named commands mean this program's\n                      internal commands; see mysql> help . When enabled, the\n                      named commands can be used from any line of the query,\n                      otherwise only from the first line, before an enter.\n                      Disable with --disable-named-commands. This option is\n                      disabled by default.\n  -i, --ignore-spaces Ignore space after function names.\n  --init-command=name SQL Command to execute when connecting to MySQL server.\n                      Will automatically be re-executed when reconnecting.\n  --local-infile      Enable/disable LOAD DATA LOCAL INFILE.\n  -b, --no-beep       Turn off beep on error.\n  -h, --host=name     Connect to host.\n  -H, --html          Produce HTML output.\n  -X, --xml           Produce XML output.\n  --line-numbers      Write line numbers for errors.\n                      (Defaults to on; use --skip-line-numbers to disable.)\n  -L, --skip-line-numbers \n                      Don't write line number for errors.\n  -n, --unbuffered    Flush buffer after each query.\n  --column-names      Write column names in results.\n                      (Defaults to on; use --skip-column-names to disable.)\n  -N, --skip-column-names \n                      Don't write column names in results.\n  --sigint-ignore     Ignore SIGINT (CTRL-C).\n  -o, --one-database  Ignore statements except those that occur while the\n                      default database is the one named at the command line.\n  --pager[=name]      Pager to use to display results. If you don't supply an\n                      option, the default pager is taken from your ENV variable\n                      PAGER. Valid pagers are less, more, cat [> filename],\n                      etc. See interactive help (\\h) also. This option does not\n                      work in batch mode. Disable with --disable-pager. This\n                      option is disabled by default.\n  -p, --password[=name] \n                      Password to use when connecting to server. If password is\n                      not given it's asked from the tty.\n  -P, --port=#        Port number to use for connection or 0 for default to, in\n                      order of preference, my.cnf, $MYSQL_TCP_PORT,\n                      /etc/services, built-in default (3306).\n  --prompt=name       Set the mysql prompt to this value.\n  --protocol=name     The protocol to use for connection (tcp, socket, pipe,\n                      memory).\n  -q, --quick         Don't cache result, print it row by row. This may slow\n                      down the server if the output is suspended. Doesn't use\n                      history file.\n  -r, --raw           Write fields without conversion. Used with --batch.\n  --reconnect         Reconnect if the connection is lost. Disable with\n                      --disable-reconnect. This option is enabled by default.\n                      (Defaults to on; use --skip-reconnect to disable.)\n  -s, --silent        Be more silent. Print results with a tab as separator,\n                      each row on new line.\n  -S, --socket=name   The socket file to use for connection.\n  --ssl               Enable SSL for connection (automatically enabled with\n                      other flags).\n  --ssl-ca=name       CA file in PEM format (check OpenSSL docs, implies\n                      --ssl).\n  --ssl-capath=name   CA directory (check OpenSSL docs, implies --ssl).\n  --ssl-cert=name     X509 cert in PEM format (implies --ssl).\n  --ssl-cipher=name   SSL cipher to use (implies --ssl).\n  --ssl-key=name      X509 key in PEM format (implies --ssl).\n  --ssl-verify-server-cert \n                      Verify server's \"Common Name\" in its cert against\n                      hostname used when connecting. This option is disabled by\n                      default.\n  -t, --table         Output in table format.\n  --tee=name          Append everything into outfile. See interactive help (\\h)\n                      also. Does not work in batch mode. Disable with\n                      --disable-tee. This option is disabled by default.\n  -u, --user=name     User for login if not current user.\n  -U, --safe-updates  Only allow UPDATE and DELETE that uses keys.\n  -U, --i-am-a-dummy  Synonym for option --safe-updates, -U.\n  -v, --verbose       Write more. (-v -v -v gives the table output format).\n  -V, --version       Output version information and exit.\n  -w, --wait          Wait and retry if connection is down.\n  --connect-timeout=# Number of seconds before connection timeout.\n  --max-allowed-packet=# \n                      The maximum packet length to send to or receive from\n                      server.\n  --net-buffer-length=# \n                      The buffer size for TCP/IP and socket communication.\n  --select-limit=#    Automatic limit for SELECT when using --safe-updates.\n  --max-join-size=#   Automatic limit for rows in a join when using\n                      --safe-updates.\n  --secure-auth       Refuse client connecting to server if it uses old\n                      (pre-4.1.1) protocol.\n  --server-arg=name   Send embedded server this as a parameter.\n  --show-warnings     Show warnings after every statement.\n  --plugin-dir=name   Directory for client-side plugins.\n  --default-auth=name Default authentication client-side plugin to use.\n\nDefault options are read from the following files in the given order:\n/etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf \nThe following groups are read: mysql client\nThe following options may be given as the first argument:\n--print-defaults        Print the program argument list and exit.\n--no-defaults           Don't read default options from any option file.\n--defaults-file=#       Only read default options from the given file #.\n--defaults-extra-file=# Read this file after the global files are read.\n\nVariables (--variable-name=value)\nand boolean options {FALSE|TRUE}  Value (after reading options)\n--------------------------------- ----------------------------------------\nauto-rehash                       TRUE\nauto-vertical-output              FALSE\ncharacter-sets-dir                (No default value)\ncolumn-type-info                  FALSE\ncomments                          FALSE\ncompress                          FALSE\ndebug-check                       FALSE\ndebug-info                        FALSE\ndatabase                          (No default value)\ndefault-character-set             auto\ndelimiter                         ;\nenable-cleartext-plugin           FALSE\nvertical                          FALSE\nforce                             FALSE\nnamed-commands                    FALSE\nignore-spaces                     FALSE\ninit-command                      (No default value)\nlocal-infile                      FALSE\nno-beep                           FALSE\nhost                              (No default value)\nhtml                              FALSE\nxml                               FALSE\nline-numbers                      TRUE\nunbuffered                        FALSE\ncolumn-names                      TRUE\nsigint-ignore                     FALSE\nport                              3306\nprompt                            mysql> \nquick                             FALSE\nraw                               FALSE\nreconnect                         TRUE\nsocket                            /var/run/mysqld/mysqld.sock\nssl                               FALSE\nssl-ca                            (No default value)\nssl-capath                        (No default value)\nssl-cert                          (No default value)\nssl-cipher                        (No default value)\nssl-key                           (No default value)\nssl-verify-server-cert            FALSE\ntable                             FALSE\nuser                              (No default value)\nsafe-updates                      FALSE\ni-am-a-dummy                      FALSE\nconnect-timeout                   0\nmax-allowed-packet                16777216\nnet-buffer-length                 16384\nselect-limit                      1000\nmax-join-size                     1000000\nsecure-auth                       FALSE\nshow-warnings                     FALSE\nplugin-dir                        (No default value)\ndefault-auth                      (No default value)\n</pre>\n","slug":"mysql_cmd","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5nw00bjmcxqiealdoor"},{"title":"mysql校对规则","date":"2016-08-03T13:27:00.000Z","_content":"\nmysql校对规则用于字符的比较和排序\n\n<!--more-->\n\n查看字符集相关变量\n```\nSHOW VARIABLES LIKE 'character%';\n```\n\n查看校对相关变量\n```\nSHOW VARIABLES LIKE 'collation_%';\n```\n\n查看可用的校对选项\n```\nshow collation like 'utf8%';\n```\n\n两个字符串比较，要求两者必须有相同的校对规则，\n或者两者的校对规则是相容的—— 所谓相容是指，两种校对规则优先级不同，\n比较的时候两者使用高优先级的校对规则进行比较，比如latin1_bin的优先级相对较高。\n如校对规则同级，则不能进行比较；如果强行比较的话，就会报错.\n\n可以在sql语句中强制指定校对规则进行比较, \n```\nselect * from tbl where col_b COLLATE latin1_danish_ci = col_c COLLATE latin1_danish_ci;\n```\n\n","source":"_posts/mysql_collation.md","raw":"title: mysql校对规则\ndate: 2016-08-03 21:27:00\ntags: [mysql, db]\n---\n\nmysql校对规则用于字符的比较和排序\n\n<!--more-->\n\n查看字符集相关变量\n```\nSHOW VARIABLES LIKE 'character%';\n```\n\n查看校对相关变量\n```\nSHOW VARIABLES LIKE 'collation_%';\n```\n\n查看可用的校对选项\n```\nshow collation like 'utf8%';\n```\n\n两个字符串比较，要求两者必须有相同的校对规则，\n或者两者的校对规则是相容的—— 所谓相容是指，两种校对规则优先级不同，\n比较的时候两者使用高优先级的校对规则进行比较，比如latin1_bin的优先级相对较高。\n如校对规则同级，则不能进行比较；如果强行比较的话，就会报错.\n\n可以在sql语句中强制指定校对规则进行比较, \n```\nselect * from tbl where col_b COLLATE latin1_danish_ci = col_c COLLATE latin1_danish_ci;\n```\n\n","slug":"mysql_collation","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5nx00blmcxqn5rt5h36"},{"title":"mysql DML","date":"2015-12-03T16:00:00.000Z","_content":"\ninsert update delete\n<!--more-->\n\n## insert\ninsert into customers values(..., ...);\n这种形式values里必须提供所有的列值,不推荐,当表结构变化时语句失效\ninsert into customers(xxx, yyy, ...) values(..., ...);\n这种形式指定插入哪些值,当表结构变化时语句仍然有效\ninsert into customers(xxx, yyy, ...) values(..., ...), (..., ...), ...;\n可以一次插入多行\n\ninsert low_priority into 表示低优先级(可能想让SELECT先执行)\nlow_priority关键字也适用于update和delete\n\ninsert select功能, 可以将select得到的结果插入表中\ninsert into customers(xxx, yyy, ...) select xxx, yyy, ... from tablename;\n\n## update\nupdate customers set cust_email = 'elmer@fudd.com' where cust_id = 10005;\n注意update和delete语句一定要写where子句, 应用程序里最好把where子句为空的情况直接报错处理\n如果确实要对所有行更新,可以明确使用where 1,避免出现where子句忘写的bug情况\n\nupdate ignore customers set ...\n表示更新过程中即使出现错误也继续更新,不回滚\n\n## delete\ndelete from customers where cust_id = 10006;\ntruncate table(直接删表重建)比delete(逐行删除)效率高\n\n## create\ncreate if not exists 表示仅在不存在时创建表\n是否使用NULL值: 默认允许NULL, NOT NULL表示不允许NULL\n\nauto_increment必须被索引,且只能定义一列\n可以覆盖auto_increment列的值,后续增量将在该基础上继续\n\nselect last_insert_id()\n返回最后一个auto_increment的值\n\ndefault关键字\n表示插入行时没有值的列使用的默认值, 很多时候倾向使用default而不是null\n\n## alter\n增删字段\nalter table vendors add vend_phone char(20);\nalter table vendors drop column vend_phone;\n\n外键约束\nalter table orderitems\nadd constraint fk_orderitems_orders\nforeign key (order_num) references orders (order_num);\n\n修改自增列的起点值\nALTER TABLE penguins AUTO_INCREMENT=1001;\n\n查看指定表的create语句\nshow create table tablename\n\n## drop\ndrop table customers;\n\n## rename\nrename table xxx to yyy;\n\n","source":"_posts/mysql_dml.md","raw":"title: mysql DML\ndate: 2015-12-04\ntags: [db]\n---\n\ninsert update delete\n<!--more-->\n\n## insert\ninsert into customers values(..., ...);\n这种形式values里必须提供所有的列值,不推荐,当表结构变化时语句失效\ninsert into customers(xxx, yyy, ...) values(..., ...);\n这种形式指定插入哪些值,当表结构变化时语句仍然有效\ninsert into customers(xxx, yyy, ...) values(..., ...), (..., ...), ...;\n可以一次插入多行\n\ninsert low_priority into 表示低优先级(可能想让SELECT先执行)\nlow_priority关键字也适用于update和delete\n\ninsert select功能, 可以将select得到的结果插入表中\ninsert into customers(xxx, yyy, ...) select xxx, yyy, ... from tablename;\n\n## update\nupdate customers set cust_email = 'elmer@fudd.com' where cust_id = 10005;\n注意update和delete语句一定要写where子句, 应用程序里最好把where子句为空的情况直接报错处理\n如果确实要对所有行更新,可以明确使用where 1,避免出现where子句忘写的bug情况\n\nupdate ignore customers set ...\n表示更新过程中即使出现错误也继续更新,不回滚\n\n## delete\ndelete from customers where cust_id = 10006;\ntruncate table(直接删表重建)比delete(逐行删除)效率高\n\n## create\ncreate if not exists 表示仅在不存在时创建表\n是否使用NULL值: 默认允许NULL, NOT NULL表示不允许NULL\n\nauto_increment必须被索引,且只能定义一列\n可以覆盖auto_increment列的值,后续增量将在该基础上继续\n\nselect last_insert_id()\n返回最后一个auto_increment的值\n\ndefault关键字\n表示插入行时没有值的列使用的默认值, 很多时候倾向使用default而不是null\n\n## alter\n增删字段\nalter table vendors add vend_phone char(20);\nalter table vendors drop column vend_phone;\n\n外键约束\nalter table orderitems\nadd constraint fk_orderitems_orders\nforeign key (order_num) references orders (order_num);\n\n修改自增列的起点值\nALTER TABLE penguins AUTO_INCREMENT=1001;\n\n查看指定表的create语句\nshow create table tablename\n\n## drop\ndrop table customers;\n\n## rename\nrename table xxx to yyy;\n\n","slug":"mysql_dml","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ny00bomcxq41sdo4af"},{"title":"mysql DDL","date":"2015-12-03T16:00:00.000Z","_content":"\n设计和创建表\n\n<!--more-->\n## 引擎\nmemory引擎功能上等同于MyISAM但是数据存储在内存中所以速度快\nInnoDB支持事务, MyISAM不支持\n\n## 数据类型\n不用于运算的值一般不应存储在数值字段,如邮编可能以0开头,存储在数值字段会导致前导0消失\n\n## 本地化\n#### 字符集\n显示可用的字符集\nshow character set;\n\n查看当前数据库使用的变量中包含character的配置\nshow variables like 'character%';\n\n#### 校对\n用于排序, 也译为排序规则\n显示可用的校对\nshow collation;\n\n_cs表示区分大小写(case sensitive),\n_ci表示不区分大小写(case insensitive)\n\n查看当前数据库使用的变量中包含collation的配置\nshow variables like 'collation%';\n\n建表时指定表级的字符集和校对\n```\ncreate ...\n(\n  ...\n) DEFAULT CHARACTER SET utf8\n  COLLATE utf8_general_ci\n```\n\n在select时也可以指定校对\nselect * from customers order by lastname, firstname collate latin1_general_cs;\n\n#### 遇到过的乱码问题\n有一次写到DB里的中文都变成问号了\n执行 show variables 发现 character_set_database 是 latin1\n查了很久, 最后执行下面的语句\n```\nALTER DATABASE databasename CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;\n```\n而且还重启了 mysql 才好..\n\n可见当初 create database 的时候真的要小心,\n要这样:\n```\nCREATE DATABASE new_db CHARACTER SET utf8mb4 DEFAULT COLLATE utf8mb4_general_ci;\n```\n\nhttps://stackoverflow.com/questions/22572558/how-to-set-character-set-database-and-collation-database-to-utf8-in-my-ini/45728067\n\n\n","source":"_posts/mysql_ddl.md","raw":"title: mysql DDL\ndate: 2015-12-04\ntags: [db]\n---\n\n设计和创建表\n\n<!--more-->\n## 引擎\nmemory引擎功能上等同于MyISAM但是数据存储在内存中所以速度快\nInnoDB支持事务, MyISAM不支持\n\n## 数据类型\n不用于运算的值一般不应存储在数值字段,如邮编可能以0开头,存储在数值字段会导致前导0消失\n\n## 本地化\n#### 字符集\n显示可用的字符集\nshow character set;\n\n查看当前数据库使用的变量中包含character的配置\nshow variables like 'character%';\n\n#### 校对\n用于排序, 也译为排序规则\n显示可用的校对\nshow collation;\n\n_cs表示区分大小写(case sensitive),\n_ci表示不区分大小写(case insensitive)\n\n查看当前数据库使用的变量中包含collation的配置\nshow variables like 'collation%';\n\n建表时指定表级的字符集和校对\n```\ncreate ...\n(\n  ...\n) DEFAULT CHARACTER SET utf8\n  COLLATE utf8_general_ci\n```\n\n在select时也可以指定校对\nselect * from customers order by lastname, firstname collate latin1_general_cs;\n\n#### 遇到过的乱码问题\n有一次写到DB里的中文都变成问号了\n执行 show variables 发现 character_set_database 是 latin1\n查了很久, 最后执行下面的语句\n```\nALTER DATABASE databasename CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;\n```\n而且还重启了 mysql 才好..\n\n可见当初 create database 的时候真的要小心,\n要这样:\n```\nCREATE DATABASE new_db CHARACTER SET utf8mb4 DEFAULT COLLATE utf8mb4_general_ci;\n```\n\nhttps://stackoverflow.com/questions/22572558/how-to-set-character-set-database-and-collation-database-to-utf8-in-my-ini/45728067\n\n\n","slug":"mysql_ddl","published":1,"updated":"2020-12-27T12:31:31.732Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5o000bqmcxqorc4mox7"},{"title":"mysql 安装","date":"2018-09-11T16:00:00.000Z","_content":"\nmysql 安装\n\n<!--more-->\n\n## 步骤\n```\n# 下载rpm文件\nwget https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm\n# 安装\nsudo yum localinstall mysql57-community-release-el7-11.noarch.rpm\nsudo yum repolist enabled | grep mysql\nsudo yum install mysql-community-{server,client,common,libs}-*\n# 查询安装了哪些mysql相关的包\nrpm -qa | grep mysql\nsudo yum list installed | grep mysql\n# 启动\nsudo systemctl start mysqld\n# 设为开机启动\nsudo systemctl enable mysqld\n# 找到root初始密码\nsudo grep 'temporary password' /var/log/mysqld.log\n# 使用root连接上之后修改密码\nmysql -uroot -p\nmysql> set password for 'root'@'localhost'=password('MyNewPass4!');\n```\n\n## 默认配置文件路径\n配置文件：/etc/my.cnf\n日志文件：/var/log/mysqld.log\n服务启动脚本：/usr/lib/systemd/system/mysqld.service\nsocket文件：/var/run/mysqld/mysqld.pid\n\n## 参考链接:\n```\nhttps://dev.mysql.com/downloads/mysql/\nhttps://dev.mysql.com/doc/refman/5.7/en/linux-installation-rpm.html\nhttps://www.jianshu.com/p/1dab9a4d0d5f\nhttps://www.cnblogs.com/ivictor/p/5142809.html\n```\n\n","source":"_posts/mysql_install.md","raw":"title: mysql 安装\ndate: 2018-09-12\ntags: [db, mysql, install]\n---\n\nmysql 安装\n\n<!--more-->\n\n## 步骤\n```\n# 下载rpm文件\nwget https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm\n# 安装\nsudo yum localinstall mysql57-community-release-el7-11.noarch.rpm\nsudo yum repolist enabled | grep mysql\nsudo yum install mysql-community-{server,client,common,libs}-*\n# 查询安装了哪些mysql相关的包\nrpm -qa | grep mysql\nsudo yum list installed | grep mysql\n# 启动\nsudo systemctl start mysqld\n# 设为开机启动\nsudo systemctl enable mysqld\n# 找到root初始密码\nsudo grep 'temporary password' /var/log/mysqld.log\n# 使用root连接上之后修改密码\nmysql -uroot -p\nmysql> set password for 'root'@'localhost'=password('MyNewPass4!');\n```\n\n## 默认配置文件路径\n配置文件：/etc/my.cnf\n日志文件：/var/log/mysqld.log\n服务启动脚本：/usr/lib/systemd/system/mysqld.service\nsocket文件：/var/run/mysqld/mysqld.pid\n\n## 参考链接:\n```\nhttps://dev.mysql.com/downloads/mysql/\nhttps://dev.mysql.com/doc/refman/5.7/en/linux-installation-rpm.html\nhttps://www.jianshu.com/p/1dab9a4d0d5f\nhttps://www.cnblogs.com/ivictor/p/5142809.html\n```\n\n","slug":"mysql_install","published":1,"updated":"2018-09-12T06:29:47.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5o100btmcxq31n10y6n"},{"title":"mysql维护","date":"2015-12-03T16:00:00.000Z","_content":"\n导入导出, 权限管理, 检查表状态, 修复表数据, 日志\n<!--more-->\n## 导入导出\nmysql -u root -p game < mysql.sql\nmysqldump -u username -p dbname > backupfile.sql\nmysqldump -u username -p dbname tablename > backup.sql\nmysqldump -u username -p dbname tablename --where='id<1000000' > backup.sql || 这样可以部分导出\n\nmysqlhotcopy\nflush tables; 确保所有数据被写到磁盘,包括索引数据\nbackup table\nselect into outfile\nrestore table\n\n## 权限管理\n创建用户\ncreate user ben identified by 'yourpasswd';\n或直接insert到user表(不推荐) \ninsert into mysql.user(Host,User,Password) values('localhost','user',password('yourpasswd'));\n变更用户名\nrename user ben to bforta;\n删除用户\ndrop user bforta;\n查询用户权限\nshow grants for bforta;\n\n用户定义为user@host, 如果不定义主机名, 则使用默认的主机名%, 授予用户访问权限而不管主机名\n\n授予和取消用户bforta对crashcourse库的所有表的select权限\ngrant select, insert on crashcourse.* to bforta;\nrevoke select, insert on crashcourse.* from bforta;\n\n更新自己的口令\nset password = password('n3w p@\\$\\$wOrd');\n更新bforta用户的口令\nset password for bforta = password('n3w p@\\$\\$wOrd');\n\n### 将指定库的所有权限授予指定用户\ngrant all privileges on databasename.* to user@localhost identified by 'yourpasswd';\n\nflush privileges; \n该命令本质上的作用是将当前user和privilige表中的用户信息/权限设置从mysql库(MySQL数据库的内置库)中提取到内存里。\nMySQL用户数据和权限有修改后，希望在\"不重启MySQL服务\"的情况下直接生效，那么就需要执行这个命令。\n\n## 维护\nanalyze table xxx; 用来检查表键是否正确\ncheck table xxx; 可以检查表的各方面, help check table查看帮助\nrepair table xxx; MyISAM引擎可能用到\noptimize table xxx; \n\nmysqld --help --verbose | less 查看配置,选项,变量的相关帮助\nmysqladmin -uroot -p variables 查看指定mysql实例当前使用的变量\n\n## 日志\nmysqladmin -uroot -p variables | grep log\n查日志的路径\nlog 查询日志\nlog_error 错误日志\nlog_bin 二进制日志\nlog_slow_querys 缓慢查询日志, 有助于找到需要优化的点\n一般是: /var/log/mysql\n\nflush logs;语句用于刷新和重新开始所有日志文件\n\n","source":"_posts/mysql_maintain.md","raw":"title: mysql维护\ndate: 2015-12-04\ntags: [db]\n---\n\n导入导出, 权限管理, 检查表状态, 修复表数据, 日志\n<!--more-->\n## 导入导出\nmysql -u root -p game < mysql.sql\nmysqldump -u username -p dbname > backupfile.sql\nmysqldump -u username -p dbname tablename > backup.sql\nmysqldump -u username -p dbname tablename --where='id<1000000' > backup.sql || 这样可以部分导出\n\nmysqlhotcopy\nflush tables; 确保所有数据被写到磁盘,包括索引数据\nbackup table\nselect into outfile\nrestore table\n\n## 权限管理\n创建用户\ncreate user ben identified by 'yourpasswd';\n或直接insert到user表(不推荐) \ninsert into mysql.user(Host,User,Password) values('localhost','user',password('yourpasswd'));\n变更用户名\nrename user ben to bforta;\n删除用户\ndrop user bforta;\n查询用户权限\nshow grants for bforta;\n\n用户定义为user@host, 如果不定义主机名, 则使用默认的主机名%, 授予用户访问权限而不管主机名\n\n授予和取消用户bforta对crashcourse库的所有表的select权限\ngrant select, insert on crashcourse.* to bforta;\nrevoke select, insert on crashcourse.* from bforta;\n\n更新自己的口令\nset password = password('n3w p@\\$\\$wOrd');\n更新bforta用户的口令\nset password for bforta = password('n3w p@\\$\\$wOrd');\n\n### 将指定库的所有权限授予指定用户\ngrant all privileges on databasename.* to user@localhost identified by 'yourpasswd';\n\nflush privileges; \n该命令本质上的作用是将当前user和privilige表中的用户信息/权限设置从mysql库(MySQL数据库的内置库)中提取到内存里。\nMySQL用户数据和权限有修改后，希望在\"不重启MySQL服务\"的情况下直接生效，那么就需要执行这个命令。\n\n## 维护\nanalyze table xxx; 用来检查表键是否正确\ncheck table xxx; 可以检查表的各方面, help check table查看帮助\nrepair table xxx; MyISAM引擎可能用到\noptimize table xxx; \n\nmysqld --help --verbose | less 查看配置,选项,变量的相关帮助\nmysqladmin -uroot -p variables 查看指定mysql实例当前使用的变量\n\n## 日志\nmysqladmin -uroot -p variables | grep log\n查日志的路径\nlog 查询日志\nlog_error 错误日志\nlog_bin 二进制日志\nlog_slow_querys 缓慢查询日志, 有助于找到需要优化的点\n一般是: /var/log/mysql\n\nflush logs;语句用于刷新和重新开始所有日志文件\n\n","slug":"mysql_maintain","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5o200bvmcxqgf7afmql"},{"title":"mysql性能优化","date":"2015-12-04T16:00:00.000Z","_content":"\n记录一点优化的经验\n<!--more-->\n\n## transaction优化多条语句的性能\n```\n> tc_avg(fun() -> \n    [db_util:update(<<\"people\">>, [\"silver\"], [random:uniform(1000000)], [<<\"id\">>], I) || I <- L]\nend, 30).\nRange: 86791 - 112256 microseconds\nMedian: 99040 microseconds\nAverage: 98503.03 microseconds\n98503.03\n> tc_avg(fun() -> \n    F = fun() -> [db_util:update(<<\"people\">>, [\"silver\"], [random:uniform(1000000)], [<<\"id\">>], I) || I <- L] end, \n    db_util:transaction(F) \nend, 30).\nRange: 5999 - 9691 microseconds\nMedian: 6388 microseconds\nAverage: 6840.17 microseconds\n6840.17\n```\n可见此例的性能差距接近15倍(平均98.5毫秒对6.8毫秒)\n\n## 将多条语句合成一条语句\n### 使用insert on duplicate key update取代多条update语句\n```\ninsert into t_member (id, name, email) values\n    (1, 'nick', 'nick@126.com'),\n    (4, 'angel','angel@163.com'),\n    (7, 'brank','ba198@126.com')\non duplicate key update name=values(name), email=values(email);\n```\n\n### 使用replace into取代多条update语句\n```\nreplace into test_tbl (id,dr) \nvalues (1,'2'),(2,'3'),...(x,'y');\n```\nreplace into和insert into on duplicate key update的不同在于：\nreplace into操作本质是对重复的记录(不一定主键,唯一索引重复也算)先delete后insert，\n如果更新的字段不全会将缺失的字段置为缺省值\n\n### 使用case取代多条update语句\n```\nupdate categories\n    set display_order = case id\n        when 1 then 3\n        when 2 then 4\n        when 3 then 5\n    end,\n    title = case id\n        when 1 then 'new title 1'\n        when 2 then 'new title 2'\n        when 3 then 'new title 3'\n    end\nwhere id in (1,2,3)\n```\n\n### 使用临时表取代多条update语句\n```\ncreate temporary table tmp(id int primary key, sum int);\ninsert into tmp (select player_id, count(*) from `pet` group by player_id);\nupdate counter, tmp set counter.data=tmp.sum \n    where counter.player_id=tmp.id and counter.domain = 0 and counter.id = 3;\n```\n\n## show processlist; \n显示所有活动进程(每条都是一个连接)以及它们的线程id和执行时间\n\n## explain语句\n查询执行计划\n\n## 其他\n* 导入数据时应关闭自动提交, 可能先删除fulltext等索引(导入完成后再建索引)\n* 当select语句中有复杂的or条件时,分拆select并使用union可能会提升性能\n* 索引有利于读,不利于写,看哪种操作比较频繁,根据需要优化\n* like很慢\n\n## 参考链接\nhttp://www.crackedzone.com/mysql-muti-sql-not-sugguest-update.html\nhttp://dev.mysql.com/doc/refman/5.0/en/insert.html\nhttp://www.educity.cn/shujuku/692086.html\n\n","source":"_posts/mysql_opti.md","raw":"title: mysql性能优化\ndate: 2015-12-05\ntags: [db]\n---\n\n记录一点优化的经验\n<!--more-->\n\n## transaction优化多条语句的性能\n```\n> tc_avg(fun() -> \n    [db_util:update(<<\"people\">>, [\"silver\"], [random:uniform(1000000)], [<<\"id\">>], I) || I <- L]\nend, 30).\nRange: 86791 - 112256 microseconds\nMedian: 99040 microseconds\nAverage: 98503.03 microseconds\n98503.03\n> tc_avg(fun() -> \n    F = fun() -> [db_util:update(<<\"people\">>, [\"silver\"], [random:uniform(1000000)], [<<\"id\">>], I) || I <- L] end, \n    db_util:transaction(F) \nend, 30).\nRange: 5999 - 9691 microseconds\nMedian: 6388 microseconds\nAverage: 6840.17 microseconds\n6840.17\n```\n可见此例的性能差距接近15倍(平均98.5毫秒对6.8毫秒)\n\n## 将多条语句合成一条语句\n### 使用insert on duplicate key update取代多条update语句\n```\ninsert into t_member (id, name, email) values\n    (1, 'nick', 'nick@126.com'),\n    (4, 'angel','angel@163.com'),\n    (7, 'brank','ba198@126.com')\non duplicate key update name=values(name), email=values(email);\n```\n\n### 使用replace into取代多条update语句\n```\nreplace into test_tbl (id,dr) \nvalues (1,'2'),(2,'3'),...(x,'y');\n```\nreplace into和insert into on duplicate key update的不同在于：\nreplace into操作本质是对重复的记录(不一定主键,唯一索引重复也算)先delete后insert，\n如果更新的字段不全会将缺失的字段置为缺省值\n\n### 使用case取代多条update语句\n```\nupdate categories\n    set display_order = case id\n        when 1 then 3\n        when 2 then 4\n        when 3 then 5\n    end,\n    title = case id\n        when 1 then 'new title 1'\n        when 2 then 'new title 2'\n        when 3 then 'new title 3'\n    end\nwhere id in (1,2,3)\n```\n\n### 使用临时表取代多条update语句\n```\ncreate temporary table tmp(id int primary key, sum int);\ninsert into tmp (select player_id, count(*) from `pet` group by player_id);\nupdate counter, tmp set counter.data=tmp.sum \n    where counter.player_id=tmp.id and counter.domain = 0 and counter.id = 3;\n```\n\n## show processlist; \n显示所有活动进程(每条都是一个连接)以及它们的线程id和执行时间\n\n## explain语句\n查询执行计划\n\n## 其他\n* 导入数据时应关闭自动提交, 可能先删除fulltext等索引(导入完成后再建索引)\n* 当select语句中有复杂的or条件时,分拆select并使用union可能会提升性能\n* 索引有利于读,不利于写,看哪种操作比较频繁,根据需要优化\n* like很慢\n\n## 参考链接\nhttp://www.crackedzone.com/mysql-muti-sql-not-sugguest-update.html\nhttp://dev.mysql.com/doc/refman/5.0/en/insert.html\nhttp://www.educity.cn/shujuku/692086.html\n\n","slug":"mysql_opti","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5o200bymcxqbjjozsuo"},{"title":"mysql replication","date":"2015-12-29T16:00:00.000Z","_content":"\nMySQL replication通过将数据从主库自动copy到从库的方式, 提供了一个维护数据多份拷贝的方便途径\n\n<!--more-->\n\n## 主库/etc/mysql/my.cnf配置\n\nbind-address            = 192.168.1.114\n\nserver-id在replication组中必须**唯一**\nserver-id               = 1\n\nreplication的真实细节被记录在下面的log文件中, slave会从这里读取变化内容\nlog_bin                 = /var/log/mysql/mysql-bin.log\n\n下面这行可以写多行以同步多个库\nbinlog_do_db            = databasename\n\n重启数据库以使配置生效\nsudo service mysql restart\n\n### 进入mysql命令行\n\n授予slave replication权限\nmysql> GRANT REPLICATION SLAVE ON *.* TO 'slave_user'@'%' IDENTIFIED BY 'password';\nmysql> FLUSH PRIVILEGES;\n\n进入想要同步的库并**加锁**以保证数据暂时不发生变化\nmysql> USE databasename;\nmysql> FLUSH TABLES WITH READ LOCK;\n\n获取Position值, 我们将让从库从这个位置开始replicate\nmysql> SHOW MASTER STATUS;\n\n此时如果再做其他操作数据库会自动解锁, 所以我们开一个新的terminal继续下面的操作, 导出数据库内容\nmysqldump -u root -p databasename > databasename.sql\n\n回到之前的terminal, 解锁并退出mysql命令行\nUNLOCK TABLES;\nQUIT;\n\n## 将导出的数据库内容导入从库\n进入从库mysql命令行\nmysql> CREATE DATABASE databasename;\nmysql> QUIT;\n导入刚刚导出的主库数据库sql文件, \nmysql -u root -p databasename < /path/to/databasename.sql\n\n## 从库/etc/mysql/my.cnf配置\n\n记住server-id不能与replication组内其他mysql实例相同\nserver-id               = 2\n\n下面这行需要加入, 没在被注释掉的行里\nrelay-log               = /var/log/mysql/mysql-relay-bin.log\n\nlog_bin                 = /var/log/mysql/mysql-bin.log\nbinlog_do_db            = databasename\n\n重启数据库以使配置生效\nsudo service mysql restart\n\n## 再次进入从库mysql命令行\n指定当前mysql实例为我们主库的从库, \n指定从库所使用的主库用户, \n指定开始replicate的位置(即前面的Position值)\nmysql> CHANGE MASTER TO MASTER_HOST='192.168.1.114', MASTER_USER='slave_user', \n    -> MASTER_PASSWORD='password', MASTER_LOG_FILE='mysql-bin.000001', MASTER_LOG_POS=  332;\nmysql> START SLAVE;\nmysql> SHOW SLAVE STATUS\\G\n检查状态, 看是否有报错信息\n\n## 验收\n在主库insert, update, delete并在从库select检查结果\n\n## 参考链接\nhttps://www.digitalocean.com/community/tutorials/how-to-set-up-master-slave-replication-in-mysql\n","source":"_posts/mysql_replication.md","raw":"title: mysql replication\ndate: 2015-12-30\ntags: [mysql]\n---\n\nMySQL replication通过将数据从主库自动copy到从库的方式, 提供了一个维护数据多份拷贝的方便途径\n\n<!--more-->\n\n## 主库/etc/mysql/my.cnf配置\n\nbind-address            = 192.168.1.114\n\nserver-id在replication组中必须**唯一**\nserver-id               = 1\n\nreplication的真实细节被记录在下面的log文件中, slave会从这里读取变化内容\nlog_bin                 = /var/log/mysql/mysql-bin.log\n\n下面这行可以写多行以同步多个库\nbinlog_do_db            = databasename\n\n重启数据库以使配置生效\nsudo service mysql restart\n\n### 进入mysql命令行\n\n授予slave replication权限\nmysql> GRANT REPLICATION SLAVE ON *.* TO 'slave_user'@'%' IDENTIFIED BY 'password';\nmysql> FLUSH PRIVILEGES;\n\n进入想要同步的库并**加锁**以保证数据暂时不发生变化\nmysql> USE databasename;\nmysql> FLUSH TABLES WITH READ LOCK;\n\n获取Position值, 我们将让从库从这个位置开始replicate\nmysql> SHOW MASTER STATUS;\n\n此时如果再做其他操作数据库会自动解锁, 所以我们开一个新的terminal继续下面的操作, 导出数据库内容\nmysqldump -u root -p databasename > databasename.sql\n\n回到之前的terminal, 解锁并退出mysql命令行\nUNLOCK TABLES;\nQUIT;\n\n## 将导出的数据库内容导入从库\n进入从库mysql命令行\nmysql> CREATE DATABASE databasename;\nmysql> QUIT;\n导入刚刚导出的主库数据库sql文件, \nmysql -u root -p databasename < /path/to/databasename.sql\n\n## 从库/etc/mysql/my.cnf配置\n\n记住server-id不能与replication组内其他mysql实例相同\nserver-id               = 2\n\n下面这行需要加入, 没在被注释掉的行里\nrelay-log               = /var/log/mysql/mysql-relay-bin.log\n\nlog_bin                 = /var/log/mysql/mysql-bin.log\nbinlog_do_db            = databasename\n\n重启数据库以使配置生效\nsudo service mysql restart\n\n## 再次进入从库mysql命令行\n指定当前mysql实例为我们主库的从库, \n指定从库所使用的主库用户, \n指定开始replicate的位置(即前面的Position值)\nmysql> CHANGE MASTER TO MASTER_HOST='192.168.1.114', MASTER_USER='slave_user', \n    -> MASTER_PASSWORD='password', MASTER_LOG_FILE='mysql-bin.000001', MASTER_LOG_POS=  332;\nmysql> START SLAVE;\nmysql> SHOW SLAVE STATUS\\G\n检查状态, 看是否有报错信息\n\n## 验收\n在主库insert, update, delete并在从库select检查结果\n\n## 参考链接\nhttps://www.digitalocean.com/community/tutorials/how-to-set-up-master-slave-replication-in-mysql\n","slug":"mysql_replication","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5o300c0mcxq4400dann"},{"title":"mysql查询","date":"2015-12-03T16:00:00.000Z","_content":"\nselect语句用法\n<!--more-->\n\n## distinct\nselect distinct vend_id, vend_name from products;\ndistinct 关键字用于去除重复的值, 注意该关键字作用于所有列而不仅是一列\n\n## limit\nselect prod_name from products limit 5;\nselect prod_name from products limit 5, 5;\nlimit 限制行数, 可以指定从第几行(第一行是行0)开始要几行, limit 1, 1表示只要第二行\n\n使用完全限定名\nselect crashcourse.product.prod_name from crashcourse.products;\n\n## between\n闭区间范围限定\nselect prod_name, prod_price from products where prod_price between 5 and 10;\n\n## 空值判定\nselect prod_name from products where prod_price IS NULL;\n\n## in \n指定条件范围\nselect prod_name, prod_price from products where vend_id in (1002, 1003);\nin的最大优点是可以包含其他SELECT语句,使得能够更动态地建立WHERE子句\n\n## not\nselect prod_name, prod_price from products where vend_id not in (1002, 1003);\n支持not in, not between, not exists\n\n## 通配符\n% 匹配任意字符出现任意次数(包括0次)\nselect prod\\_name, prod\\_price from products where prod\\_name LIKE '%anvil1%';\n\n\\_(下划线) 匹配任意单个字符\nselect prod\\_name, prod\\_price from products where prod\\_name LIKE '_ ton anvil';\n\n注意: \n通配符不能匹配NULL\n不要过度使用通配符,性能不是很好,确实需要使用时,尽量不要用在搜索模式的开始处(最慢)\n\n## regexp 正则表达式\n可以用如下方式测试正则表达式\nselect 'hello' regexp '[0-9]';\nselect 'D34' regexp '[^abc][3-7][[:alnum:]]';\n\n使用binary可以区分大小写\nselect 'C34' regexp binary '[abc][3-7][[:alnum:]]';\n\n[[:<:]]匹配词的开始\nselect 'hello world' regexp '[[:<:]]w';\n\n[[:>:]]匹配词的结尾\nselect 'hello world' regexp 'd[[:>:]]';\n\n转义字符\\\\\\\\, 是两个反斜杠, 要匹配反斜杠本身, 用\\\\\\\\\\\\,\n为什么要用两个反斜杠呢,MySQL自己解释一个,正则表达式库解释另一个\n\n## group by 分组\nHAVING: 过滤分组\nselect cust_id, count(\\*) as orders from orders where prod_price >= 10 \ngroup by cust_id having orders >= 2;\nHAVING与WHERE的区别, WHERE在分组前过滤, HAVING在分组后过滤\n\nWITH ROLLUP: 可以得到分组汇总信息\nselect vend_id, count(\\*) as num_prods from products group by vend_id with rollup;\n\n## select子句顺序\nselect\nfrom\nwhere\ngroup by \nhaving\norder by\nlimit\n\n## 子查询\n例1:用于where in\n```\nselect cust_id from orders where order_num in\n    (select order_num from orderitems where prod_id = 'TNT2');\n```\n例2:\n```\nselect \n  cust_name, \n  cust_state, \n  (select count(*) from orders where orders.cust_id = customers.cust_id) as orders \nfrom customers\norder by cust_name;\n```\n\n子查询的处理顺序是从内向外\n\n## 连接\nselect vend_name, prod_name, prod_price \nfrom vendors, products\nwhere vendors.vend_id = products.vend_id\n连接可以是多个表\n\ncross join 交叉连接\n没有连接条件的表关系返回的结果为笛卡尔积, 返回的行数目是两个表行数的乘积\n\nequijoin 内部连接, 即等值连接\n```\nselect vend_name, prod_name, prod_price \nfrom vendors inner join products\n  on vendors.vend_id = products.vend_id\n```\n\n### 自连接\nselect p1.id, p1.name from player as p1, player as p2 where p1.lvl = p2.lvl and p2.id = 301;\n\n### 自然连接\n指的是不出现重复列名的连接\n```\nselect c.*, o.order_num, oi.prod_id\nfrom customers as c, orders as o, orderitems as oi\nwhere c.cust_id = o.cust_id\n  and oi.order_num = o.order_num\n  and prod_id = 'FB';\n```\n这个效果由我们自己完成,即只对一个表使用\\*通配符,\n其他表的字段都显示写出,这样来保证不出现重复列表\n\n### 外连接\n包含相关表中没有关联行的行\n```\nselect customers.cust_id, orders.order_num\nfrom customers left outer join orders\n  on customers.cust_id = orders.cust_id\n```\n返回的结果可能会有10002 -> NULL这样的行, 这就是左外连接的目的,以左边的表为主,保留这样的行,\n右外连接类似,即以右边的表为主\n\n## 组合查询\nunion, 会自动去除重复行, 这种多数情况下与在where里加上or条件的效果相同\nunion all, 不会自动去除重复行, 这种行为无法使用where子句代替\norder by子句必须出现在最后一个select之后\nunion可以将不同表的select结果拼接在一起,只要列的数量相同且数据类型可相互转换即可\n\n## 全文本搜索\n```\ncreate table productnotes\n(\n  note_id int not null auto_increment,\n  note_text text null,\n  primary key(note_id),\n  fulltext(note_text)\n) engine=myisam;\n```\nmysql创建指定列中各词的一个索引\n导入数据时使用fulltext不如在导入完成后再添加索引,\n因为一边导入一边更新索引耗费的时间长,而导入完成后一次性创建索引比较快\n\nselect note_text from productnotes where match(note_text) against('rabbit');\nselect note_text, match(note_text) against('rabbit') as rank from productnotes;\n全文检索会按匹配等级排序, rank为0的行就会被排除在外\n\nselect note_text from productnotes where match(note_text) against('rabbit' with query expansion);\n查询扩展,会找出即使不包含rabbit,但是包含一些相关词的行\n\n布尔检索\n比较复杂,这里不介绍了\n\nMyISAM引擎支持全文本搜索,\nInnoDB引擎5.6版本才支持(不支持中文,据说也有支持的开源项目)\n可以考虑使用外部索引程序, 例如solr\n\n## 聚集函数\n* count\n使用count(\\*)计算所有行,包括NULL的行\n使用count(column)忽略NULL\nselect count(1) from player; 比 select count(\\*) from player; 效率高一点, 省了\\*的转换,也省得取多列的数据\n* sum: select sum(item_price * quantity) from orderitems;\n* min\n* max\n* avg: select avg(distinct prod_price) as avg_price from products; 加distinct可以忽略重复的项\n* group_concat \n\n## 字符串函数\n* concat: select concat('abc', 'def');\n* trim, ltrim, rtrim: select trim('  abc   ');\n* upper\n* lower\n* left\n* right\n* length\n* locate\n* substring\n* soundex\nsoundex将字符串转换为描述其语音的字母数字模式\nselect cust_name, cust_contact from customers where soundex(cust_contact) = soundex('Y Lie');\n可以找到发音与'Y Lie'的行, 如 'Y Lee'\n\n## 日期时间函数\n* adddate\n* addtime\n* curdate\n* curtime\n* date\n* time\n* datediff\n* date_add\n* date_format\n* year\n* month\n* day\n* dayofweek\n* hour\n* minute\n* second\n* now\nSQL语句中使用的日期格式是yyyy-mm-dd, 如\nselect cust_id from orders where date(order_date) = '2005-09-01'\n\n### 两位数年份\n00-69表示2000-2069, 70-99表示1970-1999\n但是尽量不要使用两位数年份这样有隐性规定的东西\n\n### from_unixtime()与unix_timestamp()\n```\nmysql> select from_unixtime(1195488000, '%Y%m%d')    \n20071120  \nmysql> select from_unixtime(1195488000, '%Y年%m月%d')   \n2007年11月20  \n```\nunix_timestamp是与之相对正好相反的时间函数  \n```\nmysql> select unix_timestamp('2007-11-20');\n1195488000  \n```\n\n## 数值处理函数\n* rand\n* abs\n* mod\n* pi\n* exp\n* sqrt\n* sin\n* cos\n* tan\n\n","source":"_posts/mysql_select.md","raw":"title: mysql查询\ndate: 2015-12-04\ntags: [db]\n---\n\nselect语句用法\n<!--more-->\n\n## distinct\nselect distinct vend_id, vend_name from products;\ndistinct 关键字用于去除重复的值, 注意该关键字作用于所有列而不仅是一列\n\n## limit\nselect prod_name from products limit 5;\nselect prod_name from products limit 5, 5;\nlimit 限制行数, 可以指定从第几行(第一行是行0)开始要几行, limit 1, 1表示只要第二行\n\n使用完全限定名\nselect crashcourse.product.prod_name from crashcourse.products;\n\n## between\n闭区间范围限定\nselect prod_name, prod_price from products where prod_price between 5 and 10;\n\n## 空值判定\nselect prod_name from products where prod_price IS NULL;\n\n## in \n指定条件范围\nselect prod_name, prod_price from products where vend_id in (1002, 1003);\nin的最大优点是可以包含其他SELECT语句,使得能够更动态地建立WHERE子句\n\n## not\nselect prod_name, prod_price from products where vend_id not in (1002, 1003);\n支持not in, not between, not exists\n\n## 通配符\n% 匹配任意字符出现任意次数(包括0次)\nselect prod\\_name, prod\\_price from products where prod\\_name LIKE '%anvil1%';\n\n\\_(下划线) 匹配任意单个字符\nselect prod\\_name, prod\\_price from products where prod\\_name LIKE '_ ton anvil';\n\n注意: \n通配符不能匹配NULL\n不要过度使用通配符,性能不是很好,确实需要使用时,尽量不要用在搜索模式的开始处(最慢)\n\n## regexp 正则表达式\n可以用如下方式测试正则表达式\nselect 'hello' regexp '[0-9]';\nselect 'D34' regexp '[^abc][3-7][[:alnum:]]';\n\n使用binary可以区分大小写\nselect 'C34' regexp binary '[abc][3-7][[:alnum:]]';\n\n[[:<:]]匹配词的开始\nselect 'hello world' regexp '[[:<:]]w';\n\n[[:>:]]匹配词的结尾\nselect 'hello world' regexp 'd[[:>:]]';\n\n转义字符\\\\\\\\, 是两个反斜杠, 要匹配反斜杠本身, 用\\\\\\\\\\\\,\n为什么要用两个反斜杠呢,MySQL自己解释一个,正则表达式库解释另一个\n\n## group by 分组\nHAVING: 过滤分组\nselect cust_id, count(\\*) as orders from orders where prod_price >= 10 \ngroup by cust_id having orders >= 2;\nHAVING与WHERE的区别, WHERE在分组前过滤, HAVING在分组后过滤\n\nWITH ROLLUP: 可以得到分组汇总信息\nselect vend_id, count(\\*) as num_prods from products group by vend_id with rollup;\n\n## select子句顺序\nselect\nfrom\nwhere\ngroup by \nhaving\norder by\nlimit\n\n## 子查询\n例1:用于where in\n```\nselect cust_id from orders where order_num in\n    (select order_num from orderitems where prod_id = 'TNT2');\n```\n例2:\n```\nselect \n  cust_name, \n  cust_state, \n  (select count(*) from orders where orders.cust_id = customers.cust_id) as orders \nfrom customers\norder by cust_name;\n```\n\n子查询的处理顺序是从内向外\n\n## 连接\nselect vend_name, prod_name, prod_price \nfrom vendors, products\nwhere vendors.vend_id = products.vend_id\n连接可以是多个表\n\ncross join 交叉连接\n没有连接条件的表关系返回的结果为笛卡尔积, 返回的行数目是两个表行数的乘积\n\nequijoin 内部连接, 即等值连接\n```\nselect vend_name, prod_name, prod_price \nfrom vendors inner join products\n  on vendors.vend_id = products.vend_id\n```\n\n### 自连接\nselect p1.id, p1.name from player as p1, player as p2 where p1.lvl = p2.lvl and p2.id = 301;\n\n### 自然连接\n指的是不出现重复列名的连接\n```\nselect c.*, o.order_num, oi.prod_id\nfrom customers as c, orders as o, orderitems as oi\nwhere c.cust_id = o.cust_id\n  and oi.order_num = o.order_num\n  and prod_id = 'FB';\n```\n这个效果由我们自己完成,即只对一个表使用\\*通配符,\n其他表的字段都显示写出,这样来保证不出现重复列表\n\n### 外连接\n包含相关表中没有关联行的行\n```\nselect customers.cust_id, orders.order_num\nfrom customers left outer join orders\n  on customers.cust_id = orders.cust_id\n```\n返回的结果可能会有10002 -> NULL这样的行, 这就是左外连接的目的,以左边的表为主,保留这样的行,\n右外连接类似,即以右边的表为主\n\n## 组合查询\nunion, 会自动去除重复行, 这种多数情况下与在where里加上or条件的效果相同\nunion all, 不会自动去除重复行, 这种行为无法使用where子句代替\norder by子句必须出现在最后一个select之后\nunion可以将不同表的select结果拼接在一起,只要列的数量相同且数据类型可相互转换即可\n\n## 全文本搜索\n```\ncreate table productnotes\n(\n  note_id int not null auto_increment,\n  note_text text null,\n  primary key(note_id),\n  fulltext(note_text)\n) engine=myisam;\n```\nmysql创建指定列中各词的一个索引\n导入数据时使用fulltext不如在导入完成后再添加索引,\n因为一边导入一边更新索引耗费的时间长,而导入完成后一次性创建索引比较快\n\nselect note_text from productnotes where match(note_text) against('rabbit');\nselect note_text, match(note_text) against('rabbit') as rank from productnotes;\n全文检索会按匹配等级排序, rank为0的行就会被排除在外\n\nselect note_text from productnotes where match(note_text) against('rabbit' with query expansion);\n查询扩展,会找出即使不包含rabbit,但是包含一些相关词的行\n\n布尔检索\n比较复杂,这里不介绍了\n\nMyISAM引擎支持全文本搜索,\nInnoDB引擎5.6版本才支持(不支持中文,据说也有支持的开源项目)\n可以考虑使用外部索引程序, 例如solr\n\n## 聚集函数\n* count\n使用count(\\*)计算所有行,包括NULL的行\n使用count(column)忽略NULL\nselect count(1) from player; 比 select count(\\*) from player; 效率高一点, 省了\\*的转换,也省得取多列的数据\n* sum: select sum(item_price * quantity) from orderitems;\n* min\n* max\n* avg: select avg(distinct prod_price) as avg_price from products; 加distinct可以忽略重复的项\n* group_concat \n\n## 字符串函数\n* concat: select concat('abc', 'def');\n* trim, ltrim, rtrim: select trim('  abc   ');\n* upper\n* lower\n* left\n* right\n* length\n* locate\n* substring\n* soundex\nsoundex将字符串转换为描述其语音的字母数字模式\nselect cust_name, cust_contact from customers where soundex(cust_contact) = soundex('Y Lie');\n可以找到发音与'Y Lie'的行, 如 'Y Lee'\n\n## 日期时间函数\n* adddate\n* addtime\n* curdate\n* curtime\n* date\n* time\n* datediff\n* date_add\n* date_format\n* year\n* month\n* day\n* dayofweek\n* hour\n* minute\n* second\n* now\nSQL语句中使用的日期格式是yyyy-mm-dd, 如\nselect cust_id from orders where date(order_date) = '2005-09-01'\n\n### 两位数年份\n00-69表示2000-2069, 70-99表示1970-1999\n但是尽量不要使用两位数年份这样有隐性规定的东西\n\n### from_unixtime()与unix_timestamp()\n```\nmysql> select from_unixtime(1195488000, '%Y%m%d')    \n20071120  \nmysql> select from_unixtime(1195488000, '%Y年%m月%d')   \n2007年11月20  \n```\nunix_timestamp是与之相对正好相反的时间函数  \n```\nmysql> select unix_timestamp('2007-11-20');\n1195488000  \n```\n\n## 数值处理函数\n* rand\n* abs\n* mod\n* pi\n* exp\n* sqrt\n* sin\n* cos\n* tan\n\n","slug":"mysql_select","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5o400c2mcxqkxuxntdb"},{"title":"mysql STRICT_MODE","date":"2016-07-31T12:36:00.000Z","_content":"\n有时想让mysql多做一点检查, 有时想让mysql少做一点检查...\n<!--more-->\n\n## 问题起源\n以前的csv里int字段没有值,例如`INSERT INTO `test` VALUES ('1', '', '', '')`这样也能导入数据库,\n现在却不行了,即使字段设为允许NULL也不行,允许NULL且默认值为0也不行,而我们只是换了MySQL的版本\n\n## 真相大白\nMySQL的5.6版本以后将sql-mode的STRICT_TRANS_TABLES设为默认\n导致一切不合法值不再被隐式转换成最接近的值,而是直接报错\n\n#1366 - Incorrect integer value: '' for column 'gold' at row 1 \n\n## 如何检查是否是STRICT模式?\n查看下列SQL语句的返回中是否包含STRICT_TRANS_TABLES\n```\nSELECT @@GLOBAL.sql_mode;\n```\n\n## 如何改回以前那样?\n如果我执行`SELECT @@GLOBAL.sql_mode;`后返回如下结果,\n\nSTRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION\n那么执行如下命令可以将上面的Strict关掉,即只保留NO_ENGINE_SUBSTITUTION,\n\nSET @@global.sql_mode= 'NO_ENGINE_SUBSTITUTION';\n从my.cnf配置中去掉STRICT_TRANS_TABLES以免下次mysql启动时再变成strict mode\n\n# Recommended in standard MySQL setup\n[mysqld]\nsql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES\n\n## NO_ZERO_DATE\nAs of MySQL 5.7.4, NO_ZERO_DATE is deprecated. \nIn MySQL 5.7.4 through 5.7.7, NO_ZERO_DATE does nothing when named explicitly. \nInstead, its effect is included in the effects of strict SQL mode. \nIn MySQL 5.7.8 and later, NO_ZERO_DATE does have an effect when named explicitly and is not part of strict mode, as before MySQL 5.7.4. \nHowever, it should be used in conjunction with strict mode and is enabled by default. \nA warning occurs if NO_ZERO_DATE is enabled without also enabling strict mode or vice versa.\n\n使用NO_ZERO_DATE之后insert时会报如下错误:\n```\nERROR 1292 (22007): Incorrect datetime value: '0000-00-00 00:00:00' for column 'updated' at row 1\n```\n\n## TIMESTAMP类型字段的默认值\n0可以, \nCURRENT_TIMESTAMP可以\n'0000-00-00 00:00:00'不行, \n'1970-01-01 00:00:00'不行, \n'1970-01-01 00:00:01'不行, \n'1970-01-02 00:00:00'可以, \n原因可能与mysql版本及sql_mode有关,暂不深究\n\n## 参考链接\nhttp://dev.mysql.com/doc/refman/5.7/en/sql-mode.html#sql-mode-strict\nhttp://www.tocker.ca/2014/01/14/making-strict-sql_mode-the-default.html\nhttp://stackoverflow.com/questions/24347906/incorrect-integer-value-for-a-mysql-column-thats-integer-and-allow-null\nhttp://stackoverflow.com/questions/8874647/general-error-1366-incorrect-integer-value-with-doctrine-2-1-and-zend-form-upda/8882396#8882396\n\n","source":"_posts/mysql_strict_mode.md","raw":"title: mysql STRICT_MODE\ndate: 2016-07-31 20:36:00\ntags: [mysql, db]\n---\n\n有时想让mysql多做一点检查, 有时想让mysql少做一点检查...\n<!--more-->\n\n## 问题起源\n以前的csv里int字段没有值,例如`INSERT INTO `test` VALUES ('1', '', '', '')`这样也能导入数据库,\n现在却不行了,即使字段设为允许NULL也不行,允许NULL且默认值为0也不行,而我们只是换了MySQL的版本\n\n## 真相大白\nMySQL的5.6版本以后将sql-mode的STRICT_TRANS_TABLES设为默认\n导致一切不合法值不再被隐式转换成最接近的值,而是直接报错\n\n#1366 - Incorrect integer value: '' for column 'gold' at row 1 \n\n## 如何检查是否是STRICT模式?\n查看下列SQL语句的返回中是否包含STRICT_TRANS_TABLES\n```\nSELECT @@GLOBAL.sql_mode;\n```\n\n## 如何改回以前那样?\n如果我执行`SELECT @@GLOBAL.sql_mode;`后返回如下结果,\n\nSTRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION\n那么执行如下命令可以将上面的Strict关掉,即只保留NO_ENGINE_SUBSTITUTION,\n\nSET @@global.sql_mode= 'NO_ENGINE_SUBSTITUTION';\n从my.cnf配置中去掉STRICT_TRANS_TABLES以免下次mysql启动时再变成strict mode\n\n# Recommended in standard MySQL setup\n[mysqld]\nsql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES\n\n## NO_ZERO_DATE\nAs of MySQL 5.7.4, NO_ZERO_DATE is deprecated. \nIn MySQL 5.7.4 through 5.7.7, NO_ZERO_DATE does nothing when named explicitly. \nInstead, its effect is included in the effects of strict SQL mode. \nIn MySQL 5.7.8 and later, NO_ZERO_DATE does have an effect when named explicitly and is not part of strict mode, as before MySQL 5.7.4. \nHowever, it should be used in conjunction with strict mode and is enabled by default. \nA warning occurs if NO_ZERO_DATE is enabled without also enabling strict mode or vice versa.\n\n使用NO_ZERO_DATE之后insert时会报如下错误:\n```\nERROR 1292 (22007): Incorrect datetime value: '0000-00-00 00:00:00' for column 'updated' at row 1\n```\n\n## TIMESTAMP类型字段的默认值\n0可以, \nCURRENT_TIMESTAMP可以\n'0000-00-00 00:00:00'不行, \n'1970-01-01 00:00:00'不行, \n'1970-01-01 00:00:01'不行, \n'1970-01-02 00:00:00'可以, \n原因可能与mysql版本及sql_mode有关,暂不深究\n\n## 参考链接\nhttp://dev.mysql.com/doc/refman/5.7/en/sql-mode.html#sql-mode-strict\nhttp://www.tocker.ca/2014/01/14/making-strict-sql_mode-the-default.html\nhttp://stackoverflow.com/questions/24347906/incorrect-integer-value-for-a-mysql-column-thats-integer-and-allow-null\nhttp://stackoverflow.com/questions/8874647/general-error-1366-incorrect-integer-value-with-doctrine-2-1-and-zend-form-upda/8882396#8882396\n\n","slug":"mysql_strict_mode","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5o500c5mcxq2eqf5f65"},{"title":"mysql 事务","date":"2016-08-09T16:00:00.000Z","_content":"\nInnoDB提供四种事务隔离级别,从低到高分别为READ UNCOMMITTED, READ COMMITTED, REPEATABLE READ, 和 SERIALIZABLE, 默认是REPEATABLE READ\nInnoDB使用不同的锁策略来支持不同的事务隔离级别.\n\n所有行为都在事务内, 默认是autocommit模式, 每条SQL语句形成一个独立的transaction.\n\nCOMMIT意味着变更确定持久化, ROLLBACK意味着放弃尚未持久化的变更, 两个操作都会释放锁.\n\ntransaction里select和update两句话之间有可能执行其他transaction的update语句么? || 有可能\n在update之前, 这个select的行会被其他transaction读到吗? || 会, 连SERILIZABLE都靠不住\n\n<!--more-->\n\n## READ UNCOMMITED 与 READ COMMITED\n\nREAD UNCOMMITED可以读到未COMMIT的内容, 这叫脏读\nREAD COMMITED满足一个事务开始时，只能“看见”已经提交的事务做的修改。\n\nclient1上start transaction;后insert一条,\nclient2使用READ UNCOMMITED可以看到\n\n<pre>\nmysql> set session transaction isolation level READ UNCOMMITTED;\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> select * from tag_perm;\n+-----+--------+---------+---------------------+---------------------+\n| id  | tag_id | perm_id | create_ts           | update_ts           |\n+-----+--------+---------+---------------------+---------------------+\n|  70 |      1 |       3 | 2016-08-10 13:50:45 | 2016-08-10 13:50:45 |\n|  71 |      2 |       3 | 2016-08-10 13:50:45 | 2016-08-10 13:50:45 |\n|  72 |      3 |       3 | 2016-08-10 13:50:45 | 2016-08-10 13:50:45 |\n+-----+--------+---------+---------------------+---------------------+\n</pre>\n\n改为READ COMMITED后就看不到了\n\n<pre>\nmysql> set session transaction isolation level READ COMMITTED;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> select * from tag_perm;\n+-----+--------+---------+---------------------+---------------------+\n| id  | tag_id | perm_id | create_ts           | update_ts           |\n+-----+--------+---------+---------------------+---------------------+\n|  70 |      1 |       3 | 2016-08-10 13:50:45 | 2016-08-10 13:50:45 |\n|  71 |      2 |       3 | 2016-08-10 13:50:45 | 2016-08-10 13:50:45 |\n+-----+--------+---------+---------------------+---------------------+\n</pre>\n\nclient1上commit,\nclient2上READ COMMITED可以看到了\n\n\n## READ COMMITED 与 REPEATABLE READ\n\n\nclient2开始transaction, select数据\n<pre>\nmysql> set session transaction isolation level READ COMMITTED;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> start transaction;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> select * from tag_perm;\n+-----+--------+---------+---------------------+---------------------+\n| id  | tag_id | perm_id | create_ts           | update_ts           |\n+-----+--------+---------+---------------------+---------------------+\n|  70 |      1 |       3 | 2016-08-10 13:50:45 | 2016-08-10 13:50:45 |\n+-----+--------+---------+---------------------+---------------------+\n</pre>\n\nclient1上commit之后\n\n<pre>\nmysql> select * from tag_perm;\n+-----+--------+---------+---------------------+---------------------+\n| id  | tag_id | perm_id | create_ts           | update_ts           |\n+-----+--------+---------+---------------------+---------------------+\n|  70 |      1 |       3 | 2016-08-10 13:50:45 | 2016-08-10 13:50:45 |\n|  71 |      2 |       3 | 2016-08-10 13:50:45 | 2016-08-10 13:50:45 |\n+-----+--------+---------+---------------------+---------------------+\n</pre>\n\n而REPEATABLE READ的情况则是client1上commit之后select也看不到外部的变更, 即仍是一行\n仍然只能看到本事务的变更, 即事务最开始的select时生成了一个snapshot(快照或副本)\n之后一直在snapshot的基础上操作\n\nREAD COMMITTED还是有读的问题,虽然未提交的不会读出来,但是自己的事务进行过程中会读到其他事务已经commit的内容,\n这是一个问题,比如事务开始后第一个select读到一个数,程序用了之后,第二次select时数变了,可能引发bug\n\n## REPEATABLE READ 与 SERILIZABLE\n\nSERIALIZABLE这个级别接近于串行执行,普通的SELECT会被自动转化成SELECT ... LOCK IN SHARE MODE,即SELECT加共享锁,能读不能写\n\nIf you use FOR UPDATE, rows examined by the query are write-locked until the end of the current transaction.\nUsing LOCK IN SHARE MODE sets a shared lock that permits other transactions to read the examined rows but not to update or delete them.\n\n## SERILIZABLE的风险\n\nselect cnt from tablename;\n程序里c2 = cnt + 1\nupdate tablename set cnt = c2;\n如果两个transaction都在select处取到0,\nupdate时都update tablename set cnt = 1; 就错了\n\n这种事SERILIZABLE也救不了你, 因为只是select加了个共享锁, 其他事务还是可以读,\n于是只能改为select cnt from tablename for update,\n或者,更推荐的是删掉select, 直接用update tablename set cnt = cnt + 1\n这两者其实都是select时加了写锁,于是其他事务读不了了,只能等写锁释放\n\n不过这里主要想说的是即使是SERILIZABLE也不是能完全放心的,\n还是要小心啊, 真实业务不会像这里的例子这样单纯\n\n## 参考链接\nhttp://dev.mysql.com/doc/refman/5.7/en/innodb-transaction-model.html\n\n","source":"_posts/mysql_transaction.md","raw":"title: mysql 事务\ndate: 2016-08-10\ntags: [db, mysql]\n---\n\nInnoDB提供四种事务隔离级别,从低到高分别为READ UNCOMMITTED, READ COMMITTED, REPEATABLE READ, 和 SERIALIZABLE, 默认是REPEATABLE READ\nInnoDB使用不同的锁策略来支持不同的事务隔离级别.\n\n所有行为都在事务内, 默认是autocommit模式, 每条SQL语句形成一个独立的transaction.\n\nCOMMIT意味着变更确定持久化, ROLLBACK意味着放弃尚未持久化的变更, 两个操作都会释放锁.\n\ntransaction里select和update两句话之间有可能执行其他transaction的update语句么? || 有可能\n在update之前, 这个select的行会被其他transaction读到吗? || 会, 连SERILIZABLE都靠不住\n\n<!--more-->\n\n## READ UNCOMMITED 与 READ COMMITED\n\nREAD UNCOMMITED可以读到未COMMIT的内容, 这叫脏读\nREAD COMMITED满足一个事务开始时，只能“看见”已经提交的事务做的修改。\n\nclient1上start transaction;后insert一条,\nclient2使用READ UNCOMMITED可以看到\n\n<pre>\nmysql> set session transaction isolation level READ UNCOMMITTED;\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> select * from tag_perm;\n+-----+--------+---------+---------------------+---------------------+\n| id  | tag_id | perm_id | create_ts           | update_ts           |\n+-----+--------+---------+---------------------+---------------------+\n|  70 |      1 |       3 | 2016-08-10 13:50:45 | 2016-08-10 13:50:45 |\n|  71 |      2 |       3 | 2016-08-10 13:50:45 | 2016-08-10 13:50:45 |\n|  72 |      3 |       3 | 2016-08-10 13:50:45 | 2016-08-10 13:50:45 |\n+-----+--------+---------+---------------------+---------------------+\n</pre>\n\n改为READ COMMITED后就看不到了\n\n<pre>\nmysql> set session transaction isolation level READ COMMITTED;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> select * from tag_perm;\n+-----+--------+---------+---------------------+---------------------+\n| id  | tag_id | perm_id | create_ts           | update_ts           |\n+-----+--------+---------+---------------------+---------------------+\n|  70 |      1 |       3 | 2016-08-10 13:50:45 | 2016-08-10 13:50:45 |\n|  71 |      2 |       3 | 2016-08-10 13:50:45 | 2016-08-10 13:50:45 |\n+-----+--------+---------+---------------------+---------------------+\n</pre>\n\nclient1上commit,\nclient2上READ COMMITED可以看到了\n\n\n## READ COMMITED 与 REPEATABLE READ\n\n\nclient2开始transaction, select数据\n<pre>\nmysql> set session transaction isolation level READ COMMITTED;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> start transaction;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> select * from tag_perm;\n+-----+--------+---------+---------------------+---------------------+\n| id  | tag_id | perm_id | create_ts           | update_ts           |\n+-----+--------+---------+---------------------+---------------------+\n|  70 |      1 |       3 | 2016-08-10 13:50:45 | 2016-08-10 13:50:45 |\n+-----+--------+---------+---------------------+---------------------+\n</pre>\n\nclient1上commit之后\n\n<pre>\nmysql> select * from tag_perm;\n+-----+--------+---------+---------------------+---------------------+\n| id  | tag_id | perm_id | create_ts           | update_ts           |\n+-----+--------+---------+---------------------+---------------------+\n|  70 |      1 |       3 | 2016-08-10 13:50:45 | 2016-08-10 13:50:45 |\n|  71 |      2 |       3 | 2016-08-10 13:50:45 | 2016-08-10 13:50:45 |\n+-----+--------+---------+---------------------+---------------------+\n</pre>\n\n而REPEATABLE READ的情况则是client1上commit之后select也看不到外部的变更, 即仍是一行\n仍然只能看到本事务的变更, 即事务最开始的select时生成了一个snapshot(快照或副本)\n之后一直在snapshot的基础上操作\n\nREAD COMMITTED还是有读的问题,虽然未提交的不会读出来,但是自己的事务进行过程中会读到其他事务已经commit的内容,\n这是一个问题,比如事务开始后第一个select读到一个数,程序用了之后,第二次select时数变了,可能引发bug\n\n## REPEATABLE READ 与 SERILIZABLE\n\nSERIALIZABLE这个级别接近于串行执行,普通的SELECT会被自动转化成SELECT ... LOCK IN SHARE MODE,即SELECT加共享锁,能读不能写\n\nIf you use FOR UPDATE, rows examined by the query are write-locked until the end of the current transaction.\nUsing LOCK IN SHARE MODE sets a shared lock that permits other transactions to read the examined rows but not to update or delete them.\n\n## SERILIZABLE的风险\n\nselect cnt from tablename;\n程序里c2 = cnt + 1\nupdate tablename set cnt = c2;\n如果两个transaction都在select处取到0,\nupdate时都update tablename set cnt = 1; 就错了\n\n这种事SERILIZABLE也救不了你, 因为只是select加了个共享锁, 其他事务还是可以读,\n于是只能改为select cnt from tablename for update,\n或者,更推荐的是删掉select, 直接用update tablename set cnt = cnt + 1\n这两者其实都是select时加了写锁,于是其他事务读不了了,只能等写锁释放\n\n不过这里主要想说的是即使是SERILIZABLE也不是能完全放心的,\n还是要小心啊, 真实业务不会像这里的例子这样单纯\n\n## 参考链接\nhttp://dev.mysql.com/doc/refman/5.7/en/innodb-transaction-model.html\n\n","slug":"mysql_transaction","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5o600c7mcxqyfa07s9y"},{"title":"mysqld_multi","date":"2015-12-29T16:00:00.000Z","_content":"\n如何启动多个mysql实例?\n\n<!--more-->\n\n## /etc/mysql/my.cnf\n加入如下配置, 其中mysqld2里的2是group number(GNR)\n<pre>\n[mysqld_multi]                                                                   \nmysqld = /usr/bin/mysqld_safe                                                    \nmysqladmin = /usr/bin/mysqladmin                                                 \nuser = multi_admin                                                               \npassword = multipass\n\n[mysqld2]                                                                        \nuser        = mysql                                                              \npid-file    = /var/run/mysqld/mysqld2.pid                                        \nsocket      = /var/run/mysqld/mysqld2.sock                                       \nport        = 3307                                                               \ndatadir     = /var/lib/mysql2 \n</pre>\n\n## 新建datadir和log目录\nsudo mkdir /var/lib/mysql2\nsudo chown -RL mysql:mysql /var/lib/mysql2\nsudo mkdir /var/log/mysql2\nsudo chown -RL mysql:mysql /var/log/mysql2\n\n## 为mysql_install_db扫除障碍, 否则apparmor会报错\nsudo apt-get install apparmor-utils\nsudo vim /etc/apparmor.d/usr.sbin.mysqld\n将文件中关于mysql的路径改成类似下面这样(方针是给新数据库实例的datadir与/var/lib/mysql相同的授权)\n<pre>\n  /etc/mysql/*.pem r,                                                            \n  /etc/mysql/conf.d/ r,                                                          \n  /etc/mysql/conf.d/* r,                                                         \n  /etc/mysql/*.cnf r,                                                            \n  /usr/lib/mysql/plugin/ r,                                                      \n  /usr/lib/mysql/plugin/*.so* mr,                                                \n  /usr/sbin/mysqld mr,                                                           \n  /usr/share/mysql/** r,                                                         \n  /var/log/mysql*.log rw,                                                        \n  /var/log/mysql*.err rw,                                                        \n  /var/lib/mysql/ r,                                                             \n  /var/lib/mysql/** rwk,                                                         \n  /var/log/mysql/ r,                                                             \n  /var/log/mysql/* rw,                                                           \n  /var/run/mysqld/mysqld*.pid rw,                                                \n  /var/run/mysqld/mysqld*.sock w,                                                \n  /run/mysqld/mysqld*.pid rw,                                                    \n  /run/mysqld/mysqld*.sock w,\n  /usr/share/mysql2/** r,                                                        \n  /var/lib/mysql2/ r,                                                            \n  /var/lib/mysql2/** rwk,                                                        \n  /var/log/mysql2/ r,                                                            \n  /var/log/mysql2/* rw,                                                          \n</pre>\n\nsudo apparmor_parser -r /etc/apparmor.d/usr.sbin.mysqld\n\n## 使用mysql_install_db(deprecated in MySQL 5.7.6)初始化datadir\n\nsudo mysql_install_db --user=mysql --datadir=/var/lib/mysql2\n\n## 启动指定group number(GNR)的mysql实例\n\nsudo mysqld_multi start 2\n\n## 检验成果\n\n<pre>\n$ sudo mysqld_multi report 2\nReporting MySQL servers\nMySQL server from group: mysqld2 is running\n</pre>\n\n<pre>\n$ ps aux | grep mysql\nmysql     1211  0.0  0.4 2400952 34464 ?       Ssl  12月19   8:56 /usr/sbin/mysqld\nmysql    18811  1.2  0.5 483128 46264 pts/33   Sl   18:51   0:00 /usr/sbin/mysqld --user=mysql --pid-file=/var/run/mysqld/mysqld2.pid --socket=/var/run/mysqld/mysqld2.sock --port=3307 --datadir=/var/lib/mysql2\n</pre>\n\n<pre>\n$ netstat -nlotp\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name Timer\ntcp        0      0 127.0.0.1:3306          0.0.0.0:*               LISTEN      -                关闭 (0.00/0/0)\ntcp        0      0 127.0.0.1:3307          0.0.0.0:*               LISTEN      -                关闭 (0.00/0/0)\n...\n</pre>\n\n设置新数据库实例的初始root密码\nmysqladmin -S /var/run/mysqld/mysqld2.sock -u root password\n连接新的数据库实例\nmysql -S /var/run/mysqld/mysqld2.sock -u root -p\n\n## 授予shutdown权限, 否则stop不了\nmysqld_multi stop关闭每个mysql实例时使用相同的用户名和密码,\n所以最好在每个mysql实例都专门建一个账号并授予shutdown权限\n<pre>\nmysql> CREATE USER 'multi_admin'@'localhost' IDENTIFIED BY 'multipass';\nmysql> GRANT SHUTDOWN ON *.* TO 'multi_admin'@'localhost';\n</pre>\n\n停止指定的数据库实例\n<pre>\n$ sudo mysqld_multi stop 2\n$ sudo mysqld_multi report 2\nReporting MySQL servers\nMySQL server from group: mysqld2 is not running\n</pre>\n\n## 参考链接\nhttp://dev.mysql.com/doc/refman/5.7/en/mysqld-multi.html\nhttp://ubuntuforums.org/showthread.php?t=782224\n\n\n","source":"_posts/mysqld_multi.md","raw":"title: mysqld_multi\ndate: 2015-12-30\ntags: [mysql]\n---\n\n如何启动多个mysql实例?\n\n<!--more-->\n\n## /etc/mysql/my.cnf\n加入如下配置, 其中mysqld2里的2是group number(GNR)\n<pre>\n[mysqld_multi]                                                                   \nmysqld = /usr/bin/mysqld_safe                                                    \nmysqladmin = /usr/bin/mysqladmin                                                 \nuser = multi_admin                                                               \npassword = multipass\n\n[mysqld2]                                                                        \nuser        = mysql                                                              \npid-file    = /var/run/mysqld/mysqld2.pid                                        \nsocket      = /var/run/mysqld/mysqld2.sock                                       \nport        = 3307                                                               \ndatadir     = /var/lib/mysql2 \n</pre>\n\n## 新建datadir和log目录\nsudo mkdir /var/lib/mysql2\nsudo chown -RL mysql:mysql /var/lib/mysql2\nsudo mkdir /var/log/mysql2\nsudo chown -RL mysql:mysql /var/log/mysql2\n\n## 为mysql_install_db扫除障碍, 否则apparmor会报错\nsudo apt-get install apparmor-utils\nsudo vim /etc/apparmor.d/usr.sbin.mysqld\n将文件中关于mysql的路径改成类似下面这样(方针是给新数据库实例的datadir与/var/lib/mysql相同的授权)\n<pre>\n  /etc/mysql/*.pem r,                                                            \n  /etc/mysql/conf.d/ r,                                                          \n  /etc/mysql/conf.d/* r,                                                         \n  /etc/mysql/*.cnf r,                                                            \n  /usr/lib/mysql/plugin/ r,                                                      \n  /usr/lib/mysql/plugin/*.so* mr,                                                \n  /usr/sbin/mysqld mr,                                                           \n  /usr/share/mysql/** r,                                                         \n  /var/log/mysql*.log rw,                                                        \n  /var/log/mysql*.err rw,                                                        \n  /var/lib/mysql/ r,                                                             \n  /var/lib/mysql/** rwk,                                                         \n  /var/log/mysql/ r,                                                             \n  /var/log/mysql/* rw,                                                           \n  /var/run/mysqld/mysqld*.pid rw,                                                \n  /var/run/mysqld/mysqld*.sock w,                                                \n  /run/mysqld/mysqld*.pid rw,                                                    \n  /run/mysqld/mysqld*.sock w,\n  /usr/share/mysql2/** r,                                                        \n  /var/lib/mysql2/ r,                                                            \n  /var/lib/mysql2/** rwk,                                                        \n  /var/log/mysql2/ r,                                                            \n  /var/log/mysql2/* rw,                                                          \n</pre>\n\nsudo apparmor_parser -r /etc/apparmor.d/usr.sbin.mysqld\n\n## 使用mysql_install_db(deprecated in MySQL 5.7.6)初始化datadir\n\nsudo mysql_install_db --user=mysql --datadir=/var/lib/mysql2\n\n## 启动指定group number(GNR)的mysql实例\n\nsudo mysqld_multi start 2\n\n## 检验成果\n\n<pre>\n$ sudo mysqld_multi report 2\nReporting MySQL servers\nMySQL server from group: mysqld2 is running\n</pre>\n\n<pre>\n$ ps aux | grep mysql\nmysql     1211  0.0  0.4 2400952 34464 ?       Ssl  12月19   8:56 /usr/sbin/mysqld\nmysql    18811  1.2  0.5 483128 46264 pts/33   Sl   18:51   0:00 /usr/sbin/mysqld --user=mysql --pid-file=/var/run/mysqld/mysqld2.pid --socket=/var/run/mysqld/mysqld2.sock --port=3307 --datadir=/var/lib/mysql2\n</pre>\n\n<pre>\n$ netstat -nlotp\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name Timer\ntcp        0      0 127.0.0.1:3306          0.0.0.0:*               LISTEN      -                关闭 (0.00/0/0)\ntcp        0      0 127.0.0.1:3307          0.0.0.0:*               LISTEN      -                关闭 (0.00/0/0)\n...\n</pre>\n\n设置新数据库实例的初始root密码\nmysqladmin -S /var/run/mysqld/mysqld2.sock -u root password\n连接新的数据库实例\nmysql -S /var/run/mysqld/mysqld2.sock -u root -p\n\n## 授予shutdown权限, 否则stop不了\nmysqld_multi stop关闭每个mysql实例时使用相同的用户名和密码,\n所以最好在每个mysql实例都专门建一个账号并授予shutdown权限\n<pre>\nmysql> CREATE USER 'multi_admin'@'localhost' IDENTIFIED BY 'multipass';\nmysql> GRANT SHUTDOWN ON *.* TO 'multi_admin'@'localhost';\n</pre>\n\n停止指定的数据库实例\n<pre>\n$ sudo mysqld_multi stop 2\n$ sudo mysqld_multi report 2\nReporting MySQL servers\nMySQL server from group: mysqld2 is not running\n</pre>\n\n## 参考链接\nhttp://dev.mysql.com/doc/refman/5.7/en/mysqld-multi.html\nhttp://ubuntuforums.org/showthread.php?t=782224\n\n\n","slug":"mysqld_multi","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5o700camcxql5i08354"},{"title":"mysql配置","date":"2018-09-17T16:00:00.000Z","_content":"\n缓存大小, 最大连接数, 等待超时时间等\n<!--more-->\n\n```\ninnodb_buffer_pool_size = 1G # (adjust value here, 50%-70% of total RAM)\n\ninnodb_log_file_size = 256M\n\ninnodb_flush_log_at_trx_commit = 2 # 设成2能提高不少性能, 代价是有极小概率会丢数据\n\ninnodb_flush_method = O_DIRECT\n\nmax_connections = 1000 # (这个值根据mysql pool的max_overflow等值来计算一下吧, 一般一个游戏服预留100-200个连接, 一般用不到这么多, 只为特殊情况需要)\n\nwait_timeout = 86400\n\ninteractive_timeout = 86400\n\n```\n\n","source":"_posts/mysqld_config.md","raw":"title: mysql配置\ndate: 2018-09-18\ntags: [db, mysql, config]\n---\n\n缓存大小, 最大连接数, 等待超时时间等\n<!--more-->\n\n```\ninnodb_buffer_pool_size = 1G # (adjust value here, 50%-70% of total RAM)\n\ninnodb_log_file_size = 256M\n\ninnodb_flush_log_at_trx_commit = 2 # 设成2能提高不少性能, 代价是有极小概率会丢数据\n\ninnodb_flush_method = O_DIRECT\n\nmax_connections = 1000 # (这个值根据mysql pool的max_overflow等值来计算一下吧, 一般一个游戏服预留100-200个连接, 一般用不到这么多, 只为特殊情况需要)\n\nwait_timeout = 86400\n\ninteractive_timeout = 86400\n\n```\n\n","slug":"mysqld_config","published":1,"updated":"2018-09-18T02:57:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5o800ccmcxqmirgbcad"},{"title":"nautilus","date":"2015-09-07T16:00:00.000Z","_content":"## 安装open-terminal\nsudo apt-get install nautilus-open-terminal\n重启nautilus才能生效\nnautilus -q\n\n## Ubuntu通过nautilus访问Windows共享文件夹的方法 \n\n#### 在windows7中设置共享文件夹方法：\n首先， 以管理员身份登录win7系统，依次打开“控制面板->网络和共享中心->更改高级共享设置”。\n选中以下四项：“启用网络发现”、“启用文件和打印机共享”、“启用公用文件夹共享”和“关闭密码保护共享”。建议也启用流媒体共享，在家庭或工作栏目下选中“允许windows管理家庭组连接”。\n\n然后，右键点击需要共享的文件夹，选择“属性->共享->高级共享”，选中“共享此文件夹”，点击应用，确定后关闭。(注：上一级文件夹如果已共享，其下面的子文件夹也同时被共享。)\n\n接下来，需要将文件夹的安全权限改为“允许任何人访问”。右键点击共享文件夹，依次选择“属性->安全->编辑->添加”，输入“everyone”，点确定。\n在权限框中选中要赋予的权限，如：“完全控制”、“更改”和“读取”。\n\n然后，右键点击需要共享的文件夹，选择“属性->共享->共享...->给需要权限的人权限(比如Everyone读取/写入)\n\n由于系统自带的防火墙的默认设置为“允许文件和打印机共享的”，\n如有第三方防火墙，还要确保其启用了文件和打印机共享，否则，会出现共享的文件夹别人无法访问的问题。\n\n#### 在Ubuntu的nautilus(文件管理器)中访问windows共享文件夹\n按Ctrl-L(即转到),\n输入例如:smb://chenduo@192.168.1.96/myshare/ 即可\n\n#### 参考\nhttp://www.help315.com.cn/a/j/xt/2011/1116/161.html\nhttp://3y.uu456.com/bp-079224ef102de2bd960588af-1.html\n\n","source":"_posts/nautilus.md","raw":"title: nautilus\ndate: 2015-09-08\ntags: linux\n---\n## 安装open-terminal\nsudo apt-get install nautilus-open-terminal\n重启nautilus才能生效\nnautilus -q\n\n## Ubuntu通过nautilus访问Windows共享文件夹的方法 \n\n#### 在windows7中设置共享文件夹方法：\n首先， 以管理员身份登录win7系统，依次打开“控制面板->网络和共享中心->更改高级共享设置”。\n选中以下四项：“启用网络发现”、“启用文件和打印机共享”、“启用公用文件夹共享”和“关闭密码保护共享”。建议也启用流媒体共享，在家庭或工作栏目下选中“允许windows管理家庭组连接”。\n\n然后，右键点击需要共享的文件夹，选择“属性->共享->高级共享”，选中“共享此文件夹”，点击应用，确定后关闭。(注：上一级文件夹如果已共享，其下面的子文件夹也同时被共享。)\n\n接下来，需要将文件夹的安全权限改为“允许任何人访问”。右键点击共享文件夹，依次选择“属性->安全->编辑->添加”，输入“everyone”，点确定。\n在权限框中选中要赋予的权限，如：“完全控制”、“更改”和“读取”。\n\n然后，右键点击需要共享的文件夹，选择“属性->共享->共享...->给需要权限的人权限(比如Everyone读取/写入)\n\n由于系统自带的防火墙的默认设置为“允许文件和打印机共享的”，\n如有第三方防火墙，还要确保其启用了文件和打印机共享，否则，会出现共享的文件夹别人无法访问的问题。\n\n#### 在Ubuntu的nautilus(文件管理器)中访问windows共享文件夹\n按Ctrl-L(即转到),\n输入例如:smb://chenduo@192.168.1.96/myshare/ 即可\n\n#### 参考\nhttp://www.help315.com.cn/a/j/xt/2011/1116/161.html\nhttp://3y.uu456.com/bp-079224ef102de2bd960588af-1.html\n\n","slug":"nautilus","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5o900cfmcxq7z90s1ry"},{"title":"neo4j","date":"2016-02-23T16:00:00.000Z","_content":"\n## 如何安装neo4j\n确保已经安装java7\n\n下载community edition\nhttp://neo4j.com/download/\n得到文件neo4j-community-2.3.2-unix.tar.gz\n\n解压\ntar xvf neo4j-community-2.3.2-unix.tar.gz\n\n启动neo4j\n./bin/neo4j start\n\n访问如下地址\nhttp://localhost:7474\nuser: neo4j, passwd: neo4j\n\n","source":"_posts/neo4j.md","raw":"title: neo4j\ndate: 2016-02-24\ntags: [db]\n---\n\n## 如何安装neo4j\n确保已经安装java7\n\n下载community edition\nhttp://neo4j.com/download/\n得到文件neo4j-community-2.3.2-unix.tar.gz\n\n解压\ntar xvf neo4j-community-2.3.2-unix.tar.gz\n\n启动neo4j\n./bin/neo4j start\n\n访问如下地址\nhttp://localhost:7474\nuser: neo4j, passwd: neo4j\n\n","slug":"neo4j","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5oa00chmcxqzach117z"},{"title":"内网穿透","date":"2018-09-12T16:00:00.000Z","_content":"\n用于在家办公访问公司内网等场景\n<!--more-->\n\n在内网机器如下创建文件 /etc/systemd/system/autossh.service 并将权限设置为644\n```\n[Unit]\nDescription=Auto SSH Tunnel\nAfter=network-online.target\n\n[Service]\nUser=username\nType=simple\nExecStart=/usr/local/bin/autossh -p 22 -o \"ServerAliveInterval 60\" -o \"ServerAliveCountMax 6\" -M 0 -NR '*:6766:localhost:22' servercloud\nExecReload=/usr/bin/kill -HUP $MAINPID\nKillMode=process\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n```\n\n在内网机器启动autossh(自定义)服务\n```\nsudo systemctl start autossh\n```\n\n如下可以通过外网服务器直接连到内网服务器\n```\nssh -p 6766 username@servercloud\n```\n\n## 参考链接\nhttp://arondight.me/2016/02/17/%E4%BD%BF%E7%94%A8SSH%E5%8F%8D%E5%90%91%E9%9A%A7%E9%81%93%E8%BF%9B%E8%A1%8C%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/\nhttp://www.cnblogs.com/starof/p/4709805.html\nhttps://www.jianshu.com/p/a9a2344e0c6d\n\n","source":"_posts/nat_expose.md","raw":"title: 内网穿透\ndate: 2018-09-13\ntags: [linux, nat, ssh]\n---\n\n用于在家办公访问公司内网等场景\n<!--more-->\n\n在内网机器如下创建文件 /etc/systemd/system/autossh.service 并将权限设置为644\n```\n[Unit]\nDescription=Auto SSH Tunnel\nAfter=network-online.target\n\n[Service]\nUser=username\nType=simple\nExecStart=/usr/local/bin/autossh -p 22 -o \"ServerAliveInterval 60\" -o \"ServerAliveCountMax 6\" -M 0 -NR '*:6766:localhost:22' servercloud\nExecReload=/usr/bin/kill -HUP $MAINPID\nKillMode=process\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n```\n\n在内网机器启动autossh(自定义)服务\n```\nsudo systemctl start autossh\n```\n\n如下可以通过外网服务器直接连到内网服务器\n```\nssh -p 6766 username@servercloud\n```\n\n## 参考链接\nhttp://arondight.me/2016/02/17/%E4%BD%BF%E7%94%A8SSH%E5%8F%8D%E5%90%91%E9%9A%A7%E9%81%93%E8%BF%9B%E8%A1%8C%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/\nhttp://www.cnblogs.com/starof/p/4709805.html\nhttps://www.jianshu.com/p/a9a2344e0c6d\n\n","slug":"nat_expose","published":1,"updated":"2018-09-13T03:40:42.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5oa00ckmcxq75tt3ype"},{"title":"netcat","date":"2016-06-04T09:17:00.000Z","_content":"\ntelnet的替代品?更多功能?\n<!--more-->\n\n## 例子\n\n### 启动一个一次性的web server在8080端口, 提供一个文件\n```\n{ echo -ne \"HTTP/1.0 200 OK\\r\\nContent-Length: $(wc -c <some.file)\\r\\n\\r\\n\"; cat some.file; } | nc -l -p 8080\n```\n参数-l: listen\n参数-p: source port\n\n### 检测hostname/ip的port是否open且listening\n```\nnc -vz suexcxine.cc 8888\n```\n参数-v: 详细信息\n参数-z: 只扫描listening的程序, 并不发数据\n\n### 简单的UDP服务器和客户端\n服务端监听8388端口\nnc -ul 8388\n客户端连接\nnc -u suexcxine.cc 8388\n双方可以输入字符通信\n\n参数-u: udp\n\n### 代理\n```\n$ nc -vl 12345 | nc www.google.com 80\nListening on [0.0.0.0] (family 0, port 12345)\nConnection from [127.0.0.1] port 12345 [tcp/*] accepted (family 2, sport 40841)\n```\n由于管道是单向的, 流量被转发到google.com但是响应不会转给客户\n\n","source":"_posts/netcat.md","raw":"title: netcat\ndate: 2016-06-04 17:17:00\ntags: linux\n---\n\ntelnet的替代品?更多功能?\n<!--more-->\n\n## 例子\n\n### 启动一个一次性的web server在8080端口, 提供一个文件\n```\n{ echo -ne \"HTTP/1.0 200 OK\\r\\nContent-Length: $(wc -c <some.file)\\r\\n\\r\\n\"; cat some.file; } | nc -l -p 8080\n```\n参数-l: listen\n参数-p: source port\n\n### 检测hostname/ip的port是否open且listening\n```\nnc -vz suexcxine.cc 8888\n```\n参数-v: 详细信息\n参数-z: 只扫描listening的程序, 并不发数据\n\n### 简单的UDP服务器和客户端\n服务端监听8388端口\nnc -ul 8388\n客户端连接\nnc -u suexcxine.cc 8388\n双方可以输入字符通信\n\n参数-u: udp\n\n### 代理\n```\n$ nc -vl 12345 | nc www.google.com 80\nListening on [0.0.0.0] (family 0, port 12345)\nConnection from [127.0.0.1] port 12345 [tcp/*] accepted (family 2, sport 40841)\n```\n由于管道是单向的, 流量被转发到google.com但是响应不会转给客户\n\n","slug":"netcat","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5oc00cmmcxqwzuhilcd"},{"title":"netstat","date":"2016-01-03T16:00:00.000Z","_content":"\nPrint network connections, routing tables, interface statistics, masquerade connections, and multicast memberships\n\n<!--more-->\n\n## 常用选项\n-a 显示全部socket(包括监听中的和非监听中的)\n-l 显示监听中(默认不显示)的socket\n\n-t 显示TCP协议的\n-u 显示UDP协议的\n\n-n 以网络IP地址而不是名称显示\n-p 显示建立相关连接的程序名和PID\n-o 包含timer相关信息\n-e 显示更多信息\n\n-c 每秒刷新\n\n-s 显示各类协议的统计信息\n\n## 其他用途\nnetstat -ie 同ifconfig\nnetstat -r 同route -e\n\n\n\n\n\n","source":"_posts/netstat.md","raw":"title: netstat\ndate: 2016-01-04\ntags: [internet, linux]\n---\n\nPrint network connections, routing tables, interface statistics, masquerade connections, and multicast memberships\n\n<!--more-->\n\n## 常用选项\n-a 显示全部socket(包括监听中的和非监听中的)\n-l 显示监听中(默认不显示)的socket\n\n-t 显示TCP协议的\n-u 显示UDP协议的\n\n-n 以网络IP地址而不是名称显示\n-p 显示建立相关连接的程序名和PID\n-o 包含timer相关信息\n-e 显示更多信息\n\n-c 每秒刷新\n\n-s 显示各类协议的统计信息\n\n## 其他用途\nnetstat -ie 同ifconfig\nnetstat -r 同route -e\n\n\n\n\n\n","slug":"netstat","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5od00comcxqrmweoz0p"},{"title":"nginx, 理解server和location配置","date":"2016-06-28T12:38:00.000Z","_content":"\nserver和location的配置还是有点小复杂的..\n\n<!--more-->\n\n## listen\n\n可以是以下几种:\n\n* ip:port\n* ip(port默认80)\n* port(ip默认0.0.0.0)\n* unix socket的路径\n\nnginx检查http请求的Host头信息\n\n## server_name\n\n可以使用通配符和正则, 就像下面这样\n```\nserver_name www.example.*;\nserver_name ~^(www|host1).*\\.example\\.com$;\n```\n允许多个\n```\nserver_name example.com www.example.com;\nserver_name example.com linode.com icann.org;\n```\n允许不合法的域名, 反正nginx只是用来与request里的Host信息比较\n局域网等情况下有用\n```\nserver_name localhost linode galloway;\n```\n空的server name表示无域名, 直接使用ip访问的请求\n```\nserver_name \"\";\n```\n\n### default_server\n这个选项表示默认, 即如果其他virtual host不匹配时, 使用这个\n```\nlisten 80 default_server;\nlisten [::]:80 default_server ipv6only=on;\n```\n允许多个listen语句,同时监听多个ip和端口\n```\nlisten     12.34.56.77:80;\nlisten     12.34.56.78:80;\nlisten     12.34.56.79:80; \n```\n\n## location\n\n```\nlocation optional_modifier location_match {\n    . . .\n}\n```\nmodifier如下:\n(none)  prefix匹配\n= 精确匹配, 性能略高, 如果有些请求确实很热就适用\n~ 大小写敏感的正则表达式匹配\n~* 大小写不敏感的正则表达式匹配\n^~ prefix匹配,且阻止后续的正则表达式匹配\n\n匹配规则如下:\n优先选择完全匹配的(即=型的), 然后选择prefix(即none型和^~的),选最长的,如果有^~,就定了,\n没有的话,先存着这个最长的,再往下看正则表达式型的,\n找到一个匹配的正则表达式就定了(意味着顺序有影响),否则用之前存着的\n\n即默认是正则表达式优先于prefix型,然而=或^~允许用户改变这种倾向\n\n例子:\n```\nlocation /site\nlocation = /page1\nlocation ~ \\.(jpe?g|png|gif|ico)$\nlocation ~* \\.(jpe?g|png|gif|ico)$\nlocation ^~ /costumes\n```\n\n### index\n当请求是目录而不是具体文件时使用的文件\n\n### try_files\n\n```\nroot /var/www/main;\n\nlocation / {\n    try_files $uri $uri.html $uri/ /fallback/index.html;\n}\n\nlocation /fallback {\n    root /var/www/another;\n}\n```\n\n### rewrite\n\n```\nroot /var/www/main;\n\nlocation / {\n    rewrite ^/rewriteme/(.*)$ /$1 last;\n    try_files $uri $uri.html $uri/ /fallback/index.html;\n}\n\nlocation /fallback {\n    root /var/www/another;\n}\n```\n\n### return\n\n会导致外部可见的跳转\n\n### error_page\n\n内部跳转\n\n```\nroot /var/www/main;\n\nlocation / {\n    error_page 404 /another/whoops.html;\n}\n\nlocation /another {\n    root /var/www;\n}\n```\n\n## 参考链接\nhttps://www.digitalocean.com/community/tutorials/understanding-nginx-server-and-location-block-selection-algorithms\nhttps://www.linode.com/docs/websites/nginx/how-to-configure-nginx\n\n","source":"_posts/nginx_server_location.md","raw":"title: nginx, 理解server和location配置\ndate: 2016-06-28 20:38\ntags: [web, linux]\n---\n\nserver和location的配置还是有点小复杂的..\n\n<!--more-->\n\n## listen\n\n可以是以下几种:\n\n* ip:port\n* ip(port默认80)\n* port(ip默认0.0.0.0)\n* unix socket的路径\n\nnginx检查http请求的Host头信息\n\n## server_name\n\n可以使用通配符和正则, 就像下面这样\n```\nserver_name www.example.*;\nserver_name ~^(www|host1).*\\.example\\.com$;\n```\n允许多个\n```\nserver_name example.com www.example.com;\nserver_name example.com linode.com icann.org;\n```\n允许不合法的域名, 反正nginx只是用来与request里的Host信息比较\n局域网等情况下有用\n```\nserver_name localhost linode galloway;\n```\n空的server name表示无域名, 直接使用ip访问的请求\n```\nserver_name \"\";\n```\n\n### default_server\n这个选项表示默认, 即如果其他virtual host不匹配时, 使用这个\n```\nlisten 80 default_server;\nlisten [::]:80 default_server ipv6only=on;\n```\n允许多个listen语句,同时监听多个ip和端口\n```\nlisten     12.34.56.77:80;\nlisten     12.34.56.78:80;\nlisten     12.34.56.79:80; \n```\n\n## location\n\n```\nlocation optional_modifier location_match {\n    . . .\n}\n```\nmodifier如下:\n(none)  prefix匹配\n= 精确匹配, 性能略高, 如果有些请求确实很热就适用\n~ 大小写敏感的正则表达式匹配\n~* 大小写不敏感的正则表达式匹配\n^~ prefix匹配,且阻止后续的正则表达式匹配\n\n匹配规则如下:\n优先选择完全匹配的(即=型的), 然后选择prefix(即none型和^~的),选最长的,如果有^~,就定了,\n没有的话,先存着这个最长的,再往下看正则表达式型的,\n找到一个匹配的正则表达式就定了(意味着顺序有影响),否则用之前存着的\n\n即默认是正则表达式优先于prefix型,然而=或^~允许用户改变这种倾向\n\n例子:\n```\nlocation /site\nlocation = /page1\nlocation ~ \\.(jpe?g|png|gif|ico)$\nlocation ~* \\.(jpe?g|png|gif|ico)$\nlocation ^~ /costumes\n```\n\n### index\n当请求是目录而不是具体文件时使用的文件\n\n### try_files\n\n```\nroot /var/www/main;\n\nlocation / {\n    try_files $uri $uri.html $uri/ /fallback/index.html;\n}\n\nlocation /fallback {\n    root /var/www/another;\n}\n```\n\n### rewrite\n\n```\nroot /var/www/main;\n\nlocation / {\n    rewrite ^/rewriteme/(.*)$ /$1 last;\n    try_files $uri $uri.html $uri/ /fallback/index.html;\n}\n\nlocation /fallback {\n    root /var/www/another;\n}\n```\n\n### return\n\n会导致外部可见的跳转\n\n### error_page\n\n内部跳转\n\n```\nroot /var/www/main;\n\nlocation / {\n    error_page 404 /another/whoops.html;\n}\n\nlocation /another {\n    root /var/www;\n}\n```\n\n## 参考链接\nhttps://www.digitalocean.com/community/tutorials/understanding-nginx-server-and-location-block-selection-algorithms\nhttps://www.linode.com/docs/websites/nginx/how-to-configure-nginx\n\n","slug":"nginx_server_location","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5oe00crmcxqamqsg0tt"},{"title":"nginx","date":"2015-11-06T16:00:00.000Z","_content":"开源,BSD许可\n跨平台\n模块间松耦合,可以分开用,也可以组合用\n内存消耗低,10000个非活跃Keep-Alive连接仅消耗2.5MB内存\n单机支持10万以上的并发连接, 更多数量取决于内存\nmaster和worker机制支持热更新\n<!--more-->\n\n## 编译环境要求\nLinux内核2.6以上\ngcc\nPCRE 支持正则表达式\nzlib\nOpenSSL\n\n## 目录\n源代码存放目录\n编译中间文件存放目录, 默认为源代码目录下的objs目录\n部署目录\n日志文件存放目录\n\n## Linux内核参数优化\n/etc/sysctl.conf\n> fs.file-max = 999999\t进程,如worker进程可以同时打开的最大文件句柄数\n> net.ipv4.tcp_tw_reuse = 1\t允许将TIME-WAIT状态的socket重新用于新的TCP连接\n> net.ipv4.tcp_keepalive_time = 600\t控制 TCP/IP 尝试验证空闲连接是否完好的频率。如果需要更快地发现丢失了接收方，请考虑减小这个值,默认是2小时检测一次,改短一些有助于快速清理无效连接\n> net.ipv4.tcp_fin_timeout = 30\t当服务器主动关闭连接时,socket保持在FIN-WAIT-2状态的最大时间\n> net.ipv4.tcp_max_tw_buckets = 5000\t允许TIME_WAIT socket数量上限\n> net.ipv4.cp_max_syn.backlog = 1024\tTCP三次握手建立阶段接收SYN请求队列的最大长度\n> net.ipv4.ip_local_port_range = 1024\t61000\tUDP和TCP连接中本地端口的取值范围\n> net.ipv4.tcp_rmem = 4096 32768 262142\tTCP接收缓存(滑动窗口用)的最小值,默认值和最大值\n> net.ipv4.tcp_wmem = 4096 32768 262142\tTCP发送缓存(滑动窗口用)的最小值,默认值和最大值\n> net.core.netdev_max_backlog = 8096\t当网卡接收数据包的速度大于内核处理的速度时,缓存这些数据包的队列上限\n> net.core.rmem_default = 262144\t\t内核套接字接收缓存的默认值\n> net.core.wmem_default = 262144\t\t内核套接字发送缓存的默认值\n> net.core.rmem_max = 2097152\t\t内核套接字接收缓存的最大值\n> net.core.wmem_max = 2097152\t\t内核套接字发送缓存的最大值\n> net.ipv4.tcp_syncookies = 1\t\t用于解决TCP的SYN攻击\n\n执行sysctl -p命令使修改生效\n\n## 获取Nginx源码\nhttp://nginx.org/en/download.html\n\n## 编译\n进入源码目录\n> ./configure --help\n>\n> --prefix=PATH\t安装目录,会做为其他参数的相对目录,默认为/usr/local/nginx\n> --sbin-path=PATH\t可执行文件路径\n> --conf-path=PATH\t配置文件路径\n> --error-log-path=PATH\t错误日志文件路径\n> --pid-path=PATH\t\tpid文件存放路径,文件形式存储进程Id\n> --lock-path=PATH\n\n## ubuntu下安装nginx\n> sudo aptitude install nginx\n\n### 查看版本和编译参数\n> $ nginx -V\n> nginx version: nginx/1.4.6 (Ubuntu)\n> built by gcc 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04)\n> TLS SNI support enabled\n> configure arguments: --with-cc-opt='-g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -D_FORTIFY_SOURCE=2' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro' --prefix=/usr/share/nginx --conf-path=/etc/nginx/nginx.conf --http-log-path=/var/log/nginx/access.log --error-log-path=/var/log/nginx/error.log --lock-path=/var/lock/nginx.lock --pid-path=/run/nginx.pid --http-client-body-temp-path=/var/lib/nginx/body --http-fastcgi-temp-path=/var/lib/nginx/fastcgi --http-proxy-temp-path=/var/lib/nginx/proxy --http-scgi-temp-path=/var/lib/nginx/scgi --http-uwsgi-temp-path=/var/lib/nginx/uwsgi --with-debug --with-pcre-jit --with-ipv6 --with-http_ssl_module --with-http_stub_status_module --with-http_realip_module --with-http_addition_module --with-http_dav_module --with-http_geoip_module --with-http_gzip_static_module --with-http_image_filter_module --with-http_spdy_module --with-http_sub_module --with-http_xslt_module --with-mail --with-mail_ssl_module\n>\n\n### 帮助\n> $ nginx -h\n> nginx version: nginx/1.4.6 (Ubuntu)\n> Usage: nginx [-?hvVtq] [-s signal] [-c filename] [-p prefix] [-g directives]\n>\n> Options:\n>   -?,-h         : this help\n>   -v            : show version and exit\n>   -V            : show version and configure options then exit\n>   -t            : test configuration and exit\n>   -q            : suppress non-error messages during configuration testing\n>   -s signal     : send signal to a master process: stop, quit, reopen, reload\n>   -p prefix     : set prefix path (default: /usr/share/nginx/)\n>   -c filename   : set configuration file (default: /etc/nginx/nginx.conf)\n>   -g directives : set global directives out of configuration file\n\n### 相关路径\n> $ whereis nginx\n> nginx: /usr/sbin/nginx /etc/nginx /usr/share/nginx /usr/share/man/man1/nginx.1.gz\n\n所有的配置文件都在/etc/nginx下，\n并且每个虚拟主机已经安排在了/etc/nginx/sites-available下\n日志放在了/var/log/nginx中，分别是access.log和error.log\n默认的虚拟主机的目录设置在了/usr/share/nginx/html\n并已经在/etc/init.d/下创建了启动脚本nginx\n\n> 先停掉apache, 放开80端口\n> sudo /etc/init.d/apache2 stop\n> 启动nginx\n> $ sudo /etc/init.d/nginx start\n\n## php支持\n所谓FastCGI就是对CGI的改进。\n它一般采用C/S结构，一般脚本处理器会启动一个或者多个daemon进程，\n每次web服务器遇到脚本的时候，直接交付给FastCGI的进程来执行，然后将得到的结果(通常为html)返回给浏览器。\n\n$ sudo apt-get install php5-fpm\n查看是否已启动\n```\n$ ps aux | grep php-fpm\nroot     30397  0.0  0.2 264876 21104 ?        Ss   21:44   0:00 php-fpm: master process (/etc/php5/fpm/php-fpm.conf)\nwww-data 30401  0.0  0.0 264876  6980 ?        S    21:44   0:00 php-fpm: pool www\nwww-data 30402  0.0  0.0 264876  6980 ?        S    21:44   0:00 php-fpm: pool www\nchenduo  30447  0.0  0.0  15960  2168 pts/35   R+   21:45   0:00 grep --color=auto php-fpm\n```\n\n/etc/nginx/nginx.conf里有如下一行:\ninclude /etc/nginx/sites-enabled/*;\n找到对应的文件\n/etc/nginx/sites-enabled/default\n```\nlocation ~ \\.php$ {\n    fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n    fastcgi_pass unix:/var/run/php5-fpm.sock;\n    fastcgi_index index.php;\n    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n    include fastcgi_params;\n}\n```\n\n$ sudo /etc/init.d/nginx restart\n\n/etc/php5/fpm/php.ini\ncgi.fix_pathinfo=0\n据说这里不设成0的话会有安全问题,详见\n<http://cnedelcu.blogspot.com/2010/05/nginx-php-via-fastcgi-important.html>\n\n/etc/php5/fpm/php-fpm.conf里有如下一行:\ninclude=/etc/php5/fpm/pool.d/*.conf\n即会包含pool.d下的配置文件\n\n用户是www-data\n\n### amazon linux 2 安装nginx和php\n```bash\nsudo amazon-linux-extras install nginx1.12\nsudo amazon-linux-extras install php7.2\n```\n像下面这样访问测试nginx是否正常工作\nhttp://ec2-13-229-239-123.ap-southeast-1.compute.amazonaws.com/\n\n### 反向代理\n将收到的流量转发到其它url, 如下\n```\nlocation / {\n    proxy_pass http://redmine.suexcxine.cc:3000;\n}\n```\n\n### php-fpm端口引发的502 BAD GATEWAY的问题\n/etc/php5/fpm/pool.d/www.conf里有listen = /var/run/php5-fpm.sock\nnginx.conf里的配置应为: fastcgi_pass unix:/var/run/php5-fpm.sock;\n或者也可以将两处都改为127.0.0.1:9000这样的配置\n\n结论:两边的配置需要一致才能通信,即nginx能找到php-fpm\n\n### fastcgi_param引发的空白页问题\n当时的配置:\nfastcgi_param  SCRIPT_FILENAME  /usr/local/nginx/html/phpmyadmin$fastcgi_script_name;\n\n结果nginx出空白页\n后来改为:\nfastcgi_param  SCRIPT_FILENAME  /usr/local/nginx/html$fastcgi_script_name;\n就好了\n\n后来又试了下:\nfastcgi_param  SCRIPT_FILENAME  \\$document_root$fastcgi_script_name;\n也没问题\n\n结论:路径配错了\n\n### 提示缺少mysqli扩展\n```\nsudo aptitude install php5-mysql\n```\n\n### default_server\n\n通过HTTP请求中的Host值找不到对应的虚拟主机配置时, 会走default_server\nhttps://www.oschina.net/question/12_3565\n\n### reverse proxy IP forwarding\n\n```\nproxy_set_header X-Real-IP  $remote_addr;\nproxy_set_header X-Forwarded-For $remote_addr;\nproxy_set_header Host $host;\nproxy_pass http://127.0.0.1:8080;\n```\nhttps://www.digitalocean.com/community/questions/nginx-reverse-proxy-ip-forwarding\n\n","source":"_posts/nginx.md","raw":"title: nginx\ndate: 2015-11-07\ntags: [web, linux]\n---\n开源,BSD许可\n跨平台\n模块间松耦合,可以分开用,也可以组合用\n内存消耗低,10000个非活跃Keep-Alive连接仅消耗2.5MB内存\n单机支持10万以上的并发连接, 更多数量取决于内存\nmaster和worker机制支持热更新\n<!--more-->\n\n## 编译环境要求\nLinux内核2.6以上\ngcc\nPCRE 支持正则表达式\nzlib\nOpenSSL\n\n## 目录\n源代码存放目录\n编译中间文件存放目录, 默认为源代码目录下的objs目录\n部署目录\n日志文件存放目录\n\n## Linux内核参数优化\n/etc/sysctl.conf\n> fs.file-max = 999999\t进程,如worker进程可以同时打开的最大文件句柄数\n> net.ipv4.tcp_tw_reuse = 1\t允许将TIME-WAIT状态的socket重新用于新的TCP连接\n> net.ipv4.tcp_keepalive_time = 600\t控制 TCP/IP 尝试验证空闲连接是否完好的频率。如果需要更快地发现丢失了接收方，请考虑减小这个值,默认是2小时检测一次,改短一些有助于快速清理无效连接\n> net.ipv4.tcp_fin_timeout = 30\t当服务器主动关闭连接时,socket保持在FIN-WAIT-2状态的最大时间\n> net.ipv4.tcp_max_tw_buckets = 5000\t允许TIME_WAIT socket数量上限\n> net.ipv4.cp_max_syn.backlog = 1024\tTCP三次握手建立阶段接收SYN请求队列的最大长度\n> net.ipv4.ip_local_port_range = 1024\t61000\tUDP和TCP连接中本地端口的取值范围\n> net.ipv4.tcp_rmem = 4096 32768 262142\tTCP接收缓存(滑动窗口用)的最小值,默认值和最大值\n> net.ipv4.tcp_wmem = 4096 32768 262142\tTCP发送缓存(滑动窗口用)的最小值,默认值和最大值\n> net.core.netdev_max_backlog = 8096\t当网卡接收数据包的速度大于内核处理的速度时,缓存这些数据包的队列上限\n> net.core.rmem_default = 262144\t\t内核套接字接收缓存的默认值\n> net.core.wmem_default = 262144\t\t内核套接字发送缓存的默认值\n> net.core.rmem_max = 2097152\t\t内核套接字接收缓存的最大值\n> net.core.wmem_max = 2097152\t\t内核套接字发送缓存的最大值\n> net.ipv4.tcp_syncookies = 1\t\t用于解决TCP的SYN攻击\n\n执行sysctl -p命令使修改生效\n\n## 获取Nginx源码\nhttp://nginx.org/en/download.html\n\n## 编译\n进入源码目录\n> ./configure --help\n>\n> --prefix=PATH\t安装目录,会做为其他参数的相对目录,默认为/usr/local/nginx\n> --sbin-path=PATH\t可执行文件路径\n> --conf-path=PATH\t配置文件路径\n> --error-log-path=PATH\t错误日志文件路径\n> --pid-path=PATH\t\tpid文件存放路径,文件形式存储进程Id\n> --lock-path=PATH\n\n## ubuntu下安装nginx\n> sudo aptitude install nginx\n\n### 查看版本和编译参数\n> $ nginx -V\n> nginx version: nginx/1.4.6 (Ubuntu)\n> built by gcc 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04)\n> TLS SNI support enabled\n> configure arguments: --with-cc-opt='-g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -D_FORTIFY_SOURCE=2' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro' --prefix=/usr/share/nginx --conf-path=/etc/nginx/nginx.conf --http-log-path=/var/log/nginx/access.log --error-log-path=/var/log/nginx/error.log --lock-path=/var/lock/nginx.lock --pid-path=/run/nginx.pid --http-client-body-temp-path=/var/lib/nginx/body --http-fastcgi-temp-path=/var/lib/nginx/fastcgi --http-proxy-temp-path=/var/lib/nginx/proxy --http-scgi-temp-path=/var/lib/nginx/scgi --http-uwsgi-temp-path=/var/lib/nginx/uwsgi --with-debug --with-pcre-jit --with-ipv6 --with-http_ssl_module --with-http_stub_status_module --with-http_realip_module --with-http_addition_module --with-http_dav_module --with-http_geoip_module --with-http_gzip_static_module --with-http_image_filter_module --with-http_spdy_module --with-http_sub_module --with-http_xslt_module --with-mail --with-mail_ssl_module\n>\n\n### 帮助\n> $ nginx -h\n> nginx version: nginx/1.4.6 (Ubuntu)\n> Usage: nginx [-?hvVtq] [-s signal] [-c filename] [-p prefix] [-g directives]\n>\n> Options:\n>   -?,-h         : this help\n>   -v            : show version and exit\n>   -V            : show version and configure options then exit\n>   -t            : test configuration and exit\n>   -q            : suppress non-error messages during configuration testing\n>   -s signal     : send signal to a master process: stop, quit, reopen, reload\n>   -p prefix     : set prefix path (default: /usr/share/nginx/)\n>   -c filename   : set configuration file (default: /etc/nginx/nginx.conf)\n>   -g directives : set global directives out of configuration file\n\n### 相关路径\n> $ whereis nginx\n> nginx: /usr/sbin/nginx /etc/nginx /usr/share/nginx /usr/share/man/man1/nginx.1.gz\n\n所有的配置文件都在/etc/nginx下，\n并且每个虚拟主机已经安排在了/etc/nginx/sites-available下\n日志放在了/var/log/nginx中，分别是access.log和error.log\n默认的虚拟主机的目录设置在了/usr/share/nginx/html\n并已经在/etc/init.d/下创建了启动脚本nginx\n\n> 先停掉apache, 放开80端口\n> sudo /etc/init.d/apache2 stop\n> 启动nginx\n> $ sudo /etc/init.d/nginx start\n\n## php支持\n所谓FastCGI就是对CGI的改进。\n它一般采用C/S结构，一般脚本处理器会启动一个或者多个daemon进程，\n每次web服务器遇到脚本的时候，直接交付给FastCGI的进程来执行，然后将得到的结果(通常为html)返回给浏览器。\n\n$ sudo apt-get install php5-fpm\n查看是否已启动\n```\n$ ps aux | grep php-fpm\nroot     30397  0.0  0.2 264876 21104 ?        Ss   21:44   0:00 php-fpm: master process (/etc/php5/fpm/php-fpm.conf)\nwww-data 30401  0.0  0.0 264876  6980 ?        S    21:44   0:00 php-fpm: pool www\nwww-data 30402  0.0  0.0 264876  6980 ?        S    21:44   0:00 php-fpm: pool www\nchenduo  30447  0.0  0.0  15960  2168 pts/35   R+   21:45   0:00 grep --color=auto php-fpm\n```\n\n/etc/nginx/nginx.conf里有如下一行:\ninclude /etc/nginx/sites-enabled/*;\n找到对应的文件\n/etc/nginx/sites-enabled/default\n```\nlocation ~ \\.php$ {\n    fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n    fastcgi_pass unix:/var/run/php5-fpm.sock;\n    fastcgi_index index.php;\n    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n    include fastcgi_params;\n}\n```\n\n$ sudo /etc/init.d/nginx restart\n\n/etc/php5/fpm/php.ini\ncgi.fix_pathinfo=0\n据说这里不设成0的话会有安全问题,详见\n<http://cnedelcu.blogspot.com/2010/05/nginx-php-via-fastcgi-important.html>\n\n/etc/php5/fpm/php-fpm.conf里有如下一行:\ninclude=/etc/php5/fpm/pool.d/*.conf\n即会包含pool.d下的配置文件\n\n用户是www-data\n\n### amazon linux 2 安装nginx和php\n```bash\nsudo amazon-linux-extras install nginx1.12\nsudo amazon-linux-extras install php7.2\n```\n像下面这样访问测试nginx是否正常工作\nhttp://ec2-13-229-239-123.ap-southeast-1.compute.amazonaws.com/\n\n### 反向代理\n将收到的流量转发到其它url, 如下\n```\nlocation / {\n    proxy_pass http://redmine.suexcxine.cc:3000;\n}\n```\n\n### php-fpm端口引发的502 BAD GATEWAY的问题\n/etc/php5/fpm/pool.d/www.conf里有listen = /var/run/php5-fpm.sock\nnginx.conf里的配置应为: fastcgi_pass unix:/var/run/php5-fpm.sock;\n或者也可以将两处都改为127.0.0.1:9000这样的配置\n\n结论:两边的配置需要一致才能通信,即nginx能找到php-fpm\n\n### fastcgi_param引发的空白页问题\n当时的配置:\nfastcgi_param  SCRIPT_FILENAME  /usr/local/nginx/html/phpmyadmin$fastcgi_script_name;\n\n结果nginx出空白页\n后来改为:\nfastcgi_param  SCRIPT_FILENAME  /usr/local/nginx/html$fastcgi_script_name;\n就好了\n\n后来又试了下:\nfastcgi_param  SCRIPT_FILENAME  \\$document_root$fastcgi_script_name;\n也没问题\n\n结论:路径配错了\n\n### 提示缺少mysqli扩展\n```\nsudo aptitude install php5-mysql\n```\n\n### default_server\n\n通过HTTP请求中的Host值找不到对应的虚拟主机配置时, 会走default_server\nhttps://www.oschina.net/question/12_3565\n\n### reverse proxy IP forwarding\n\n```\nproxy_set_header X-Real-IP  $remote_addr;\nproxy_set_header X-Forwarded-For $remote_addr;\nproxy_set_header Host $host;\nproxy_pass http://127.0.0.1:8080;\n```\nhttps://www.digitalocean.com/community/questions/nginx-reverse-proxy-ip-forwarding\n\n","slug":"nginx","published":1,"updated":"2018-09-14T02:54:49.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5of00ctmcxqq6d7mkt6"},{"title":"nmap","date":"2016-06-06T11:09:00.000Z","_content":"\n端口扫描工具\n<!--more-->\n\n```\n# 扫描单个主机\nnmap scanme.nmap.org\n# 扫描整个子网\nnmap 192.168.1.1/24\n# 扫描多个目标\nnmap 192.168.1.2 192.168.1.5\n# 扫描范围目标\nnmap 192.168.1.1-100\n# 如果你有一个ip地址列表，将这个保存为一个txt文件，和namp在同一目录下,扫描这个txt内的所有主机\nnmap -iL target.txt\n参数 -iL: input from list\n# 显示扫描目标列表\nnmap -sL 192.168.1.1/24\n参数 -sL: List Scan - simply list targets to scan\n# 扫描除过某些ip外的所有子网主机\nnmap 192.168.1.1/24 -exclude 192.168.1.1-100\n# 指定端口\nnmap -p80,21,23 192.168.1.1\n```\n\n## Nmap的扫描技术\n```\nTcp SYN Scan (sS)\nnmap -sS 192.168.1.1\nTcp connect() scan(sT)\nnmap -sT 192.168.1.1\nUdp scan(sU)\nnmap -sU 192.168.1.1\nFIN scan (sF)\nnmap -sF 192.168.1.8\nPING Scan (sP)\nnmap -sP 192.168.1.1\n版本检测(sV)\nnmap -sV 192.168.1.1\nIdle scan (sL)\nnmap -sL 192.168.1.6 192.168.1.1\n```\n\n## Nmap的OS检测（O）, 只是猜, 不准\nnmap -O -PN 192.168.1.1/24\nnmap -O --osscan-guess 192.168.1.1\n\n## 其他\n#### sun-answerbook是什么鬼?\n出现在nmap的service列中\n调查发现: \nsun-answerbook是sun的过时的文档http服务,该服务正好也用8888端口,\n于是nmap看到8888端口就以为是sun answerbook, 其实不是, 所以nmap的这个不准\n用netstat -ontlp看看8888端口的进程名还能明白点\n\n## 参考链接\nhttp://www.2cto.com/Article/201207/142903.html\n\n","source":"_posts/nmap.md","raw":"title: nmap\ndate: 2016-06-06 19:09:00\ntags: [internet, test]\n---\n\n端口扫描工具\n<!--more-->\n\n```\n# 扫描单个主机\nnmap scanme.nmap.org\n# 扫描整个子网\nnmap 192.168.1.1/24\n# 扫描多个目标\nnmap 192.168.1.2 192.168.1.5\n# 扫描范围目标\nnmap 192.168.1.1-100\n# 如果你有一个ip地址列表，将这个保存为一个txt文件，和namp在同一目录下,扫描这个txt内的所有主机\nnmap -iL target.txt\n参数 -iL: input from list\n# 显示扫描目标列表\nnmap -sL 192.168.1.1/24\n参数 -sL: List Scan - simply list targets to scan\n# 扫描除过某些ip外的所有子网主机\nnmap 192.168.1.1/24 -exclude 192.168.1.1-100\n# 指定端口\nnmap -p80,21,23 192.168.1.1\n```\n\n## Nmap的扫描技术\n```\nTcp SYN Scan (sS)\nnmap -sS 192.168.1.1\nTcp connect() scan(sT)\nnmap -sT 192.168.1.1\nUdp scan(sU)\nnmap -sU 192.168.1.1\nFIN scan (sF)\nnmap -sF 192.168.1.8\nPING Scan (sP)\nnmap -sP 192.168.1.1\n版本检测(sV)\nnmap -sV 192.168.1.1\nIdle scan (sL)\nnmap -sL 192.168.1.6 192.168.1.1\n```\n\n## Nmap的OS检测（O）, 只是猜, 不准\nnmap -O -PN 192.168.1.1/24\nnmap -O --osscan-guess 192.168.1.1\n\n## 其他\n#### sun-answerbook是什么鬼?\n出现在nmap的service列中\n调查发现: \nsun-answerbook是sun的过时的文档http服务,该服务正好也用8888端口,\n于是nmap看到8888端口就以为是sun answerbook, 其实不是, 所以nmap的这个不准\n用netstat -ontlp看看8888端口的进程名还能明白点\n\n## 参考链接\nhttp://www.2cto.com/Article/201207/142903.html\n\n","slug":"nmap","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5og00cwmcxq1spyzhwz"},{"title":"坎坷之路 open-vm-tools","date":"2016-07-24T13:34:00.000Z","_content":"\n\n","source":"_posts/noteasy_open_vm_tools.md","raw":"title: 坎坷之路 open-vm-tools\ndate: 2016-07-24 21:34:00\ntags: linux\n---\n\n\n","slug":"noteasy_open_vm_tools","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5oh00cymcxq70ktss0p"},{"title":"-noshell参数启动的erlang如何让standard_io支持unicode","date":"2016-06-13T11:29:00.000Z","_content":"\n使用relx自动生成的启动脚本有foreground模式, 适合docker使用,\n使用后发现docker logs里出来的日志有许多乱码...\n<!--more-->\n\n查看脚本发现如下一行\n```\nFOREGROUNDOPTIONS=\"-noshell -noinput +Bd\"\n```\ngoogle搜索\"noshell unicode\", 在erlang文档里stdlib app的user guide中发现如下这段话:\n\n> io:setopts/{1,2} and the -oldshell/-noshell flags.\n> When Erlang is started with -oldshell or -noshell, the I/O-server for standard_io is default set to bytewise encoding, while an interactive shell defaults to what the environment variables says.\n> \n> With the io:setopts/2 function you can set the encoding of a file or other I/O-server. This can also be set when opening a file. Setting the terminal (or other standard_io server) unconditionally to the option {encoding,utf8} will for example make UTF-8 encoded characters being written to the device regardless of how Erlang was started or the users environment.\n> \n> Opening files with encoding option is convenient when writing or reading text files in a known encoding.\n> \n> You can retrieve the encoding setting for an I/O-server using io:getopts().\n\n找出error_logger的group_leader进程pid\n```\n> process_info(whereis(error_logger), group_leader).\n{group_leader,<0.615.0>}\n```\n发现是user进程\n```\n> process_info(pid(0,615,0), registered_name).\n{registered_name,user}\n```\n发现encoding为latin1\n```\n> io:getopts(user).                                 \n[{binary,false},{encoding,latin1}]\n```\n设为unicode\n```\n> io:setopts(user, [{encoding, unicode}]).          \nok\n> io:getopts(user).                       \n[{binary,false},{encoding,unicode}]\n```\n\n解决!\n\n## 参考链接\nhttp://erlang.org/doc/apps/stdlib/unicode_usage.html\nhttp://erlang.org/doc/man/user.html\n\n","source":"_posts/noshell_unicode.md","raw":"title: -noshell参数启动的erlang如何让standard_io支持unicode\ndate: 2016-06-13 19:29:00\ntags: [erlang, unicode]\n---\n\n使用relx自动生成的启动脚本有foreground模式, 适合docker使用,\n使用后发现docker logs里出来的日志有许多乱码...\n<!--more-->\n\n查看脚本发现如下一行\n```\nFOREGROUNDOPTIONS=\"-noshell -noinput +Bd\"\n```\ngoogle搜索\"noshell unicode\", 在erlang文档里stdlib app的user guide中发现如下这段话:\n\n> io:setopts/{1,2} and the -oldshell/-noshell flags.\n> When Erlang is started with -oldshell or -noshell, the I/O-server for standard_io is default set to bytewise encoding, while an interactive shell defaults to what the environment variables says.\n> \n> With the io:setopts/2 function you can set the encoding of a file or other I/O-server. This can also be set when opening a file. Setting the terminal (or other standard_io server) unconditionally to the option {encoding,utf8} will for example make UTF-8 encoded characters being written to the device regardless of how Erlang was started or the users environment.\n> \n> Opening files with encoding option is convenient when writing or reading text files in a known encoding.\n> \n> You can retrieve the encoding setting for an I/O-server using io:getopts().\n\n找出error_logger的group_leader进程pid\n```\n> process_info(whereis(error_logger), group_leader).\n{group_leader,<0.615.0>}\n```\n发现是user进程\n```\n> process_info(pid(0,615,0), registered_name).\n{registered_name,user}\n```\n发现encoding为latin1\n```\n> io:getopts(user).                                 \n[{binary,false},{encoding,latin1}]\n```\n设为unicode\n```\n> io:setopts(user, [{encoding, unicode}]).          \nok\n> io:getopts(user).                       \n[{binary,false},{encoding,unicode}]\n```\n\n解决!\n\n## 参考链接\nhttp://erlang.org/doc/apps/stdlib/unicode_usage.html\nhttp://erlang.org/doc/man/user.html\n\n","slug":"noshell_unicode","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5oj00d1mcxqohjjm1bc"},{"title":"noproxy 环境变量","date":"2018-10-08T16:00:00.000Z","_content":"\n格式是逗号分隔的\n```bash\nexport no_proxy=\"localhost,127.0.0.1,192.168.2.120\"\n```\n\n<!--more-->\n\n### 参考链接\nhttps://unix.stackexchange.com/questions/23452/set-a-network-range-in-the-no-proxy-environment-variable\n\n","source":"_posts/noproxy_env.md","raw":"title: noproxy 环境变量\ndate: 2018-10-09\ntags: [env, proxy]\n---\n\n格式是逗号分隔的\n```bash\nexport no_proxy=\"localhost,127.0.0.1,192.168.2.120\"\n```\n\n<!--more-->\n\n### 参考链接\nhttps://unix.stackexchange.com/questions/23452/set-a-network-range-in-the-no-proxy-environment-variable\n\n","slug":"noproxy_env","published":1,"updated":"2018-10-10T04:23:59.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ok00d3mcxq8tyr9gdb"},{"title":"odbc","date":"2021-07-30T04:00:00.000Z","_content":"\n今天想试试用 erlang/elixir 通过 odbc 读 excel, 结果...\n\n<!--more-->\n\n从 erlang mail list\n\nhttp://erlang.org/pipermail/erlang-questions/2009-April/043094.html\n\n这里读到可以通过 odbc 来读 excel, 就不用再去读 excel 的各个版本的 format(几百页...) 了\n\n立即着手去找 excel 的 odbc driver, 结果只找到一个 cdata 出的商业版的, \n\n立即下载试用, 安装后照着目录里带的 help.htm 操作了一波装好 driver\n\n先试一波 excel 2003, 即 xls\n\n```erlang\n1> odbc:start().\nok\n2> ConnStr = \"Driver={CData ODBC Driver for Excel};URI=/Users/chenduo/Downloads/53KF_broken.xls\".\n\"Driver={CData ODBC Driver for Excel};URI=/Users/chenduo/Downloads/53KF_broken.xls\"\n3> {ok, Ref} = odbc:connect( ConnStr, [{timeout, 45000}] ).\n{ok,<0.95.0>}\n4> odbc:sql_query(Ref, \"SELECT * FROM Worksheet;\").\n{error,\"This Excel file version is not supported. SQLSTATE IS: HY000\"}\n```\n\n歇菜...\n\n再试一波 excel 2007+, 即 xlsx\n\n```erlang\n1> odbc:start().\nok\n2> ConnStr = \"Driver={CData ODBC Driver for Excel};URI=/Users/chenduo/Downloads/test.xlsx\".\n\"Driver={CData ODBC Driver for Excel};URI=/Users/chenduo/Downloads/test.xlsx\"\n3> {ok, Ref} = odbc:connect( ConnStr, [{timeout, 45000}] ).\n{ok,<0.95.0>}\n4> odbc:sql_query(Ref, \"SELECT * FROM sheet1;\").\n{selected,[\"RowId\",\"head1\",\"head2\",\"head3\",\"head4\",\"head5\"],\n          [{2,\n            <<97,0,0,0,50,0,0,0>>,\n            <<49,0,0,0,48,0,0,0,48,0,0,0>>,\n            <<98,0,0,0,50,0,0,0>>,\n            <<99,0,0,0,50,0,0,0>>,\n            <<100,0,0,0,50,0,0,0>>},\n           {3,\n            <<101,0,0,0,50,0,0,0>>,\n            <<97,0,0,0,51,0,0,0>>,\n            <<98,0,0,0,51,0,0,0>>,\n            <<101,0,0,0,51,0,0,0>>,\n            <<99,0,0,0,51,0,0,0>>}]}\n```\n\n成功了, 我的excel内容是这样的\n\n| head1 | head2 | head3 | head4 | head5 |\n| ----- | ----- | ----- | ----- | ----- |\n| a2    | 100   | c2    | d2    | e2    |\n| a3    | b3    | c3    | d3    | e3    |\n\n看来它是把每一个字符变成 32bit 的 binary 给我返回来了, 表头的 \"RowId\"也不知道是啥\n\n总之算不上很好用, 而且这个 CData 还是 commercial 的\n\n## odbc driver\n\n网上逛了很久发现第三方的厂商主要就是 cdata 和 devart 两家, 都是商用的\n\n其他就是官方的, 比如 mysql, mariadb, sql server 各家自己出的\n\n## 参考链接\n\nexcel 的 format 链接如下:\n\nhttps://www.loc.gov/preservation/digital/formats/digformatspecs/Excel97-2007BinaryFileFormat(xls)Specification.pdf\n\nhttp://www.openoffice.org/sc/excelfileformat.pdf\n\nodbc相关链接\n\nhttp://www.unixodbc.org/\n\nhttps://www.cdata.com/drivers/excel/download/odbc/#macos\n\nhttps://www.connectionstrings.com/\n\n","source":"_posts/odbc.md","raw":"title: odbc\ndate: 2021-07-30 12:00:00\n\ntags: [odbc, erlang]\n---\n\n今天想试试用 erlang/elixir 通过 odbc 读 excel, 结果...\n\n<!--more-->\n\n从 erlang mail list\n\nhttp://erlang.org/pipermail/erlang-questions/2009-April/043094.html\n\n这里读到可以通过 odbc 来读 excel, 就不用再去读 excel 的各个版本的 format(几百页...) 了\n\n立即着手去找 excel 的 odbc driver, 结果只找到一个 cdata 出的商业版的, \n\n立即下载试用, 安装后照着目录里带的 help.htm 操作了一波装好 driver\n\n先试一波 excel 2003, 即 xls\n\n```erlang\n1> odbc:start().\nok\n2> ConnStr = \"Driver={CData ODBC Driver for Excel};URI=/Users/chenduo/Downloads/53KF_broken.xls\".\n\"Driver={CData ODBC Driver for Excel};URI=/Users/chenduo/Downloads/53KF_broken.xls\"\n3> {ok, Ref} = odbc:connect( ConnStr, [{timeout, 45000}] ).\n{ok,<0.95.0>}\n4> odbc:sql_query(Ref, \"SELECT * FROM Worksheet;\").\n{error,\"This Excel file version is not supported. SQLSTATE IS: HY000\"}\n```\n\n歇菜...\n\n再试一波 excel 2007+, 即 xlsx\n\n```erlang\n1> odbc:start().\nok\n2> ConnStr = \"Driver={CData ODBC Driver for Excel};URI=/Users/chenduo/Downloads/test.xlsx\".\n\"Driver={CData ODBC Driver for Excel};URI=/Users/chenduo/Downloads/test.xlsx\"\n3> {ok, Ref} = odbc:connect( ConnStr, [{timeout, 45000}] ).\n{ok,<0.95.0>}\n4> odbc:sql_query(Ref, \"SELECT * FROM sheet1;\").\n{selected,[\"RowId\",\"head1\",\"head2\",\"head3\",\"head4\",\"head5\"],\n          [{2,\n            <<97,0,0,0,50,0,0,0>>,\n            <<49,0,0,0,48,0,0,0,48,0,0,0>>,\n            <<98,0,0,0,50,0,0,0>>,\n            <<99,0,0,0,50,0,0,0>>,\n            <<100,0,0,0,50,0,0,0>>},\n           {3,\n            <<101,0,0,0,50,0,0,0>>,\n            <<97,0,0,0,51,0,0,0>>,\n            <<98,0,0,0,51,0,0,0>>,\n            <<101,0,0,0,51,0,0,0>>,\n            <<99,0,0,0,51,0,0,0>>}]}\n```\n\n成功了, 我的excel内容是这样的\n\n| head1 | head2 | head3 | head4 | head5 |\n| ----- | ----- | ----- | ----- | ----- |\n| a2    | 100   | c2    | d2    | e2    |\n| a3    | b3    | c3    | d3    | e3    |\n\n看来它是把每一个字符变成 32bit 的 binary 给我返回来了, 表头的 \"RowId\"也不知道是啥\n\n总之算不上很好用, 而且这个 CData 还是 commercial 的\n\n## odbc driver\n\n网上逛了很久发现第三方的厂商主要就是 cdata 和 devart 两家, 都是商用的\n\n其他就是官方的, 比如 mysql, mariadb, sql server 各家自己出的\n\n## 参考链接\n\nexcel 的 format 链接如下:\n\nhttps://www.loc.gov/preservation/digital/formats/digformatspecs/Excel97-2007BinaryFileFormat(xls)Specification.pdf\n\nhttp://www.openoffice.org/sc/excelfileformat.pdf\n\nodbc相关链接\n\nhttp://www.unixodbc.org/\n\nhttps://www.cdata.com/drivers/excel/download/odbc/#macos\n\nhttps://www.connectionstrings.com/\n\n","slug":"odbc","published":1,"updated":"2021-07-30T05:49:18.600Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ol00d6mcxq4b9pbcld"},{"title":"关于面向对象编程","date":"2015-10-12T16:00:00.000Z","_content":"\n## OOP的设计目标,实现手段和目标是否达成\nOOP最重要的目标，是OCP，即「开闭原则」,对扩展开放,对修改关闭,\n但是***OCP不是免费的***,教条主义泛滥,在不需要的地方使用OCP仅仅是浪费\n\n继承的意义并不很大，甚至常常是有害的。因为它使得子类与基类出现强耦合。\n接口规范带来的归一化的效果才是有用的, 但是***归一化本身并非必须是OOP***  \nGolang没有继承, smalltalk不用继承和接口也可以归一化, unix的泛文件概念也是归一化\n\n### 业界存在太多误导和误解\n一切皆对象实质上是在鼓励堆砌毫无意义的繁杂类设计,例如教条化的***设计模式驱动编程***\n为了设计模式而设计模式并无意义\n用面向对象语言写程序，和一个程序的设计是面向对象的，两者是八杆子打不着的两码事。\n纯C写的linux kernel事实上比c++/java之类语言搞出来的大多数项目更加面向对象\n\n### OOP提供的所谓「保证旧代码不需要被修改」(其实也保证不了)是否有意义\n面向对象编程有很多用途，很多用法，但是我们会发现「设计模式驱动」成为了非常有代表性的流派。\n有时我们会疑惑，为什么会有设计模式，为什么面向对象编程会出现如此恐怖的这么复杂的类关系。\n\n可能这是为了满足「增量式开发」。它假定几个前提：\n1，将一份代码测试调试稳定所需要花的时间，远远大于撰写代码的时间。\n2，已经通过测试的旧代码永远不修改，只对新代码进行新增，是最可靠的开发方式。\n3，你经常需要重用没有源代码的库，并且扩展和修改其功能。\n\n很多面向对象的设计，其实是为了满足一个很基本的目的：不修改旧代码，只新增代码。\n代码只增不改，所以才会出现「继承」这种东西。因为你不需要原有的源代码也不需要修改原有的类，而是派生一个类增加新的方法。\n「继承」的本来目的看起来就是为了解决这个问题。\n\n因此，很多类层次关系的设计，不是为了更高的效率，不是为了代码看起来更清晰，而是为了「保证旧代码不需要被修改」这个目的。\n\n不过，这是不是事实呢？在某些公司，这是事实，在很多公司，以上的假定不是事实。\n1，很多代码并没有经过长时间的充分的测试，因而没有必要为了不浪费原有测试资源而拒绝修改旧代码。\n2，修改旧代码在大多数公司是不可避免的。\n3，很多时候我们提倡读懂库的源代码，而不会盲目使用无源代码的库。\n4，现在流行的敏捷开发模型中宣传要拥抱变化。在敏捷模型中，测试案例是被固化的，而代码与架构都可以经常被修改，\n换句话说，***不修改旧代码，以及通过类层次关系设计系统架构，这些特性对敏捷来说都不重要，甚至背道而驰***。\n\n### 绑定数据和函数是否利于代码重用\n面向对象得目标是大规模重用代码。\n面向对象的手段是绑定数据和函数。\n面向对象的哲学含义是给客体下定义来完成形式化抽象。 目的说白了就是为了尽可能重用代码来减少程序员工作。\n但是矛盾的地方在于，真实世界中的客体的定义随着主体的看法而改变，换句话，不存在固定的形式化抽象，一切都要符合环境（上下文）。\n最简单的例子就是，中文词的含义天天变，只有根据环境知识才能知道是什么含义。\n而代码是为了具体问题而出现的，所以不存在通用抽象，也就不存在可以无限重用的定义和逻辑。\n\n更加合理的设计理念应该还是 提供机制而不限制策略 \n所以从这一点上来看，提供一个***常用的函数库要比精心设计复杂的对象模型要好的多***。\n\n更进一步，理想状态是全世界共享一种函数式语言，共享一份源代码，并对问题分类，\n将所有函数按照问题进行整理，只有这样感觉才能彻底避免重新发明轮子。\n\n### OOP鼻祖Smalltalk与C/JAVA的不同\n在 Smalltalk 里的“对象”实际上是一种高级的动态模块。\n一个 Smalltalk 程序，是由一系列这样的高级动态模块构成的。\n你可以在程序运行时（注意是运行时，而不是编译时）动态的修改、替换任意模块，而无需停止整个程序。\n\n之所以在模块二字前加上“高级”和“动态”，实际上是对比其他非面向对象语言而言的。\n\n例如 C 语言中你可以把 printf() 理解为一个控制台输出模块。\n但是这样的模块，用起来容易，却不太灵活——如果你有实际的编程经验肯定能有所体会。\n例如，你能够在程序运行的过程中，动态的替换掉 printf() 这个模块吗？\n你能够动态的改变 printf() 这个模块的代码吗？\n你能够动态的获取 printf() 这个模块的基本信息吗（参数列表，返回值甚至代码）？\n\n别说，你还真的能，因为你可以通过各种技巧间接的实现这一点，但是这这是你的发明创造，而不是 C 语言本身的特性。\n所以我们可以知道，C 语言对模块的支持仅仅止步于函数级别。\n\nSmalltalk 的亮点就在于，它在语言层面引入了一种称为“对象”的高级动态模块系统。\n一个 Smalltalk 程序由一系列的高级动态模块构成，每个模块之间通过通信进行协同。\n\n也就是说，Smalltalk 所秉承的面向对象思想使得整个软件系统的可分割性和可组合性迈上了一个新台阶。这是面向对象思想的光辉所在。\n\n现在我们回过头来看看 C++ 和 Java 中的面向对象。\n\n事实上，C++ 和 Java 在实现面向对象的路途上遇到的第一道坎是他们本身都是静态类型的语言。\n也就是说，这类语言的设计信条是一切结构皆须预先描述，因为编译器要检查。\n于是没什么悬念的的就走上了 Class-based OOP 这条路（另一条路是 Prototype-based OOP）。\n\nClass-based OOP 的一个特征是***对象的结构需要预先声明***，并且在运行过程中不允许改变—— \nC++ 和 Java 的作者有一千个理由这么干，最基本的原因就是性能考虑——但这样做的代价首先就削弱了系统的动态性。\n\n更糟糕的是，C++ 和 Java 中，连***对象的可替换性也需要预先声明***。\n我这么说一部分朋友可能没办法马上反应过来。其实就是说，在 Smalltalk 中，我们可以用任何一个对象随意替换掉另外一个，只要他们对外界而言行为一致，那么系统依然可以正常运行，\n这一点，在大家更熟悉的 Ruby、Javascript 等语言中，被称为 Duck-Type 概念。\n\n在 C++ 和 Java 中，你不能随意找个对象 x 来替换掉另外一个对象 y。即使他们拥有完全相同的行为也不行。\n因为 C++ 和 Java 是 Class-based OOP 所以连可替换性也需要预先声明！这种声明方式就是让无数人潸然泪下的——继承！\n即使一个对象 x 和 y 的行为是完全一样的，你也不能用 x 去替换 y。允许你替换的唯一前提是，x 被声明为继承自 y 的。\n简单的来说，“继承”是一人分饰两角的典型——它既作为代码复用的一种手段，同时又成为了可替换性的一种声明。\n这种设计非常失败，难以使用到直接导致了面向对象在 C++ 和 Java 中成为了一个阉割后的太监。\n\n为了弥补继承的这种缺陷，于是引入了 Interface （只表明可替换性，不复用代码），\n但这也改变不了什么了。毕竟 Interface 竟然也开始互相玩起了继承的游戏……\n\n### OO的弊端就是：设计抽象和封装的时间远远超过你解决问题的时间。\n软件工程里对一个大型项目而言这样其实已经***背离了设计规则，不是将一个大问题进行分解，而是将它放到一个更大的一个问题里***，\n你会发现OO就是不断地重构，重构，你会重新思考接口，重新改进设计模式，等等，一切，而却忽略了真正解决问题。\n我曾一度觉得OO是大师们的智慧结晶，其实可以说这些是哲学的产物吧。等你发现，早已深陷其中。\n还是要从实际解决问题入手！ \n\n### 静态的OO结构难以应对变化\n\n我举一个具体的例子。假如一个组织的组织架构是静态的，那么OO方法足以描述这个组织，也可以在架构和人员不变的前提下定义好正常的公文流转等业务流程。\n只要组织里的人、职责是固定的，那么用OO就足以按照组织机构树和职责进行分而治之。\n\n但是，世界上不存在这么完美的事情。组织里某个人可能要请假造成公文无法流转，有人可能要临时身兼数职、有些公文突然会要求会签... \n你马上会发现，看起来严谨的组织机构树和职责定义面对这么多的“临时状况”毫无应变的灵活性，而“临时状况”从上线第一天起就没有停过。\n显然，OO的方法学在面对不断变化且超出设计预期的“状态”时非常非常力不从心。\n（在OO的年代，我也尝试通过定义复杂状态机的方法来应对这个问题，但是同样地，设计阶段枚举得好好的状态，到了真实业务运转时完全走了样。）\n\n所以，***对于不断变化的“状态”我们必须引入新的“分而治之”的方法***，\n这就是为什么函数式编程(Functional Reactive Programming)、流编程（Unix或者Node.JS中的 Stream）现在越来越多地被应用在设计中的原因。\n\n描述静态关系时，OO仍然是有用的，但是在应对复杂变化且相互变化的状态时，只有函数式编程方式可以让状态之间松耦。\n\n## 性能\n由于内存墙,内存存取成为现代计算机性能的重要瓶颈,\n现时的OOP编程有可能不缓存友好（cache friendly），导致有时候并不能发挥硬件最佳性能\n过度封装,多态,OOP的数据布局都会增大cache miss的可能性\n\n## Joe Armstrong的观点\n\n1. 数据结构和函数不应该被绑定到一起.这是最根本的错误,函数和数据完全不同,函数将输入转为输出,数据结构就是数据的结构,绑定到一起限制了它们的使用.\n2. 什么都必须是对象.连Time都必须是一个对象,Erlang里Time并不是对象.\n3. 数据类型定义散落在各个类里.Erlang或C可以在一个头文件里定义数据类型\n4. 对象有私有状态.状态是一切罪恶的根源,OOP不是直面状态尽可能将状态带来的影响减到最小,而是隐藏状态\n\nOOP流行只是因为炒作,因为它可以创造一个新的软件工业,赚更多的钱\n\n# 参考链接\nhttp://www.zhihu.com/question/20275578\nhttp://harmful.cat-v.org/software/OO_programming/why_oo_sucks\n\n","source":"_posts/oo_sucks.md","raw":"title: 关于面向对象编程\ndate: 2015-10-13\ntags: [programming]\n---\n\n## OOP的设计目标,实现手段和目标是否达成\nOOP最重要的目标，是OCP，即「开闭原则」,对扩展开放,对修改关闭,\n但是***OCP不是免费的***,教条主义泛滥,在不需要的地方使用OCP仅仅是浪费\n\n继承的意义并不很大，甚至常常是有害的。因为它使得子类与基类出现强耦合。\n接口规范带来的归一化的效果才是有用的, 但是***归一化本身并非必须是OOP***  \nGolang没有继承, smalltalk不用继承和接口也可以归一化, unix的泛文件概念也是归一化\n\n### 业界存在太多误导和误解\n一切皆对象实质上是在鼓励堆砌毫无意义的繁杂类设计,例如教条化的***设计模式驱动编程***\n为了设计模式而设计模式并无意义\n用面向对象语言写程序，和一个程序的设计是面向对象的，两者是八杆子打不着的两码事。\n纯C写的linux kernel事实上比c++/java之类语言搞出来的大多数项目更加面向对象\n\n### OOP提供的所谓「保证旧代码不需要被修改」(其实也保证不了)是否有意义\n面向对象编程有很多用途，很多用法，但是我们会发现「设计模式驱动」成为了非常有代表性的流派。\n有时我们会疑惑，为什么会有设计模式，为什么面向对象编程会出现如此恐怖的这么复杂的类关系。\n\n可能这是为了满足「增量式开发」。它假定几个前提：\n1，将一份代码测试调试稳定所需要花的时间，远远大于撰写代码的时间。\n2，已经通过测试的旧代码永远不修改，只对新代码进行新增，是最可靠的开发方式。\n3，你经常需要重用没有源代码的库，并且扩展和修改其功能。\n\n很多面向对象的设计，其实是为了满足一个很基本的目的：不修改旧代码，只新增代码。\n代码只增不改，所以才会出现「继承」这种东西。因为你不需要原有的源代码也不需要修改原有的类，而是派生一个类增加新的方法。\n「继承」的本来目的看起来就是为了解决这个问题。\n\n因此，很多类层次关系的设计，不是为了更高的效率，不是为了代码看起来更清晰，而是为了「保证旧代码不需要被修改」这个目的。\n\n不过，这是不是事实呢？在某些公司，这是事实，在很多公司，以上的假定不是事实。\n1，很多代码并没有经过长时间的充分的测试，因而没有必要为了不浪费原有测试资源而拒绝修改旧代码。\n2，修改旧代码在大多数公司是不可避免的。\n3，很多时候我们提倡读懂库的源代码，而不会盲目使用无源代码的库。\n4，现在流行的敏捷开发模型中宣传要拥抱变化。在敏捷模型中，测试案例是被固化的，而代码与架构都可以经常被修改，\n换句话说，***不修改旧代码，以及通过类层次关系设计系统架构，这些特性对敏捷来说都不重要，甚至背道而驰***。\n\n### 绑定数据和函数是否利于代码重用\n面向对象得目标是大规模重用代码。\n面向对象的手段是绑定数据和函数。\n面向对象的哲学含义是给客体下定义来完成形式化抽象。 目的说白了就是为了尽可能重用代码来减少程序员工作。\n但是矛盾的地方在于，真实世界中的客体的定义随着主体的看法而改变，换句话，不存在固定的形式化抽象，一切都要符合环境（上下文）。\n最简单的例子就是，中文词的含义天天变，只有根据环境知识才能知道是什么含义。\n而代码是为了具体问题而出现的，所以不存在通用抽象，也就不存在可以无限重用的定义和逻辑。\n\n更加合理的设计理念应该还是 提供机制而不限制策略 \n所以从这一点上来看，提供一个***常用的函数库要比精心设计复杂的对象模型要好的多***。\n\n更进一步，理想状态是全世界共享一种函数式语言，共享一份源代码，并对问题分类，\n将所有函数按照问题进行整理，只有这样感觉才能彻底避免重新发明轮子。\n\n### OOP鼻祖Smalltalk与C/JAVA的不同\n在 Smalltalk 里的“对象”实际上是一种高级的动态模块。\n一个 Smalltalk 程序，是由一系列这样的高级动态模块构成的。\n你可以在程序运行时（注意是运行时，而不是编译时）动态的修改、替换任意模块，而无需停止整个程序。\n\n之所以在模块二字前加上“高级”和“动态”，实际上是对比其他非面向对象语言而言的。\n\n例如 C 语言中你可以把 printf() 理解为一个控制台输出模块。\n但是这样的模块，用起来容易，却不太灵活——如果你有实际的编程经验肯定能有所体会。\n例如，你能够在程序运行的过程中，动态的替换掉 printf() 这个模块吗？\n你能够动态的改变 printf() 这个模块的代码吗？\n你能够动态的获取 printf() 这个模块的基本信息吗（参数列表，返回值甚至代码）？\n\n别说，你还真的能，因为你可以通过各种技巧间接的实现这一点，但是这这是你的发明创造，而不是 C 语言本身的特性。\n所以我们可以知道，C 语言对模块的支持仅仅止步于函数级别。\n\nSmalltalk 的亮点就在于，它在语言层面引入了一种称为“对象”的高级动态模块系统。\n一个 Smalltalk 程序由一系列的高级动态模块构成，每个模块之间通过通信进行协同。\n\n也就是说，Smalltalk 所秉承的面向对象思想使得整个软件系统的可分割性和可组合性迈上了一个新台阶。这是面向对象思想的光辉所在。\n\n现在我们回过头来看看 C++ 和 Java 中的面向对象。\n\n事实上，C++ 和 Java 在实现面向对象的路途上遇到的第一道坎是他们本身都是静态类型的语言。\n也就是说，这类语言的设计信条是一切结构皆须预先描述，因为编译器要检查。\n于是没什么悬念的的就走上了 Class-based OOP 这条路（另一条路是 Prototype-based OOP）。\n\nClass-based OOP 的一个特征是***对象的结构需要预先声明***，并且在运行过程中不允许改变—— \nC++ 和 Java 的作者有一千个理由这么干，最基本的原因就是性能考虑——但这样做的代价首先就削弱了系统的动态性。\n\n更糟糕的是，C++ 和 Java 中，连***对象的可替换性也需要预先声明***。\n我这么说一部分朋友可能没办法马上反应过来。其实就是说，在 Smalltalk 中，我们可以用任何一个对象随意替换掉另外一个，只要他们对外界而言行为一致，那么系统依然可以正常运行，\n这一点，在大家更熟悉的 Ruby、Javascript 等语言中，被称为 Duck-Type 概念。\n\n在 C++ 和 Java 中，你不能随意找个对象 x 来替换掉另外一个对象 y。即使他们拥有完全相同的行为也不行。\n因为 C++ 和 Java 是 Class-based OOP 所以连可替换性也需要预先声明！这种声明方式就是让无数人潸然泪下的——继承！\n即使一个对象 x 和 y 的行为是完全一样的，你也不能用 x 去替换 y。允许你替换的唯一前提是，x 被声明为继承自 y 的。\n简单的来说，“继承”是一人分饰两角的典型——它既作为代码复用的一种手段，同时又成为了可替换性的一种声明。\n这种设计非常失败，难以使用到直接导致了面向对象在 C++ 和 Java 中成为了一个阉割后的太监。\n\n为了弥补继承的这种缺陷，于是引入了 Interface （只表明可替换性，不复用代码），\n但这也改变不了什么了。毕竟 Interface 竟然也开始互相玩起了继承的游戏……\n\n### OO的弊端就是：设计抽象和封装的时间远远超过你解决问题的时间。\n软件工程里对一个大型项目而言这样其实已经***背离了设计规则，不是将一个大问题进行分解，而是将它放到一个更大的一个问题里***，\n你会发现OO就是不断地重构，重构，你会重新思考接口，重新改进设计模式，等等，一切，而却忽略了真正解决问题。\n我曾一度觉得OO是大师们的智慧结晶，其实可以说这些是哲学的产物吧。等你发现，早已深陷其中。\n还是要从实际解决问题入手！ \n\n### 静态的OO结构难以应对变化\n\n我举一个具体的例子。假如一个组织的组织架构是静态的，那么OO方法足以描述这个组织，也可以在架构和人员不变的前提下定义好正常的公文流转等业务流程。\n只要组织里的人、职责是固定的，那么用OO就足以按照组织机构树和职责进行分而治之。\n\n但是，世界上不存在这么完美的事情。组织里某个人可能要请假造成公文无法流转，有人可能要临时身兼数职、有些公文突然会要求会签... \n你马上会发现，看起来严谨的组织机构树和职责定义面对这么多的“临时状况”毫无应变的灵活性，而“临时状况”从上线第一天起就没有停过。\n显然，OO的方法学在面对不断变化且超出设计预期的“状态”时非常非常力不从心。\n（在OO的年代，我也尝试通过定义复杂状态机的方法来应对这个问题，但是同样地，设计阶段枚举得好好的状态，到了真实业务运转时完全走了样。）\n\n所以，***对于不断变化的“状态”我们必须引入新的“分而治之”的方法***，\n这就是为什么函数式编程(Functional Reactive Programming)、流编程（Unix或者Node.JS中的 Stream）现在越来越多地被应用在设计中的原因。\n\n描述静态关系时，OO仍然是有用的，但是在应对复杂变化且相互变化的状态时，只有函数式编程方式可以让状态之间松耦。\n\n## 性能\n由于内存墙,内存存取成为现代计算机性能的重要瓶颈,\n现时的OOP编程有可能不缓存友好（cache friendly），导致有时候并不能发挥硬件最佳性能\n过度封装,多态,OOP的数据布局都会增大cache miss的可能性\n\n## Joe Armstrong的观点\n\n1. 数据结构和函数不应该被绑定到一起.这是最根本的错误,函数和数据完全不同,函数将输入转为输出,数据结构就是数据的结构,绑定到一起限制了它们的使用.\n2. 什么都必须是对象.连Time都必须是一个对象,Erlang里Time并不是对象.\n3. 数据类型定义散落在各个类里.Erlang或C可以在一个头文件里定义数据类型\n4. 对象有私有状态.状态是一切罪恶的根源,OOP不是直面状态尽可能将状态带来的影响减到最小,而是隐藏状态\n\nOOP流行只是因为炒作,因为它可以创造一个新的软件工业,赚更多的钱\n\n# 参考链接\nhttp://www.zhihu.com/question/20275578\nhttp://harmful.cat-v.org/software/OO_programming/why_oo_sucks\n\n","slug":"oo_sucks","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5on00d8mcxqs15r37y0"},{"title":"npm","date":"2018-10-19T16:00:00.000Z","_content":"\n这里慢慢积攒一些 npm 相关的事情\n\n```\nnpm config set registry https://registry.npm.taobao.org --global\n```\n\n","source":"_posts/npm.md","raw":"title: npm\ndate: 2018-10-20\ntags: [node, npm]\n---\n\n这里慢慢积攒一些 npm 相关的事情\n\n```\nnpm config set registry https://registry.npm.taobao.org --global\n```\n\n","slug":"npm","published":1,"updated":"2018-10-20T13:12:31.885Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5oo00dbmcxqdho834vm"},{"title":"U盘复制文件时系统提示文件过大无法复制","date":"2015-07-16T04:00:00.000Z","_content":"查看U盘的文件系统是FAT32还是NTFS\n如果是FAT32的话,不能复制超过4G的文件\n格式化为NTFS即可\n\n","source":"_posts/os_copyfile_toobig.md","raw":"title: U盘复制文件时系统提示文件过大无法复制\ndate: 2015-07-16 12:00:00\ntags: windows \n---\n查看U盘的文件系统是FAT32还是NTFS\n如果是FAT32的话,不能复制超过4G的文件\n格式化为NTFS即可\n\n","slug":"os_copyfile_toobig","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5op00ddmcxqsva7xd0v"},{"title":"操作系统中锁的实现原理","date":"2016-01-03T16:00:00.000Z","_content":"\n大概有test and set硬件指令和关中断,锁内存总线等同步机制\n\n<!--more-->\n\n## 参考链接\nhttp://blog.sina.com.cn/s/blog_75f0b54d0100r7af.html  \nhttps://en.wikipedia.org/wiki/Test-and-set\nhttp://faculty.salina.k-state.edu/tim/ossg/IPC_sync/ts.html\nhttp://www.moserware.com/2008/09/how-do-locks-lock.html\nhttps://software.intel.com/en-us/node/544402\nhttp://book.51cto.com/art/201205/337730.htm\n\n","source":"_posts/os_lock.md","raw":"title: 操作系统中锁的实现原理\ndate: 2016-01-04\ntags: [computer]\n---\n\n大概有test and set硬件指令和关中断,锁内存总线等同步机制\n\n<!--more-->\n\n## 参考链接\nhttp://blog.sina.com.cn/s/blog_75f0b54d0100r7af.html  \nhttps://en.wikipedia.org/wiki/Test-and-set\nhttp://faculty.salina.k-state.edu/tim/ossg/IPC_sync/ts.html\nhttp://www.moserware.com/2008/09/how-do-locks-lock.html\nhttps://software.intel.com/en-us/node/544402\nhttp://book.51cto.com/art/201205/337730.htm\n\n","slug":"os_lock","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5oq00dgmcxqe4efozn8"},{"title":"pgrep & pkill","date":"2016-06-16T07:19:00.000Z","_content":"\npkill可以使用名称给进程发信号,\n使用pkill之前,可以用pgrep命令确认一下\n```\n$ pgrep -a php5-fpm\n26677 php-fpm: master process (/etc/php5/fpm/php-fpm.conf)\n26680 php-fpm: pool www\n26681 php-fpm: pool www\n$ sudo pkill -HUP php5-fpm\n```\n","source":"_posts/pgrep_pkill_cmd.md","raw":"title: pgrep & pkill\ndate: 2016-06-16 15:19:00\ntags: [linux]\n---\n\npkill可以使用名称给进程发信号,\n使用pkill之前,可以用pgrep命令确认一下\n```\n$ pgrep -a php5-fpm\n26677 php-fpm: master process (/etc/php5/fpm/php-fpm.conf)\n26680 php-fpm: pool www\n26681 php-fpm: pool www\n$ sudo pkill -HUP php5-fpm\n```\n","slug":"pgrep_pkill_cmd","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5or00dimcxqjffq01fv"},{"title":"phpmyadmin","date":"2015-08-12T16:00:00.000Z","_content":"基于web的图形化mysql管理工具\n<!--more-->\n## 安装\n```bash\nsudo apt-get install phpmyadmin\n```\n系统默认安装在了/usr/share/下\n到/var/www/html下建立一个软连接,指向/usr/share/phpmyadmin\n```bash\nsudo ln -s /usr/share/phpmyadmin phpmyadmin\n```\n打开浏览器进入\nhttp://localhost/phpmyadmin\n\n## 解决导航面板翻页问题\n默认50张表导航面板就会翻页,在第1页的搜索框里搜不到第2页的表,影响工作效率\nconfig.inc.php配置文件中加入以覆盖默认值,改为200条或更大\n$cfg['MaxNavigationItems']=200\n\n","source":"_posts/phpmyadmin.md","raw":"title: phpmyadmin\ndate: 2015-08-13\ntags: [mysql, db, linux]\n---\n基于web的图形化mysql管理工具\n<!--more-->\n## 安装\n```bash\nsudo apt-get install phpmyadmin\n```\n系统默认安装在了/usr/share/下\n到/var/www/html下建立一个软连接,指向/usr/share/phpmyadmin\n```bash\nsudo ln -s /usr/share/phpmyadmin phpmyadmin\n```\n打开浏览器进入\nhttp://localhost/phpmyadmin\n\n## 解决导航面板翻页问题\n默认50张表导航面板就会翻页,在第1页的搜索框里搜不到第2页的表,影响工作效率\nconfig.inc.php配置文件中加入以覆盖默认值,改为200条或更大\n$cfg['MaxNavigationItems']=200\n\n","slug":"phpmyadmin","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5os00dlmcxq5vexqdpb"},{"title":"polipo","date":"2016-08-06T16:00:00.000Z","_content":"\n有时光有socks5代理还不行, 有些应用只认http代理,\n无奈, socks5 -> http\n\n<!--more-->\n\n## 结合polipo将socks5转换成http代理                                              \n\n    sudo apt-get install polipo                                                      \n    sudo vim /etc/polipo/config \n\n配置如下:                                                                        \n\n    logSyslog = true                                                                 \n    logFile = /var/log/polipo/polipo.log                                                 \n    socksParentProxy = \"127.0.0.1:1080\"                                              \n    socksProxyType = socks5                                                          \n    proxyAddress = \"::0\"        # both IPv4 and IPv6                                 \n    # or IPv4 only                                                                   \n    # # proxyAddress = \"0.0.0.0\"                                                     \n    proxyPort = 8123  \n启动, 最好不用sudo(基本原则,能不用root权限就不用root权限),\n\n    polipo -c /opt/local/etc/polipo/config\n使用浏览器可以访问如下页面, 测试polipo是否已启动                                 \nhttp://localhost:8123/                                                           \n测试是否可用                                                                     \n\n    curl --proxy http://127.0.0.1:8123 https://www.google.com  \n其他使用方法                                                                     \n\n    http_proxy=http://localhost:8123 apt-get update                                  \n    http_proxy=http://localhost:8123 curl www.google.com                             \n    http_proxy=http://localhost:8123 wget www.google.com                             \n    git config --global http.proxy 127.0.0.1:8123                                    \n    git clone https://github.com/xxx/xxx.git                                         \n    git xxx                                                                          \n    git xxx                                                                          \n    git config --global --unset-all http.proxy  \n重启                                                                             \n\n    sudo service polipo restart  \n帮助                                                                             \n\n    man polipo \n\n## 手动编译\n\n编译后在后台启动\n\n    $ sudo polipo daemonise=true logFile=\"/var/log/polipo.log\"\n\n## 参考链接\nhttps://github.com/jech/polipo/blob/master/INSTALL\nhttps://github.com/shadowsocks/shadowsocks/wiki/Convert-Shadowsocks-into-an-HTTP-proxy\n\n","source":"_posts/polipo.md","raw":"title: polipo\ndate: 2016-08-07\ntags: [internet, linux, proxy]\n---\n\n有时光有socks5代理还不行, 有些应用只认http代理,\n无奈, socks5 -> http\n\n<!--more-->\n\n## 结合polipo将socks5转换成http代理                                              \n\n    sudo apt-get install polipo                                                      \n    sudo vim /etc/polipo/config \n\n配置如下:                                                                        \n\n    logSyslog = true                                                                 \n    logFile = /var/log/polipo/polipo.log                                                 \n    socksParentProxy = \"127.0.0.1:1080\"                                              \n    socksProxyType = socks5                                                          \n    proxyAddress = \"::0\"        # both IPv4 and IPv6                                 \n    # or IPv4 only                                                                   \n    # # proxyAddress = \"0.0.0.0\"                                                     \n    proxyPort = 8123  \n启动, 最好不用sudo(基本原则,能不用root权限就不用root权限),\n\n    polipo -c /opt/local/etc/polipo/config\n使用浏览器可以访问如下页面, 测试polipo是否已启动                                 \nhttp://localhost:8123/                                                           \n测试是否可用                                                                     \n\n    curl --proxy http://127.0.0.1:8123 https://www.google.com  \n其他使用方法                                                                     \n\n    http_proxy=http://localhost:8123 apt-get update                                  \n    http_proxy=http://localhost:8123 curl www.google.com                             \n    http_proxy=http://localhost:8123 wget www.google.com                             \n    git config --global http.proxy 127.0.0.1:8123                                    \n    git clone https://github.com/xxx/xxx.git                                         \n    git xxx                                                                          \n    git xxx                                                                          \n    git config --global --unset-all http.proxy  \n重启                                                                             \n\n    sudo service polipo restart  \n帮助                                                                             \n\n    man polipo \n\n## 手动编译\n\n编译后在后台启动\n\n    $ sudo polipo daemonise=true logFile=\"/var/log/polipo.log\"\n\n## 参考链接\nhttps://github.com/jech/polipo/blob/master/INSTALL\nhttps://github.com/shadowsocks/shadowsocks/wiki/Convert-Shadowsocks-into-an-HTTP-proxy\n\n","slug":"polipo","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ot00dnmcxqsjr9oavj"},{"title":"使用ppa源","date":"2015-07-27T16:00:00.000Z","_content":"## 使用ppa源安装官方源里没有的软件\nsudo add-apt-repository ppa:ubuntu-wine/ppa\nsudo apt-get update\nsudo apt-get install wine\n## 删除\ncd /etc/apt/sources.list.d/\n可以看到关于源的文件,删除即可\n或者GUI的方式: 系统设置->软件和更新->其他软件,删除不想要的源\n\n","source":"_posts/ppa源.md","raw":"title: 使用ppa源\ndate: 2015-07-28\ntags: linux\n---\n## 使用ppa源安装官方源里没有的软件\nsudo add-apt-repository ppa:ubuntu-wine/ppa\nsudo apt-get update\nsudo apt-get install wine\n## 删除\ncd /etc/apt/sources.list.d/\n可以看到关于源的文件,删除即可\n或者GUI的方式: 系统设置->软件和更新->其他软件,删除不想要的源\n\n","slug":"ppa源","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ou00dqmcxqm4uodaww"},{"title":"阿里云 polardb 体验有感","date":"2021-07-28T16:00:00.000Z","_content":"\n记录一下目前为止的感受, 写一些官方文档里没有说的话\n\n<!--more-->\n\n### TDE加密\n\n开启TDE时, 8.0版本下可以选择新建的表都自动加密, 否则的话, 对每个表都需要手动开启加密模式\n\n```mysql\n# 对于老表 \nALTER TABLE <tablename> ENCRYPTION = 'Y';\n# 对于新表\nCREATE TABLE t1 (id int PRIMARY KEY,c1 varchar(10)) ENCRYPTION= 'Y'; \n```\n\n这里的ALTER TABLE需要挺长时间, 阿里云给出的估算时间是 100MB/s, 实测达不到这个速度, 可能与机器配置有关吧, 我算的是大约 50MB/s, 8C32G的配置\n\n对于大表来说还是很慢, 难以接受, 更难受的一点是过程中会占用元数据锁(MDL), 于是DML都会卡住, 所以最好是一开始就加密, 要不就建议用DTS工具同步到一张新表再改名的方法来做\n\n阿里云DTS工具还是比较好用\n\n\n\n### 秒加字段\n\n线上一个 40亿行的大表\n\nmysql> alter table message add column test_field int NOT NULL;\nQuery OK, 0 rows affected (0.47 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\n这个真的很开心\n\n不过 drop column 就和以前一样很慢了, 大概还是 COPY 的方式吧\n\n或者用 DMS 的无锁变更或者 pt_online_schema_change 等等东西去搞也是非常慢\n\n所以不要 drop column, 如果你有洁癖看不得废字段的话,\n\n先把应用里用到这个column的地方都改掉, 然后\n\n`ALTER TABLE message RENAME COLUMN test_field TO xxx_deprecated;`\n\n这样搞吧, 感觉比较舒服些\n\n如果这个字段里面还没有值, 比如全是0或空串或null的话, 那就\n\n`ALTER TABLE message RENAME COLUMN test_field TO reserved1;`\n\n","source":"_posts/polardb.md","raw":"title: 阿里云 polardb 体验有感\ndate: 2021-07-29\n\ntags: [mysql, db]\n---\n\n记录一下目前为止的感受, 写一些官方文档里没有说的话\n\n<!--more-->\n\n### TDE加密\n\n开启TDE时, 8.0版本下可以选择新建的表都自动加密, 否则的话, 对每个表都需要手动开启加密模式\n\n```mysql\n# 对于老表 \nALTER TABLE <tablename> ENCRYPTION = 'Y';\n# 对于新表\nCREATE TABLE t1 (id int PRIMARY KEY,c1 varchar(10)) ENCRYPTION= 'Y'; \n```\n\n这里的ALTER TABLE需要挺长时间, 阿里云给出的估算时间是 100MB/s, 实测达不到这个速度, 可能与机器配置有关吧, 我算的是大约 50MB/s, 8C32G的配置\n\n对于大表来说还是很慢, 难以接受, 更难受的一点是过程中会占用元数据锁(MDL), 于是DML都会卡住, 所以最好是一开始就加密, 要不就建议用DTS工具同步到一张新表再改名的方法来做\n\n阿里云DTS工具还是比较好用\n\n\n\n### 秒加字段\n\n线上一个 40亿行的大表\n\nmysql> alter table message add column test_field int NOT NULL;\nQuery OK, 0 rows affected (0.47 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\n这个真的很开心\n\n不过 drop column 就和以前一样很慢了, 大概还是 COPY 的方式吧\n\n或者用 DMS 的无锁变更或者 pt_online_schema_change 等等东西去搞也是非常慢\n\n所以不要 drop column, 如果你有洁癖看不得废字段的话,\n\n先把应用里用到这个column的地方都改掉, 然后\n\n`ALTER TABLE message RENAME COLUMN test_field TO xxx_deprecated;`\n\n这样搞吧, 感觉比较舒服些\n\n如果这个字段里面还没有值, 比如全是0或空串或null的话, 那就\n\n`ALTER TABLE message RENAME COLUMN test_field TO reserved1;`\n\n","slug":"polardb","published":1,"updated":"2021-07-29T12:53:17.841Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ov00dsmcxqypmdozhy"},{"title":"编程心得","date":"2016-08-15T13:27:00.000Z","_content":"\n## 如何少出bug\n\n任何和timer相关或异步的操作(如启动一个web server),\n都要考虑使用的时候是否已启动或前提条件是否满足等\n\n用到减法(加法也要小心, 怕加到负数)时要考虑结果为负数的情况\n\n用到除法时要考虑除零的情况\n\n","source":"_posts/programming_mind.md","raw":"title: 编程心得\ndate: 2016-08-15 21:27:00\ntags: [programming]\n---\n\n## 如何少出bug\n\n任何和timer相关或异步的操作(如启动一个web server),\n都要考虑使用的时候是否已启动或前提条件是否满足等\n\n用到减法(加法也要小心, 怕加到负数)时要考虑结果为负数的情况\n\n用到除法时要考虑除零的情况\n\n","slug":"programming_mind","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ow00dvmcxqc1vms2rn"},{"title":"编程点滴","date":"2019-01-29T12:04:00.000Z","_content":"日常引起思考的点点滴滴\n<!--more-->\n\n#### 对一个 byte 执行 & 0xff 是干什么? 意义何在?\n例:\n```\nint n = (0xff & byte_a) + (0xff & byte_b);\n```\n根本原因是 Java 这样的语言里没有 unsigned byte\n在处理二进制数据的时候为了得到一个 unsigned byte 的效果, 就只能这么做了\n0xff 一个 32 位字面值, 即 00 00 00 ff , 和一个 byte 做与运算后得到一个int\n如: -1 会变成 255 , 而 255 正是想要的 unsigned byte 值\n反之, 如果直接 `int n = byte_a;` 就会得到 -1\n\n保持二进制补码的一致性 因为byte类型字符是8bit的  而int为32bit 会自动补齐高位1\n所以与上0xFF之后可以保持高位一致性 当byte要转化为int的时候，高的24位必然会补1，这样，其二进制补码其实已经不一致了，\n& 0xff可以将高的24位置为0，低8位保持原样，这样做的目的就是为了保证二进制数据的一致性。\n\n","source":"_posts/programming_drips.md","raw":"title: 编程点滴\ndate: 2019-01-29 20:04:00\ntags: programming\n---\n日常引起思考的点点滴滴\n<!--more-->\n\n#### 对一个 byte 执行 & 0xff 是干什么? 意义何在?\n例:\n```\nint n = (0xff & byte_a) + (0xff & byte_b);\n```\n根本原因是 Java 这样的语言里没有 unsigned byte\n在处理二进制数据的时候为了得到一个 unsigned byte 的效果, 就只能这么做了\n0xff 一个 32 位字面值, 即 00 00 00 ff , 和一个 byte 做与运算后得到一个int\n如: -1 会变成 255 , 而 255 正是想要的 unsigned byte 值\n反之, 如果直接 `int n = byte_a;` 就会得到 -1\n\n保持二进制补码的一致性 因为byte类型字符是8bit的  而int为32bit 会自动补齐高位1\n所以与上0xFF之后可以保持高位一致性 当byte要转化为int的时候，高的24位必然会补1，这样，其二进制补码其实已经不一致了，\n& 0xff可以将高的24位置为0，低8位保持原样，这样做的目的就是为了保证二进制数据的一致性。\n\n","slug":"programming_drips","published":1,"updated":"2019-01-29T07:11:39.286Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ox00dxmcxq2tnqse98"},{"title":"python","date":"2016-07-18T08:52:00.000Z","_content":"\n## virtualenv\n沙箱机制\nubuntu 14.04用的是python 2.7.6, 有些旧了\n自己上python官网下载了2.7.12的源码并编译安装，\n创建virtualenv使用如下命令, 在新环境里使用2.7.12\n```\nvirtualenv --python=/usr/local/bin/python venv\n```\n\n## 解决问题: 自己编译的python,方向键不能用\n\n原来是编译时缺一些dev, 没有编译readline\n```\nsudo apt-get install libreadline6 libreadline6-dev\nsudo apt-get install libgdbm-dev\nsudo apt-get install libsqlite3-dev\nsudo apt-get install libbz2-dev\n```\n有第一个就可以解决方向键的问题，剩下的是其他依赖，\n不需要的话就可以不管\n做完这些之后再重新编译一遍python就好\n\n```\nsudo apt-get install python-dev\nsudo easy_install gnureadline\n```\n\n","source":"_posts/python.md","raw":"title: python\ndate: 2016-07-18 16:52:00\ntags: linux\n---\n\n## virtualenv\n沙箱机制\nubuntu 14.04用的是python 2.7.6, 有些旧了\n自己上python官网下载了2.7.12的源码并编译安装，\n创建virtualenv使用如下命令, 在新环境里使用2.7.12\n```\nvirtualenv --python=/usr/local/bin/python venv\n```\n\n## 解决问题: 自己编译的python,方向键不能用\n\n原来是编译时缺一些dev, 没有编译readline\n```\nsudo apt-get install libreadline6 libreadline6-dev\nsudo apt-get install libgdbm-dev\nsudo apt-get install libsqlite3-dev\nsudo apt-get install libbz2-dev\n```\n有第一个就可以解决方向键的问题，剩下的是其他依赖，\n不需要的话就可以不管\n做完这些之后再重新编译一遍python就好\n\n```\nsudo apt-get install python-dev\nsudo easy_install gnureadline\n```\n\n","slug":"python","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5oy00e0mcxqvm08xnb6"},{"title":"python语言槽点","date":"2016-08-18T13:27:00.000Z","_content":"\n想起一条写一条\n\n<!--more-->\n\n## 没有编译时类型检查等\n\n允许同名函数的出现，后一个函数会覆盖前一个函数, 导致bug\n\n## 并发\n\nGIL无法多线程,只能多进程\ndjango的网络是同步阻塞的，也就是说，如果我们需要访问外部的一个服务，在等待结果返回这段时间，django不能处理任何其他的逻辑\ntornado的网络模型是异步的，这意味着它不会出现django那样因为外部服务不可用导致这个服务无法响应的问题。\n虽然tornado是异步的，但是python的mysql库都不支持异步，这也就意味着如果我们在tornado里面访问数据库，我们仍然可能面临因为数据库问题造成的整个服务不可用。\n其实异步模型最大的问题在于代码逻辑的割裂\npython没有原生的协程支持，虽然可以通过gevent，greenlet这种的上patch方式来支持协程，但毕竟更改了python源码。另外，python的yield也可以进行简单的协程模拟，但毕竟不能跨堆栈，局限性很大\n\n","source":"_posts/python_flaws.md","raw":"title: python语言槽点\ndate: 2016-08-18 21:27:00\ntags: [python, programming]\n---\n\n想起一条写一条\n\n<!--more-->\n\n## 没有编译时类型检查等\n\n允许同名函数的出现，后一个函数会覆盖前一个函数, 导致bug\n\n## 并发\n\nGIL无法多线程,只能多进程\ndjango的网络是同步阻塞的，也就是说，如果我们需要访问外部的一个服务，在等待结果返回这段时间，django不能处理任何其他的逻辑\ntornado的网络模型是异步的，这意味着它不会出现django那样因为外部服务不可用导致这个服务无法响应的问题。\n虽然tornado是异步的，但是python的mysql库都不支持异步，这也就意味着如果我们在tornado里面访问数据库，我们仍然可能面临因为数据库问题造成的整个服务不可用。\n其实异步模型最大的问题在于代码逻辑的割裂\npython没有原生的协程支持，虽然可以通过gevent，greenlet这种的上patch方式来支持协程，但毕竟更改了python源码。另外，python的yield也可以进行简单的协程模拟，但毕竟不能跨堆栈，局限性很大\n\n","slug":"python_flaws","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5oz00e2mcxql1zklet5"},{"title":"补码","date":"2015-11-06T16:00:00.000Z","_content":"在计算机系统中，数值一律用补码来表示和存储。原因在于，使用补码，可以将符号位和数值域统一处理；\n同时，加法和减法也可以统一处理。此外，补码与原码相互转换，其运算过程是相同的，不需要额外的硬件电路。\n<!--more-->\n## 原码存在的问题\n在计算的时候,人脑可以知道第一位是符号位,我们会根据符号位,选择对真值区域的加减\n而计算机辨别\"符号位\"显然会让计算机的基础电路设计变得十分复杂,于是人们想出了将符号位也参与运算的方法. \n我们知道, 根据运算法则减去一个正数等于加上一个负数, 即: 1-1 = 1 + (-1) = 0, \n所以机器可以只有加法而没有减法, 这样计算机运算的设计就更简单了.\n于是人们开始探索 将符号位参与运算, 并且只保留加法的方法. \n我们来看原码: 计算十进制的表达式: 1-1=0\n1 - 1 = 1 + (-1) = [00000001]原 + [10000001]原 = [10000010]原 = -2\n这个结果不正确.这就是为何计算机内部不使用原码的原因\n\n## 模\n模的概念可以帮助理解补码。\n“模”是指一个计量系统的计数范围。如时钟等。\n计算机也可以看成一个计量机器，它也有一个计量范围，即都存在一个“模”。例如：\n时钟的计量范围是0～11，模=12。表示n位的计算机计量范围是0～2^(n)-1，模=2^(n)。\n“模”实质上是计量器产生“溢出”的量，它的值在计量器上表示不出来，计量器上只能表示出模的余数。\n任何有模的计量器，均可化减法为加法运算。\n例如：假设当前时针指向10点，而准确时间是6点，\n调整时间可有以下两种拨法：一种是倒拨4小时，即：10-4=6；另一种是顺拨8小时：10+8=12+6=6\n**在以12为模的系统中，加8和减4效果是一样的，因此凡是减4运算，都可以用加8来代替。**\n对“模”而言，8和4互为补数。实际上以12模的系统中，11和1，10和2，9和3，7和5，6和6都有这个特性。共同的特点是两者相加等于模。\n对于计算机，其概念和方法完全一样。n位计算机，设n=8，所能表示的最大数是11111111，\n若再加1成为100000000(9位），但因只有8位，最高位1自然丢失。又回了00000000，所以8位二进制系统的模为2^8。\n在这样的系统中减法问题也可以化成加法问题，只需把减数用相应的补数表示就可以了。\n把补数用到计算机对数的处理上，就是补码。\n\n## 使用补数\n实现化减法为加法\n如: 7 - 4 = 7 + 4的补数\n但是取补数怎么取呢?根据上面的原数+补数=模这一特点,用模-原数的方式取补数还是有减法啊?有没有别的办法取补数?\n取反操作对计算机而言是一个简单的操作,只需切换每一位的状态,\n原数+取反后的原数=模-1,即:取反后的原数+1=模-原数=补数\n7 - 4 = 0111 - 0100 = 0111 + (0100的补数) = 0111 + (0100取反+1) = 0111 + (1011 + 1) = \n0111 + 1100 = 10011(溢出舍去最左边的1) = 0011 即 3\n即可无须特殊处理符号位(符号位如上参与加法运算),达到简化硬件设计,提高效率,降低成本的目的\n\n**补码体现了统一处理的优势,降低复杂度的同时降低成本**\n软件工程也应如此,该统一的地方一定要统一\n\n## 特性\n* 一个负整数（或原码）与其补数（或补码）相加，和为模。\n* 对一个整数的补码再求补码，等于该整数自身。\n* 补码的正零与负零表示方法相同。\n\n## 16位补码示例\n16位二进制数能够表示2的16次方即65536个数.\n有符号16位二进制补码所能表示的数值范围是-32768到32767.\n无符号16位二进制补码所能表示的数值范围是0到65535.\n\n补码是循环的，最大的数32767,加1就等于最小的数-32768,\n0111 1111 1111 1111 ( 32767) 加1以后等于\n1000 0000 0000 0000 (-32768) \n无符号的(32768)1000 0000 0000 0000取反再加1所得到的-32768的补码\n仍然是1000 0000 0000 0000\n所以1000 0000 0000 0000在无符号时是32768，有符号时是-32768\n并且有符号时,对1000 0000 0000 0000这个数一直加, 可以得到如下的循环：\n\n1000 0000 0000 0001(-32767)\n1000 0000 0000 0010(-32766)\n1000 0000 0000 0011(-32765)\n……\n1111 1111 1111 1100(-4)\n1111 1111 1111 1101(-3)\n1111 1111 1111 1110(-2)\n1111 1111 1111 1111(-1)\n0000 0000 0000 0000( 0) (溢出的一位丢失了)\n0000 0000 0000 0001( 1)\n0000 0000 0000 0010( 2)\n0000 0000 0000 0011( 3)\n……\n0111 1111 1111 1100( 32764)\n0111 1111 1111 1101( 32765)\n0111 1111 1111 1110( 32766)\n0111 1111 1111 1111( 32767)\n1000 0000 0000 0000(-32768)\n\n## 参考链接\n[百度百科补码][1]\n[为什么要用补码][2]\n\n  [1]: http://baike.baidu.com/link?url=qnF_xOyyl8tb5fYHq34eitdx1Eb1yH7OdS_q1tJ1nYSZ-gU0LiEbSScT0YjD0FvK1ZGLobuBHoKBCBp3JRES_K\n  [2]: http://blog.csdn.net/pud_zha/article/details/7815109\n\n","source":"_posts/radix_complement.md","raw":"title: 补码\ndate: 2015-11-07\ntags: [computer]\n---\n在计算机系统中，数值一律用补码来表示和存储。原因在于，使用补码，可以将符号位和数值域统一处理；\n同时，加法和减法也可以统一处理。此外，补码与原码相互转换，其运算过程是相同的，不需要额外的硬件电路。\n<!--more-->\n## 原码存在的问题\n在计算的时候,人脑可以知道第一位是符号位,我们会根据符号位,选择对真值区域的加减\n而计算机辨别\"符号位\"显然会让计算机的基础电路设计变得十分复杂,于是人们想出了将符号位也参与运算的方法. \n我们知道, 根据运算法则减去一个正数等于加上一个负数, 即: 1-1 = 1 + (-1) = 0, \n所以机器可以只有加法而没有减法, 这样计算机运算的设计就更简单了.\n于是人们开始探索 将符号位参与运算, 并且只保留加法的方法. \n我们来看原码: 计算十进制的表达式: 1-1=0\n1 - 1 = 1 + (-1) = [00000001]原 + [10000001]原 = [10000010]原 = -2\n这个结果不正确.这就是为何计算机内部不使用原码的原因\n\n## 模\n模的概念可以帮助理解补码。\n“模”是指一个计量系统的计数范围。如时钟等。\n计算机也可以看成一个计量机器，它也有一个计量范围，即都存在一个“模”。例如：\n时钟的计量范围是0～11，模=12。表示n位的计算机计量范围是0～2^(n)-1，模=2^(n)。\n“模”实质上是计量器产生“溢出”的量，它的值在计量器上表示不出来，计量器上只能表示出模的余数。\n任何有模的计量器，均可化减法为加法运算。\n例如：假设当前时针指向10点，而准确时间是6点，\n调整时间可有以下两种拨法：一种是倒拨4小时，即：10-4=6；另一种是顺拨8小时：10+8=12+6=6\n**在以12为模的系统中，加8和减4效果是一样的，因此凡是减4运算，都可以用加8来代替。**\n对“模”而言，8和4互为补数。实际上以12模的系统中，11和1，10和2，9和3，7和5，6和6都有这个特性。共同的特点是两者相加等于模。\n对于计算机，其概念和方法完全一样。n位计算机，设n=8，所能表示的最大数是11111111，\n若再加1成为100000000(9位），但因只有8位，最高位1自然丢失。又回了00000000，所以8位二进制系统的模为2^8。\n在这样的系统中减法问题也可以化成加法问题，只需把减数用相应的补数表示就可以了。\n把补数用到计算机对数的处理上，就是补码。\n\n## 使用补数\n实现化减法为加法\n如: 7 - 4 = 7 + 4的补数\n但是取补数怎么取呢?根据上面的原数+补数=模这一特点,用模-原数的方式取补数还是有减法啊?有没有别的办法取补数?\n取反操作对计算机而言是一个简单的操作,只需切换每一位的状态,\n原数+取反后的原数=模-1,即:取反后的原数+1=模-原数=补数\n7 - 4 = 0111 - 0100 = 0111 + (0100的补数) = 0111 + (0100取反+1) = 0111 + (1011 + 1) = \n0111 + 1100 = 10011(溢出舍去最左边的1) = 0011 即 3\n即可无须特殊处理符号位(符号位如上参与加法运算),达到简化硬件设计,提高效率,降低成本的目的\n\n**补码体现了统一处理的优势,降低复杂度的同时降低成本**\n软件工程也应如此,该统一的地方一定要统一\n\n## 特性\n* 一个负整数（或原码）与其补数（或补码）相加，和为模。\n* 对一个整数的补码再求补码，等于该整数自身。\n* 补码的正零与负零表示方法相同。\n\n## 16位补码示例\n16位二进制数能够表示2的16次方即65536个数.\n有符号16位二进制补码所能表示的数值范围是-32768到32767.\n无符号16位二进制补码所能表示的数值范围是0到65535.\n\n补码是循环的，最大的数32767,加1就等于最小的数-32768,\n0111 1111 1111 1111 ( 32767) 加1以后等于\n1000 0000 0000 0000 (-32768) \n无符号的(32768)1000 0000 0000 0000取反再加1所得到的-32768的补码\n仍然是1000 0000 0000 0000\n所以1000 0000 0000 0000在无符号时是32768，有符号时是-32768\n并且有符号时,对1000 0000 0000 0000这个数一直加, 可以得到如下的循环：\n\n1000 0000 0000 0001(-32767)\n1000 0000 0000 0010(-32766)\n1000 0000 0000 0011(-32765)\n……\n1111 1111 1111 1100(-4)\n1111 1111 1111 1101(-3)\n1111 1111 1111 1110(-2)\n1111 1111 1111 1111(-1)\n0000 0000 0000 0000( 0) (溢出的一位丢失了)\n0000 0000 0000 0001( 1)\n0000 0000 0000 0010( 2)\n0000 0000 0000 0011( 3)\n……\n0111 1111 1111 1100( 32764)\n0111 1111 1111 1101( 32765)\n0111 1111 1111 1110( 32766)\n0111 1111 1111 1111( 32767)\n1000 0000 0000 0000(-32768)\n\n## 参考链接\n[百度百科补码][1]\n[为什么要用补码][2]\n\n  [1]: http://baike.baidu.com/link?url=qnF_xOyyl8tb5fYHq34eitdx1Eb1yH7OdS_q1tJ1nYSZ-gU0LiEbSScT0YjD0FvK1ZGLobuBHoKBCBp3JRES_K\n  [2]: http://blog.csdn.net/pud_zha/article/details/7815109\n\n","slug":"radix_complement","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5p000e5mcxqbwjgahc1"},{"title":"redis","date":"2016-11-08T09:14:00.000Z","_content":"\n偶尔研究一下 redis\n\n<!--more-->\n\n## 慢查询日志\n\n访问 redis instance\n用 slowlog len 先看看长度\n然后 slowlog get count\n\n# redis 3.2 cluster\n\n## Redis Cluster TCP ports\n\n每个结点两个端口,\n如给client用的端口是6379, 则10000(固定) + 6379即16739端口用于结点间通讯\n\n暂不支持 ip 或 port 映射\n\n# Redis Cluster data sharding\n\n集群共有 16384 个 hash slot, 对 key 做 CRC16 并对 16384 取余得到对应的 hash slot, 每个结点负责一部分 hash slot,\n这种设计, 摘除和增加结点都比较容易, 把hash slot复制到别的结点即可\nhash tags可以让key在同一个slot里, 从而允许类似事务的操作\n\n# Redis Cluster master-slave model\n\n每个master可以有N个slaves,\n\n# Redis Cluster consistency guarantees\n\n保证不了强一致性, 意味着特殊情况下会丢数据(而且是已经给前端确认写入成功的).\n\n原因1: 异步replicate, 所以master自己写完就告诉client ok了, 然后才发到从库, 这时如果master down了, 没有发到从库, 这次写入就丢了. 这里要想解决的话, 就要从库全写成功才告诉client ok, (使用WAIT命令), 但是这个性能代价很高.\n\n原因2: 网络分裂后, 如果客户端和master(B)在一起, 而另一侧的网络里在node timeout 这个时间后B的slave被提升成master, 那么在此期间客户端写到这个B上的数据会丢.\n(node timeout后B发现自己与多数master失去联系了也会进入一个error状态, 即只有进入error状态之前的这一段时间内的数据会告诉client成功却丢, 之后就写不了了)\n\n## 参考链接\nhttp://redis.io/topics/cluster-tutorial\n\n","source":"_posts/redis.md","raw":"title: redis\ndate: 2016-11-08 17:14:00\ntags: [db]\n---\n\n偶尔研究一下 redis\n\n<!--more-->\n\n## 慢查询日志\n\n访问 redis instance\n用 slowlog len 先看看长度\n然后 slowlog get count\n\n# redis 3.2 cluster\n\n## Redis Cluster TCP ports\n\n每个结点两个端口,\n如给client用的端口是6379, 则10000(固定) + 6379即16739端口用于结点间通讯\n\n暂不支持 ip 或 port 映射\n\n# Redis Cluster data sharding\n\n集群共有 16384 个 hash slot, 对 key 做 CRC16 并对 16384 取余得到对应的 hash slot, 每个结点负责一部分 hash slot,\n这种设计, 摘除和增加结点都比较容易, 把hash slot复制到别的结点即可\nhash tags可以让key在同一个slot里, 从而允许类似事务的操作\n\n# Redis Cluster master-slave model\n\n每个master可以有N个slaves,\n\n# Redis Cluster consistency guarantees\n\n保证不了强一致性, 意味着特殊情况下会丢数据(而且是已经给前端确认写入成功的).\n\n原因1: 异步replicate, 所以master自己写完就告诉client ok了, 然后才发到从库, 这时如果master down了, 没有发到从库, 这次写入就丢了. 这里要想解决的话, 就要从库全写成功才告诉client ok, (使用WAIT命令), 但是这个性能代价很高.\n\n原因2: 网络分裂后, 如果客户端和master(B)在一起, 而另一侧的网络里在node timeout 这个时间后B的slave被提升成master, 那么在此期间客户端写到这个B上的数据会丢.\n(node timeout后B发现自己与多数master失去联系了也会进入一个error状态, 即只有进入error状态之前的这一段时间内的数据会告诉client成功却丢, 之后就写不了了)\n\n## 参考链接\nhttp://redis.io/topics/cluster-tutorial\n\n","slug":"redis","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5p100e7mcxqq9ixrfld"},{"title":"关于 http 协议里 querystring 里 array 的写法","date":"2021-06-22T16:00:00.000Z","_content":"\n传说中有如下三种:\n\n```\nagent_id=1,2\n\nagent_id=1&agent_id=2 \n\nagent_id[]=1&agent_id[]=2\n```\n\n这几种在 erlang, elixir 里的支持程度怎么样呢?\n\n<!--more-->\n\n```elixir\n> URI.decode_query(\"a=1,2\")\n%{\"a\" => \"1,2\"}\n> URI.decode_query(\"a=1&a=2\")\n%{\"a\" => \"2\"}\n> URI.decode_query(\"a[]=1&a[]=2\")\n%{\"a[]\" => \"2\"}\n```\n\n可见 URI.decode_query 三种都不支持\n\n```erlang\n> :cow_qs.parse_qs(\"a=1,2\")\n[{\"a\", \"1,2\"}]\n> :cow_qs.parse_qs(\"a=1&a=2\")\n[{\"a\", \"1\"}, {\"a\", \"2\"}]\n> :cow_qs.parse_qs(\"a[]=1&a[]=2\")\n[{\"a[]\", \"1\"}, {\"a[]\", \"2\"}]\n```\n\n呃, cowboy 里这种算勉强支持第三种写法? 至少数据没有丢, 可以自行处理 \n\n```elixir\n> Plug.Conn.Query.decode(\"a=1,2\")\n%{\"a\" => \"1,2\"}\n> Plug.Conn.Query.decode(\"a=1&a=2\")\n%{\"a\" => \"2\"}\n> Plug.Conn.Query.decode(\"a[]=1&a[]=2\")\n%{\"a\" => [\"1\", \"2\"]}\n```\n\nPlug.Conn.Query 里的支持可谓完美\n\n赞一个!\n\n","source":"_posts/querystring_array.md","raw":"title: 关于 http 协议里 querystring 里 array 的写法\ndate: 2021-06-23\n\ntags: [http, erlang, elixir, plug, cowboy]\n---\n\n传说中有如下三种:\n\n```\nagent_id=1,2\n\nagent_id=1&agent_id=2 \n\nagent_id[]=1&agent_id[]=2\n```\n\n这几种在 erlang, elixir 里的支持程度怎么样呢?\n\n<!--more-->\n\n```elixir\n> URI.decode_query(\"a=1,2\")\n%{\"a\" => \"1,2\"}\n> URI.decode_query(\"a=1&a=2\")\n%{\"a\" => \"2\"}\n> URI.decode_query(\"a[]=1&a[]=2\")\n%{\"a[]\" => \"2\"}\n```\n\n可见 URI.decode_query 三种都不支持\n\n```erlang\n> :cow_qs.parse_qs(\"a=1,2\")\n[{\"a\", \"1,2\"}]\n> :cow_qs.parse_qs(\"a=1&a=2\")\n[{\"a\", \"1\"}, {\"a\", \"2\"}]\n> :cow_qs.parse_qs(\"a[]=1&a[]=2\")\n[{\"a[]\", \"1\"}, {\"a[]\", \"2\"}]\n```\n\n呃, cowboy 里这种算勉强支持第三种写法? 至少数据没有丢, 可以自行处理 \n\n```elixir\n> Plug.Conn.Query.decode(\"a=1,2\")\n%{\"a\" => \"1,2\"}\n> Plug.Conn.Query.decode(\"a=1&a=2\")\n%{\"a\" => \"2\"}\n> Plug.Conn.Query.decode(\"a[]=1&a[]=2\")\n%{\"a\" => [\"1\", \"2\"]}\n```\n\nPlug.Conn.Query 里的支持可谓完美\n\n赞一个!\n\n","slug":"querystring_array","published":1,"updated":"2021-06-23T15:10:57.321Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5p200eamcxqmfz3k49n"},{"title":"正则表达式","date":"2015-09-05T16:00:00.000Z","_content":"## 关于[A-Z]的ASCII顺序和字典顺序的问题\n[A-Z]这种正则表达式可能被解释为[ABCDEFGHIJKLMNOPQRSTUVWXYZ](ASCII顺序),\n也可能被解释为[AbBcCdDeEfFgGhHiIjJkKlLmMnNoOpPqQrRsStTuUvVwWxXyYzZ](字典顺序)\n\n例如, shell:\n$ ls /usr/sbin/[A-Z]*\n/usr/sbin/bccmd     /usr/sbin/fdformat    /usr/sbin/lpinfo    /usr/sbin/readprofile    /usr/sbin/update-dictcommon-hunspell\n\n$ ls /usr/sbin/[[:upper:]]*\n/usr/sbin/ModemManager  /usr/sbin/NetworkManager\n\n而, erlang:\n> filelib:wildcard(\"/usr/sbin/[A-Z]*\").\n[\"/usr/sbin/ModemManager\",\"/usr/sbin/NetworkManager\"]\n\n貌似只有shell有这个问题\n\n","source":"_posts/regular_expression.md","raw":"title: 正则表达式\ndate: 2015-09-06\ntags: linux\n---\n## 关于[A-Z]的ASCII顺序和字典顺序的问题\n[A-Z]这种正则表达式可能被解释为[ABCDEFGHIJKLMNOPQRSTUVWXYZ](ASCII顺序),\n也可能被解释为[AbBcCdDeEfFgGhHiIjJkKlLmMnNoOpPqQrRsStTuUvVwWxXyYzZ](字典顺序)\n\n例如, shell:\n$ ls /usr/sbin/[A-Z]*\n/usr/sbin/bccmd     /usr/sbin/fdformat    /usr/sbin/lpinfo    /usr/sbin/readprofile    /usr/sbin/update-dictcommon-hunspell\n\n$ ls /usr/sbin/[[:upper:]]*\n/usr/sbin/ModemManager  /usr/sbin/NetworkManager\n\n而, erlang:\n> filelib:wildcard(\"/usr/sbin/[A-Z]*\").\n[\"/usr/sbin/ModemManager\",\"/usr/sbin/NetworkManager\"]\n\n貌似只有shell有这个问题\n\n","slug":"regular_expression","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5p300ecmcxq6l0mrdq5"},{"title":"rlwrap","date":"2015-09-05T16:00:00.000Z","_content":"rlwrap is a wrapper that uses the GNU readline library to allow the editing of keyboard input for any other command. \nInput history is kept between invocations, separately for each command; history completion and search work as in bash and completion word lists can be specified on the command line.\n\n","source":"_posts/rlwrap.md","raw":"title: rlwrap\ntag: linux\ndate: 2015-09-06\n---\nrlwrap is a wrapper that uses the GNU readline library to allow the editing of keyboard input for any other command. \nInput history is kept between invocations, separately for each command; history completion and search work as in bash and completion word lists can be specified on the command line.\n\n","slug":"rlwrap","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5p500efmcxqx8r121iu"},{"title":"rsync","date":"2015-09-05T16:00:00.000Z","_content":"rsync是类unix系统下的数据镜像备份工具——remote sync。\n<!--more-->\n## 创建/etc/rsyncd.conf配置文件\n> uid = root\n> gid = root\n> use chroot = yes\n> max connections = 10\n> transfer logging = no\n> list = yes\n> secrets file = /etc/rsyncd/rsyncd.secrets\n> log file = /var/log/rsyncd.log\n> pid file = /var/run/rsyncd.pid\n> lock file = /var/run/rsyncd.lock\n> charset = UTF-8\n> read only = yes\n> dont compress   = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.bz2\n> hosts allow = *\n> [my_share]\n> path = /data/share\n> auth users = rsy_user\n> read only = true\n> transfer logging = no\n> ignore errors\n\n## 创建/etc/rsyncd/rsyncd.secrets密码文件\n> rsy_user:youareaFOOL\n\n修改权限\n```bash\nsudo chmod 600 rsyncd.secrets\n```\n\n## 启动rsync\n```\nrsync --daemon\n```\n\n## 客户端同步数据\n```\nrsync -azvp rsync://rsy_user@172.16.205.129/my_share ~/tmp\n```\n","source":"_posts/rsync.md","raw":"title: rsync\ndate: 2015-09-06\ntags: [linux]\n---\nrsync是类unix系统下的数据镜像备份工具——remote sync。\n<!--more-->\n## 创建/etc/rsyncd.conf配置文件\n> uid = root\n> gid = root\n> use chroot = yes\n> max connections = 10\n> transfer logging = no\n> list = yes\n> secrets file = /etc/rsyncd/rsyncd.secrets\n> log file = /var/log/rsyncd.log\n> pid file = /var/run/rsyncd.pid\n> lock file = /var/run/rsyncd.lock\n> charset = UTF-8\n> read only = yes\n> dont compress   = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.bz2\n> hosts allow = *\n> [my_share]\n> path = /data/share\n> auth users = rsy_user\n> read only = true\n> transfer logging = no\n> ignore errors\n\n## 创建/etc/rsyncd/rsyncd.secrets密码文件\n> rsy_user:youareaFOOL\n\n修改权限\n```bash\nsudo chmod 600 rsyncd.secrets\n```\n\n## 启动rsync\n```\nrsync --daemon\n```\n\n## 客户端同步数据\n```\nrsync -azvp rsync://rsy_user@172.16.205.129/my_share ~/tmp\n```\n","slug":"rsync","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5p600ehmcxqu3yfzqn8"},{"title":"键盘扫描码","date":"2015-10-15T16:00:00.000Z","_content":"\n键位        | 扫描码\n------------|-------\nESC         | 00 01\nTAB         | 00 0F\nCapsLock    | 00 3A\n左Shift     | 00 2A\n右Shift     | 00 36\n左Alt       | 00 38\n右Alt       | E0 38\n左Ctrl      | 00 1D\n右Ctrl      | E0 1D\nPrintScreen | E0 37\n上矢印      | E0 48\n下矢印      | E0 50\n右矢印      | E0 4D\n左矢印      | E0 4B\nInsert      | E0 52\nDelete      | E0 53\nHome        | E0 47\nEnd         | E0 4F\nPageUp      | E0 49\nPageDown    | E0 51\n左Win key   | E0 5B\n右Win key   | E0 5C\napplication | E0 5D\nPAUSE       | 00 45\nScrollLock  | 00 46\n\n## 参考链接\nhttps://www.win.tue.nl/~aeb/linux/kbd/scancodes-1.html\n\n","source":"_posts/scancode.md","raw":"title: 键盘扫描码\ndate: 2015-10-16\ntags: [keyboard]\n---\n\n键位        | 扫描码\n------------|-------\nESC         | 00 01\nTAB         | 00 0F\nCapsLock    | 00 3A\n左Shift     | 00 2A\n右Shift     | 00 36\n左Alt       | 00 38\n右Alt       | E0 38\n左Ctrl      | 00 1D\n右Ctrl      | E0 1D\nPrintScreen | E0 37\n上矢印      | E0 48\n下矢印      | E0 50\n右矢印      | E0 4D\n左矢印      | E0 4B\nInsert      | E0 52\nDelete      | E0 53\nHome        | E0 47\nEnd         | E0 4F\nPageUp      | E0 49\nPageDown    | E0 51\n左Win key   | E0 5B\n右Win key   | E0 5C\napplication | E0 5D\nPAUSE       | 00 45\nScrollLock  | 00 46\n\n## 参考链接\nhttps://www.win.tue.nl/~aeb/linux/kbd/scancodes-1.html\n\n","slug":"scancode","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5p900ejmcxqrruq8ldw"},{"title":"screen","date":"2015-11-04T16:00:00.000Z","_content":"将.screenrc文件放到home目录即~下即可在screen里显示窗口列表\n\nscreen -S name 新建一个session\n\nscreen -ls 列出当前所有虚拟终端\nscreen -rd sessionid 断开(detach)其他连接并进入(reattach)指定的虚拟终端\n\nC-a ? 帮助\nC-a w 窗口列表\nC-a c 创建一个\nC-a A 当前的改名\nC-a k 杀掉当前的\nC-a d 退出screen, 但screen里的窗口依然保持, 之后还可以attach\n\nC-a [ 进入copy mode, 可以滚动窗口和选择文本拷贝\n\nC-a n 切换到下一个 window \nC-a p 切换到前一个 window \nC-a 0..9 切换到第 0..9 个 window \n\n","source":"_posts/screen.md","raw":"title: screen \ndate: 2015-11-05\ntags: linux\n---\n将.screenrc文件放到home目录即~下即可在screen里显示窗口列表\n\nscreen -S name 新建一个session\n\nscreen -ls 列出当前所有虚拟终端\nscreen -rd sessionid 断开(detach)其他连接并进入(reattach)指定的虚拟终端\n\nC-a ? 帮助\nC-a w 窗口列表\nC-a c 创建一个\nC-a A 当前的改名\nC-a k 杀掉当前的\nC-a d 退出screen, 但screen里的窗口依然保持, 之后还可以attach\n\nC-a [ 进入copy mode, 可以滚动窗口和选择文本拷贝\n\nC-a n 切换到下一个 window \nC-a p 切换到前一个 window \nC-a 0..9 切换到第 0..9 个 window \n\n","slug":"screen","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pa00emmcxqqx7jnwyy"},{"title":"ruby问题集","date":"2018-10-19T16:00:00.000Z","_content":"据说是由于ruby官网用的 ssl 从 sha1 改到 sha256 导致的问题(完整的背景见参考链接)\n\n安装 gem 时出现如下问题\n```\nSSL_connect returned=1 errno=0 state=SSLv3 read server certificate B: certificate verify failed\n```\n\n命令行更新 ruby 也更新不了, 只能从官网下载了个 2.5.2 的 ruby 的安装包,\n又装了个 rbenv (为了不和 macos 系统自带的 ruby 相冲突), 安装了 ruby 之后\n才成功地 gem install 了几个 gem\n\n<!--more-->\n\n## 参考链接\nhttps://gist.github.com/luislavena/f064211759ee0f806c88\nhttps://bundler.io/v1.16/guides/rubygems_tls_ssl_troubleshooting_guide.html#troubleshooting-certificate-errors\n\n","source":"_posts/ruby.md","raw":"title: ruby问题集\ndate: 2018-10-20\ntags: [ruby, rbenv]\n---\n据说是由于ruby官网用的 ssl 从 sha1 改到 sha256 导致的问题(完整的背景见参考链接)\n\n安装 gem 时出现如下问题\n```\nSSL_connect returned=1 errno=0 state=SSLv3 read server certificate B: certificate verify failed\n```\n\n命令行更新 ruby 也更新不了, 只能从官网下载了个 2.5.2 的 ruby 的安装包,\n又装了个 rbenv (为了不和 macos 系统自带的 ruby 相冲突), 安装了 ruby 之后\n才成功地 gem install 了几个 gem\n\n<!--more-->\n\n## 参考链接\nhttps://gist.github.com/luislavena/f064211759ee0f806c88\nhttps://bundler.io/v1.16/guides/rubygems_tls_ssl_troubleshooting_guide.html#troubleshooting-certificate-errors\n\n","slug":"ruby","published":1,"updated":"2018-10-20T04:05:02.064Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pb00eomcxq770ydxpd"},{"title":"HTML <script> defer 属性","date":"2016-06-14T11:19:00.000Z","_content":"\n自己搭建的博客使用了swiftype之后, 有些css的渲染经常中断, 具体是博文的标签没显示出来\n查了半天, 貌似是swiftype加载过程会中断页面渲染,\n找到一个defer属性, 要求必须和src属性配合着用,\n于是又把swiftype提供的代码移到一个单独的js文件中,\n使用src属性引用, 即如下这样:\n```\n<script defer src=\"/js/swiftype.js\" type=\"text/javascript\"></script>\n```\n\n这么改完之后情况好多了, 基本没再出现标签显示不出来的问题了\n\n","source":"_posts/script_defer.md","raw":"title: HTML <script> defer 属性\ndate: 2016-06-14 19:19:00\ntags: [html, javascript, web]\n---\n\n自己搭建的博客使用了swiftype之后, 有些css的渲染经常中断, 具体是博文的标签没显示出来\n查了半天, 貌似是swiftype加载过程会中断页面渲染,\n找到一个defer属性, 要求必须和src属性配合着用,\n于是又把swiftype提供的代码移到一个单独的js文件中,\n使用src属性引用, 即如下这样:\n```\n<script defer src=\"/js/swiftype.js\" type=\"text/javascript\"></script>\n```\n\n这么改完之后情况好多了, 基本没再出现标签显示不出来的问题了\n\n","slug":"script_defer","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pc00ermcxqmx7anokd"},{"title":"socket","date":"2015-11-24T16:00:00.000Z","_content":"网络进程间通讯需要唯一标识一个进程,使用ip地址和端口可以做到\n<!--more-->\n## socket\n一个网络套接字(Socket)至少由以下信息表示:\n本地socket地址: 本地ip和端口号\n协议类型: TCP, UDP, raw IP等, 于是TCP端口53与UDP端口53可以区分开来\n一个已经连接上的socket,即ESTABLISHED状态的socket,还有远端socket地址\n\n一个tcp server可以同时为很多client提供服务,服务端为每个client创建一个socket,\n从tcp server的角度来看,这些socket的本地socket地址都相同, 远端socket地址不同(即client的ip和端口)\n\n## Socket pairs\n每个连接(socket pair)由一个唯一的四元组{本地ip,本地端口,远程ip,远程端口}表示,\nTCP下,每个socket pair对应一个整数,即socket descriptor\nUDP下,由于UDP是无连接的,所以每个本地socket地址对应一个整数,即socket descriptor\n\n## Socket文件\nsocket起源于UNIX，在Unix一切皆文件哲学的思想下，socket是一种\"打开—读/写—关闭\"模式的实现，服务器和客户端各自维护一个\"文件\"，在建立连接打开后，可以向自己文件写入内容供对方读取或者读取对方内容，通讯结束时关闭文件。\n\n## 心跳\n为了及时检测到无效连接,由应用程序发送心跳包来检测连接是否还有效(还活着)\n大致的方法:\n客户端定时向服务端发一个很小的数据包(小是为了不浪费流量,空包也可以),意思是告诉服务端我还活着(故称心跳包)\n服务端定时检查上次检查到现在这段时间内有没有收到客户端发来的数据包\n如果没有(或连续几次没有)则认为客户端连接断开,在这个时机(timing)可以做一些逻辑处理,如一些清理操作\n反之,如果客户端在一定时间内没有收到服务端对心跳包的响应,则认为连接不可用\n\n## 参考链接\nhttps://en.wikipedia.org/wiki/Network_socket\n","source":"_posts/socket.markdown","raw":"title: socket\ndate: 2015-11-25\ntags: [internet]\n---\n网络进程间通讯需要唯一标识一个进程,使用ip地址和端口可以做到\n<!--more-->\n## socket\n一个网络套接字(Socket)至少由以下信息表示:\n本地socket地址: 本地ip和端口号\n协议类型: TCP, UDP, raw IP等, 于是TCP端口53与UDP端口53可以区分开来\n一个已经连接上的socket,即ESTABLISHED状态的socket,还有远端socket地址\n\n一个tcp server可以同时为很多client提供服务,服务端为每个client创建一个socket,\n从tcp server的角度来看,这些socket的本地socket地址都相同, 远端socket地址不同(即client的ip和端口)\n\n## Socket pairs\n每个连接(socket pair)由一个唯一的四元组{本地ip,本地端口,远程ip,远程端口}表示,\nTCP下,每个socket pair对应一个整数,即socket descriptor\nUDP下,由于UDP是无连接的,所以每个本地socket地址对应一个整数,即socket descriptor\n\n## Socket文件\nsocket起源于UNIX，在Unix一切皆文件哲学的思想下，socket是一种\"打开—读/写—关闭\"模式的实现，服务器和客户端各自维护一个\"文件\"，在建立连接打开后，可以向自己文件写入内容供对方读取或者读取对方内容，通讯结束时关闭文件。\n\n## 心跳\n为了及时检测到无效连接,由应用程序发送心跳包来检测连接是否还有效(还活着)\n大致的方法:\n客户端定时向服务端发一个很小的数据包(小是为了不浪费流量,空包也可以),意思是告诉服务端我还活着(故称心跳包)\n服务端定时检查上次检查到现在这段时间内有没有收到客户端发来的数据包\n如果没有(或连续几次没有)则认为客户端连接断开,在这个时机(timing)可以做一些逻辑处理,如一些清理操作\n反之,如果客户端在一定时间内没有收到服务端对心跳包的响应,则认为连接不可用\n\n## 参考链接\nhttps://en.wikipedia.org/wiki/Network_socket\n","slug":"socket","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pd00etmcxqn5whjpw3"},{"title":"关于排序稳定性","date":"2015-10-09T16:00:00.000Z","_content":"稳定排序会保持输入数据的相对顺序,而不稳定排序则不一定保持.\n<!--more-->\n## erlang\n官方文档中lists:keysort说明是稳定的,然而lists:sort没有说是否稳定,那到底如何呢?\n```\n> lists:sort(fun({_, T1}, {_, T2}) -> T1 < T2 end, [{\"UK\", \"London\"}, {\"US\", \"New York\"}, {\"US\", \"Birmingham\"}, {\"UK\", \"Birmingham\"}]).\n[{\"UK\",\"Birmingham\"},\n {\"US\",\"Birmingham\"},\n {\"UK\",\"London\"},\n {\"US\",\"New York\"}]\n> lists:keysort(2, [{\"UK\", \"London\"}, {\"US\", \"New York\"}, {\"US\", \"Birmingham\"}, {\"UK\", \"Birmingham\"}]).\n[{\"US\",\"Birmingham\"},\n {\"UK\",\"Birmingham\"},\n {\"UK\",\"London\"},\n {\"US\",\"New York\"}]\n```\n可见lists:sort不稳定,没有保持输入顺序\n\n## 参考链接\nhttp://www.erlang.org/doc/man/lists.html\n","source":"_posts/sort.md","raw":"title: 关于排序稳定性\ndate: 2015-10-10\ntags: [erlang, algorithm]\n---\n稳定排序会保持输入数据的相对顺序,而不稳定排序则不一定保持.\n<!--more-->\n## erlang\n官方文档中lists:keysort说明是稳定的,然而lists:sort没有说是否稳定,那到底如何呢?\n```\n> lists:sort(fun({_, T1}, {_, T2}) -> T1 < T2 end, [{\"UK\", \"London\"}, {\"US\", \"New York\"}, {\"US\", \"Birmingham\"}, {\"UK\", \"Birmingham\"}]).\n[{\"UK\",\"Birmingham\"},\n {\"US\",\"Birmingham\"},\n {\"UK\",\"London\"},\n {\"US\",\"New York\"}]\n> lists:keysort(2, [{\"UK\", \"London\"}, {\"US\", \"New York\"}, {\"US\", \"Birmingham\"}, {\"UK\", \"Birmingham\"}]).\n[{\"US\",\"Birmingham\"},\n {\"UK\",\"Birmingham\"},\n {\"UK\",\"London\"},\n {\"US\",\"New York\"}]\n```\n可见lists:sort不稳定,没有保持输入顺序\n\n## 参考链接\nhttp://www.erlang.org/doc/man/lists.html\n","slug":"sort","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pe00ewmcxqpah9lcqu"},{"title":"ssh","date":"2015-08-02T16:00:00.000Z","_content":"## 安装\nsudo apt-get install openssh-server\nsudo service ssh start\n验证服务是否已启动\nps -e | grep ssh\n<!--more-->\n## 配置\n/etc/ssh/sshd_config\n\n不允许使用密码登录\nPasswordAuthentication no\n\n是否允许Root登录(no不允许, without-password不允许密码登录, yes允许密码登录)\nPermitRootLogin without-password\n默认是yes, 建议改成without-password或者no(先用别的用户登进去然后再切换到root)\n\n重启服务或重新加载配置文件\nsudo service ssh restart\n或\nsudo service ssh reload\n\n## 客户端生成密钥\nssh-keygen -t rsa\n\n## 服务端加入公钥\n在.ssh目录下创建authorized_keys文件,加入Client端的公钥内容\n修改权限\nchmod 600 authorized_keys\n要允许哪个用户登录就在哪个用户的home目录下的.ssh目录里的authorized_keys加上对应的公钥, \n如果要允许ssh登录root,则需要在/root/.ssh/authorized_keys里加上对应的公钥\nssh-copy-id -i ~/.ssh/id_rsa.pub username@hostname -p port\n\n## 客户端登录\nssh username@192.168.1.112\n省略username也可以,好像是以当前用户名登录\nssh 192.168.1.112\n\n## 反向隧道\nautossh -M 3333 -f -NR 4444:localhost:22 username@host -p 5555\n-M  指定monitor的端口\n-f  后台运行\n-N  ssh参数, Do not execute a remote command(比如在远程启动shell?).  This is useful for just forwarding ports (protocol version 2 only).\n-R  ssh参数, [bind_address:]port:host:hostport, port填监听的远程端口,host和hostport填自己和自己的端口\n其中22也可以是其他端口,比如80,或者任意其他的端口比如6789\n\n查看反向隧道是否成功\n<pre>\n# netstat -onltp\nActive Internet connections (only servers)\nProto Recv-Q Send-Q Local Address               Foreign Address             State       PID/Program name    Timer\ntcp        0      0 127.0.0.1:4444              0.0.0.0:*                   LISTEN      5310/sshd           off (0.00/0/0)\ntcp        0      0 ::1:4444                    :::*                        LISTEN      5310/sshd           off (0.00/0/0)\n</pre>\n\n连接到发起反向隧道的机器\nssh username@127.0.0.1 -p 4444\n\n## config\n把一些参数放到config里, 方便平常输命令, config文件示例如下:\n<pre>\ncontents of $HOME/.ssh/config\nHost dev\n    HostName dev.example.com\n    Port 22000\n    User fooey\nHost github-project1\n    User git\n    HostName github.com\n    IdentityFile ~/.ssh/github.project1.key\nHost github-org\n    User git\n    HostName github.com\n    IdentityFile ~/.ssh/github.org.key\nHost github.com\n    User git\n    IdentityFile ~/.ssh/github.key\nHost tunnel\n    HostName database.example.com\n    IdentityFile ~/.ssh/coolio.example.key\n    LocalForward 9906 127.0.0.1:3306\n    User coolio\n</pre>\n\n## finger print\n为了防范'中间人攻击', ssh程序会将远程ssh服务器发来的服务器公钥的finger print和上次连接时保存的finger print对比\n如果检测到fingerprint变化,即表示你所连接的机器的public key发生了改变,\n这可能是由于ssh软件重装, 也可能是由于load balancer将你的请求转到了域名/IP的另一台机器,\n也可能是遇到了'中间人攻击',攻击者截取/转发你的ssh连接到另一台机器,可能会窃取你的用户名/密码\n\n服务器公钥一般在/etc/ssh目录下,如ssh_host_rsa_key.pub或其他类型如ecdsa, \n这个finger print一般会被客户端保存在$HOME/.ssh/authorized_keys,\nfinger print是服务器公钥的一个简略版(通过hast生成), 比起公钥容易对比一些. 想要找到finger print的公钥碰撞很难.\n\n微软的软件里, 使用thumbprint而不是fingerprint,\n\n如何查看公钥的finger print?\nssh-keygen -lf filename\n也可以查看known_hosts里的finger print\nssh-keygen -lf ~/.ssh/known_hosts\n也可以查看私钥的finger print\n\n## 参考链接\nhttp://nerderati.com/2011/03/17/simplify-your-life-with-an-ssh-config-file/\nhttp://linux.die.net/man/1/ssh-copy-id\nhttp://linux.die.net/man/5/ssh_config\n\n","source":"_posts/ssh.md","raw":"title: ssh\ndate: 2015-08-03\ntags: [internet, linux]\n---\n## 安装\nsudo apt-get install openssh-server\nsudo service ssh start\n验证服务是否已启动\nps -e | grep ssh\n<!--more-->\n## 配置\n/etc/ssh/sshd_config\n\n不允许使用密码登录\nPasswordAuthentication no\n\n是否允许Root登录(no不允许, without-password不允许密码登录, yes允许密码登录)\nPermitRootLogin without-password\n默认是yes, 建议改成without-password或者no(先用别的用户登进去然后再切换到root)\n\n重启服务或重新加载配置文件\nsudo service ssh restart\n或\nsudo service ssh reload\n\n## 客户端生成密钥\nssh-keygen -t rsa\n\n## 服务端加入公钥\n在.ssh目录下创建authorized_keys文件,加入Client端的公钥内容\n修改权限\nchmod 600 authorized_keys\n要允许哪个用户登录就在哪个用户的home目录下的.ssh目录里的authorized_keys加上对应的公钥, \n如果要允许ssh登录root,则需要在/root/.ssh/authorized_keys里加上对应的公钥\nssh-copy-id -i ~/.ssh/id_rsa.pub username@hostname -p port\n\n## 客户端登录\nssh username@192.168.1.112\n省略username也可以,好像是以当前用户名登录\nssh 192.168.1.112\n\n## 反向隧道\nautossh -M 3333 -f -NR 4444:localhost:22 username@host -p 5555\n-M  指定monitor的端口\n-f  后台运行\n-N  ssh参数, Do not execute a remote command(比如在远程启动shell?).  This is useful for just forwarding ports (protocol version 2 only).\n-R  ssh参数, [bind_address:]port:host:hostport, port填监听的远程端口,host和hostport填自己和自己的端口\n其中22也可以是其他端口,比如80,或者任意其他的端口比如6789\n\n查看反向隧道是否成功\n<pre>\n# netstat -onltp\nActive Internet connections (only servers)\nProto Recv-Q Send-Q Local Address               Foreign Address             State       PID/Program name    Timer\ntcp        0      0 127.0.0.1:4444              0.0.0.0:*                   LISTEN      5310/sshd           off (0.00/0/0)\ntcp        0      0 ::1:4444                    :::*                        LISTEN      5310/sshd           off (0.00/0/0)\n</pre>\n\n连接到发起反向隧道的机器\nssh username@127.0.0.1 -p 4444\n\n## config\n把一些参数放到config里, 方便平常输命令, config文件示例如下:\n<pre>\ncontents of $HOME/.ssh/config\nHost dev\n    HostName dev.example.com\n    Port 22000\n    User fooey\nHost github-project1\n    User git\n    HostName github.com\n    IdentityFile ~/.ssh/github.project1.key\nHost github-org\n    User git\n    HostName github.com\n    IdentityFile ~/.ssh/github.org.key\nHost github.com\n    User git\n    IdentityFile ~/.ssh/github.key\nHost tunnel\n    HostName database.example.com\n    IdentityFile ~/.ssh/coolio.example.key\n    LocalForward 9906 127.0.0.1:3306\n    User coolio\n</pre>\n\n## finger print\n为了防范'中间人攻击', ssh程序会将远程ssh服务器发来的服务器公钥的finger print和上次连接时保存的finger print对比\n如果检测到fingerprint变化,即表示你所连接的机器的public key发生了改变,\n这可能是由于ssh软件重装, 也可能是由于load balancer将你的请求转到了域名/IP的另一台机器,\n也可能是遇到了'中间人攻击',攻击者截取/转发你的ssh连接到另一台机器,可能会窃取你的用户名/密码\n\n服务器公钥一般在/etc/ssh目录下,如ssh_host_rsa_key.pub或其他类型如ecdsa, \n这个finger print一般会被客户端保存在$HOME/.ssh/authorized_keys,\nfinger print是服务器公钥的一个简略版(通过hast生成), 比起公钥容易对比一些. 想要找到finger print的公钥碰撞很难.\n\n微软的软件里, 使用thumbprint而不是fingerprint,\n\n如何查看公钥的finger print?\nssh-keygen -lf filename\n也可以查看known_hosts里的finger print\nssh-keygen -lf ~/.ssh/known_hosts\n也可以查看私钥的finger print\n\n## 参考链接\nhttp://nerderati.com/2011/03/17/simplify-your-life-with-an-ssh-config-file/\nhttp://linux.die.net/man/1/ssh-copy-id\nhttp://linux.die.net/man/5/ssh_config\n\n","slug":"ssh","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pg00eymcxqyodmf6gu"},{"title":"ssl","date":"2016-03-08T16:00:00.000Z","_content":"\nSSL(Secure Sockets Layer 安全套接层), 及其继任者传输层安全（Transport Layer Security，TLS）\n是为网络通信提供安全及数据完整性的一种安全协议。TLS与SSL在传输层对网络连接进行加密。\n<!--more-->\n\n## CA\nCA(certificate authority), 数字证书授权机构\n\n## 根证书\n根证书是未被签名的公钥证书或自签名的证书，是CA认证中心给自己颁发的证书，是信任链的起始点。安装根证书意味着对这个CA认证中心的信任。\n\n## 证书链\nA信任B,B信任C,C信任D,...这就是证书链\n\n在互联网上使用的SSL服务器证书需要第三方机构签署。但是证书签署机构不一定会用它的根证书签署你的证书。\n如使用GeoTrust SSL CA签署的二级证书(intermediate certificate)，签署该证书的是GeoTrust Global CA。\n这个根证书是大多数浏览器很操作系统所信任的。一般而且多数浏览器和服务器并不保存二级证书。如果二级证书没有传到客户端，就无法验证服务器证书的有效性。只有把二级证书也传递到客户端，通过客户端信任GeoTrust Gloabal CA，GeoTrust Global CA信任GeoTrust SSL CA，而Geo SSL CA又信任你的SSL证书构建起的证书的信任链。由此可见，只要服务器证书不是用根证书签署的，就必须让服务器把二级证书也传输到客户端。\n在配置服务器传输证书链而非单个证书之前需要生成证书链文件，也可以从CA那里获得。该文件是一些以pem格式的证书文件按照从服务器证书到根证书的顺序叠加在一起。\n\n## ubuntu下根证书信任操作\n/etc/ssl/certs/ca-certificates.crt文件保存了所有根证书\n\n添加受信任的根证书\nsudo cp yourcrt.crt /usr/local/share/ca-certificates\nsudo update-ca-certificates\n\n删除受信任的根证书\n编辑 /etc/ca-certificates.conf 文件\n使用前缀!号表示不信任,或干脆删除那一行\nsudo update-ca-certificates\n\n## nginx配置https\n安装\nyum install nginx\n\n启动nginx\n/etc/init.d/nginx start\n\n测试\ncurl localhost:80\n或者在浏览器上输入ip地址或域名测试\n\n添加域名解析\n通过startssl验证域名, 获取证书\n\n使用在startssl设定的密码将已加密的私钥解开,得到私钥\nopenssl rsa -in ssl.key -out ssl.key\n\n从startssl下载crt bundle, \n将crt和key文件配置到nginx\n如:\n```\nserver {\n    listen       443;\n    server_name  yourdomain;\n\n    ssl                  on;\n    ssl_certificate      yourcrt.crt;\n    ssl_certificate_key  yourkey.key;\n}\n```\n重新加载配置\n/etc/init.d/nginx reload\n\n在浏览器上输入https://yourdomain测试https是否配置成功\n\n到下面的网站验证服务器的安全性\nhttps://www.ssllabs.com\n\n## 安装 Let’s Encrypt 客户端\n记住要在服务器(提供nginx服务的机器)上安装\n装前准备，更新系统和安装 git & bc：\napt-get update\napt-get -y install git bc\n克隆 Let’s Encrypt 到  /opt/letsencrypt:\ngit clone https://github.com/letsencrypt/letsencrypt /opt/letsencrypt\n\n## 获取证书\n首先关闭 Nginx：\nservice nginx stop\n\n并且检查一下 80 端口没有被占用：\nnetstat -onltp | grep ':80.*LISTEN'\n\n运行 Let’s Encrypt:\ncd /opt/letsencrypt\n./letsencrypt-auto certonly --standalone\n\n注意：Let’s Encrypt 需要超级用户权限，如果你没有使用 sudo 命令，可能会让你输入密码。\n\n之后会出现图形界面输入邮箱、条款、域名等信息\n支持多域名，只需要用空格或者英文逗号分隔就好了。\n\n签发的证书位于 /etc/letsencrypt，注意备份。\n\n如果使用国内 VPS，此处可能会由于 DNS 问题出错，可以尝试更换 VPS 的 DNS 为第三方，比如 8.8.8.8。\n\n每一个域名都会自动生成四个文件，位于 /etc/letsencrypt/archive/domain 目录下：\ncert.pem: 域名证书\nchain.pem: The Let’s Encrypt 证书\nfullchain.pem: 上面两者合体\nprivkey.pem: 证书密钥\n\n## 配置 Nginx\n有了域名证书，就开始配置 Nginx 了。\n\n打开对应网站的配置文件，一般在 /etc/nginx/sites-available/default 或者 /usr/local/nginx/conf/ 中，试你自己的情况。\n```\nserver {\n    listen 443 ssl;\n    server_name your_domain_name;\n    …\n    \n    ssl on;\n    ssl_certificate /etc/letsencrypt/live/your_domain_name/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/your_domain_name/privkey.pem;\n    \n    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n    ssl_prefer_server_ciphers on;\n    ssl_ciphers 'EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH';\n    \n    …\n}\n```\n如果你想开启全站 https，需要将 http 转向到 https，再添加一个 server 就好了：\n\n```\nserver {\n    listen 80;\n    server_name your_domain_name;\n    return 301 https://$host$request_uri;\n}\n```\n注意以上配置文件需要根据实际情况修改。\n保存，重启 Nginx\nservice nginx restart\n\n此时，打开你的域名比如 https:// 就能看到绿色的地址栏了。\n\n## 自动续签证书\nLet’s Encrypt 证书只有 90 天的有效期，这和之前按年使用的商业证书有些区别，\n所以我们还需要设置自动续签，好让证书一直有效。\n\n安装 Webroot 插件\n这是一个可以不用停止 Web 服务就能让 Let’s Encrypt 验证域名的插件，再次打开 Nginx 配置文件，在 ssl 下面添加：\n```\nlocation ~ /.well-known {\n    allow all;\n}\n```\n保存。\n\n使用命令行续签证书\n```\ncd /opt/letsencrypt\n./letsencrypt-auto certonly -a webroot --agree-tos --renew-by-default --webroot-path=/usr/share/nginx/html -d example.com -d www.example.com\n```\n注意修改 webroot-path 参数，这是你的网站路径。\n重新加载 Nginx 配置文件。\nservice nginx reload\n\n创建  Let’s Encrypt 续签配置文件\ncp /opt/letsencrypt/examples/cli.ini /usr/local/etc/le-renew-webroot.ini\n\n我们将直接编辑示例配置文件：\nvi /usr/local/etc/le-renew-webroot.ini\n\n修改以下几行：\n```\nrsa-key-size = 4096\nemail = you@example.com\ndomains = example.com, www.example.com\nwebroot-path = /usr/share/nginx/html\n```\n\n于是可以使用配置文件续签证书\ncd /opt/letsencrypt\n./letsencrypt-auto certonly -a webroot --renew-by-default --config /usr/local/etc/le-renew-webroot.ini\n\n下载续签脚本并设置权限：\n```\ncurl -L -o /usr/local/sbin/le-renew-webroot https://gist.githubusercontent.com/thisismitch/e1b603165523df66d5cc/raw/fbffbf358e96110d5566f13677d9bd5f4f65794c/le-renew-webroot\nchmod +x /usr/local/sbin/le-renew-webroot\n```\n注意：确保上一步创建的 续签配置文件 /usr/local/etc/le-renew-webroot.ini 存在，否则脚本将无法运行。\n试运行脚本：\nle-renew-webroot\n\n创建定时任务：\ncrontab -e\n添加下面一行，让每周一早上 2 点 30 分运行一次，并记录到日志文件中。\n30 2 * * 1 /usr/local/sbin/le-renew-webroot >> /var/log/le-renewal.log\n\n## 什么是ACME?\nThe Automated Certificate Management Environment (ACME) protocol \nis a communications protocol for automating interactions between certificate authorities and their users' web servers, \nallowing the automated deployment of public key infrastructure at very low cost. \nIt was designed by the Internet Security Research Group for their Let's Encrypt service.\n\n## 遇到过的问题\n\n有一次从网上下载一个数字证书, 以为下下来了, 结果下的是一个html, 但是文件名却是对的, xxx.crt\n将xxx.crt添加到/usr/local/share/ca-certificates并update-ca-certificates后\ngit命令出现了如下错误:\n$ git pull\nfatal: unable to access 'https://github.com/erlang/otp.git/': Problem with the SSL CA cert (path? access rights?)\n多方找解决方案而不得, 最后发现/etc/ssl/certs/ca-certificates.crt文件里有一大堆html, \n删掉那些html代码后恢复正常\n\n## 参考链接\nhttps://program-think.blogspot.com/2010/02/introduce-digital-certificate-and-ca.html\nhttps://www.evssl.cn/ev-ssl-ask/122.html\nhttps://support.ssl.com/Knowledgebase/Article/View/19/0/der-vs-crt-vs-cer-vs-pem-certificates-and-how-to-convert-them\nhttps://en.wikipedia.org/wiki/Automated_Certificate_Management_Environment\nhttps://letsencrypt.org/getting-started/\nhttps://letsencrypt.org/how-it-works/\nhttps://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-14-04\nhttps://www.ssllabs.com/\nhttp://nginx.org/en/docs/http/configuring_https_servers.html\nhttp://schnell18.iteye.com/blog/2048296\nhttp://chenling1018.blog.163.com/blog/static/1480254201058112410789/\nhttp://www.appinn.com/use-letsencrypt-with-nginx/\n\n","source":"_posts/ssl.md","raw":"title: ssl\ndate: 2016-03-09\ntags: [internet]\n---\n\nSSL(Secure Sockets Layer 安全套接层), 及其继任者传输层安全（Transport Layer Security，TLS）\n是为网络通信提供安全及数据完整性的一种安全协议。TLS与SSL在传输层对网络连接进行加密。\n<!--more-->\n\n## CA\nCA(certificate authority), 数字证书授权机构\n\n## 根证书\n根证书是未被签名的公钥证书或自签名的证书，是CA认证中心给自己颁发的证书，是信任链的起始点。安装根证书意味着对这个CA认证中心的信任。\n\n## 证书链\nA信任B,B信任C,C信任D,...这就是证书链\n\n在互联网上使用的SSL服务器证书需要第三方机构签署。但是证书签署机构不一定会用它的根证书签署你的证书。\n如使用GeoTrust SSL CA签署的二级证书(intermediate certificate)，签署该证书的是GeoTrust Global CA。\n这个根证书是大多数浏览器很操作系统所信任的。一般而且多数浏览器和服务器并不保存二级证书。如果二级证书没有传到客户端，就无法验证服务器证书的有效性。只有把二级证书也传递到客户端，通过客户端信任GeoTrust Gloabal CA，GeoTrust Global CA信任GeoTrust SSL CA，而Geo SSL CA又信任你的SSL证书构建起的证书的信任链。由此可见，只要服务器证书不是用根证书签署的，就必须让服务器把二级证书也传输到客户端。\n在配置服务器传输证书链而非单个证书之前需要生成证书链文件，也可以从CA那里获得。该文件是一些以pem格式的证书文件按照从服务器证书到根证书的顺序叠加在一起。\n\n## ubuntu下根证书信任操作\n/etc/ssl/certs/ca-certificates.crt文件保存了所有根证书\n\n添加受信任的根证书\nsudo cp yourcrt.crt /usr/local/share/ca-certificates\nsudo update-ca-certificates\n\n删除受信任的根证书\n编辑 /etc/ca-certificates.conf 文件\n使用前缀!号表示不信任,或干脆删除那一行\nsudo update-ca-certificates\n\n## nginx配置https\n安装\nyum install nginx\n\n启动nginx\n/etc/init.d/nginx start\n\n测试\ncurl localhost:80\n或者在浏览器上输入ip地址或域名测试\n\n添加域名解析\n通过startssl验证域名, 获取证书\n\n使用在startssl设定的密码将已加密的私钥解开,得到私钥\nopenssl rsa -in ssl.key -out ssl.key\n\n从startssl下载crt bundle, \n将crt和key文件配置到nginx\n如:\n```\nserver {\n    listen       443;\n    server_name  yourdomain;\n\n    ssl                  on;\n    ssl_certificate      yourcrt.crt;\n    ssl_certificate_key  yourkey.key;\n}\n```\n重新加载配置\n/etc/init.d/nginx reload\n\n在浏览器上输入https://yourdomain测试https是否配置成功\n\n到下面的网站验证服务器的安全性\nhttps://www.ssllabs.com\n\n## 安装 Let’s Encrypt 客户端\n记住要在服务器(提供nginx服务的机器)上安装\n装前准备，更新系统和安装 git & bc：\napt-get update\napt-get -y install git bc\n克隆 Let’s Encrypt 到  /opt/letsencrypt:\ngit clone https://github.com/letsencrypt/letsencrypt /opt/letsencrypt\n\n## 获取证书\n首先关闭 Nginx：\nservice nginx stop\n\n并且检查一下 80 端口没有被占用：\nnetstat -onltp | grep ':80.*LISTEN'\n\n运行 Let’s Encrypt:\ncd /opt/letsencrypt\n./letsencrypt-auto certonly --standalone\n\n注意：Let’s Encrypt 需要超级用户权限，如果你没有使用 sudo 命令，可能会让你输入密码。\n\n之后会出现图形界面输入邮箱、条款、域名等信息\n支持多域名，只需要用空格或者英文逗号分隔就好了。\n\n签发的证书位于 /etc/letsencrypt，注意备份。\n\n如果使用国内 VPS，此处可能会由于 DNS 问题出错，可以尝试更换 VPS 的 DNS 为第三方，比如 8.8.8.8。\n\n每一个域名都会自动生成四个文件，位于 /etc/letsencrypt/archive/domain 目录下：\ncert.pem: 域名证书\nchain.pem: The Let’s Encrypt 证书\nfullchain.pem: 上面两者合体\nprivkey.pem: 证书密钥\n\n## 配置 Nginx\n有了域名证书，就开始配置 Nginx 了。\n\n打开对应网站的配置文件，一般在 /etc/nginx/sites-available/default 或者 /usr/local/nginx/conf/ 中，试你自己的情况。\n```\nserver {\n    listen 443 ssl;\n    server_name your_domain_name;\n    …\n    \n    ssl on;\n    ssl_certificate /etc/letsencrypt/live/your_domain_name/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/your_domain_name/privkey.pem;\n    \n    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n    ssl_prefer_server_ciphers on;\n    ssl_ciphers 'EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH';\n    \n    …\n}\n```\n如果你想开启全站 https，需要将 http 转向到 https，再添加一个 server 就好了：\n\n```\nserver {\n    listen 80;\n    server_name your_domain_name;\n    return 301 https://$host$request_uri;\n}\n```\n注意以上配置文件需要根据实际情况修改。\n保存，重启 Nginx\nservice nginx restart\n\n此时，打开你的域名比如 https:// 就能看到绿色的地址栏了。\n\n## 自动续签证书\nLet’s Encrypt 证书只有 90 天的有效期，这和之前按年使用的商业证书有些区别，\n所以我们还需要设置自动续签，好让证书一直有效。\n\n安装 Webroot 插件\n这是一个可以不用停止 Web 服务就能让 Let’s Encrypt 验证域名的插件，再次打开 Nginx 配置文件，在 ssl 下面添加：\n```\nlocation ~ /.well-known {\n    allow all;\n}\n```\n保存。\n\n使用命令行续签证书\n```\ncd /opt/letsencrypt\n./letsencrypt-auto certonly -a webroot --agree-tos --renew-by-default --webroot-path=/usr/share/nginx/html -d example.com -d www.example.com\n```\n注意修改 webroot-path 参数，这是你的网站路径。\n重新加载 Nginx 配置文件。\nservice nginx reload\n\n创建  Let’s Encrypt 续签配置文件\ncp /opt/letsencrypt/examples/cli.ini /usr/local/etc/le-renew-webroot.ini\n\n我们将直接编辑示例配置文件：\nvi /usr/local/etc/le-renew-webroot.ini\n\n修改以下几行：\n```\nrsa-key-size = 4096\nemail = you@example.com\ndomains = example.com, www.example.com\nwebroot-path = /usr/share/nginx/html\n```\n\n于是可以使用配置文件续签证书\ncd /opt/letsencrypt\n./letsencrypt-auto certonly -a webroot --renew-by-default --config /usr/local/etc/le-renew-webroot.ini\n\n下载续签脚本并设置权限：\n```\ncurl -L -o /usr/local/sbin/le-renew-webroot https://gist.githubusercontent.com/thisismitch/e1b603165523df66d5cc/raw/fbffbf358e96110d5566f13677d9bd5f4f65794c/le-renew-webroot\nchmod +x /usr/local/sbin/le-renew-webroot\n```\n注意：确保上一步创建的 续签配置文件 /usr/local/etc/le-renew-webroot.ini 存在，否则脚本将无法运行。\n试运行脚本：\nle-renew-webroot\n\n创建定时任务：\ncrontab -e\n添加下面一行，让每周一早上 2 点 30 分运行一次，并记录到日志文件中。\n30 2 * * 1 /usr/local/sbin/le-renew-webroot >> /var/log/le-renewal.log\n\n## 什么是ACME?\nThe Automated Certificate Management Environment (ACME) protocol \nis a communications protocol for automating interactions between certificate authorities and their users' web servers, \nallowing the automated deployment of public key infrastructure at very low cost. \nIt was designed by the Internet Security Research Group for their Let's Encrypt service.\n\n## 遇到过的问题\n\n有一次从网上下载一个数字证书, 以为下下来了, 结果下的是一个html, 但是文件名却是对的, xxx.crt\n将xxx.crt添加到/usr/local/share/ca-certificates并update-ca-certificates后\ngit命令出现了如下错误:\n$ git pull\nfatal: unable to access 'https://github.com/erlang/otp.git/': Problem with the SSL CA cert (path? access rights?)\n多方找解决方案而不得, 最后发现/etc/ssl/certs/ca-certificates.crt文件里有一大堆html, \n删掉那些html代码后恢复正常\n\n## 参考链接\nhttps://program-think.blogspot.com/2010/02/introduce-digital-certificate-and-ca.html\nhttps://www.evssl.cn/ev-ssl-ask/122.html\nhttps://support.ssl.com/Knowledgebase/Article/View/19/0/der-vs-crt-vs-cer-vs-pem-certificates-and-how-to-convert-them\nhttps://en.wikipedia.org/wiki/Automated_Certificate_Management_Environment\nhttps://letsencrypt.org/getting-started/\nhttps://letsencrypt.org/how-it-works/\nhttps://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-14-04\nhttps://www.ssllabs.com/\nhttp://nginx.org/en/docs/http/configuring_https_servers.html\nhttp://schnell18.iteye.com/blog/2048296\nhttp://chenling1018.blog.163.com/blog/static/1480254201058112410789/\nhttp://www.appinn.com/use-letsencrypt-with-nginx/\n\n","slug":"ssl","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ph00f1mcxqw56srfi3"},{"title":"为什么在许多语言里, String类型都是immutable的?","date":"2016-08-21T05:24:00.000Z","_content":"\nString做成immutable的意义何在?\n一句话回答: 为了安全, 并发和复用, 详情请入内\n\n<!--more-->\n\n# 安全\n\n### security\n\n网络连接,文件操作中,如果string可以被修改,那么可能某函数以为它操作的对象是XXX,但是其实不是,因为被改了(比如黑客改了),导致安全问题\n如下:\n```\nboolean connect(string s){\n    if (!isSecure(s)) {\n        throw new SecurityException();\n    }\n    // here will cause problem, if s is changed before this by using other references.\n    causeProblem(s);\n}\n```\n\n### hash中用做key\n\n如果可变string做了hash的key, 以\"a\"为例,\n\n1 hash表计算出\"a\"的hash值并存储\"a\"和对应的value,\n2 之后这个\"a\"被修改成了\"b\"\n3 其他代码以另一个\"a\"(原来那个\"a\"已经被改掉了)去hash表中取值,\nhash表计算\"a\"的hash值找到了正确的位置, 但是当比较key时, 发现\"a\" != \"b\", 于是取不到值...\n\n### set\n\n假设String是可变的,那么下面的代码\n```\nHashSet<String> set = new HashSet<String>();\nset.add(new String(\"a\"));\nset.add(new String(\"b\"));\nset.add(new String(\"c\"));\n\nfor(String a: set)\n    a.value = \"a\";\n```\n将会使得Set中出现重复, 违背了Set的本义\n\n# 并发(Thread Safe)\n\n因为不会被改变, 可以在线程中共享, 而无须加锁,\n更新这个值其实是整个读出来, 在另一个地方做运算, 最后用整个新值替换原值,\n所以不会出现中间状态, 于是无须用锁等同步手段来保护中间状态不被其他线程看到\n\n而如果是可变类型的话, 则程序员很可能会把中间状态写回同一个内存地址,\n导致中间状态被其他线程看到, 于是需要用锁等同步手段\n\n所以关键点就是中间状态会不会被其他代码看到\n\n另外还有一种情况:\n有字符串\"abc\", 和一个去掉字符串首字母的函数, 两个线程几乎同时执行这个函数\n那么即使是immutable string, 也有可能两个函数都读到\"abc\"并写回\"bc\", 而正确结果应该是\"c\"\n这种情况还是要加锁\n\n而actor模型能够保证这种情况也不出问题,\n字符串\"abc\"存在一个actor中, 另外两个actor给这个actor发消息,\n这个actor顺序处理这两条消息\n\n# 复用\n\nJVM用String常量池实现String的复用, 下次用到时省得分配内存,\n由于一个String常量可能被多个变量名引用, 所以不能允许String被修改, 否则就影响到其他引用该String的变量了,\n也因此String类还被标记为final, 不允许修改其行为\n\nerlang里的值也可以因immutable而省内存, 如A = [1,2,3], B = A, C = [4|B] 这种情况,\n内存里其实只有[1,2,3]和连到[1,2,3]上的4, 而不是两份[1,2,3]和一份[4,1,2,3], 也就是说[1,2,3]被三个变量共用, 节省了内存\n\n# 杂谈\n\n有人说String a = \"a\";之后可以a = \"b\";修改\n这里其实string没有被修改, 只是a这个引用改了而已, 指向新的\"b\"字符串了\n虽然String是immutable的, 但是引用的变量不是immutable的, 其实a是个内存地址嘛\n\nerlang里就没有这个问题, A = \"a\"之后, 不能再A = \"b\", 编译不过\n\n","source":"_posts/string_immutable.md","raw":"title: 为什么在许多语言里, String类型都是immutable的?\ndate: 2016-08-21 13:24:00\ntags: [cs]\n---\n\nString做成immutable的意义何在?\n一句话回答: 为了安全, 并发和复用, 详情请入内\n\n<!--more-->\n\n# 安全\n\n### security\n\n网络连接,文件操作中,如果string可以被修改,那么可能某函数以为它操作的对象是XXX,但是其实不是,因为被改了(比如黑客改了),导致安全问题\n如下:\n```\nboolean connect(string s){\n    if (!isSecure(s)) {\n        throw new SecurityException();\n    }\n    // here will cause problem, if s is changed before this by using other references.\n    causeProblem(s);\n}\n```\n\n### hash中用做key\n\n如果可变string做了hash的key, 以\"a\"为例,\n\n1 hash表计算出\"a\"的hash值并存储\"a\"和对应的value,\n2 之后这个\"a\"被修改成了\"b\"\n3 其他代码以另一个\"a\"(原来那个\"a\"已经被改掉了)去hash表中取值,\nhash表计算\"a\"的hash值找到了正确的位置, 但是当比较key时, 发现\"a\" != \"b\", 于是取不到值...\n\n### set\n\n假设String是可变的,那么下面的代码\n```\nHashSet<String> set = new HashSet<String>();\nset.add(new String(\"a\"));\nset.add(new String(\"b\"));\nset.add(new String(\"c\"));\n\nfor(String a: set)\n    a.value = \"a\";\n```\n将会使得Set中出现重复, 违背了Set的本义\n\n# 并发(Thread Safe)\n\n因为不会被改变, 可以在线程中共享, 而无须加锁,\n更新这个值其实是整个读出来, 在另一个地方做运算, 最后用整个新值替换原值,\n所以不会出现中间状态, 于是无须用锁等同步手段来保护中间状态不被其他线程看到\n\n而如果是可变类型的话, 则程序员很可能会把中间状态写回同一个内存地址,\n导致中间状态被其他线程看到, 于是需要用锁等同步手段\n\n所以关键点就是中间状态会不会被其他代码看到\n\n另外还有一种情况:\n有字符串\"abc\", 和一个去掉字符串首字母的函数, 两个线程几乎同时执行这个函数\n那么即使是immutable string, 也有可能两个函数都读到\"abc\"并写回\"bc\", 而正确结果应该是\"c\"\n这种情况还是要加锁\n\n而actor模型能够保证这种情况也不出问题,\n字符串\"abc\"存在一个actor中, 另外两个actor给这个actor发消息,\n这个actor顺序处理这两条消息\n\n# 复用\n\nJVM用String常量池实现String的复用, 下次用到时省得分配内存,\n由于一个String常量可能被多个变量名引用, 所以不能允许String被修改, 否则就影响到其他引用该String的变量了,\n也因此String类还被标记为final, 不允许修改其行为\n\nerlang里的值也可以因immutable而省内存, 如A = [1,2,3], B = A, C = [4|B] 这种情况,\n内存里其实只有[1,2,3]和连到[1,2,3]上的4, 而不是两份[1,2,3]和一份[4,1,2,3], 也就是说[1,2,3]被三个变量共用, 节省了内存\n\n# 杂谈\n\n有人说String a = \"a\";之后可以a = \"b\";修改\n这里其实string没有被修改, 只是a这个引用改了而已, 指向新的\"b\"字符串了\n虽然String是immutable的, 但是引用的变量不是immutable的, 其实a是个内存地址嘛\n\nerlang里就没有这个问题, A = \"a\"之后, 不能再A = \"b\", 编译不过\n\n","slug":"string_immutable","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pj00f3mcxqpulkygg2"},{"title":"su sudo gksudo","date":"2015-08-11T16:00:00.000Z","_content":"这几个命令的相同点和不同点...\n<!--more-->\n## login shell & non-login shell\nlogin shell: 登录shell, 会执行.bash_profile和.bashrc, 需要用户名和密码, Ctrl+Alt+F1登录后就是一个登录shell\nnon-login shell: 非登录shell, 执行.bashrc, 不执行.bash_profile, 需要已经登录, 在gnome里开启的图形terminal是非登录shell\n\n## interactive shell & non-interactive shell\ninteractive shell: 交互式shell, 例如gnome的图形terminal\nnon-interactive shell: 非交互式shell, 可能由一个进程启动, 用户看不到输入或输出\n\n## su\nsu -c apt-get install vlc\n-c 执行命令\n\nsu -\n登录shell\n\n## sudo\n用户必须在sudoers文件里或在一个group里(这个group在sudoers文件里)\n\nsudo su\n非登录shell, HOME环境变量变成root\n\nsudo -i\n登录shell \n近似于sudo su -\n启动由目标用户的password数据库项指定的shell\n\nsudo -s\n非登录shell, HOME环境变量还是当前用户\n启动由SHELL环境变量指定的shell\n如果没有SHELL环境变量则启动由当前用户的password数据库项指定的shell\n\nsudo su = sudo + su + shell \nsudo -i = sudo + shell\n\n## 检测是否处于登录shell中(仅限bash)\n```bash\nshopt -q login_shell && echo 'Login shell' || echo 'No login shell'\n```\n\n## sudo和gksudo\nsudo和gksudo都是使用root权限来执行应用\nsudo执行程序时使用的是当前用户的home及其配置，而gksudo使用的是root用户的home和配置\n\n一般情况下看不出什么区别，但是对于那些针对不同用户有不同的配置文件和表现形式的应用程序来说，这两种方式的结果区别就很明显了。\n比如使用sudo firefox出现权限问题，gksudo firefox就没有这个问题。\n\n在不通过终端运行程序时，sudo没有办法提供一个界面来输入管理员密码，比如在快捷方式中。\n还有些GUI程序只能用gksudo\n\n## Ubuntu设置root密码\n在普通用户shell里\nsudo passwd\n但是最好不要使用root密码,通过sudo机制处理root权限比较好\n\n","source":"_posts/su_sudo_gksudo.md","raw":"title: su sudo gksudo\ndate: 2015-08-12 \ntags: linux\n---\n这几个命令的相同点和不同点...\n<!--more-->\n## login shell & non-login shell\nlogin shell: 登录shell, 会执行.bash_profile和.bashrc, 需要用户名和密码, Ctrl+Alt+F1登录后就是一个登录shell\nnon-login shell: 非登录shell, 执行.bashrc, 不执行.bash_profile, 需要已经登录, 在gnome里开启的图形terminal是非登录shell\n\n## interactive shell & non-interactive shell\ninteractive shell: 交互式shell, 例如gnome的图形terminal\nnon-interactive shell: 非交互式shell, 可能由一个进程启动, 用户看不到输入或输出\n\n## su\nsu -c apt-get install vlc\n-c 执行命令\n\nsu -\n登录shell\n\n## sudo\n用户必须在sudoers文件里或在一个group里(这个group在sudoers文件里)\n\nsudo su\n非登录shell, HOME环境变量变成root\n\nsudo -i\n登录shell \n近似于sudo su -\n启动由目标用户的password数据库项指定的shell\n\nsudo -s\n非登录shell, HOME环境变量还是当前用户\n启动由SHELL环境变量指定的shell\n如果没有SHELL环境变量则启动由当前用户的password数据库项指定的shell\n\nsudo su = sudo + su + shell \nsudo -i = sudo + shell\n\n## 检测是否处于登录shell中(仅限bash)\n```bash\nshopt -q login_shell && echo 'Login shell' || echo 'No login shell'\n```\n\n## sudo和gksudo\nsudo和gksudo都是使用root权限来执行应用\nsudo执行程序时使用的是当前用户的home及其配置，而gksudo使用的是root用户的home和配置\n\n一般情况下看不出什么区别，但是对于那些针对不同用户有不同的配置文件和表现形式的应用程序来说，这两种方式的结果区别就很明显了。\n比如使用sudo firefox出现权限问题，gksudo firefox就没有这个问题。\n\n在不通过终端运行程序时，sudo没有办法提供一个界面来输入管理员密码，比如在快捷方式中。\n还有些GUI程序只能用gksudo\n\n## Ubuntu设置root密码\n在普通用户shell里\nsudo passwd\n但是最好不要使用root密码,通过sudo机制处理root权限比较好\n\n","slug":"su_sudo_gksudo","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pk00f6mcxqaktl3zpw"},{"title":"svn","date":"2015-08-06T16:00:00.000Z","_content":"SVN是Subversion的简称\n<!--more-->\n## 安装\n```bash\nsudo apt-get install subversion\n```\n\n## 将默认编辑器设置为vim\n编辑配置文件~/.subversion/config\neditor-cmd = vim\n或\n```bash\nsudo update-alternatives --config editor\n```\n\n## Ubuntu14.04下搭建SVN服务器\n\n### 建版本仓库, 取名suexbag\n```bash\ncd /srv\nsudo mkdir svn\ncd /srv/svn\nsudo mkdir suexbag\nsudo svnadmin create /srv/svn/suexbag\n```\n\n### 配置\n进入suex/conf目录\n编辑配置文件svnserve.conf\n[general]\nanon-access = none\nauth-access = write\npassword-db = passwd\nauthz-db = authz\n\n编辑配置文件authz \n组名取为admin,可以用逗号分割允许多个用户在同一个组内\n[groups]\nadmin = suex\n\n[/]\n@admin = rw\n*=r\n\n编辑passwd文件 \n设定用户密码, 此处是明文\n[users]\nsuex = www\n\n### 启动svn服务器\n```bash\nsudo svnserve -d -r /srv/svn/\n```\n\n### 客户端checkout代码\n```bash\nsvn co svn://172.16.205.129/suexbag --username=suex\n```\n\n## svn cleanup\n清除写锁(svn st时发现状态为L),取消未完成的状态\n\n## svn ignore\n```bash\nsvn propset svn:ignore \"*.beam\" .\nsvn propget svn:ignore\n```\n\n\n\n","source":"_posts/svn.md","raw":"title: svn\ndate: 2015-08-07\ntags: linux\n---\nSVN是Subversion的简称\n<!--more-->\n## 安装\n```bash\nsudo apt-get install subversion\n```\n\n## 将默认编辑器设置为vim\n编辑配置文件~/.subversion/config\neditor-cmd = vim\n或\n```bash\nsudo update-alternatives --config editor\n```\n\n## Ubuntu14.04下搭建SVN服务器\n\n### 建版本仓库, 取名suexbag\n```bash\ncd /srv\nsudo mkdir svn\ncd /srv/svn\nsudo mkdir suexbag\nsudo svnadmin create /srv/svn/suexbag\n```\n\n### 配置\n进入suex/conf目录\n编辑配置文件svnserve.conf\n[general]\nanon-access = none\nauth-access = write\npassword-db = passwd\nauthz-db = authz\n\n编辑配置文件authz \n组名取为admin,可以用逗号分割允许多个用户在同一个组内\n[groups]\nadmin = suex\n\n[/]\n@admin = rw\n*=r\n\n编辑passwd文件 \n设定用户密码, 此处是明文\n[users]\nsuex = www\n\n### 启动svn服务器\n```bash\nsudo svnserve -d -r /srv/svn/\n```\n\n### 客户端checkout代码\n```bash\nsvn co svn://172.16.205.129/suexbag --username=suex\n```\n\n## svn cleanup\n清除写锁(svn st时发现状态为L),取消未完成的状态\n\n## svn ignore\n```bash\nsvn propset svn:ignore \"*.beam\" .\nsvn propget svn:ignore\n```\n\n\n\n","slug":"svn","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pl00f8mcxq59y8x9lk"},{"title":"svn client","date":"2015-11-26T16:00:00.000Z","_content":"subversion客户端常用命令\n<!--more-->\n## 常用命令\n1、将文件checkout到本地目录\nsvn checkout path（path是服务器上的目录）\n例如：svn checkout svn://192.168.1.1/pro/domain\n简写：svn co\n\n2、往版本库中添加新的文件\nsvn add file\n例如：svn add test.php(添加test.php)\nsvn add \\*.php(添加当前目录下所有的php文件)\n\n3、将改动的文件提交到版本库\nsvn commit -m \"LogMessage\" [-N] [--no-unlock] PATH(如果选择了保持锁，就使用--no-unlock开关)\n例如：svn commit -m \"add test file for my test\" test.php\n简写：svn ci\n\n4、加锁/解锁\nsvn lock -m \"LockMessage\" [--force] PATH\n例如：svn lock -m \"lock test file\" test.php\nsvn unlock PATH\n\n5、更新到某个版本\nsvn update -r m path\n例如：\nsvn update如果后面没有目录，默认将当前目录以及子目录下的所有文件都更新到最新版本。\nsvn update -r 200 test.php(将版本库中的文件test.php还原到版本200)\nsvn update test.php(更新，于版本库同步。如果在提交的时候提示过期的话，是因为冲突，需要先update，修改文件，然后清除svn resolved，最后再提交commit)\n简写：svn up\n\n6、查看文件或者目录状态\n1）svn status path（目录下的文件和子目录的状态，正常状态不显示）\n【?：不在svn的控制中；M：内容被修改；C：发生冲突；A：预定加入到版本库；K：被锁定】\n2）svn status -v path(显示所有文件详细状态)\n第一列保持相同，第二列显示工作版本号，第三和第四列显示最后一次修改的版本号和修改人。\n注：svn status、svn diff和 svn revert这三条命令在没有网络的情况下也可以执行的，\n原因是svn在本地的.svn中保留了本地版本的原始拷贝。\n简写：svn st\n\n7、删除文件\nsvn delete path -m \"delete test fle\"\n例如：svn delete svn://192.168.1.1/pro/domain/test.php -m \"delete test file\"\n或者先svn delete test.php 然后再svn ci -m \"delete test file\"，推荐使用这种\n简写：svn (del, remove, rm)\n\n8、查看日志\nsvn log path\n例如：svn log test.php 显示这个文件的所有修改记录，及其版本号的变化\nsvn log -l 10 path\n参数 -l N 表示查看最近的N个版本\nsvn log -r {2015-10-7}:{2015-11-15} --search \"chenduo\" -v\n参数 -r {2015-10-7}:{2015-11-15} 查看指定日期区间的版本\n参数 --search \"chenduo\" 指定一个search pattern, 可用于筛选指定用户提交的版本\n参数 -v 表示查看详细信息, 会显示这个版本具体改动的路径列表\n\n9、查看文件详细信息\nsvn info path\n例如：svn info test.php\n\n10、比较差异\nsvn diff path(将修改的文件与基础版本比较)\n例如：svn diff test.php\nsvn diff -r m:n path(对版本m和版本n比较差异)\n例如：svn diff -r 200:201 test.php\n简写：svn di\nsvn di -c 559 src/world/team_mgr.erl --diff-cmd meld\n参数 -c 查看指定版本的修改内容\n参数 --diff-cmd meld 使用指定的外部命令查看差分\n\n11、分支合并\n新建分支\nsvn copy http://mysvn.com/svn/server/trunk http://mysvn.com/svn/server/myname -m \"我的分支\"\n\nsvn merge -r m:n path\n例如：svn merge -r 200:205 test.php\n（将版本200与205之间的差异合并到当前文件，但是一般都会产生冲突，需要处理一下）\n\nsvn merge --dry-run -r r3050:r3113 http://mysvn.com/svn/server/trunk\n--dry-run参数表示并不实际执行,只是想看一下合并后是什么状态\n注意区分方向: merge命令是把path里的内容合并到当前分支, 而不是把当前内容推到外面, 是pull而不是push\n\n12、SVN 帮助\nsvn help\n如: svn help ci\n\n13、版本库下的文件和目录列表\nsvn list path\n显示path目录下的所有属于版本库的文件和目录\n简写：svn ls\n\n14、创建纳入版本控制下的新目录\nsvn mkdir: 创建纳入版本控制下的新目录。\n用法:\n1、mkdir PATH…\n每一个以工作副本 PATH 指定的目录，都会创建在本地端，并且加入新增调度，以待下一次的提交。\n2、mkdir URL…\n每个以URL指定的目录，都会通过立即提交于仓库中创建。在这两个情况下，所有的中间目录都必须事先存在。\n\n15、撤销本地修改\nsvn revert: 恢复为原始未改变的工作副本文件 (撤销大部份的本地修改)。\n用法: revert PATH…\n注意: 本子命令不会存取网络，并且会解除冲突的状况。但是它不会恢复被删除的目录\nsvn revert -R path\n参数 -R 对path的文件和子目录递归操作,比较危险,慎用\n\n16、代码库URL变更\nsvn switch (sw): 更新工作副本至不同的URL。\n用法: \n1、switch URL [PATH]\n更新你的工作副本，映射到一个新的URL，\n其行为跟“svn update”很像，也会将服务器上文件与本地文件合并。\n这是将工作副本对应到同一仓库中某个分支或者标记的方法\n2、switch --relocate FROM TO [PATH...]\n改写工作副本的URL元数据，以反映单纯的URL上的改变。\n当仓库的根URL变动(比如方案名或是主机名称变动)，\n但是工作副本仍旧对映到同一仓库的同一目录时使用这个命令更新工作副本与仓库的对应关系。\n\n17、移除冲突状态\nsvn resolved: 移除工作副本的目录或文件的“冲突”状态。\n用法: resolved PATH…\n注意: 本子命令不会依语法来解决冲突或是移除冲突标记；它只是移除冲突的相关文件，然后让PATH可以再次提交。\n\n18、输出指定文件或URL的内容\nsvn cat 目标[@版本]…如果指定了版本，将从指定的版本开始查找。\nsvn cat -r PREV filename > haha \n(PREV 是上一版本,也可以写具体版本号,这样可以得到一个文件haha,其内容是指定版本的filename的内容)\n\n19、设置属性\nsvn propedit svn:ignore .\n上例表示编辑当前目录(.)的svn:ignore属性\n\n20、blame(查看指定文件每一行的作者相关信息)\nsvn blame src/player/gm_command.erl -r 3000:4349 -v | less\n参数 -v 查看详细信息,包含时间戳\n\n## 参数链接\nhttp://www.rjgc.net/control/content/content.php?nid=4418\n","source":"_posts/svn_client.markdown","raw":"title: svn client\ndate: 2015-11-27\ntags: [versioncontrol]\n---\nsubversion客户端常用命令\n<!--more-->\n## 常用命令\n1、将文件checkout到本地目录\nsvn checkout path（path是服务器上的目录）\n例如：svn checkout svn://192.168.1.1/pro/domain\n简写：svn co\n\n2、往版本库中添加新的文件\nsvn add file\n例如：svn add test.php(添加test.php)\nsvn add \\*.php(添加当前目录下所有的php文件)\n\n3、将改动的文件提交到版本库\nsvn commit -m \"LogMessage\" [-N] [--no-unlock] PATH(如果选择了保持锁，就使用--no-unlock开关)\n例如：svn commit -m \"add test file for my test\" test.php\n简写：svn ci\n\n4、加锁/解锁\nsvn lock -m \"LockMessage\" [--force] PATH\n例如：svn lock -m \"lock test file\" test.php\nsvn unlock PATH\n\n5、更新到某个版本\nsvn update -r m path\n例如：\nsvn update如果后面没有目录，默认将当前目录以及子目录下的所有文件都更新到最新版本。\nsvn update -r 200 test.php(将版本库中的文件test.php还原到版本200)\nsvn update test.php(更新，于版本库同步。如果在提交的时候提示过期的话，是因为冲突，需要先update，修改文件，然后清除svn resolved，最后再提交commit)\n简写：svn up\n\n6、查看文件或者目录状态\n1）svn status path（目录下的文件和子目录的状态，正常状态不显示）\n【?：不在svn的控制中；M：内容被修改；C：发生冲突；A：预定加入到版本库；K：被锁定】\n2）svn status -v path(显示所有文件详细状态)\n第一列保持相同，第二列显示工作版本号，第三和第四列显示最后一次修改的版本号和修改人。\n注：svn status、svn diff和 svn revert这三条命令在没有网络的情况下也可以执行的，\n原因是svn在本地的.svn中保留了本地版本的原始拷贝。\n简写：svn st\n\n7、删除文件\nsvn delete path -m \"delete test fle\"\n例如：svn delete svn://192.168.1.1/pro/domain/test.php -m \"delete test file\"\n或者先svn delete test.php 然后再svn ci -m \"delete test file\"，推荐使用这种\n简写：svn (del, remove, rm)\n\n8、查看日志\nsvn log path\n例如：svn log test.php 显示这个文件的所有修改记录，及其版本号的变化\nsvn log -l 10 path\n参数 -l N 表示查看最近的N个版本\nsvn log -r {2015-10-7}:{2015-11-15} --search \"chenduo\" -v\n参数 -r {2015-10-7}:{2015-11-15} 查看指定日期区间的版本\n参数 --search \"chenduo\" 指定一个search pattern, 可用于筛选指定用户提交的版本\n参数 -v 表示查看详细信息, 会显示这个版本具体改动的路径列表\n\n9、查看文件详细信息\nsvn info path\n例如：svn info test.php\n\n10、比较差异\nsvn diff path(将修改的文件与基础版本比较)\n例如：svn diff test.php\nsvn diff -r m:n path(对版本m和版本n比较差异)\n例如：svn diff -r 200:201 test.php\n简写：svn di\nsvn di -c 559 src/world/team_mgr.erl --diff-cmd meld\n参数 -c 查看指定版本的修改内容\n参数 --diff-cmd meld 使用指定的外部命令查看差分\n\n11、分支合并\n新建分支\nsvn copy http://mysvn.com/svn/server/trunk http://mysvn.com/svn/server/myname -m \"我的分支\"\n\nsvn merge -r m:n path\n例如：svn merge -r 200:205 test.php\n（将版本200与205之间的差异合并到当前文件，但是一般都会产生冲突，需要处理一下）\n\nsvn merge --dry-run -r r3050:r3113 http://mysvn.com/svn/server/trunk\n--dry-run参数表示并不实际执行,只是想看一下合并后是什么状态\n注意区分方向: merge命令是把path里的内容合并到当前分支, 而不是把当前内容推到外面, 是pull而不是push\n\n12、SVN 帮助\nsvn help\n如: svn help ci\n\n13、版本库下的文件和目录列表\nsvn list path\n显示path目录下的所有属于版本库的文件和目录\n简写：svn ls\n\n14、创建纳入版本控制下的新目录\nsvn mkdir: 创建纳入版本控制下的新目录。\n用法:\n1、mkdir PATH…\n每一个以工作副本 PATH 指定的目录，都会创建在本地端，并且加入新增调度，以待下一次的提交。\n2、mkdir URL…\n每个以URL指定的目录，都会通过立即提交于仓库中创建。在这两个情况下，所有的中间目录都必须事先存在。\n\n15、撤销本地修改\nsvn revert: 恢复为原始未改变的工作副本文件 (撤销大部份的本地修改)。\n用法: revert PATH…\n注意: 本子命令不会存取网络，并且会解除冲突的状况。但是它不会恢复被删除的目录\nsvn revert -R path\n参数 -R 对path的文件和子目录递归操作,比较危险,慎用\n\n16、代码库URL变更\nsvn switch (sw): 更新工作副本至不同的URL。\n用法: \n1、switch URL [PATH]\n更新你的工作副本，映射到一个新的URL，\n其行为跟“svn update”很像，也会将服务器上文件与本地文件合并。\n这是将工作副本对应到同一仓库中某个分支或者标记的方法\n2、switch --relocate FROM TO [PATH...]\n改写工作副本的URL元数据，以反映单纯的URL上的改变。\n当仓库的根URL变动(比如方案名或是主机名称变动)，\n但是工作副本仍旧对映到同一仓库的同一目录时使用这个命令更新工作副本与仓库的对应关系。\n\n17、移除冲突状态\nsvn resolved: 移除工作副本的目录或文件的“冲突”状态。\n用法: resolved PATH…\n注意: 本子命令不会依语法来解决冲突或是移除冲突标记；它只是移除冲突的相关文件，然后让PATH可以再次提交。\n\n18、输出指定文件或URL的内容\nsvn cat 目标[@版本]…如果指定了版本，将从指定的版本开始查找。\nsvn cat -r PREV filename > haha \n(PREV 是上一版本,也可以写具体版本号,这样可以得到一个文件haha,其内容是指定版本的filename的内容)\n\n19、设置属性\nsvn propedit svn:ignore .\n上例表示编辑当前目录(.)的svn:ignore属性\n\n20、blame(查看指定文件每一行的作者相关信息)\nsvn blame src/player/gm_command.erl -r 3000:4349 -v | less\n参数 -v 查看详细信息,包含时间戳\n\n## 参数链接\nhttp://www.rjgc.net/control/content/content.php?nid=4418\n","slug":"svn_client","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pl00famcxqc5vj5p0f"},{"title":"tcp","date":"2016-06-13T07:49:00.000Z","_content":"\n继续回顾计算机网络的内容\n\n<!--more-->\n\n## 握手和挥手\n\n建立tcp连接需要三次握手: SYN, SYN+ACK, ACK\n断开tcp连接需要四次挥手: FIN, ACK, FIN, ACK\n\n![tcp](/pics/tcp/tcp.gif)\n\n![建立tcp连接](/pics/tcp/tcp_establish.gif)\n\n![断开tcp连接](/pics/tcp/tcp_close.gif)\n\n【注意】 在TIME_WAIT状态中，如果TCP client端最后一次发送的ACK丢失了，它将重新发送。\nTIME_WAIT状态中所需要的时间是依赖于实现方法的。典型的值为30秒、1分钟和2分钟。\n等待之后连接正式关闭，并且所有的资源(包括端口号)都被释放。\n\n### 为什么连接的时候是三次握手，关闭的时候却是四次握手？\n答：因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。\n其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，\n很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，\"你发的FIN报文我收到了\"。\n只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。\n\n### 为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？\n答：虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。\n所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。\n\n## keep alive\n\n* tcp_keepalive_time 最后一次数据交换到发送第一个keepalive探测包的间隔,默认值为7200s（2h）。\n* tcp_keepalive_probes 在tcp_keepalive_time之后,没有接收到对方确认,继续发送keepalive探测包次数，默认值为9（次）。\n* tcp_keepalive_intvl 在tcp_keepalive_time之后,没有接收到对方确认,继续发送keepalive探测包的时间间隔，默认值为75s。\n\ntcp_keepalive_intvl乘以tcp_keepalive_probes，就得到了从开始探测到放弃探测确定连接断开所需的时间\n\n例子: 修改/etc/sysctl.conf文件,\n```\nnet.ipv4.tcp_keepalive_time=90\nnet.ipv4.tcp_keepalive_intvl=15\nnet.ipv4.tcp_keepalive_probes=2\n```\n执行sysctl -p生效, sysctl -a | grep keepalive可查看\n\n## tcp_retries\n\n* tcp_syn_retries 对于一个新建连接,内核要发送多少个 SYN 连接请求才决定放弃。默认值是5。\n* tcp_retries1 放弃回应一个TCP连接请求前,需要进行多少次重试。默认值3。\n* tcp_retries2 在丢弃激活(已建立通讯状况)的TCP连接之前,需要进行多少次重试。默认值为15。\n\n## 参考链接\nhttp://blog.csdn.net/whuslei/article/details/6667471\n\n","source":"_posts/tcp.md","raw":"title: tcp\ndate: 2016-06-13 15:49:00\ntags: [internet, tcp]\n---\n\n继续回顾计算机网络的内容\n\n<!--more-->\n\n## 握手和挥手\n\n建立tcp连接需要三次握手: SYN, SYN+ACK, ACK\n断开tcp连接需要四次挥手: FIN, ACK, FIN, ACK\n\n![tcp](/pics/tcp/tcp.gif)\n\n![建立tcp连接](/pics/tcp/tcp_establish.gif)\n\n![断开tcp连接](/pics/tcp/tcp_close.gif)\n\n【注意】 在TIME_WAIT状态中，如果TCP client端最后一次发送的ACK丢失了，它将重新发送。\nTIME_WAIT状态中所需要的时间是依赖于实现方法的。典型的值为30秒、1分钟和2分钟。\n等待之后连接正式关闭，并且所有的资源(包括端口号)都被释放。\n\n### 为什么连接的时候是三次握手，关闭的时候却是四次握手？\n答：因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。\n其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，\n很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，\"你发的FIN报文我收到了\"。\n只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。\n\n### 为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？\n答：虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。\n所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。\n\n## keep alive\n\n* tcp_keepalive_time 最后一次数据交换到发送第一个keepalive探测包的间隔,默认值为7200s（2h）。\n* tcp_keepalive_probes 在tcp_keepalive_time之后,没有接收到对方确认,继续发送keepalive探测包次数，默认值为9（次）。\n* tcp_keepalive_intvl 在tcp_keepalive_time之后,没有接收到对方确认,继续发送keepalive探测包的时间间隔，默认值为75s。\n\ntcp_keepalive_intvl乘以tcp_keepalive_probes，就得到了从开始探测到放弃探测确定连接断开所需的时间\n\n例子: 修改/etc/sysctl.conf文件,\n```\nnet.ipv4.tcp_keepalive_time=90\nnet.ipv4.tcp_keepalive_intvl=15\nnet.ipv4.tcp_keepalive_probes=2\n```\n执行sysctl -p生效, sysctl -a | grep keepalive可查看\n\n## tcp_retries\n\n* tcp_syn_retries 对于一个新建连接,内核要发送多少个 SYN 连接请求才决定放弃。默认值是5。\n* tcp_retries1 放弃回应一个TCP连接请求前,需要进行多少次重试。默认值3。\n* tcp_retries2 在丢弃激活(已建立通讯状况)的TCP连接之前,需要进行多少次重试。默认值为15。\n\n## 参考链接\nhttp://blog.csdn.net/whuslei/article/details/6667471\n\n","slug":"tcp","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pn00fdmcxqmybp8bkk"},{"title":"timer","date":"2016-01-03T16:00:00.000Z","_content":"\n## 参考链接\nhttp://novoland.github.io/%E5%B9%B6%E5%8F%91/2014/07/26/%E5%AE%9A%E6%97%B6%E5%99%A8%EF%BC%88Timer%EF%BC%89%E7%9A%84%E5%AE%9E%E7%8E%B0.html\nhttp://blog.csdn.net/babyfans/article/details/5445184\nhttps://www.ibm.com/developerworks/cn/linux/l-cn-clocks/\n\n","source":"_posts/timer.md","raw":"title: timer\ndate: 2016-01-04\ntags: [computer, linux]\n---\n\n## 参考链接\nhttp://novoland.github.io/%E5%B9%B6%E5%8F%91/2014/07/26/%E5%AE%9A%E6%97%B6%E5%99%A8%EF%BC%88Timer%EF%BC%89%E7%9A%84%E5%AE%9E%E7%8E%B0.html\nhttp://blog.csdn.net/babyfans/article/details/5445184\nhttps://www.ibm.com/developerworks/cn/linux/l-cn-clocks/\n\n","slug":"timer","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5po00ffmcxqjz3jaqqk"},{"title":"top命令","date":"2016-06-15T09:21:00.000Z","_content":"\n## 排序\nshift+p, 按CPU占用量降序显示\nshift+m, 按内存占用量降序显示\n\n## 名词解释\nVIRT  --  Virtual Image (kb)\nThe  total  amount  of  virtual  memory  used  by the task.  It includes all code, data and shared libraries  \nplus  pages  that have  been  swapped out and pages that have been mapped but not used.\n\nRES  --  Resident size (kb)\nThe non-swapped physical memory a task has used.\n\nSHR  --  Shared Mem size (kb)\nThe amount of shared memory used by a task.  It simply reflects\nmemory that could be potentially shared with other processes.\n\n","source":"_posts/top_cmd.md","raw":"title: top命令\ndate: 2016-06-15 17:21:00\ntags: [linux]\n---\n\n## 排序\nshift+p, 按CPU占用量降序显示\nshift+m, 按内存占用量降序显示\n\n## 名词解释\nVIRT  --  Virtual Image (kb)\nThe  total  amount  of  virtual  memory  used  by the task.  It includes all code, data and shared libraries  \nplus  pages  that have  been  swapped out and pages that have been mapped but not used.\n\nRES  --  Resident size (kb)\nThe non-swapped physical memory a task has used.\n\nSHR  --  Shared Mem size (kb)\nThe amount of shared memory used by a task.  It simply reflects\nmemory that could be potentially shared with other processes.\n\n","slug":"top_cmd","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pp00fimcxqa9sufh3x"},{"title":"traceroute","date":"2016-06-06T12:55:00.000Z","_content":"\nTraceroute(windows里是tracert)用来侦测源主机到目的主机之间经过的路径。\n<!--more-->\n\n## 原理\n\nTraceroute 使用 ICMP 报文和 IP 首部中的 TTL 字段，它充分利用了 ICMP 超时消息。\n其原理是，开始时发送一个 TTL 字段为 1 的 UDP 数据报，而后每次收到 ICMP 超时后，按顺序再发送一个 TTL 字段加 1 的 UDP 数据报，以确定路径中的每个路由器，\n而每个路由器在丢弃 UDP 数据报时都会返回一个 ICMP 超时报文，\n而最终到达目的主机后，由于 ICMP选择了一个不可能的值作为 UDP 端口(大于30000)。\n这样目的主机就会发送一个端口不可达的 ICMP 差错报文。这样就知道已经到达目的主机, 不必再继续循环了。\n\n一条路径上的每个设备traceroute默认要测3次。\n输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。\n\n## 使用\n```\n$ traceroute -n -q 2 -m 20 suexcxine.cc\ntraceroute to suexcxine.cc (118.193.216.246), 20 hops max, 60 byte packets\n 1  192.168.1.1  0.348 ms  0.600 ms\n 2  123.120.0.1  6.108 ms  6.188 ms\n 3  61.148.163.105  5.917 ms  6.008 ms\n 4  124.65.56.117  6.496 ms  6.592 ms\n 5  202.106.36.2  6.281 ms  6.382 ms\n 6  219.158.6.42  9.513 ms  9.608 ms\n 7  219.158.6.42  9.702 ms  9.797 ms\n 8  * *\n 9  * *\n10  * *\n11  * *\n12  * *\n13  * *\n14  118.193.216.246  57.480 ms !X  57.475 ms !X\n\n```\n以星号表示的行, 可能是防火墙封掉了ICMP的返回信息。\n\n#### 参数\n-n 不使用dns, 直接使用ip地址\n-q 每个网关发送数据包数量\n-m 最大跳数\n\n","source":"_posts/traceroute.md","raw":"title: traceroute\ndate: 2016-06-06 20:55:00\ntags: [internet]\n---\n\nTraceroute(windows里是tracert)用来侦测源主机到目的主机之间经过的路径。\n<!--more-->\n\n## 原理\n\nTraceroute 使用 ICMP 报文和 IP 首部中的 TTL 字段，它充分利用了 ICMP 超时消息。\n其原理是，开始时发送一个 TTL 字段为 1 的 UDP 数据报，而后每次收到 ICMP 超时后，按顺序再发送一个 TTL 字段加 1 的 UDP 数据报，以确定路径中的每个路由器，\n而每个路由器在丢弃 UDP 数据报时都会返回一个 ICMP 超时报文，\n而最终到达目的主机后，由于 ICMP选择了一个不可能的值作为 UDP 端口(大于30000)。\n这样目的主机就会发送一个端口不可达的 ICMP 差错报文。这样就知道已经到达目的主机, 不必再继续循环了。\n\n一条路径上的每个设备traceroute默认要测3次。\n输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。\n\n## 使用\n```\n$ traceroute -n -q 2 -m 20 suexcxine.cc\ntraceroute to suexcxine.cc (118.193.216.246), 20 hops max, 60 byte packets\n 1  192.168.1.1  0.348 ms  0.600 ms\n 2  123.120.0.1  6.108 ms  6.188 ms\n 3  61.148.163.105  5.917 ms  6.008 ms\n 4  124.65.56.117  6.496 ms  6.592 ms\n 5  202.106.36.2  6.281 ms  6.382 ms\n 6  219.158.6.42  9.513 ms  9.608 ms\n 7  219.158.6.42  9.702 ms  9.797 ms\n 8  * *\n 9  * *\n10  * *\n11  * *\n12  * *\n13  * *\n14  118.193.216.246  57.480 ms !X  57.475 ms !X\n\n```\n以星号表示的行, 可能是防火墙封掉了ICMP的返回信息。\n\n#### 参数\n-n 不使用dns, 直接使用ip地址\n-q 每个网关发送数据包数量\n-m 最大跳数\n\n","slug":"traceroute","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pq00fkmcxqi6coathv"},{"title":"tsocks","date":"2015-07-26T16:00:00.000Z","_content":"不仅浏览器,有时其他应用程序也需要代理,比如git clone的时候\ntsocks让shell也可以用代理\n<!--more-->\n## 安装tsocks\nsudo apt-get install tsocks\n\n## 编辑配置文件:/etc/tsocks.conf\n> local = 192.168.1.0/255.255.255.0\n> local = 127.0.0.0/255.0.0.0\n> server = 127.0.0.1 \n> server_type = 5\n> server_port = 1080 \n\n## 测试是否生效\ntsocks wget www.google.com\n--2015-07-27 14:27:24--  http://www.google.com/\n正在解析主机 www.google.com (www.google.com)... 216.58.221.36, 2404:6800:4005:809::2004\n正在连接 www.google.com (www.google.com)|216.58.221.36|:80... 已连接。\n已发出 HTTP 请求，正在等待回应... 200 OK\n长度： 未指定 [text/html]\n正在保存至: “index.html”\n...\n    2015-07-27 14:27:25 (73.9 KB/s) - “index.html” 已保存 [20410]\n\n## 其他使用方法\n. tsocks -on\n. tsocks -off\n\n## 查看当前LD_PRELOAD的值\ntsocks -sh\n\n## 其他参考\nman 1 tsocks\nman 8 tsocks\n\n","source":"_posts/tsocks.md","raw":"title: tsocks\ndate: 2015-07-27\ntags: [internet, linux]\n---\n不仅浏览器,有时其他应用程序也需要代理,比如git clone的时候\ntsocks让shell也可以用代理\n<!--more-->\n## 安装tsocks\nsudo apt-get install tsocks\n\n## 编辑配置文件:/etc/tsocks.conf\n> local = 192.168.1.0/255.255.255.0\n> local = 127.0.0.0/255.0.0.0\n> server = 127.0.0.1 \n> server_type = 5\n> server_port = 1080 \n\n## 测试是否生效\ntsocks wget www.google.com\n--2015-07-27 14:27:24--  http://www.google.com/\n正在解析主机 www.google.com (www.google.com)... 216.58.221.36, 2404:6800:4005:809::2004\n正在连接 www.google.com (www.google.com)|216.58.221.36|:80... 已连接。\n已发出 HTTP 请求，正在等待回应... 200 OK\n长度： 未指定 [text/html]\n正在保存至: “index.html”\n...\n    2015-07-27 14:27:25 (73.9 KB/s) - “index.html” 已保存 [20410]\n\n## 其他使用方法\n. tsocks -on\n. tsocks -off\n\n## 查看当前LD_PRELOAD的值\ntsocks -sh\n\n## 其他参考\nman 1 tsocks\nman 8 tsocks\n\n","slug":"tsocks","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pr00fnmcxq6sp1g61v"},{"title":"坎坷之路 Ubuntu 16.04","date":"2016-07-24T13:34:00.000Z","_content":"\n至今仍然没能成功\n\n<!--more-->\n\n上周下载了16.04的镜像, 做好U盘后, 重启电脑, 设为从U盘启动\n\n结果出现error: 一行一行地持续出,\n\ngoogle后有人说按tab键, 可以看到几个可选的命令，输入live回车即可，\n可是我输入live后就卡死，两分钟后，出现如下报错:\ntask swapper/0:1 blocked for more than 120 seconds.\n还有几个swapper以外的名字, 不过都是被阻塞了超过120秒\n一遍一遍不停地出, 只能强制关机\n\n不放弃, 再次google, 可是这次什么有用的信息也没有查到\n\n不放弃, 换Ubuntu-kylin 16.04试试, 结果一样\n\n不放弃, 昨天出了16.04.1, 估计官方把这些bug都改好了吧?\n又下载了16.04.1的镜像,还是一样... 失望\n\n不放弃, 从14.04升级到16.04吧,\n```\nsudo update-manage -d\n```\n两个多小时后, 一切顺利! 安装过程中桌面背景刷新了, 好漂亮, 好激动! 最后一步重启,\n\n重启.. 粉屏, 卡住了..\n\n两分钟后, 再次出现task xxx blocked for more than 120 seconds.\n\n好吧, 可能我这笔记本的硬件或者BIOS什么的不兼容吧..\n不放弃, 等我以后换了电脑再装\n\n最后还得重新装14.04, 重装环境...\n\n## 或许可以16.04和3.19的linux内核搭配着用\n\n因为发现14.04升级内核到4.4也出现了同样的问题\nhttp://askubuntu.com/questions/758452/ubuntu-16-04-lts-with-3-kernel\n\n","source":"_posts/ubuntu_16.04_noteasy.md","raw":"title: 坎坷之路 Ubuntu 16.04\ndate: 2016-07-24 21:34:00\ntags: linux\n---\n\n至今仍然没能成功\n\n<!--more-->\n\n上周下载了16.04的镜像, 做好U盘后, 重启电脑, 设为从U盘启动\n\n结果出现error: 一行一行地持续出,\n\ngoogle后有人说按tab键, 可以看到几个可选的命令，输入live回车即可，\n可是我输入live后就卡死，两分钟后，出现如下报错:\ntask swapper/0:1 blocked for more than 120 seconds.\n还有几个swapper以外的名字, 不过都是被阻塞了超过120秒\n一遍一遍不停地出, 只能强制关机\n\n不放弃, 再次google, 可是这次什么有用的信息也没有查到\n\n不放弃, 换Ubuntu-kylin 16.04试试, 结果一样\n\n不放弃, 昨天出了16.04.1, 估计官方把这些bug都改好了吧?\n又下载了16.04.1的镜像,还是一样... 失望\n\n不放弃, 从14.04升级到16.04吧,\n```\nsudo update-manage -d\n```\n两个多小时后, 一切顺利! 安装过程中桌面背景刷新了, 好漂亮, 好激动! 最后一步重启,\n\n重启.. 粉屏, 卡住了..\n\n两分钟后, 再次出现task xxx blocked for more than 120 seconds.\n\n好吧, 可能我这笔记本的硬件或者BIOS什么的不兼容吧..\n不放弃, 等我以后换了电脑再装\n\n最后还得重新装14.04, 重装环境...\n\n## 或许可以16.04和3.19的linux内核搭配着用\n\n因为发现14.04升级内核到4.4也出现了同样的问题\nhttp://askubuntu.com/questions/758452/ubuntu-16-04-lts-with-3-kernel\n\n","slug":"ubuntu_16.04_noteasy","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5ps00fpmcxqlep3l3vy"},{"title":"ubuntu下如何安装.bundle文件","date":"2015-09-05T16:00:00.000Z","_content":"```bash\n$ sudo chmod +x ./VMware-Workstation-Full-11.1.2-2780323.x86_64.bundle \n$ sudo ./VMware-Workstation-Full-11.1.2-2780323.x86_64.bundle\n```\n\n","source":"_posts/ubuntu_bundle.md","raw":"title: ubuntu下如何安装.bundle文件 \ndate: 2015-09-06\ntags: linux\n---\n```bash\n$ sudo chmod +x ./VMware-Workstation-Full-11.1.2-2780323.x86_64.bundle \n$ sudo ./VMware-Workstation-Full-11.1.2-2780323.x86_64.bundle\n```\n\n","slug":"ubuntu_bundle","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pt00fsmcxq7fsrvye4"},{"title":"Ubuntu下Caps Lock键替换成Ctrl键","date":"2015-07-15T16:00:00.000Z","_content":"\n## 交换左ctrl和caps lock键\n```bash\nsetxkbmap -option ctrl:swapcaps # Swap Left Control and Caps Lock\n```\n## 将caps lock键改为ctrl键\n```bash\nsetxkbmap -option ctrl:nocaps # Make Caps Lock a Control key\n```\n## 或者在/etc/default/keyboard 文件中\n```bash\nXKBOPTIONS=\"ctrl:nocaps\"\n```\n","source":"_posts/ubuntu_nocaps.md","raw":"title: Ubuntu下Caps Lock键替换成Ctrl键\ndate: 2015-07-16\ntags: linux\n---\n\n## 交换左ctrl和caps lock键\n```bash\nsetxkbmap -option ctrl:swapcaps # Swap Left Control and Caps Lock\n```\n## 将caps lock键改为ctrl键\n```bash\nsetxkbmap -option ctrl:nocaps # Make Caps Lock a Control key\n```\n## 或者在/etc/default/keyboard 文件中\n```bash\nXKBOPTIONS=\"ctrl:nocaps\"\n```\n","slug":"ubuntu_nocaps","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pu00fumcxq1a78j1p6"},{"title":"坎坷之路 Ubuntu python","date":"2016-07-24T13:34:00.000Z","_content":"\n由于Ubuntu 14.04的python版本是2.7.6, 觉得不够用了, 上上周自己编译了一个2.7.12版,\n默认装在/usr/local/lib下, 结果出了不少问题\n\n<!--more-->\n\n因为Ubuntu内部多处用到了python, 不能影响到系统用的python\n\nwhich python返回的是2.7.12版的python, 但是进去之后pip安装的库访问不到...\n汗\n有一次要用passlib.hash.bcrypt, 用pip装了passlib,又装了bcrypt\n结果有时能用有时用不了, 有时cd一下之后就用不了了, \n总报错说找不到bcrypt\n\n终于耐心耗尽,想把自己编译的python干掉, google找了几种方法, 结果都不干净\n为了让which python返回系统的2.7.6的python, 把/usr/local/bin下的python软链删除了\nhash -r后发现which python指向/usr/bin下2.7.6的python, 还以为问题解决了\n\n结果后来任务栏上出现一个奇怪的图标,说Dependency count如何如何,\ngoogle之后发现此时打开software center会有提示,照做即可\n\n傻傻地照做了... 走了一个进度条..\n\n发现重启后进不了图形界面了...\n一定是被software center删了不少东西..., 以依赖不满足为名..\n\n这个世界好复杂\n\n","source":"_posts/ubuntu_python_noteasy.md","raw":"title: 坎坷之路 Ubuntu python\ndate: 2016-07-24 21:34:00\ntags: [linux, python]\n---\n\n由于Ubuntu 14.04的python版本是2.7.6, 觉得不够用了, 上上周自己编译了一个2.7.12版,\n默认装在/usr/local/lib下, 结果出了不少问题\n\n<!--more-->\n\n因为Ubuntu内部多处用到了python, 不能影响到系统用的python\n\nwhich python返回的是2.7.12版的python, 但是进去之后pip安装的库访问不到...\n汗\n有一次要用passlib.hash.bcrypt, 用pip装了passlib,又装了bcrypt\n结果有时能用有时用不了, 有时cd一下之后就用不了了, \n总报错说找不到bcrypt\n\n终于耐心耗尽,想把自己编译的python干掉, google找了几种方法, 结果都不干净\n为了让which python返回系统的2.7.6的python, 把/usr/local/bin下的python软链删除了\nhash -r后发现which python指向/usr/bin下2.7.6的python, 还以为问题解决了\n\n结果后来任务栏上出现一个奇怪的图标,说Dependency count如何如何,\ngoogle之后发现此时打开software center会有提示,照做即可\n\n傻傻地照做了... 走了一个进度条..\n\n发现重启后进不了图形界面了...\n一定是被software center删了不少东西..., 以依赖不满足为名..\n\n这个世界好复杂\n\n","slug":"ubuntu_python_noteasy","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pu00fwmcxqltrsmr1p"},{"title":"ubuntu下截图","date":"2016-08-19T13:27:00.000Z","_content":"\nSystem Settings -> Keyboard -> Shortcuts -> Screenshots\n\n## 可以截全网页的chrome插件\nAwesome Screenshot\n","source":"_posts/ubuntu_screenshot.md","raw":"title: ubuntu下截图\ndate: 2016-08-19 21:27:00\ntags: [ubuntu]\n---\n\nSystem Settings -> Keyboard -> Shortcuts -> Screenshots\n\n## 可以截全网页的chrome插件\nAwesome Screenshot\n","slug":"ubuntu_screenshot","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pw00fzmcxqrvhs0ej8"},{"title":"Ubuntu swappiness","date":"2015-07-15T16:00:00.000Z","_content":"swappiness=0表示最大限度使用物理内存\nswappiness=100表示积极的使用swap分区，并且把内存上的数据及时的搬运到swap\nubuntu的默认值为60，可以修改为10：\n1.查看当前swappiness\n```bash\n$ cat /proc/sys/vm/swappiness\n```\n2.修改swappiness值为10\n```bash\n$ sudo sysctl vm.swappiness=10\n```\n但这只是临时有效的修改，重启系统后会恢复默认的60，所以，还要做一步：\n```bash\n$ vim /etc/sysctl.conf\n```\n在这个文档的最后加上这样一行:\n```bash\nvm.swappiness=10\n```\n","source":"_posts/ubuntu_swappiness.md","raw":"title: Ubuntu swappiness\ndate: 2015-07-16\ntags: linux\n---\nswappiness=0表示最大限度使用物理内存\nswappiness=100表示积极的使用swap分区，并且把内存上的数据及时的搬运到swap\nubuntu的默认值为60，可以修改为10：\n1.查看当前swappiness\n```bash\n$ cat /proc/sys/vm/swappiness\n```\n2.修改swappiness值为10\n```bash\n$ sudo sysctl vm.swappiness=10\n```\n但这只是临时有效的修改，重启系统后会恢复默认的60，所以，还要做一步：\n```bash\n$ vim /etc/sysctl.conf\n```\n在这个文档的最后加上这样一行:\n```bash\nvm.swappiness=10\n```\n","slug":"ubuntu_swappiness","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pw00g1mcxqpfmcnd3h"},{"title":"ubuntu如何禁用笔记本触摸板","date":"2016-07-17T04:38:00.000Z","_content":"\n用笔记本时碰到很多次在打字的时候碰到触摸板导致误操作。\n<!--more-->\n\n## 功能键方法\n多数笔记本支持Fn+F6功能键可以禁用和启用触摸板。\n\n## 也可以使用modprobe关闭触摸板\n```\n sudo modprobe -r psmouse #关闭 \n sudo modprobe psmouse    #打开\n```\n\n## 或者安装touchpad-indicator软件\n可以检测是否有插上鼠标来确定是否去关闭触摸板。\n```\nsudo add-apt-repository ppa:atareao/atareao \nsudo apt-get update \nsudo apt-get install touchpad-indicator\n```\n\n","source":"_posts/ubuntu_touchpad.md","raw":"title: ubuntu如何禁用笔记本触摸板\ndate: 2016-07-17 12:38:00\ntags: [ubuntu, linux]\n---\n\n用笔记本时碰到很多次在打字的时候碰到触摸板导致误操作。\n<!--more-->\n\n## 功能键方法\n多数笔记本支持Fn+F6功能键可以禁用和启用触摸板。\n\n## 也可以使用modprobe关闭触摸板\n```\n sudo modprobe -r psmouse #关闭 \n sudo modprobe psmouse    #打开\n```\n\n## 或者安装touchpad-indicator软件\n可以检测是否有插上鼠标来确定是否去关闭触摸板。\n```\nsudo add-apt-repository ppa:atareao/atareao \nsudo apt-get update \nsudo apt-get install touchpad-indicator\n```\n\n","slug":"ubuntu_touchpad","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5px00g4mcxqryn5vsv8"},{"title":"解决ubuntu 14.04下wifi功能突然丢失的问题","date":"2016-07-17T03:17:00.000Z","_content":"\n今天笔记本电脑电池电量耗尽后，再重启时发现wifi功能没有了，任务栏上的网络图标点开之后选项少了许多。\n<!--more-->\n\n```\nsudo lshw -C network\n```\n发现Wireless interface那标记着\"UNCLAIMED\"\n我的无线网卡型号是\n<pre>\nproduct: RT3290 Wireless 802.11n 1T/1R PCIe\nvendor: Ralink corp.\n</pre>\n\n```\nsudo modprobe ath9k\n```\n重启， 再查看lshw -C network, 如果状态变为disabled了，\n尝试Fn+F2, 笔记本电脑一般都有这个功能键可以禁用和启用wifi\n\n## wifi经常断线的问题\n下载驱动: https://docs.google.com/file/d/0B7kbO9nS2qKEMmQ5elZXVUhDRjA/edit\n并按如下操作编译部署\n\n* 解压rt3290sta-2.6.0.0目录到/usr/src\n* 如果没装dkms, 则`sudo apt-get install dkms`\n* 执行`sudo dkms install -m rt3290sta -v 2.6.0.0 --force`\n* 重新启动\n\n## 参考链接\nhttp://askubuntu.com/questions/455030/ralink-rt3290-wifi-driver-is-not-working-in-ubuntu-14-04\n\n","source":"_posts/ubuntu_wifi_unclaimed.md","raw":"title: 解决ubuntu 14.04下wifi功能突然丢失的问题\ndate: 2016-07-17 11:17:00\ntags: [ubuntu, linux, wifi]\n---\n\n今天笔记本电脑电池电量耗尽后，再重启时发现wifi功能没有了，任务栏上的网络图标点开之后选项少了许多。\n<!--more-->\n\n```\nsudo lshw -C network\n```\n发现Wireless interface那标记着\"UNCLAIMED\"\n我的无线网卡型号是\n<pre>\nproduct: RT3290 Wireless 802.11n 1T/1R PCIe\nvendor: Ralink corp.\n</pre>\n\n```\nsudo modprobe ath9k\n```\n重启， 再查看lshw -C network, 如果状态变为disabled了，\n尝试Fn+F2, 笔记本电脑一般都有这个功能键可以禁用和启用wifi\n\n## wifi经常断线的问题\n下载驱动: https://docs.google.com/file/d/0B7kbO9nS2qKEMmQ5elZXVUhDRjA/edit\n并按如下操作编译部署\n\n* 解压rt3290sta-2.6.0.0目录到/usr/src\n* 如果没装dkms, 则`sudo apt-get install dkms`\n* 执行`sudo dkms install -m rt3290sta -v 2.6.0.0 --force`\n* 重新启动\n\n## 参考链接\nhttp://askubuntu.com/questions/455030/ralink-rt3290-wifi-driver-is-not-working-in-ubuntu-14-04\n\n","slug":"ubuntu_wifi_unclaimed","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5py00g6mcxqwad3jfhw"},{"title":"ulimit","date":"2016-05-29T16:00:00.000Z","_content":"The pam_limits.so module applies ulimit limits, nice priority and number of simultaneous login sessions limit to user login sessions.\n曾经有个工程需要用root权限,只为了设一个ulimit值...\n<!--more-->\n\n### ulimit命令后不设置新limit即可查看当前值\n如, 文件描述符数量限制:\n```\n$ ulimit -n\n1024\n```\n想改值只能改小不能改大\n\n### ulimit里的那些限制对每个shell分别生效\n所以在执行程序之前要设置\n\n### 查看全部\n```\n$ ulimit -a\ncore file size          (blocks, -c) 999999999\ndata seg size           (kbytes, -d) unlimited\nscheduling priority             (-e) 0\nfile size               (blocks, -f) unlimited\npending signals                 (-i) 31647\nmax locked memory       (kbytes, -l) 64\nmax memory size         (kbytes, -m) unlimited\nopen files                      (-n) 1024\npipe size            (512 bytes, -p) 8\nPOSIX message queues     (bytes, -q) 819200\nreal-time priority              (-r) 0\nstack size              (kbytes, -s) 8192\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 31647\nvirtual memory          (kbytes, -v) unlimited\nfile locks                      (-x) unlimited\n```\n\n### 修改默认值\nsudo vim /etc/security/limits.conf\n```\n*   -       nofile       60000 \n```\n需要重启或重登录\n这样就不需要为ulimit给程序root权限了\n\n## 参考链接\nman bash 搜索ulimit\n\n","source":"_posts/ulimit.md","raw":"title: ulimit\ndate: 2016-05-30\ntags: [linux, socket, pam]\n---\nThe pam_limits.so module applies ulimit limits, nice priority and number of simultaneous login sessions limit to user login sessions.\n曾经有个工程需要用root权限,只为了设一个ulimit值...\n<!--more-->\n\n### ulimit命令后不设置新limit即可查看当前值\n如, 文件描述符数量限制:\n```\n$ ulimit -n\n1024\n```\n想改值只能改小不能改大\n\n### ulimit里的那些限制对每个shell分别生效\n所以在执行程序之前要设置\n\n### 查看全部\n```\n$ ulimit -a\ncore file size          (blocks, -c) 999999999\ndata seg size           (kbytes, -d) unlimited\nscheduling priority             (-e) 0\nfile size               (blocks, -f) unlimited\npending signals                 (-i) 31647\nmax locked memory       (kbytes, -l) 64\nmax memory size         (kbytes, -m) unlimited\nopen files                      (-n) 1024\npipe size            (512 bytes, -p) 8\nPOSIX message queues     (bytes, -q) 819200\nreal-time priority              (-r) 0\nstack size              (kbytes, -s) 8192\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 31647\nvirtual memory          (kbytes, -v) unlimited\nfile locks                      (-x) unlimited\n```\n\n### 修改默认值\nsudo vim /etc/security/limits.conf\n```\n*   -       nofile       60000 \n```\n需要重启或重登录\n这样就不需要为ulimit给程序root权限了\n\n## 参考链接\nman bash 搜索ulimit\n\n","slug":"ulimit","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5pz00g9mcxqghomvxp6"},{"title":"unicode","date":"2015-09-05T16:00:00.000Z","_content":"## UTF-8 字节流模板\n1字节\n000000 - 00007F 0xxxxxxx\n2字节\n000080 - 0007FF 110xxxxx 10xxxxxx\n3字节\n000800 - 00FFFF 1110xxxx 10xxxxxx 10xxxxxx\n4字节\n010000 - 10FFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx\n据此可以算出当前的字符会占几个字节\n\n## 16#4e00-16#9fff是中日韩字符的unicode范围\n以此为依据判断一个字符是否中文字符?\n\n    \n","source":"_posts/unicode.md","raw":"title: unicode\ntag: charsets\ndate: 2015-09-06\n---\n## UTF-8 字节流模板\n1字节\n000000 - 00007F 0xxxxxxx\n2字节\n000080 - 0007FF 110xxxxx 10xxxxxx\n3字节\n000800 - 00FFFF 1110xxxx 10xxxxxx 10xxxxxx\n4字节\n010000 - 10FFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx\n据此可以算出当前的字符会占几个字节\n\n## 16#4e00-16#9fff是中日韩字符的unicode范围\n以此为依据判断一个字符是否中文字符?\n\n    \n","slug":"unicode","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5q000gbmcxqz8m5vbxj"},{"title":"vim","date":"2015-08-05T16:00:00.000Z","_content":"## 安装vim\nsudo apt-get install vim\n\n## 安装vundle\ngit clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim\n\n拷贝github上的.vimrc的部分到自己的.vimrc\n进入vim执行:PluginInstall\nsudo apt-get install cscope\nvim-scripts/cscope.vim 这个插件不能用master分支下面的,要用1.01或者1.0?\n\n## 让vim把.swp统一放到指定的文件夹\nVim默认可以将.swp保存到指定的位置，而不是当前文件夹下，在 vimrc 中加入：\n```bash\nset directory=~/.vimbak,/tmp\n```\nVim会先找 ~/.vimbak,如果有，.swp 文件就暂时放到此处，如果没有就会找下一个，路径用逗号隔开，逗号后面不要加空格。\n\n## 查找功能\n循环查找\n:set wrapscan\n:set nowrapscan\n\n## vim插件scrooloose/syntastic\nerlang对应的语法检查文件是:\n~/.vim/bundle/syntastic/syntax_checkers/erlang/erlang_check_file.erl\n\n如果代码里用到了include以外路径的头文件,那么需要加一个i参数,如下\n```erlang\nDefs = [strong_validation,\n        warn_export_all,\n        warn_shadow_vars,\n        warn_obsolete_guard,\n        warn_unused_import,\n        report,\n        {i, Dir ++ \"/include\"},\n        {i, Dir ++ \"/src\"}],\n```\n\n## 使Vim工作在vi兼容模式下:\nset cp\nset nocp\n\n## 大小写转换\ngu 小写\ngU 大写\n后面跟范围即可, 如guw, guip\n\n## 二进制模式\n\n把所有的行(%)用本地(!)的xxd程序打开\n```\n:%!xxd\n```\n\n返回正常显示： \n```\n:%!xxd -r \n```\n\nxxd程序的文档\n```\nman xxd\n```\n\n## 忽略大小写\n有时候希望查找忽略大小写\n```\n:set ic\n```\n即ignore case\n```\n:set noic\n```\n大小写敏感\n\n","source":"_posts/vim.md","raw":"title: vim\ndate: 2015-08-06\ntags: [linux, erlang]\n---\n## 安装vim\nsudo apt-get install vim\n\n## 安装vundle\ngit clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim\n\n拷贝github上的.vimrc的部分到自己的.vimrc\n进入vim执行:PluginInstall\nsudo apt-get install cscope\nvim-scripts/cscope.vim 这个插件不能用master分支下面的,要用1.01或者1.0?\n\n## 让vim把.swp统一放到指定的文件夹\nVim默认可以将.swp保存到指定的位置，而不是当前文件夹下，在 vimrc 中加入：\n```bash\nset directory=~/.vimbak,/tmp\n```\nVim会先找 ~/.vimbak,如果有，.swp 文件就暂时放到此处，如果没有就会找下一个，路径用逗号隔开，逗号后面不要加空格。\n\n## 查找功能\n循环查找\n:set wrapscan\n:set nowrapscan\n\n## vim插件scrooloose/syntastic\nerlang对应的语法检查文件是:\n~/.vim/bundle/syntastic/syntax_checkers/erlang/erlang_check_file.erl\n\n如果代码里用到了include以外路径的头文件,那么需要加一个i参数,如下\n```erlang\nDefs = [strong_validation,\n        warn_export_all,\n        warn_shadow_vars,\n        warn_obsolete_guard,\n        warn_unused_import,\n        report,\n        {i, Dir ++ \"/include\"},\n        {i, Dir ++ \"/src\"}],\n```\n\n## 使Vim工作在vi兼容模式下:\nset cp\nset nocp\n\n## 大小写转换\ngu 小写\ngU 大写\n后面跟范围即可, 如guw, guip\n\n## 二进制模式\n\n把所有的行(%)用本地(!)的xxd程序打开\n```\n:%!xxd\n```\n\n返回正常显示： \n```\n:%!xxd -r \n```\n\nxxd程序的文档\n```\nman xxd\n```\n\n## 忽略大小写\n有时候希望查找忽略大小写\n```\n:set ic\n```\n即ignore case\n```\n:set noic\n```\n大小写敏感\n\n","slug":"vim","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5q100gemcxqizaud6ba"},{"title":"vmware","date":"2015-07-29T16:00:00.000Z","_content":"## 安装vmware\n官网下载workstation\nsudo chmod +x ./VMware-Workstation-Full-11.1.2-2780323.x86_64.bundle \nsudo ./VMware-Workstation-Full-11.1.2-2780323.x86_64.bundle\nKey: ZC79R-F3Z15-H8E5Z-TXMEE-PUU8F\n<!--more-->\n## 安装ubuntu虚拟机\n使用ubuntu的iso镜像安装\n\n## 安装vmware tools\n首先虚拟机的右键菜单里选择安装vmware tools,虚拟机会加载一个光盘,打开shell\n虚拟机里需要先安装编译用的东西 \n```bash\nsudo apt-get install build-essential\nsudo apt-get install linux-headers-`uname -r`\ncp /cdrom/*.gz /tmp/ # 此处cdrom可能会对应于/media/xxxxx/xxx\ncd /tmp\ntar xvzf VM*.gz\ncd vmware*\nsudo ./vmware-install.pl\n```\n出现提示时一律使用默认\n\n## 共享文件夹\n要求已安装vmware tools\n虚拟机右键菜单Settings->Options->Always Enabled->添加文件夹\n重启虚拟机\n/mnt/hgfs/share即是共享文件夹\n如下命令可用于检查是否已经加载成功\n```bash\nlsmod | grep vmhgfs\n```\n如果没有结果,尝试下面的命令\n```bash\nmodprobe vmhgfs\n```\n如果报错,可能是因为没有安装vmware tools\n\n## 焦点移出\nvmware使用ctrl + alt将光标移出虚拟机\n\n\n","source":"_posts/vmware.md","raw":"title: vmware\ndate: 2015-07-30\ntags: linux\n---\n## 安装vmware\n官网下载workstation\nsudo chmod +x ./VMware-Workstation-Full-11.1.2-2780323.x86_64.bundle \nsudo ./VMware-Workstation-Full-11.1.2-2780323.x86_64.bundle\nKey: ZC79R-F3Z15-H8E5Z-TXMEE-PUU8F\n<!--more-->\n## 安装ubuntu虚拟机\n使用ubuntu的iso镜像安装\n\n## 安装vmware tools\n首先虚拟机的右键菜单里选择安装vmware tools,虚拟机会加载一个光盘,打开shell\n虚拟机里需要先安装编译用的东西 \n```bash\nsudo apt-get install build-essential\nsudo apt-get install linux-headers-`uname -r`\ncp /cdrom/*.gz /tmp/ # 此处cdrom可能会对应于/media/xxxxx/xxx\ncd /tmp\ntar xvzf VM*.gz\ncd vmware*\nsudo ./vmware-install.pl\n```\n出现提示时一律使用默认\n\n## 共享文件夹\n要求已安装vmware tools\n虚拟机右键菜单Settings->Options->Always Enabled->添加文件夹\n重启虚拟机\n/mnt/hgfs/share即是共享文件夹\n如下命令可用于检查是否已经加载成功\n```bash\nlsmod | grep vmhgfs\n```\n如果没有结果,尝试下面的命令\n```bash\nmodprobe vmhgfs\n```\n如果报错,可能是因为没有安装vmware tools\n\n## 焦点移出\nvmware使用ctrl + alt将光标移出虚拟机\n\n\n","slug":"vmware","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5q100ggmcxq58y8yab1"},{"title":"vsftpd指南","date":"2015-07-22T16:00:00.000Z","_content":"vsftpd: very secure ftp daemon\n<!--more-->\n### 安装vsftpd\n```bash\n$ sudo apt-get install vsftpd\n```\n\n### 虚拟用户配置\n创建虚拟用户数据库\n```bash\n$ sudo mkdir /etc/vsftpd\n$ cd /etc/vsftpd\n$ sudo vi vusers.txt\n```\n输入以下内容:\n> vivek\n> vivekpass\n> sayali\n> sayalipass\n\n```bash\n$ sudo apt-get install db-util\n$ sudo db_load -T -t hash -f vusers.txt vsftpd-virtual-user.db \n$ sudo chmod 600 vsftpd-virtual-user.db\n$ sudo rm vusers.txt\n$ sudo vi /etc/vsftpd.conf\n```\n输入以下内容:\n> anonymous_enable=NO\n> local_enable=YES\n> write_enable=YES \n> virtual_use_local_privs=YES\n> pam_service_name=vsftpd.virtual\n> guest_enable=YES\n> user_sub_token=$USER\n> local_root=/home/vftp/$USER\n> chroot_local_user=YES\n> force_dot_files=YES\n> hide_ids=YES\n\n$ sudo vi /etc/pam.d/vsftpd.virtual\n输入以下内容:\n```\n#%PAM-1.0\nauth       required     pam_userdb.so db=/etc/vsftpd/vsftpd-virtual-user\naccount    required     pam_userdb.so db=/etc/vsftpd/vsftpd-virtual-user\nsession    required     pam_loginuid.so\n```\n创建ftp使用的目录\n```bash\n$ sudo mkdir /home/vftp\n$ sudo mkdir -p /home/vftp/{vivek,sayali}\n$ sudo chown -R ftp:ftp /home/vftp\n```\n\n### 查看/etc/ftpusers\n如有vftp则去掉, 这个文件存的是黑名单\n\n### 重启FTP服务器\n> $ sudo service vsftpd restart\n> vsftpd stop/waiting\n> vsftpd start/running, process 7482\n\n### 测试ftp连接\n> $ ftp localhost\n> Connected to localhost.\n> 220 Welcome to suex FTP service.\n> Name (localhost:chenduo): sayali\n> 331 Please specify the password.\n> Password:\n> 230 Login successful.\n> Remote system type is UNIX.\n> Using binary mode to transfer files.\n> ftp> \n\n### 解决问题: 500 OOPS: vsftpd: refusing to run with writable root inside chroot()\n* /etc/vsftpd.conf文件中添加一行: allow_writeable_chroot=YES\n* 或者也可以用命令sudo chmod a-w /home/vsftp/vivek去除用户根目录的写权限, \n  并在vivek文件夹下再建子文件夹(这个要有w权限)让用户写\n\n### TLS/SSL/FTPS\n如果你是从Internet连接到你的服务器，必须确定使用这个，否则密码会有明文传输等安全问题。\n让vsftpd使用加密（更安全），修改或添加下列选项（某些选项不在原始配置文件中，需要添加）\n在/etc/vsftpd.conf文件中加入如下配置:\n> ssl_enable=YES\n> allow_anon_ssl=NO\n> force_local_data_ssl=YES\n> force_local_logins_ssl=YES\n> ssl_tlsv1=YES\n> ssl_sslv2=YES\n> ssl_sslv3=YES\n\n使用Filezilla客户端时，使用加密\"FTPES - FTP over explicit TLS/SSL\"选项，以使用TLS/SSL/FTPS连接到你的服务器。\n\n","source":"_posts/vsftpd指南.md","raw":"title: vsftpd指南\ndate: 2015-07-23\ntags: [linux, ftp]\n---\nvsftpd: very secure ftp daemon\n<!--more-->\n### 安装vsftpd\n```bash\n$ sudo apt-get install vsftpd\n```\n\n### 虚拟用户配置\n创建虚拟用户数据库\n```bash\n$ sudo mkdir /etc/vsftpd\n$ cd /etc/vsftpd\n$ sudo vi vusers.txt\n```\n输入以下内容:\n> vivek\n> vivekpass\n> sayali\n> sayalipass\n\n```bash\n$ sudo apt-get install db-util\n$ sudo db_load -T -t hash -f vusers.txt vsftpd-virtual-user.db \n$ sudo chmod 600 vsftpd-virtual-user.db\n$ sudo rm vusers.txt\n$ sudo vi /etc/vsftpd.conf\n```\n输入以下内容:\n> anonymous_enable=NO\n> local_enable=YES\n> write_enable=YES \n> virtual_use_local_privs=YES\n> pam_service_name=vsftpd.virtual\n> guest_enable=YES\n> user_sub_token=$USER\n> local_root=/home/vftp/$USER\n> chroot_local_user=YES\n> force_dot_files=YES\n> hide_ids=YES\n\n$ sudo vi /etc/pam.d/vsftpd.virtual\n输入以下内容:\n```\n#%PAM-1.0\nauth       required     pam_userdb.so db=/etc/vsftpd/vsftpd-virtual-user\naccount    required     pam_userdb.so db=/etc/vsftpd/vsftpd-virtual-user\nsession    required     pam_loginuid.so\n```\n创建ftp使用的目录\n```bash\n$ sudo mkdir /home/vftp\n$ sudo mkdir -p /home/vftp/{vivek,sayali}\n$ sudo chown -R ftp:ftp /home/vftp\n```\n\n### 查看/etc/ftpusers\n如有vftp则去掉, 这个文件存的是黑名单\n\n### 重启FTP服务器\n> $ sudo service vsftpd restart\n> vsftpd stop/waiting\n> vsftpd start/running, process 7482\n\n### 测试ftp连接\n> $ ftp localhost\n> Connected to localhost.\n> 220 Welcome to suex FTP service.\n> Name (localhost:chenduo): sayali\n> 331 Please specify the password.\n> Password:\n> 230 Login successful.\n> Remote system type is UNIX.\n> Using binary mode to transfer files.\n> ftp> \n\n### 解决问题: 500 OOPS: vsftpd: refusing to run with writable root inside chroot()\n* /etc/vsftpd.conf文件中添加一行: allow_writeable_chroot=YES\n* 或者也可以用命令sudo chmod a-w /home/vsftp/vivek去除用户根目录的写权限, \n  并在vivek文件夹下再建子文件夹(这个要有w权限)让用户写\n\n### TLS/SSL/FTPS\n如果你是从Internet连接到你的服务器，必须确定使用这个，否则密码会有明文传输等安全问题。\n让vsftpd使用加密（更安全），修改或添加下列选项（某些选项不在原始配置文件中，需要添加）\n在/etc/vsftpd.conf文件中加入如下配置:\n> ssl_enable=YES\n> allow_anon_ssl=NO\n> force_local_data_ssl=YES\n> force_local_logins_ssl=YES\n> ssl_tlsv1=YES\n> ssl_sslv2=YES\n> ssl_sslv3=YES\n\n使用Filezilla客户端时，使用加密\"FTPES - FTP over explicit TLS/SSL\"选项，以使用TLS/SSL/FTPS连接到你的服务器。\n\n","slug":"vsftpd指南","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5q200gimcxqm4tighd6"},{"title":"websocket","date":"2016-12-12T16:00:00.000Z","_content":"WebSocket protocol 是HTML5的一种新协议。它实现了浏览器与服务器全双工通信(full-duplex)。\n<!--more-->\n## websocket是为了解决什么问题\n\n很多网站为了实现推送技术，所用的技术都是polling(轮询)。轮询是在特定的的时间间隔（如每1秒），由浏览器对服务器发出HTTP request，然后由服务器返回最新的数据给客户端的浏览器。\n![poll](/pics/polling.png)\n比较新的技术采用long polling, 在服务器有数据之前hold住连接, 等服务器有数据时返回response, client收到后立即发出一个新的请求, 循环往复, 稍好于普通的polling, 请求数变少.\n![long poll](/pics/longpolling.png)\n\n这两种模式都有明显的缺点，即浏览器需要不断的向服务器发出请求，然而HTTP request的header是非常长的，里面包含的数据可能只是一个很小的值，这样会占用很多的带宽和服务器资源。\n\n面对这种状况...\n\n## websocket横空出世\n\nHTML5定义了WebSocket协议，能更好的节省服务器资源和带宽并达到实时通讯。\n浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的TCP连接，允许全双工通讯。\n允许服务端直接向客户端推送数据而不需要客户端发送请求.\n![websocket](/pics/websocket.png)\n## 握手(Handshake)\n\n和 HTTP 的唯一关联是使用 HTTP 协议的101状态码进行协议切换\n握手用HTTP协议所以web服务器可以使用相同的端口(无需修改firewall规则)处理websocket握手和普通的http请求(80, 443)\n一旦websocket连接建立, 通讯即切换为与HTTP无关的双向二进制协议\n\n浏览器请求示例\n```\nGET /chat HTTP/1.1\nHost: example.com:8000\nUpgrade: websocket\nConnection: Upgrade\nSec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==\nSec-WebSocket-Version: 13\n```\n\n服务器回应示例\n```\nHTTP/1.1 101 Switching Protocols\nUpgrade: websocket\nConnection: Upgrade\nSec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo=\n```\n\n请求中的“Sec-WebSocket-Key”是随机的，服务器端会用这些数据来构造出一个SHA-1的信息摘要。\n服务器端把“Sec-WebSocket-Key”拼上一个固定的字符串“258EAFA5-E914-47DA-95CA-C5AB0DC85B11”。使用SHA-1加密，之后进行BASE-64编码，将结果做为“Sec-WebSocket-Accept”头的值，返回给客户端。\n\n这种做法的目的是\n1. 明确判断server是否支持websocket. 避免出现server不支持websocket而按普通http请求处理的情况发生.\n2. 避免缓存proxy或者server把之前缓存下来的东西发过来\n\n## 数据帧(Frame)\n\nRFC 6455(2011年)\n\nFrame format:\n\n```\n      0                   1                   2                   3\n      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n     +-+-+-+-+-------+-+-------------+-------------------------------+\n     |F|R|R|R| opcode|M| Payload len |    Extended payload length    |\n     |I|S|S|S|  (4)  |A|     (7)     |             (16/64)           |\n     |N|V|V|V|       |S|             |   (if payload len==126/127)   |\n     | |1|2|3|       |K|             |                               |\n     +-+-+-+-+-------+-+-------------+ - - - - - - - - - - - - - - - +\n     |     Extended payload length continued, if payload len == 127  |\n     + - - - - - - - - - - - - - - - +-------------------------------+\n     |                               |Masking-key, if MASK set to 1  |\n     +-------------------------------+-------------------------------+\n     | Masking-key (continued)       |          Payload Data         |\n     +-------------------------------- - - - - - - - - - - - - - - - +\n     :                     Payload Data continued ...                :\n     + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +\n     |                     Payload Data continued ...                |\n     +---------------------------------------------------------------+\n```\n\n### opcode\n\n0x0: continuation\n0x1: text(UTF-8)\n0x2: binary\n0x3-0x7: undefined\n0x8: close\n0x9: ping\n0xA: pong\n0xB-0xF: undefined\n\n### Message Fragmentation\n\n一条message可以分多个frame发\n```\nClient: FIN=1, opcode=0x1, msg=\"hello\"\nServer: (process complete message immediately) Hi.\nClient: FIN=0, opcode=0x1, msg=\"and a\"\nServer: (listening, new message containing text started)\nClient: FIN=0, opcode=0x0, msg=\"happy new\"\nServer: (listening, payload concatenated to previous message)\nClient: FIN=1, opcode=0x0, msg=\"year!\"\nServer: (process complete message) Happy new year to you too!\n```\n\n### Fragmentation是干什么用的?\n\n既然长度都可以用64bit了, Fragmentation还有什么用?\n\nFragmentation的主要目的是允许发送总长度未知的message.\n如果不支持fragmentation, 那么端需要自己buffer, 直到一整条消息都有了, 然后计算出总长度发过去.\n有了Fragmentation以后, 端可以定一个合理的size buffer, 当buffer满了就发一个fragment到websocket.\n\n另一种场景是在multiplexing的环境下,\n不希望一条太大的message独占带宽, 影响其他人的体验\n\n> The primary purpose of fragmentation is to allow sending a message\n> that is of unknown size when the message is started without having to\n> buffer that message.  If messages couldn't be fragmented, then an\n> endpoint would have to buffer the entire message so its length could\n> be counted before the first byte is sent.  With fragmentation, a\n> server or intermediary may choose a reasonable size buffer and, when\n> the buffer is full, write a fragment to the network.\n>\n> A secondary use-case for fragmentation is for multiplexing, where it\n> is not desirable for a large message on one logical channel to\n> monopolize the output channel, so the multiplexing needs to be free\n> to split the message into smaller fragments to better share the\n> output channel.  (Note that the multiplexing extension is not\n> described in this document.)\n\n摘自: https://tools.ietf.org/html/rfc6455#section-5.4\n\n### Decoding Payload Length\n\n读取bit 9-15, 如果小于等于125, 这个就是frame长度.\n如果是126, 那么后面16个bit是frame长度.\n如果是127, 那么后面64个bit是frame长度.\n\n### Reading and Unmasking the Data\n\nMASK bit 表示 message 是否被 encode 了\n如果被encode了, 读取32bit mask key, 使用这个mask key解码, 异或即可, 如下\n\n```\nvar DECODED = \"\";\nfor (var i = 0; i < ENCODED.length; i++) {\n    DECODED[i] = ENCODED[i] ^ MASK[i % 4];\n}\n```\n\n### Mask有什么用?\n\nKey都包含了, 直接异或就行, 有什么用?\n\nRFC6455文档中说明是为了避免缓存投毒\n\n如果攻击者通过client发送一个看起来很像HTTP请求\n(比如请求一个特定的资源如计算网站浏览量的一个js文件)\n的数据帧到一个攻击者控制下(或者有漏洞)的server,\nserver再发回一个看起来像是那个HTTP响应的数据帧(这里面是毒, 比如恶意的js代码).\n然后这个响应会被天真的proxy缓存住,\n于是之后别的用户发一个这样的HTTP请求就会得到被缓存住的有毒的Response\n\n为了解决这个问题, 要求client给server发的Frame做Mask, 而且mask key必须每帧不同且不可预测,\n这样攻击者就不知道怎么才能让一个请求在mask后变得很像正经的HTTP请求,\n于是即使是天真的proxy也不会把数据帧当成是HTTP请求缓存住, 或者即使缓存住了也不会影响其他用户的正经HTTP请求\n\n那直接就发HTTP请求然后返回恶意代码不就可以了么? 为什么要走websocket?\n可能http反而不好搞, 比如全站https了, 这时如果client没有做mask就这条路比较好搞\n所以标准说如果client没有做mask, server应当断开连接\n\n参考: https://tools.ietf.org/html/rfc6455#section-10.3\n\n### Pings and Pongs: The Heartbeat of WebSockets\n\n0x9: ping\n0xA: pong\n\n收到ping时, 发一个data一样的pong包做为应答.\n\n如果你没有发ping就收到一个pong, 忽略它.\n如果你收到ping后在你腾出手来发pong之前你又收到一个ping, 你只需发一次pong.\n\n### 其他字段\nRSV1-3是用于扩展的.\n\n### 安全性\n\n可以用wss(Web Socket Secure)协议,\n```\nws-URI = \"ws:\" \"//\" host [ \":\" port ] path [ \"?\" query ]\nwss-URI = \"wss:\" \"//\" host [ \":\" port ] path [ \"?\" query ]\n```\n握手用https, 传输用TLS\n\n> Connection confidentiality and integrity is provided by running the\n> WebSocket Protocol over TLS (wss URIs).  WebSocket implementations\n> MUST support TLS and SHOULD employ it when communicating with their\n> peers.\n\n摘自: https://tools.ietf.org/html/rfc6455#section-10.6\n\n## 浏览器支持情况\nIE10及以后才支持, 其他浏览器都支持得比较早\n\n## nginx反向代理websocket\n\nNGINX 1.3 及以后支持 websocket, 可以做为反向代理和负载均衡\n\n```\nlocation /wsapp/ {\n    proxy_pass http://wsbackend;\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection \"upgrade\";\n}\n```\n\ntcp连接建立后, nginx将从client那里得到的数据包直接转给server\n这个阶段不走nginx的负载均衡\n\n## sockjs\n\nsockjs连接成功后服务器会给客户端推一个o\n之后每20秒会推一个h, 这是心跳\n客户端需要在10秒内回复[\"h\"], 这是应答, 否则连接会被中断\n\n其他详情见:\nhttps://github.com/sockjs/sockjs-protocol/wiki/Heartbeats-and-SockJS\nhttps://github.com/sockjs/sockjs-protocol/wiki/Connecting-to-SockJS-without-the-browser\n","source":"_posts/websocket.md","raw":"title: websocket\ndate: 2016-12-13\ntags: [internet]\n---\nWebSocket protocol 是HTML5的一种新协议。它实现了浏览器与服务器全双工通信(full-duplex)。\n<!--more-->\n## websocket是为了解决什么问题\n\n很多网站为了实现推送技术，所用的技术都是polling(轮询)。轮询是在特定的的时间间隔（如每1秒），由浏览器对服务器发出HTTP request，然后由服务器返回最新的数据给客户端的浏览器。\n![poll](/pics/polling.png)\n比较新的技术采用long polling, 在服务器有数据之前hold住连接, 等服务器有数据时返回response, client收到后立即发出一个新的请求, 循环往复, 稍好于普通的polling, 请求数变少.\n![long poll](/pics/longpolling.png)\n\n这两种模式都有明显的缺点，即浏览器需要不断的向服务器发出请求，然而HTTP request的header是非常长的，里面包含的数据可能只是一个很小的值，这样会占用很多的带宽和服务器资源。\n\n面对这种状况...\n\n## websocket横空出世\n\nHTML5定义了WebSocket协议，能更好的节省服务器资源和带宽并达到实时通讯。\n浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的TCP连接，允许全双工通讯。\n允许服务端直接向客户端推送数据而不需要客户端发送请求.\n![websocket](/pics/websocket.png)\n## 握手(Handshake)\n\n和 HTTP 的唯一关联是使用 HTTP 协议的101状态码进行协议切换\n握手用HTTP协议所以web服务器可以使用相同的端口(无需修改firewall规则)处理websocket握手和普通的http请求(80, 443)\n一旦websocket连接建立, 通讯即切换为与HTTP无关的双向二进制协议\n\n浏览器请求示例\n```\nGET /chat HTTP/1.1\nHost: example.com:8000\nUpgrade: websocket\nConnection: Upgrade\nSec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==\nSec-WebSocket-Version: 13\n```\n\n服务器回应示例\n```\nHTTP/1.1 101 Switching Protocols\nUpgrade: websocket\nConnection: Upgrade\nSec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo=\n```\n\n请求中的“Sec-WebSocket-Key”是随机的，服务器端会用这些数据来构造出一个SHA-1的信息摘要。\n服务器端把“Sec-WebSocket-Key”拼上一个固定的字符串“258EAFA5-E914-47DA-95CA-C5AB0DC85B11”。使用SHA-1加密，之后进行BASE-64编码，将结果做为“Sec-WebSocket-Accept”头的值，返回给客户端。\n\n这种做法的目的是\n1. 明确判断server是否支持websocket. 避免出现server不支持websocket而按普通http请求处理的情况发生.\n2. 避免缓存proxy或者server把之前缓存下来的东西发过来\n\n## 数据帧(Frame)\n\nRFC 6455(2011年)\n\nFrame format:\n\n```\n      0                   1                   2                   3\n      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n     +-+-+-+-+-------+-+-------------+-------------------------------+\n     |F|R|R|R| opcode|M| Payload len |    Extended payload length    |\n     |I|S|S|S|  (4)  |A|     (7)     |             (16/64)           |\n     |N|V|V|V|       |S|             |   (if payload len==126/127)   |\n     | |1|2|3|       |K|             |                               |\n     +-+-+-+-+-------+-+-------------+ - - - - - - - - - - - - - - - +\n     |     Extended payload length continued, if payload len == 127  |\n     + - - - - - - - - - - - - - - - +-------------------------------+\n     |                               |Masking-key, if MASK set to 1  |\n     +-------------------------------+-------------------------------+\n     | Masking-key (continued)       |          Payload Data         |\n     +-------------------------------- - - - - - - - - - - - - - - - +\n     :                     Payload Data continued ...                :\n     + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +\n     |                     Payload Data continued ...                |\n     +---------------------------------------------------------------+\n```\n\n### opcode\n\n0x0: continuation\n0x1: text(UTF-8)\n0x2: binary\n0x3-0x7: undefined\n0x8: close\n0x9: ping\n0xA: pong\n0xB-0xF: undefined\n\n### Message Fragmentation\n\n一条message可以分多个frame发\n```\nClient: FIN=1, opcode=0x1, msg=\"hello\"\nServer: (process complete message immediately) Hi.\nClient: FIN=0, opcode=0x1, msg=\"and a\"\nServer: (listening, new message containing text started)\nClient: FIN=0, opcode=0x0, msg=\"happy new\"\nServer: (listening, payload concatenated to previous message)\nClient: FIN=1, opcode=0x0, msg=\"year!\"\nServer: (process complete message) Happy new year to you too!\n```\n\n### Fragmentation是干什么用的?\n\n既然长度都可以用64bit了, Fragmentation还有什么用?\n\nFragmentation的主要目的是允许发送总长度未知的message.\n如果不支持fragmentation, 那么端需要自己buffer, 直到一整条消息都有了, 然后计算出总长度发过去.\n有了Fragmentation以后, 端可以定一个合理的size buffer, 当buffer满了就发一个fragment到websocket.\n\n另一种场景是在multiplexing的环境下,\n不希望一条太大的message独占带宽, 影响其他人的体验\n\n> The primary purpose of fragmentation is to allow sending a message\n> that is of unknown size when the message is started without having to\n> buffer that message.  If messages couldn't be fragmented, then an\n> endpoint would have to buffer the entire message so its length could\n> be counted before the first byte is sent.  With fragmentation, a\n> server or intermediary may choose a reasonable size buffer and, when\n> the buffer is full, write a fragment to the network.\n>\n> A secondary use-case for fragmentation is for multiplexing, where it\n> is not desirable for a large message on one logical channel to\n> monopolize the output channel, so the multiplexing needs to be free\n> to split the message into smaller fragments to better share the\n> output channel.  (Note that the multiplexing extension is not\n> described in this document.)\n\n摘自: https://tools.ietf.org/html/rfc6455#section-5.4\n\n### Decoding Payload Length\n\n读取bit 9-15, 如果小于等于125, 这个就是frame长度.\n如果是126, 那么后面16个bit是frame长度.\n如果是127, 那么后面64个bit是frame长度.\n\n### Reading and Unmasking the Data\n\nMASK bit 表示 message 是否被 encode 了\n如果被encode了, 读取32bit mask key, 使用这个mask key解码, 异或即可, 如下\n\n```\nvar DECODED = \"\";\nfor (var i = 0; i < ENCODED.length; i++) {\n    DECODED[i] = ENCODED[i] ^ MASK[i % 4];\n}\n```\n\n### Mask有什么用?\n\nKey都包含了, 直接异或就行, 有什么用?\n\nRFC6455文档中说明是为了避免缓存投毒\n\n如果攻击者通过client发送一个看起来很像HTTP请求\n(比如请求一个特定的资源如计算网站浏览量的一个js文件)\n的数据帧到一个攻击者控制下(或者有漏洞)的server,\nserver再发回一个看起来像是那个HTTP响应的数据帧(这里面是毒, 比如恶意的js代码).\n然后这个响应会被天真的proxy缓存住,\n于是之后别的用户发一个这样的HTTP请求就会得到被缓存住的有毒的Response\n\n为了解决这个问题, 要求client给server发的Frame做Mask, 而且mask key必须每帧不同且不可预测,\n这样攻击者就不知道怎么才能让一个请求在mask后变得很像正经的HTTP请求,\n于是即使是天真的proxy也不会把数据帧当成是HTTP请求缓存住, 或者即使缓存住了也不会影响其他用户的正经HTTP请求\n\n那直接就发HTTP请求然后返回恶意代码不就可以了么? 为什么要走websocket?\n可能http反而不好搞, 比如全站https了, 这时如果client没有做mask就这条路比较好搞\n所以标准说如果client没有做mask, server应当断开连接\n\n参考: https://tools.ietf.org/html/rfc6455#section-10.3\n\n### Pings and Pongs: The Heartbeat of WebSockets\n\n0x9: ping\n0xA: pong\n\n收到ping时, 发一个data一样的pong包做为应答.\n\n如果你没有发ping就收到一个pong, 忽略它.\n如果你收到ping后在你腾出手来发pong之前你又收到一个ping, 你只需发一次pong.\n\n### 其他字段\nRSV1-3是用于扩展的.\n\n### 安全性\n\n可以用wss(Web Socket Secure)协议,\n```\nws-URI = \"ws:\" \"//\" host [ \":\" port ] path [ \"?\" query ]\nwss-URI = \"wss:\" \"//\" host [ \":\" port ] path [ \"?\" query ]\n```\n握手用https, 传输用TLS\n\n> Connection confidentiality and integrity is provided by running the\n> WebSocket Protocol over TLS (wss URIs).  WebSocket implementations\n> MUST support TLS and SHOULD employ it when communicating with their\n> peers.\n\n摘自: https://tools.ietf.org/html/rfc6455#section-10.6\n\n## 浏览器支持情况\nIE10及以后才支持, 其他浏览器都支持得比较早\n\n## nginx反向代理websocket\n\nNGINX 1.3 及以后支持 websocket, 可以做为反向代理和负载均衡\n\n```\nlocation /wsapp/ {\n    proxy_pass http://wsbackend;\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection \"upgrade\";\n}\n```\n\ntcp连接建立后, nginx将从client那里得到的数据包直接转给server\n这个阶段不走nginx的负载均衡\n\n## sockjs\n\nsockjs连接成功后服务器会给客户端推一个o\n之后每20秒会推一个h, 这是心跳\n客户端需要在10秒内回复[\"h\"], 这是应答, 否则连接会被中断\n\n其他详情见:\nhttps://github.com/sockjs/sockjs-protocol/wiki/Heartbeats-and-SockJS\nhttps://github.com/sockjs/sockjs-protocol/wiki/Connecting-to-SockJS-without-the-browser\n","slug":"websocket","published":1,"updated":"2018-01-29T04:39:57.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5q300glmcxq91t45kcc"},{"title":"wecenter","date":"2016-06-16T04:30:00.000Z","_content":"试着搭了一个wecenter, 仿知乎的...\n<!--more-->\n\n从官网(http://www.wecenter.com/downloads/)下载网站代码, 解压放到/usr/share/nginx/wecenter\n\nnginx配置\n```\nserver {                                                                         \n    listen 10000;\n    root /usr/share/nginx/wecenter;                                              \n    index index.php\n    server_name localhost;\n    location / {                                                                 \n        try_files $uri $uri/ =404;                                               \n    } \n    location ~ \\.php$ {                                                          \n        fastcgi_split_path_info ^(.+\\.php)(/.+)$;                                \n        fastcgi_pass unix:/var/run/php5-fpm.sock;                                \n        fastcgi_index index.php;                                                 \n        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;        \n        include fastcgi_params;                                                  \n    }                                                                            \n}\n```\n访问http://localhost:10000, 看到不满足条件的项,一一解决,\n\n. ./system, ./system/config需要写权限\n```\nsudo chmod a+w wecenter/\nsudo chmod a+w wecenter/system\nsudo chmod -R a+w wecenter/system/config\n```\n\n安装时提示没有CURL支持, 我明明装了curl呀, 查了半天原来是要php5-curl...\n```\nsudo apt-get install php5-curl\n```\n\n提示需要Mcrypt支持, 明明安装了呀, php5-mcrypt也装了还不行, 怎么办... 只能看代码了?\n研究片刻发现判断当前是否支持mcrypt的依据是`function_exists('mcrypt_module_open')`\n继续google, 发现如下解决方案:\n```\nsudo apt-get install mcrypt php5-mcrypt\nsudo ln -s /etc/php5/conf.d/mcrypt.ini /etc/php5/mods-available\nsudo php5enmod mcrypt\nsudo pkill php5-fpm\nsudo service nginx restart\n```\n\n继续, 配置mysql, 成功~\n\n## docker\n\n下面这个人的dockerfile可用于参考, 虽然我试了一下跑不起来... \nhttps://hub.docker.com/r/lee2011/wecenter/\n\n## 参考链接\nhttp://stackoverflow.com/questions/22721630/the-mcrypt-extension-is-missing-please-check-your-php-configuration\n\n","source":"_posts/wecenter.md","raw":"title: wecenter\ndate: 2016-06-16 12:30:00\ntags: [sns, web]\n---\n试着搭了一个wecenter, 仿知乎的...\n<!--more-->\n\n从官网(http://www.wecenter.com/downloads/)下载网站代码, 解压放到/usr/share/nginx/wecenter\n\nnginx配置\n```\nserver {                                                                         \n    listen 10000;\n    root /usr/share/nginx/wecenter;                                              \n    index index.php\n    server_name localhost;\n    location / {                                                                 \n        try_files $uri $uri/ =404;                                               \n    } \n    location ~ \\.php$ {                                                          \n        fastcgi_split_path_info ^(.+\\.php)(/.+)$;                                \n        fastcgi_pass unix:/var/run/php5-fpm.sock;                                \n        fastcgi_index index.php;                                                 \n        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;        \n        include fastcgi_params;                                                  \n    }                                                                            \n}\n```\n访问http://localhost:10000, 看到不满足条件的项,一一解决,\n\n. ./system, ./system/config需要写权限\n```\nsudo chmod a+w wecenter/\nsudo chmod a+w wecenter/system\nsudo chmod -R a+w wecenter/system/config\n```\n\n安装时提示没有CURL支持, 我明明装了curl呀, 查了半天原来是要php5-curl...\n```\nsudo apt-get install php5-curl\n```\n\n提示需要Mcrypt支持, 明明安装了呀, php5-mcrypt也装了还不行, 怎么办... 只能看代码了?\n研究片刻发现判断当前是否支持mcrypt的依据是`function_exists('mcrypt_module_open')`\n继续google, 发现如下解决方案:\n```\nsudo apt-get install mcrypt php5-mcrypt\nsudo ln -s /etc/php5/conf.d/mcrypt.ini /etc/php5/mods-available\nsudo php5enmod mcrypt\nsudo pkill php5-fpm\nsudo service nginx restart\n```\n\n继续, 配置mysql, 成功~\n\n## docker\n\n下面这个人的dockerfile可用于参考, 虽然我试了一下跑不起来... \nhttps://hub.docker.com/r/lee2011/wecenter/\n\n## 参考链接\nhttp://stackoverflow.com/questions/22721630/the-mcrypt-extension-is-missing-please-check-your-php-configuration\n\n","slug":"wecenter","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5q400gnmcxq9c5qzqx0"},{"title":"Windows下Caps Lock键替换成Ctrl键","date":"2015-10-15T16:00:00.000Z","_content":"修改注册名映射键位\n<!--more-->\n![修改注册表](/pics/windows_nocaps.png)\n如图:\n>  [HKEY_LOCAL_MACHINE] \n>  +[SYSTEM] \n>  +[CurrentControlSet] \n>  +[Control] \n>  +[Keyboard Layout]\n\n添加\"Scancode Map\"二进制项，内容为\n> 00 00 00 00 00 00 00 00\n> 03 00 00 00 1D 00 3A 00\n> 00 00 00 00 00 00 00 00\n\n","source":"_posts/windows_nocaps.md","raw":"title: Windows下Caps Lock键替换成Ctrl键\ndate: 2015-10-16\ntags: [windows]\n---\n修改注册名映射键位\n<!--more-->\n![修改注册表](/pics/windows_nocaps.png)\n如图:\n>  [HKEY_LOCAL_MACHINE] \n>  +[SYSTEM] \n>  +[CurrentControlSet] \n>  +[Control] \n>  +[Keyboard Layout]\n\n添加\"Scancode Map\"二进制项，内容为\n> 00 00 00 00 00 00 00 00\n> 03 00 00 00 1D 00 3A 00\n> 00 00 00 00 00 00 00 00\n\n","slug":"windows_nocaps","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5q500gqmcxqtd0vccye"},{"title":"win8修改Windows目录下文件遇到的权限问题","date":"2015-07-24T16:00:00.000Z","_content":"很无语,找到文件使用记事本打开却无法保存,提示没有权限,我明明是管理员\n上网查发现需要以管理员身份运行记事本才行\n<!--more-->\n## 以管理员身份运行\n去C:\\Windows下找到notepad,右键点击以管理员身份运行\n再通过记事本的文件->打开菜单找到想要修改的文件,才能保存\n\n## 使用组策略配置\n运行: gpedit.msc\n计算机配置->Windows设置->安全设置->本地策略->安全选项\n在右侧的窗口找到\"用户账户控制:以管理员批准模式运行所有管理员\"，\n右击-属性（或双击它），选择已禁用。\n可能需要重启计算机。\n以后就省事了。\n\n","source":"_posts/win8修改Windows目录下文件遇到的权限问题.md","raw":"title: win8修改Windows目录下文件遇到的权限问题\ndate: 2015-07-25\ntags: windows\n---\n很无语,找到文件使用记事本打开却无法保存,提示没有权限,我明明是管理员\n上网查发现需要以管理员身份运行记事本才行\n<!--more-->\n## 以管理员身份运行\n去C:\\Windows下找到notepad,右键点击以管理员身份运行\n再通过记事本的文件->打开菜单找到想要修改的文件,才能保存\n\n## 使用组策略配置\n运行: gpedit.msc\n计算机配置->Windows设置->安全设置->本地策略->安全选项\n在右侧的窗口找到\"用户账户控制:以管理员批准模式运行所有管理员\"，\n右击-属性（或双击它），选择已禁用。\n可能需要重启计算机。\n以后就省事了。\n\n","slug":"win8修改Windows目录下文件遇到的权限问题","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5q600gsmcxqft0t2v1n"},{"title":"windows和ubuntu中看到的时间不一样的问题","date":"2015-08-04T16:00:00.000Z","_content":"正好差时区的值\n<!--more-->\n## 原因: Windows与Mac/Linux缺省看待系统硬件时间的方式不一样\nWindows把系统硬件时间当作本地时间(local time)，即操作系统中显示的时间跟BIOS中显示的时间是一样的。\nLinux/Unix/Mac把硬件时间当作UTC，操作系统中显示的时间是硬件时间按时区计算得来的，比如说北京时间是硬件时间+8小时。\n\n## 让Windows把硬件时间当作UTC\n开始->运行->CMD\nReg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation /v RealTimeIsUniversal /t REG_DWORD /d 1\n\n## 或修改Mac和Ubuntu不使用UTC的时间\nsudo gedit /etc/default/rcS\n将UTC=yes改为UTC=no\n\n","source":"_posts/windows和ubuntu的时间差问题.md","raw":"title: windows和ubuntu中看到的时间不一样的问题\ndate: 2015-08-05\ntags: [windows, linux]\n---\n正好差时区的值\n<!--more-->\n## 原因: Windows与Mac/Linux缺省看待系统硬件时间的方式不一样\nWindows把系统硬件时间当作本地时间(local time)，即操作系统中显示的时间跟BIOS中显示的时间是一样的。\nLinux/Unix/Mac把硬件时间当作UTC，操作系统中显示的时间是硬件时间按时区计算得来的，比如说北京时间是硬件时间+8小时。\n\n## 让Windows把硬件时间当作UTC\n开始->运行->CMD\nReg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation /v RealTimeIsUniversal /t REG_DWORD /d 1\n\n## 或修改Mac和Ubuntu不使用UTC的时间\nsudo gedit /etc/default/rcS\n将UTC=yes改为UTC=no\n\n","slug":"windows和ubuntu的时间差问题","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5q700gvmcxqonproq7d"},{"title":"wireshark interface list为空的问题","date":"2016-06-15T07:31:00.000Z","_content":"\n执行以下命令并重启\n```\nsudo dpkg-reconfigure wireshark-common \nsudo usermod -a -G wireshark $USER\n```\n\n## 参考链接\nhttp://stackoverflow.com/questions/8255644/why-doesnt-wireshark-detect-my-interface\n\n","source":"_posts/wireshark.md","raw":"title: wireshark interface list为空的问题\ndate: 2016-06-15 15:31:00\ntags: [internet, linux]\n---\n\n执行以下命令并重启\n```\nsudo dpkg-reconfigure wireshark-common \nsudo usermod -a -G wireshark $USER\n```\n\n## 参考链接\nhttp://stackoverflow.com/questions/8255644/why-doesnt-wireshark-detect-my-interface\n\n","slug":"wireshark","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5q800gxmcxqkbvrxr55"},{"title":"火狐+FoxyProxy Standard实现Chrome+SwitchyProxy的效果","date":"2015-07-23T16:00:00.000Z","_content":"### 下载FoxyProxy Standard插件并安装\nhttps://addons.mozilla.org/en-us/firefox/addon/foxyproxy-standard/\n\n### 配置\n进入FoxyProxy的选项\n* 代理服务器->新建一个使用SOCKS v5的代理服务器\n* 将工作模块修改为\"为全部Urls启动代理服务器XXXX\",即使用全局模式,以便能下载(更新)gfwlist\n* 模式订阅->添加新的模式订阅 Format: AutoProxy, Obfuscation: Base64\n* 订阅网址 http://autoproxy-gfwlist.googlecode.com/svn/trunk/gfwlist.txt\n* 为模式订阅选择代理服务器, 即跟上面的SOCKS v5代理绑定\n* 将工作模式修改为\"使用基于其预定义模板的代理服务器\",实现需要的用代理,不需要的直接连\n* 重启浏览器\n\n","source":"_posts/火狐和FoxyProxy.md","raw":"title: 火狐+FoxyProxy Standard实现Chrome+SwitchyProxy的效果\ndate: 2015-07-24\ntags: internet\n---\n### 下载FoxyProxy Standard插件并安装\nhttps://addons.mozilla.org/en-us/firefox/addon/foxyproxy-standard/\n\n### 配置\n进入FoxyProxy的选项\n* 代理服务器->新建一个使用SOCKS v5的代理服务器\n* 将工作模块修改为\"为全部Urls启动代理服务器XXXX\",即使用全局模式,以便能下载(更新)gfwlist\n* 模式订阅->添加新的模式订阅 Format: AutoProxy, Obfuscation: Base64\n* 订阅网址 http://autoproxy-gfwlist.googlecode.com/svn/trunk/gfwlist.txt\n* 为模式订阅选择代理服务器, 即跟上面的SOCKS v5代理绑定\n* 将工作模式修改为\"使用基于其预定义模板的代理服务器\",实现需要的用代理,不需要的直接连\n* 重启浏览器\n\n","slug":"火狐和FoxyProxy","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5q900h0mcxqfkfgwl02"},{"title":"xcode 点滴","date":"2018-10-19T16:00:00.000Z","_content":"\n* xcode 更新问题\n* 按住 option 键点击关键字可以查看文档\n\n<!--more-->\n\n## xcode更新问题\n想要更新到 xcode 10 , 结果在 appstore 上只有一个 open 按钮,\n并没有 get 或 download , 烦\n找了半天, 找到如下链接可以从官网直接下载\n\nhttps://developer.apple.com/download/more/\n\n## 参考链接\nhttps://www.quora.com/How-do-you-download-Xcode-without-the-App-Store\n\n","source":"_posts/xcode_upgrade.md","raw":"title: xcode 点滴\ndate: 2018-10-20\ntags: [mac, xcode]\n---\n\n* xcode 更新问题\n* 按住 option 键点击关键字可以查看文档\n\n<!--more-->\n\n## xcode更新问题\n想要更新到 xcode 10 , 结果在 appstore 上只有一个 open 按钮,\n并没有 get 或 download , 烦\n找了半天, 找到如下链接可以从官网直接下载\n\nhttps://developer.apple.com/download/more/\n\n## 参考链接\nhttps://www.quora.com/How-do-you-download-Xcode-without-the-App-Store\n\n","slug":"xcode_upgrade","published":1,"updated":"2018-10-21T13:32:30.342Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5qa00h2mcxqjfqgkucb"},{"title":"环回地址","date":"2015-07-22T16:00:00.000Z","_content":"网络地址127是一个保留地址，用于网络软件测试以及本地机进程间通信，叫做环回地址（loopback address）。\n无论什么程序，一旦使用环回地址发送数据，协议软件立即返回，不进行任何网络传输。\n127.0.0.1～127.255.255.254都是环回地址\n\n","source":"_posts/环回地址.md","raw":"title: 环回地址\ndate: 2015-07-23\ntags: internet\n---\n网络地址127是一个保留地址，用于网络软件测试以及本地机进程间通信，叫做环回地址（loopback address）。\n无论什么程序，一旦使用环回地址发送数据，协议软件立即返回，不进行任何网络传输。\n127.0.0.1～127.255.255.254都是环回地址\n\n","slug":"环回地址","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5qb00h5mcxq1uuwuv3t"},{"title":"阿里公共DNS","date":"2015-07-24T16:00:00.000Z","_content":"\n223.5.5.5\n或\n223.6.6.6\n\n","source":"_posts/阿里公共DNS.md","raw":"title: 阿里公共DNS\ndate: 2015-07-25\ntags: internet\n---\n\n223.5.5.5\n或\n223.6.6.6\n\n","slug":"阿里公共DNS","published":1,"updated":"2018-01-29T04:37:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrtcb5qb00h7mcxqqdetp7q9"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"ckrtcb5ih0001mcxqs142sohz","tag_id":"ckrtcb5im0003mcxqln0hs3uf","_id":"ckrtcb5it0008mcxqtxchcgjx"},{"post_id":"ckrtcb5ik0002mcxqrk9j21lq","tag_id":"ckrtcb5im0003mcxqln0hs3uf","_id":"ckrtcb5iv000cmcxq5sz7ddzz"},{"post_id":"ckrtcb5in0004mcxq9vm711li","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5iz000hmcxq4ledqf1g"},{"post_id":"ckrtcb5j1000kmcxqh886e5a7","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5j2000nmcxq36whvdkx"},{"post_id":"ckrtcb5j1000kmcxqh886e5a7","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5j3000pmcxqpndchcs7"},{"post_id":"ckrtcb5ip0005mcxqx8221er3","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5j4000smcxq1lal2zib"},{"post_id":"ckrtcb5ip0005mcxqx8221er3","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5j6000umcxqt2j1nyj7"},{"post_id":"ckrtcb5j1000lmcxqh1ilmswg","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5j7000xmcxqovlrkli4"},{"post_id":"ckrtcb5j1000lmcxqh1ilmswg","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5j8000zmcxqecv0eyha"},{"post_id":"ckrtcb5j3000omcxqiwng1r6u","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5j90012mcxq47t02a5c"},{"post_id":"ckrtcb5j3000omcxqiwng1r6u","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5ja0014mcxq8xcf4757"},{"post_id":"ckrtcb5j4000qmcxqbmxfxrgh","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5jb0017mcxqo1d6a12n"},{"post_id":"ckrtcb5j4000qmcxqbmxfxrgh","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5jc0019mcxq6jr26iy9"},{"post_id":"ckrtcb5j5000tmcxqqcb9k8qx","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5je001cmcxq35fc5qk9"},{"post_id":"ckrtcb5j5000tmcxqqcb9k8qx","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5jf001emcxqrdcq9lag"},{"post_id":"ckrtcb5iq0006mcxqdvx8cyh1","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5jg001hmcxq3j863qw4"},{"post_id":"ckrtcb5iq0006mcxqdvx8cyh1","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5jh001jmcxqkwsjfset"},{"post_id":"ckrtcb5j6000vmcxq013tzkzi","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5ji001mmcxqu7bzv0x9"},{"post_id":"ckrtcb5j6000vmcxq013tzkzi","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5jj001omcxq2c8jlld1"},{"post_id":"ckrtcb5j7000ymcxqypa6ocsg","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5jk001rmcxq1qk3m149"},{"post_id":"ckrtcb5j7000ymcxqypa6ocsg","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5jl001tmcxqk66mmiaf"},{"post_id":"ckrtcb5j80010mcxq0emt38in","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5jm001wmcxqnff4qdwc"},{"post_id":"ckrtcb5j80010mcxq0emt38in","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5jn001ymcxqem978oqf"},{"post_id":"ckrtcb5j90013mcxqfim7ygdw","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5jo0020mcxqvkfrw2bn"},{"post_id":"ckrtcb5j90013mcxqfim7ygdw","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5jq0022mcxqv29icw7d"},{"post_id":"ckrtcb5it0009mcxqp3j4jybg","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5jr0024mcxqvzlkkeie"},{"post_id":"ckrtcb5it0009mcxqp3j4jybg","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5js0026mcxqr9tpiecl"},{"post_id":"ckrtcb5ja0015mcxq4j4twb0c","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5js0028mcxq7m7qh76k"},{"post_id":"ckrtcb5ja0015mcxq4j4twb0c","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5jt002amcxqoqvklmiu"},{"post_id":"ckrtcb5jc0018mcxqpdc78iiq","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5ju002cmcxqa5masgys"},{"post_id":"ckrtcb5jc0018mcxqpdc78iiq","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5jw002fmcxqgddkhaf1"},{"post_id":"ckrtcb5jd001amcxq667cdea3","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5jy002hmcxqipogvyo3"},{"post_id":"ckrtcb5jd001amcxq667cdea3","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5jz002jmcxqjti924g7"},{"post_id":"ckrtcb5je001dmcxqmj28pxiu","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5k0002mmcxq2h53z609"},{"post_id":"ckrtcb5je001dmcxqmj28pxiu","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5k0002omcxqpkdmb80g"},{"post_id":"ckrtcb5iu000amcxqn278qsts","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5k1002qmcxqvn892h1n"},{"post_id":"ckrtcb5iu000amcxqn278qsts","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5k2002tmcxqfwpb5owh"},{"post_id":"ckrtcb5jf001fmcxq89j2zefz","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5k3002vmcxqsom2qd1a"},{"post_id":"ckrtcb5jf001fmcxq89j2zefz","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5k4002ymcxq6wdacy15"},{"post_id":"ckrtcb5jg001imcxqackpj2qi","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5k50030mcxq61hcfrts"},{"post_id":"ckrtcb5jg001imcxqackpj2qi","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5k70033mcxqhd3zrg5w"},{"post_id":"ckrtcb5iw000dmcxqqt6f3ae3","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5k70035mcxqndliyecj"},{"post_id":"ckrtcb5iw000dmcxqqt6f3ae3","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5k80038mcxqqf215s35"},{"post_id":"ckrtcb5jh001kmcxqgjjtbznf","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5k9003amcxqghupwc6h"},{"post_id":"ckrtcb5jh001kmcxqgjjtbznf","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5ka003cmcxqq3212xqv"},{"post_id":"ckrtcb5ji001nmcxquublvtnw","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5kb003fmcxq79vymaa0"},{"post_id":"ckrtcb5ji001nmcxquublvtnw","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5kc003hmcxqs6ttuh62"},{"post_id":"ckrtcb5ix000emcxqwqah24dp","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5kd003kmcxq93mzfsfm"},{"post_id":"ckrtcb5ix000emcxqwqah24dp","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5ke003mmcxql0w0a2a5"},{"post_id":"ckrtcb5jj001pmcxqr4zer4wq","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5kf003pmcxqiqnay6hp"},{"post_id":"ckrtcb5jj001pmcxqr4zer4wq","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5kf003rmcxqertqbbbw"},{"post_id":"ckrtcb5jk001smcxqquaoho9j","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5kg003umcxqdxaza9ck"},{"post_id":"ckrtcb5jk001smcxqquaoho9j","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5kh003wmcxqw3kp08z3"},{"post_id":"ckrtcb5iz000gmcxqpzcs28bj","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5ki003ymcxq16elhef7"},{"post_id":"ckrtcb5iz000gmcxqpzcs28bj","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5kj0041mcxqfrumuwa6"},{"post_id":"ckrtcb5jl001umcxq8w3wplgn","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5kk0043mcxqdzpjpytp"},{"post_id":"ckrtcb5jl001umcxq8w3wplgn","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5km0046mcxq3y7li3e4"},{"post_id":"ckrtcb5jn001xmcxq78i4qnzn","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5ko0048mcxqbck1zly2"},{"post_id":"ckrtcb5jn001xmcxq78i4qnzn","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5kp004bmcxq8y5q7rqb"},{"post_id":"ckrtcb5j0000imcxqyvqp59g3","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5kq004dmcxq7aetg621"},{"post_id":"ckrtcb5j0000imcxqyvqp59g3","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5kr004gmcxqpul1axwt"},{"post_id":"ckrtcb5jn001zmcxqk68ufyyb","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5ku004imcxqu9c9vw9l"},{"post_id":"ckrtcb5jn001zmcxqk68ufyyb","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5kv004kmcxqp4hoisot"},{"post_id":"ckrtcb5jp0021mcxqmkxlf6c1","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5kw004nmcxqps7lpz11"},{"post_id":"ckrtcb5jp0021mcxqmkxlf6c1","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5kw004pmcxqsasguqkc"},{"post_id":"ckrtcb5jq0023mcxq7ewemcnd","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5kx004smcxqy7ihap6x"},{"post_id":"ckrtcb5jq0023mcxq7ewemcnd","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5ky004umcxqlvlpwy2l"},{"post_id":"ckrtcb5jr0025mcxqyv3w6on5","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5l0004xmcxqh4karm82"},{"post_id":"ckrtcb5jr0025mcxqyv3w6on5","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5l1004zmcxqpg5ugxtd"},{"post_id":"ckrtcb5js0027mcxqziyuasei","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5l20052mcxqlpb2lw29"},{"post_id":"ckrtcb5js0027mcxqziyuasei","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5l30054mcxqq3s2ztd6"},{"post_id":"ckrtcb5js0029mcxqk1dstqel","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5l40056mcxqf250i89p"},{"post_id":"ckrtcb5js0029mcxqk1dstqel","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5l50059mcxquylam4sz"},{"post_id":"ckrtcb5ju002dmcxqkyfwfwnh","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5l6005bmcxqzlidfr7g"},{"post_id":"ckrtcb5ju002dmcxqkyfwfwnh","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5l7005emcxqdbyfqgvp"},{"post_id":"ckrtcb5jw002gmcxqry83qy3x","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5l8005gmcxqrpu7b55n"},{"post_id":"ckrtcb5jt002bmcxqbgs0p0hq","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5la005jmcxqmfv3ax1i"},{"post_id":"ckrtcb5k2002umcxq4qp0z6x8","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5lb005lmcxqx3jwkee7"},{"post_id":"ckrtcb5jy002imcxqsuelau0h","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5lc005omcxqly99bvxd"},{"post_id":"ckrtcb5jy002imcxqsuelau0h","tag_id":"ckrtcb5k0002lmcxqtpv0wvmb","_id":"ckrtcb5ld005qmcxqu4wb38dn"},{"post_id":"ckrtcb5jy002imcxqsuelau0h","tag_id":"ckrtcb5k2002smcxq3l2jtyeb","_id":"ckrtcb5lf005tmcxqnb0ra910"},{"post_id":"ckrtcb5k3002wmcxqhlis0cca","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5lg005vmcxqbcsihzcl"},{"post_id":"ckrtcb5k3002wmcxqhlis0cca","tag_id":"ckrtcb5j0000jmcxq802zskw3","_id":"ckrtcb5lh005xmcxqldepe38i"},{"post_id":"ckrtcb5k80039mcxqa9y8t0cg","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5li0060mcxqn4i3gunk"},{"post_id":"ckrtcb5jz002kmcxqbuvoofbv","tag_id":"ckrtcb5k4002xmcxqffjc62l2","_id":"ckrtcb5lj0062mcxqd5bwjyen"},{"post_id":"ckrtcb5jz002kmcxqbuvoofbv","tag_id":"ckrtcb5k60032mcxqo0mqoomi","_id":"ckrtcb5lk0065mcxq2o3u2xjd"},{"post_id":"ckrtcb5jz002kmcxqbuvoofbv","tag_id":"ckrtcb5k80037mcxqxg2hplcm","_id":"ckrtcb5ll0067mcxqbvlz7kgk"},{"post_id":"ckrtcb5k0002nmcxqy6twceho","tag_id":"ckrtcb5kb003emcxq9z4dyulr","_id":"ckrtcb5lm006amcxq5vu3zp70"},{"post_id":"ckrtcb5k1002pmcxqd0uupil1","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5ln006cmcxqfd8jbdep"},{"post_id":"ckrtcb5k1002pmcxqd0uupil1","tag_id":"ckrtcb5kd003jmcxq30qj17z2","_id":"ckrtcb5lp006fmcxqa1d1lbjy"},{"post_id":"ckrtcb5ki003zmcxqv0ahcv9c","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5lq006hmcxqyz7otdye"},{"post_id":"ckrtcb5ki003zmcxqv0ahcv9c","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5lr006kmcxqkadrmhxk"},{"post_id":"ckrtcb5k1002rmcxqzuckbnmx","tag_id":"ckrtcb5ke003omcxqjj5n37fy","_id":"ckrtcb5lr006mmcxqvh8rgah9"},{"post_id":"ckrtcb5k1002rmcxqzuckbnmx","tag_id":"ckrtcb5kg003tmcxq3ftqpvuj","_id":"ckrtcb5lv006pmcxq8gih0503"},{"post_id":"ckrtcb5k1002rmcxqzuckbnmx","tag_id":"ckrtcb5kj0040mcxqt88eifos","_id":"ckrtcb5lv006rmcxq1fi3ktt6"},{"post_id":"ckrtcb5k5002zmcxqlac8kr5d","tag_id":"ckrtcb5km0045mcxqjbf859bd","_id":"ckrtcb5lw006umcxq1mh9loxh"},{"post_id":"ckrtcb5k50031mcxq1buiw9w5","tag_id":"ckrtcb5ko004amcxq6bpgjqlz","_id":"ckrtcb5ly006wmcxq2xlsoi6m"},{"post_id":"ckrtcb5k70034mcxqdt8co46u","tag_id":"ckrtcb5kr004fmcxqb8hgm1ce","_id":"ckrtcb5lz006zmcxq1q9s9mck"},{"post_id":"ckrtcb5k70036mcxqpuakeuoj","tag_id":"ckrtcb5kv004mmcxqjpoifxmh","_id":"ckrtcb5m00071mcxqapvmkd8f"},{"post_id":"ckrtcb5k9003bmcxqk3ipi3b1","tag_id":"ckrtcb5kx004rmcxqld12ioib","_id":"ckrtcb5m10074mcxqqi7f5zv2"},{"post_id":"ckrtcb5ka003dmcxqfxmdg0l8","tag_id":"ckrtcb5kz004wmcxq7nviwd3e","_id":"ckrtcb5m30076mcxqujt1lgkw"},{"post_id":"ckrtcb5ka003dmcxqfxmdg0l8","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5m40079mcxqz5354kbm"},{"post_id":"ckrtcb5ka003dmcxqfxmdg0l8","tag_id":"ckrtcb5l20051mcxqghyogbyg","_id":"ckrtcb5m5007bmcxq43t3h8k5"},{"post_id":"ckrtcb5l5005amcxqyupi7dy9","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5m6007emcxqxpirq11y"},{"post_id":"ckrtcb5kb003gmcxq0gxfxfpw","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5m7007gmcxql6l5gitq"},{"post_id":"ckrtcb5l6005cmcxqkndaq8fn","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5m7007jmcxq8pk7pqbl"},{"post_id":"ckrtcb5l7005fmcxq1yexxkc7","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5m8007lmcxqbzg8saa1"},{"post_id":"ckrtcb5kc003imcxqv9fmf98v","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5m9007omcxqh0mp0xjm"},{"post_id":"ckrtcb5kc003imcxqv9fmf98v","tag_id":"ckrtcb5l7005dmcxqyej8wnro","_id":"ckrtcb5ma007qmcxqinl3ba4o"},{"post_id":"ckrtcb5la005kmcxq1of0hkem","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5mb007tmcxqx9nm5ieh"},{"post_id":"ckrtcb5kd003lmcxq8r4eof5g","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5mc007vmcxq00x12gdi"},{"post_id":"ckrtcb5kd003lmcxq8r4eof5g","tag_id":"ckrtcb5l7005dmcxqyej8wnro","_id":"ckrtcb5md007ymcxqd4bj8ju2"},{"post_id":"ckrtcb5lb005mmcxqv4qf5i7r","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5me0080mcxqhz4ri18d"},{"post_id":"ckrtcb5lc005pmcxqfuut2l91","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5mf0083mcxq6wg5qk65"},{"post_id":"ckrtcb5ld005rmcxqv51udp8s","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5mg0085mcxq366xrw2y"},{"post_id":"ckrtcb5lg005wmcxq9jk8wxif","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5mh0088mcxqktgi8ism"},{"post_id":"ckrtcb5ke003nmcxqq0m43s8x","tag_id":"ckrtcb5lc005nmcxq7zvetb29","_id":"ckrtcb5mi008amcxqfjm6558z"},{"post_id":"ckrtcb5ke003nmcxqq0m43s8x","tag_id":"ckrtcb5lf005smcxqjx5w67di","_id":"ckrtcb5mj008dmcxqmmu8pof1"},{"post_id":"ckrtcb5lh005ymcxqfmepmdft","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5mk008fmcxqrg9xlaan"},{"post_id":"ckrtcb5li0061mcxqteo33eoh","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5ml008imcxqnzut065d"},{"post_id":"ckrtcb5kf003qmcxq8ft4yqez","tag_id":"ckrtcb5lc005nmcxq7zvetb29","_id":"ckrtcb5mm008kmcxq4onkrh2f"},{"post_id":"ckrtcb5lj0063mcxqicu3n2x9","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5mm008nmcxqngxcekvl"},{"post_id":"ckrtcb5lk0066mcxq6nrzv1mt","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5mn008pmcxqoqepb29h"},{"post_id":"ckrtcb5kg003smcxqhfb2rlsb","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5mo008rmcxqk0vcthv5"},{"post_id":"ckrtcb5kg003smcxqhfb2rlsb","tag_id":"ckrtcb5l7005dmcxqyej8wnro","_id":"ckrtcb5mp008umcxqmbttj2bj"},{"post_id":"ckrtcb5ll0068mcxq643u0uqu","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5mq008wmcxqczsgwo2c"},{"post_id":"ckrtcb5kh003vmcxq5blkwrc4","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5mq008zmcxq07987jm9"},{"post_id":"ckrtcb5kh003vmcxq5blkwrc4","tag_id":"ckrtcb5l7005dmcxqyej8wnro","_id":"ckrtcb5mr0091mcxqkq4y7j3w"},{"post_id":"ckrtcb5ln006dmcxq2z118k3i","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5mt0094mcxqoi0w8ntk"},{"post_id":"ckrtcb5lp006gmcxq9y2t2h99","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5mu0096mcxqp0bxxdgu"},{"post_id":"ckrtcb5kh003xmcxqee6hcand","tag_id":"ckrtcb5lo006emcxq72ngfi40","_id":"ckrtcb5mv0099mcxqoemm1jn7"},{"post_id":"ckrtcb5lr006lmcxqs5w45ast","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5mw009bmcxqi8v472hp"},{"post_id":"ckrtcb5ls006nmcxqes3tazhg","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5my009emcxqvxjjy8cs"},{"post_id":"ckrtcb5lv006qmcxq2ebyn7yy","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5mz009gmcxqaab2g0jd"},{"post_id":"ckrtcb5kj0042mcxq1nnoekej","tag_id":"ckrtcb5lq006jmcxq4ha3bccp","_id":"ckrtcb5n0009jmcxq7g0f58zz"},{"post_id":"ckrtcb5kj0042mcxq1nnoekej","tag_id":"ckrtcb5lu006omcxq8famyn25","_id":"ckrtcb5n2009lmcxq0ko4cxvy"},{"post_id":"ckrtcb5lw006smcxqwtvws60v","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5n3009omcxqcb5hksvd"},{"post_id":"ckrtcb5kk0044mcxqswoagww9","tag_id":"ckrtcb5kv004mmcxqjpoifxmh","_id":"ckrtcb5n4009qmcxqgdubcjrq"},{"post_id":"ckrtcb5ly006xmcxq52tb75ue","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5n4009smcxqjz3ewioi"},{"post_id":"ckrtcb5lz0070mcxq9imgtlpm","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5n6009vmcxqpfgpii06"},{"post_id":"ckrtcb5lz0070mcxq9imgtlpm","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5n7009xmcxqbne57loq"},{"post_id":"ckrtcb5km0047mcxq8plch3cm","tag_id":"ckrtcb5lq006jmcxq4ha3bccp","_id":"ckrtcb5n900a0mcxq9dhdcwp9"},{"post_id":"ckrtcb5m00072mcxqqat3wunk","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5na00a2mcxqwbzqxk9v"},{"post_id":"ckrtcb5m10075mcxqvp40d5jv","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5nc00a5mcxq5dh7qbin"},{"post_id":"ckrtcb5ko0049mcxq8fr5r9uh","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5nd00a7mcxqjtpwk1p5"},{"post_id":"ckrtcb5m30077mcxq11tod3gc","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5ne00aamcxqwi0utsvq"},{"post_id":"ckrtcb5m4007amcxqzqesyjyy","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5nf00acmcxqzmsa9bt2"},{"post_id":"ckrtcb5kp004cmcxq6zh9zgmh","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5ng00afmcxqulm71re0"},{"post_id":"ckrtcb5m6007fmcxqrx0ti2wt","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5nh00ahmcxq7wxex8sd"},{"post_id":"ckrtcb5m6007fmcxqrx0ti2wt","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5ni00akmcxq3yifmsw8"},{"post_id":"ckrtcb5kq004emcxq8z53jguh","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5nj00ammcxqh2veyv9d"},{"post_id":"ckrtcb5m7007hmcxqckpct5he","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5nk00apmcxql202ra1w"},{"post_id":"ckrtcb5m7007hmcxqckpct5he","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5nl00armcxqp3a81ivj"},{"post_id":"ckrtcb5ks004hmcxqiacad2t0","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5nm00atmcxq7lzxrxhw"},{"post_id":"ckrtcb5m9007mmcxqebxakiol","tag_id":"ckrtcb5im0003mcxqln0hs3uf","_id":"ckrtcb5no00awmcxqfy55yr0s"},{"post_id":"ckrtcb5ku004jmcxqdc97cws9","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5np00aymcxqg5nvv880"},{"post_id":"ckrtcb5mb007umcxq1aj3cxs6","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5nq00b1mcxq5lof8ztu"},{"post_id":"ckrtcb5kv004lmcxq6pbimsqc","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5nr00b3mcxqzvljzx9q"},{"post_id":"ckrtcb5mc007wmcxq8irxi6v7","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5ns00b6mcxqron87o3k"},{"post_id":"ckrtcb5md007zmcxqi22gav3r","tag_id":"ckrtcb5kv004mmcxqjpoifxmh","_id":"ckrtcb5nt00b8mcxq0o47x81c"},{"post_id":"ckrtcb5kw004omcxqv5ziikuh","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5nu00bbmcxqzjyjanvn"},{"post_id":"ckrtcb5kw004qmcxqojw87fj7","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5nv00bdmcxqhfcb6gyl"},{"post_id":"ckrtcb5kx004tmcxqmur2aelg","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5nv00bfmcxqlnzb2cis"},{"post_id":"ckrtcb5mn008qmcxqxuvvnx9k","tag_id":"ckrtcb5kv004mmcxqjpoifxmh","_id":"ckrtcb5nw00bimcxqxyo1syfq"},{"post_id":"ckrtcb5mp008vmcxqg3cuady3","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5nx00bkmcxqzpuc15sd"},{"post_id":"ckrtcb5mq008xmcxq49o4d0k4","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5ny00bnmcxqx1h8yodr"},{"post_id":"ckrtcb5mr0090mcxqqf4o949b","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5nz00bpmcxq1pghfx3c"},{"post_id":"ckrtcb5ky004vmcxqs7opgy82","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5o100bsmcxqkqnxbrtd"},{"post_id":"ckrtcb5ky004vmcxqs7opgy82","tag_id":"ckrtcb5lu006omcxq8famyn25","_id":"ckrtcb5o100bumcxq4e996g1e"},{"post_id":"ckrtcb5ky004vmcxqs7opgy82","tag_id":"ckrtcb5mm008mmcxq4ii1frfj","_id":"ckrtcb5o200bxmcxq2iwdgi6o"},{"post_id":"ckrtcb5ky004vmcxqs7opgy82","tag_id":"ckrtcb5mp008tmcxqlh2t793z","_id":"ckrtcb5o300bzmcxqo7vl4spx"},{"post_id":"ckrtcb5ky004vmcxqs7opgy82","tag_id":"ckrtcb5mq008ymcxq9q0m8pbo","_id":"ckrtcb5o400c1mcxqjy7zopda"},{"post_id":"ckrtcb5mr0092mcxqyf9wrnug","tag_id":"ckrtcb5k0002lmcxqtpv0wvmb","_id":"ckrtcb5o500c4mcxqw23r0mwh"},{"post_id":"ckrtcb5mt0095mcxqbv7fleuo","tag_id":"ckrtcb5k0002lmcxqtpv0wvmb","_id":"ckrtcb5o600c6mcxq7bkr3xqn"},{"post_id":"ckrtcb5l0004ymcxq676sihof","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5o700c9mcxqpitbhf18"},{"post_id":"ckrtcb5mu0097mcxqeq1gq9js","tag_id":"ckrtcb5k0002lmcxqtpv0wvmb","_id":"ckrtcb5o800cbmcxq6l7dx3o5"},{"post_id":"ckrtcb5mv009amcxq95h4g7dk","tag_id":"ckrtcb5k0002lmcxqtpv0wvmb","_id":"ckrtcb5o900cemcxq7qgwyir6"},{"post_id":"ckrtcb5mw009cmcxq1246type","tag_id":"ckrtcb5k0002lmcxqtpv0wvmb","_id":"ckrtcb5o900cgmcxqzchp6105"},{"post_id":"ckrtcb5my009fmcxq7f9d13je","tag_id":"ckrtcb5k0002lmcxqtpv0wvmb","_id":"ckrtcb5oa00cjmcxqvpso8woi"},{"post_id":"ckrtcb5l10050mcxqpbvej7hw","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5ob00clmcxqoz30wrhu"},{"post_id":"ckrtcb5l10050mcxqpbvej7hw","tag_id":"ckrtcb5mx009dmcxqtgqyno9f","_id":"ckrtcb5oc00cnmcxq8e6tvmhb"},{"post_id":"ckrtcb5mz009hmcxq3bu5cylg","tag_id":"ckrtcb5k0002lmcxqtpv0wvmb","_id":"ckrtcb5od00cqmcxq4waqoc8c"},{"post_id":"ckrtcb5n0009kmcxqml1geqxh","tag_id":"ckrtcb5k0002lmcxqtpv0wvmb","_id":"ckrtcb5of00csmcxq001sthj4"},{"post_id":"ckrtcb5n2009mmcxquumegr8c","tag_id":"ckrtcb5k0002lmcxqtpv0wvmb","_id":"ckrtcb5og00cvmcxq5zm45hiy"},{"post_id":"ckrtcb5n3009pmcxqontwaann","tag_id":"ckrtcb5k0002lmcxqtpv0wvmb","_id":"ckrtcb5oh00cxmcxq06sku4wr"},{"post_id":"ckrtcb5l20053mcxqc2tx84zp","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5oj00d0mcxqebmwvwrm"},{"post_id":"ckrtcb5l20053mcxqc2tx84zp","tag_id":"ckrtcb5n3009nmcxqza7sbu12","_id":"ckrtcb5ok00d2mcxqhuisjin3"},{"post_id":"ckrtcb5n5009tmcxqviyy2zdj","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5ol00d5mcxqjgq9kclf"},{"post_id":"ckrtcb5l30055mcxqtojtfuoz","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5on00d7mcxq8dhiar70"},{"post_id":"ckrtcb5na00a1mcxqmqc334yy","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5oo00damcxqbt667ifh"},{"post_id":"ckrtcb5l40057mcxqu024ealf","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5op00dcmcxq6uh4ixnb"},{"post_id":"ckrtcb5nb00a3mcxqr0ftn199","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5oq00dfmcxq9r3kgyoc"},{"post_id":"ckrtcb5nd00a8mcxqv55v1ldp","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5or00dhmcxqg8eiwurv"},{"post_id":"ckrtcb5l8005hmcxqsywujiyn","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5os00dkmcxq4u3e8yx1"},{"post_id":"ckrtcb5l8005hmcxqsywujiyn","tag_id":"ckrtcb5lq006jmcxq4ha3bccp","_id":"ckrtcb5ot00dmmcxqbhgvtsks"},{"post_id":"ckrtcb5l8005hmcxqsywujiyn","tag_id":"ckrtcb5ne00a9mcxqe7fmnapt","_id":"ckrtcb5ou00dpmcxqk0bua5dj"},{"post_id":"ckrtcb5lf005umcxqt7zv10c1","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5ov00drmcxqhxe4s4d3"},{"post_id":"ckrtcb5lf005umcxqt7zv10c1","tag_id":"ckrtcb5ng00aemcxq0so75ldq","_id":"ckrtcb5ow00dumcxqs3jxfljk"},{"post_id":"ckrtcb5nh00aimcxquym5e18s","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5ox00dwmcxqg61cvhr6"},{"post_id":"ckrtcb5nj00anmcxq6690dgyy","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5oy00dzmcxqjl6dmkbf"},{"post_id":"ckrtcb5nk00aqmcxqpcqmiusu","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5oz00e1mcxqr15c9qm1"},{"post_id":"ckrtcb5lm006bmcxq8w2epyyy","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5p000e4mcxqj95avi4t"},{"post_id":"ckrtcb5lm006bmcxq8w2epyyy","tag_id":"ckrtcb5ni00ajmcxqsnhsd3v4","_id":"ckrtcb5p100e6mcxqeroievcz"},{"post_id":"ckrtcb5lm006bmcxq8w2epyyy","tag_id":"ckrtcb5nk00aomcxq1amwmiu3","_id":"ckrtcb5p200e9mcxq9nbnmryt"},{"post_id":"ckrtcb5no00axmcxqajrm2s5v","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5p300ebmcxqfkz09so7"},{"post_id":"ckrtcb5lq006imcxq4vejxd0a","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5p500eemcxqljfj4m3x"},{"post_id":"ckrtcb5lq006imcxq4vejxd0a","tag_id":"ckrtcb5nm00avmcxqxunwsfws","_id":"ckrtcb5p600egmcxq0i9k20dx"},{"post_id":"ckrtcb5np00azmcxqmdmy57qz","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5p900eimcxq8el2egsi"},{"post_id":"ckrtcb5nq00b2mcxq6pvk1ts6","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5pa00elmcxqa7qhvhbo"},{"post_id":"ckrtcb5lx006vmcxqu6kyfc3m","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5pb00enmcxqm7tfwmyk"},{"post_id":"ckrtcb5lx006vmcxqu6kyfc3m","tag_id":"ckrtcb5nq00b0mcxqh46hj2ed","_id":"ckrtcb5pc00eqmcxqbjg930ce"},{"post_id":"ckrtcb5nr00b4mcxquj5p9bpg","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5pd00esmcxqz4q2ewix"},{"post_id":"ckrtcb5nt00b9mcxq5803rge7","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5pe00evmcxqclowog1o"},{"post_id":"ckrtcb5nv00bemcxqt1oarwi5","tag_id":"ckrtcb5ko004amcxq6bpgjqlz","_id":"ckrtcb5pg00exmcxqanpaj9sw"},{"post_id":"ckrtcb5nw00bjmcxqiealdoor","tag_id":"ckrtcb5lo006emcxq72ngfi40","_id":"ckrtcb5ph00f0mcxqh35ociqg"},{"post_id":"ckrtcb5ny00bomcxq41sdo4af","tag_id":"ckrtcb5lo006emcxq72ngfi40","_id":"ckrtcb5pj00f2mcxqbw3tlva5"},{"post_id":"ckrtcb5m5007cmcxq9aqv4r3p","tag_id":"ckrtcb5nr00b5mcxqexyhea5g","_id":"ckrtcb5pk00f5mcxq9e9sr68z"},{"post_id":"ckrtcb5m5007cmcxq9aqv4r3p","tag_id":"ckrtcb5nu00bamcxq40ertail","_id":"ckrtcb5pk00f7mcxqndisiis3"},{"post_id":"ckrtcb5m5007cmcxq9aqv4r3p","tag_id":"ckrtcb5nw00bhmcxq86ftjah0","_id":"ckrtcb5pl00f9mcxq1vt5bbhs"},{"post_id":"ckrtcb5m5007cmcxq9aqv4r3p","tag_id":"ckrtcb5ny00bmmcxqlmfyx4ck","_id":"ckrtcb5pn00fcmcxqt1nb9a30"},{"post_id":"ckrtcb5o000bqmcxqorc4mox7","tag_id":"ckrtcb5lo006emcxq72ngfi40","_id":"ckrtcb5pn00femcxqq445ejyn"},{"post_id":"ckrtcb5o200bvmcxqgf7afmql","tag_id":"ckrtcb5lo006emcxq72ngfi40","_id":"ckrtcb5pp00fhmcxqu1vvhtgy"},{"post_id":"ckrtcb5o200bymcxqbjjozsuo","tag_id":"ckrtcb5lo006emcxq72ngfi40","_id":"ckrtcb5pq00fjmcxqw6nqh90z"},{"post_id":"ckrtcb5m8007kmcxqffhufwqk","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5pr00fmmcxqjklps8hh"},{"post_id":"ckrtcb5m8007kmcxqffhufwqk","tag_id":"ckrtcb5o000brmcxqhnk5t669","_id":"ckrtcb5ps00fomcxqenybgq7y"},{"post_id":"ckrtcb5m8007kmcxqffhufwqk","tag_id":"ckrtcb5o200bwmcxqzpac3cee","_id":"ckrtcb5pt00frmcxqphbp91lu"},{"post_id":"ckrtcb5o400c2mcxqkxuxntdb","tag_id":"ckrtcb5lo006emcxq72ngfi40","_id":"ckrtcb5pt00ftmcxqfhusbyz9"},{"post_id":"ckrtcb5m9007pmcxqsiy8qze7","tag_id":"ckrtcb5o500c3mcxq1ajgvz4j","_id":"ckrtcb5pu00fvmcxqvezn72a7"},{"post_id":"ckrtcb5ma007rmcxqfjd75gj5","tag_id":"ckrtcb5o700c8mcxq76fdvz13","_id":"ckrtcb5pw00fymcxq4zay7mx6"},{"post_id":"ckrtcb5o900cfmcxq7z90s1ry","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5pw00g0mcxq2pvcz1sm"},{"post_id":"ckrtcb5me0081mcxqb0f0mxqb","tag_id":"ckrtcb5o800cdmcxqcmzcg527","_id":"ckrtcb5px00g3mcxq5zwuxihu"},{"post_id":"ckrtcb5oa00chmcxqzach117z","tag_id":"ckrtcb5lo006emcxq72ngfi40","_id":"ckrtcb5py00g5mcxq7mcrvewm"},{"post_id":"ckrtcb5oc00cmmcxqwzuhilcd","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5pz00g8mcxqjuou32my"},{"post_id":"ckrtcb5mf0084mcxqgyo7oinr","tag_id":"ckrtcb5oa00cimcxq4m4gsi2p","_id":"ckrtcb5q000gamcxq684oz47x"},{"post_id":"ckrtcb5od00comcxqrmweoz0p","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5q100gdmcxqf3ygx77c"},{"post_id":"ckrtcb5od00comcxqrmweoz0p","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5q100gfmcxqu3pp9mn2"},{"post_id":"ckrtcb5oe00crmcxqamqsg0tt","tag_id":"ckrtcb5km0045mcxqjbf859bd","_id":"ckrtcb5q200ghmcxquym85w8f"},{"post_id":"ckrtcb5oe00crmcxqamqsg0tt","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5q300gkmcxqjsqce269"},{"post_id":"ckrtcb5of00ctmcxqq6d7mkt6","tag_id":"ckrtcb5km0045mcxqjbf859bd","_id":"ckrtcb5q400gmmcxq20hwuv8e"},{"post_id":"ckrtcb5of00ctmcxqq6d7mkt6","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5q500gpmcxq5j74xsua"},{"post_id":"ckrtcb5og00cwmcxq1spyzhwz","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5q600grmcxqbahf60my"},{"post_id":"ckrtcb5og00cwmcxq1spyzhwz","tag_id":"ckrtcb5kd003jmcxq30qj17z2","_id":"ckrtcb5q700gumcxqwxhgk9lh"},{"post_id":"ckrtcb5mg0086mcxqtt53gaji","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5q800gwmcxqccfj9tiz"},{"post_id":"ckrtcb5mg0086mcxqtt53gaji","tag_id":"ckrtcb5od00cpmcxqa5183z3l","_id":"ckrtcb5q800gzmcxq0t6g58js"},{"post_id":"ckrtcb5mg0086mcxqtt53gaji","tag_id":"ckrtcb5og00cumcxq7p2puxyw","_id":"ckrtcb5qa00h1mcxq6mc1ofi1"},{"post_id":"ckrtcb5oh00cymcxq70ktss0p","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qb00h4mcxqy4zaccur"},{"post_id":"ckrtcb5mh0089mcxq7dfkcl11","tag_id":"ckrtcb5oa00cimcxq4m4gsi2p","_id":"ckrtcb5qb00h6mcxqzukgn0n6"},{"post_id":"ckrtcb5mi008bmcxqrhonj20s","tag_id":"ckrtcb5oa00cimcxq4m4gsi2p","_id":"ckrtcb5qc00h8mcxqmd81i3tp"},{"post_id":"ckrtcb5on00d8mcxqs15r37y0","tag_id":"ckrtcb5o500c3mcxq1ajgvz4j","_id":"ckrtcb5qd00hamcxq6eivdzn7"},{"post_id":"ckrtcb5mj008emcxqx3clkyq0","tag_id":"ckrtcb5oa00cimcxq4m4gsi2p","_id":"ckrtcb5qd00hbmcxqqt4598pu"},{"post_id":"ckrtcb5oq00dgmcxqe4efozn8","tag_id":"ckrtcb5ko004amcxq6bpgjqlz","_id":"ckrtcb5qe00hdmcxq5dlla4x8"},{"post_id":"ckrtcb5mk008gmcxq9hef4r2q","tag_id":"ckrtcb5oa00cimcxq4m4gsi2p","_id":"ckrtcb5qe00hemcxqfwx2y0h1"},{"post_id":"ckrtcb5or00dimcxqjffq01fv","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qe00hgmcxqfjk2sjsi"},{"post_id":"ckrtcb5ml008jmcxqnbdui17v","tag_id":"ckrtcb5oa00cimcxq4m4gsi2p","_id":"ckrtcb5qe00hhmcxquqnji37g"},{"post_id":"ckrtcb5ou00dqmcxqm4uodaww","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qg00hjmcxqbfuk8em5"},{"post_id":"ckrtcb5mm008lmcxq6a5ndary","tag_id":"ckrtcb5oa00cimcxq4m4gsi2p","_id":"ckrtcb5qg00hkmcxq78bd91r9"},{"post_id":"ckrtcb5ow00dvmcxqc1vms2rn","tag_id":"ckrtcb5o500c3mcxq1ajgvz4j","_id":"ckrtcb5qh00hmmcxq42pmb45v"},{"post_id":"ckrtcb5mn008omcxq9gte3k07","tag_id":"ckrtcb5o800cdmcxqcmzcg527","_id":"ckrtcb5qh00hnmcxq5johs1la"},{"post_id":"ckrtcb5ox00dxmcxq2tnqse98","tag_id":"ckrtcb5o500c3mcxq1ajgvz4j","_id":"ckrtcb5qh00hpmcxqwpn6kyxe"},{"post_id":"ckrtcb5oy00e0mcxqvm08xnb6","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qh00hqmcxqdzxba0qx"},{"post_id":"ckrtcb5mo008smcxq4kxg7zxu","tag_id":"ckrtcb5oa00cimcxq4m4gsi2p","_id":"ckrtcb5qi00hsmcxqr4plblep"},{"post_id":"ckrtcb5p000e5mcxqbwjgahc1","tag_id":"ckrtcb5ko004amcxq6bpgjqlz","_id":"ckrtcb5qi00htmcxqn2gcclfn"},{"post_id":"ckrtcb5n4009rmcxqqjvlfpbf","tag_id":"ckrtcb5p000e3mcxqzc3pupt2","_id":"ckrtcb5qi00hvmcxqtcvhwmpv"},{"post_id":"ckrtcb5n4009rmcxqqjvlfpbf","tag_id":"ckrtcb5lc005nmcxq7zvetb29","_id":"ckrtcb5qj00hwmcxq8yegwi8k"},{"post_id":"ckrtcb5p100e7mcxqq9ixrfld","tag_id":"ckrtcb5lo006emcxq72ngfi40","_id":"ckrtcb5qj00hymcxqw97krtyz"},{"post_id":"ckrtcb5n6009wmcxqcm88i4o1","tag_id":"ckrtcb5o500c3mcxq1ajgvz4j","_id":"ckrtcb5qj00hzmcxqxqppza8g"},{"post_id":"ckrtcb5p300ecmcxq6l0mrdq5","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qk00i1mcxqk141l6bh"},{"post_id":"ckrtcb5p500efmcxqx8r121iu","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qk00i2mcxq78vt9rhu"},{"post_id":"ckrtcb5p600ehmcxqu3yfzqn8","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qk00i3mcxqbcl5w0yn"},{"post_id":"ckrtcb5n7009ymcxq2s0r0r16","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5qk00i5mcxq7c65r1o9"},{"post_id":"ckrtcb5n7009ymcxq2s0r0r16","tag_id":"ckrtcb5lq006jmcxq4ha3bccp","_id":"ckrtcb5qk00i6mcxqq4yn8v0u"},{"post_id":"ckrtcb5n7009ymcxq2s0r0r16","tag_id":"ckrtcb5mm008mmcxq4ii1frfj","_id":"ckrtcb5ql00i8mcxq405s4qck"},{"post_id":"ckrtcb5n7009ymcxq2s0r0r16","tag_id":"ckrtcb5mp008tmcxqlh2t793z","_id":"ckrtcb5ql00i9mcxqzzjwk73f"},{"post_id":"ckrtcb5n7009ymcxq2s0r0r16","tag_id":"ckrtcb5p500edmcxq7a9lr3zc","_id":"ckrtcb5ql00ibmcxqyrqcpfvb"},{"post_id":"ckrtcb5pa00emmcxqqx7jnwyy","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5ql00icmcxqo9oo9t77"},{"post_id":"ckrtcb5nc00a6mcxq5sslmtt1","tag_id":"ckrtcb5o500c3mcxq1ajgvz4j","_id":"ckrtcb5ql00iemcxqrkr55x7y"},{"post_id":"ckrtcb5ne00abmcxq748srtnk","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qm00ifmcxqvfklsgpt"},{"post_id":"ckrtcb5ne00abmcxq748srtnk","tag_id":"ckrtcb5pc00epmcxq01h7xa9s","_id":"ckrtcb5qm00igmcxq2rhsjwg3"},{"post_id":"ckrtcb5pd00etmcxqn5whjpw3","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5qm00iimcxqr874oli6"},{"post_id":"ckrtcb5pe00ewmcxqpah9lcqu","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5qm00ijmcxql3bltnrv"},{"post_id":"ckrtcb5pe00ewmcxqpah9lcqu","tag_id":"ckrtcb5kv004mmcxqjpoifxmh","_id":"ckrtcb5qn00ilmcxq4imbpl2r"},{"post_id":"ckrtcb5nf00admcxqnwgll9ie","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qn00immcxqhbm6jxt2"},{"post_id":"ckrtcb5nf00admcxqnwgll9ie","tag_id":"ckrtcb5pd00eumcxqdan547uk","_id":"ckrtcb5qo00iomcxq5c9pm6lf"},{"post_id":"ckrtcb5pg00eymcxqyodmf6gu","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5qo00ipmcxq0p7avkzx"},{"post_id":"ckrtcb5pg00eymcxqyodmf6gu","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qp00irmcxqoyzlqvd7"},{"post_id":"ckrtcb5ph00f1mcxqw56srfi3","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5qp00ismcxqex4zaupm"},{"post_id":"ckrtcb5pj00f3mcxqpulkygg2","tag_id":"ckrtcb5im0003mcxqln0hs3uf","_id":"ckrtcb5qp00iumcxqv42obnou"},{"post_id":"ckrtcb5pk00f6mcxqaktl3zpw","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qp00ivmcxqc6binwtb"},{"post_id":"ckrtcb5pl00f8mcxq59y8x9lk","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qp00ixmcxqu1res3q0"},{"post_id":"ckrtcb5ng00agmcxqj0lzkpfa","tag_id":"ckrtcb5ph00ezmcxqnxj6joaq","_id":"ckrtcb5qq00iymcxqtd3i2m3u"},{"post_id":"ckrtcb5ng00agmcxqj0lzkpfa","tag_id":"ckrtcb5pk00f4mcxq5pp1htop","_id":"ckrtcb5qq00j0mcxqc8e654e1"},{"post_id":"ckrtcb5ng00agmcxqj0lzkpfa","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5qq00j1mcxq2ro360l8"},{"post_id":"ckrtcb5pl00famcxqc5vj5p0f","tag_id":"ckrtcb5o800cdmcxqcmzcg527","_id":"ckrtcb5qq00j2mcxqujmn6hd3"},{"post_id":"ckrtcb5pn00fdmcxqmybp8bkk","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5qr00j4mcxq7p8f62i7"},{"post_id":"ckrtcb5pn00fdmcxqmybp8bkk","tag_id":"ckrtcb5nq00b0mcxqh46hj2ed","_id":"ckrtcb5qr00j5mcxqctm0krqh"},{"post_id":"ckrtcb5ni00almcxqdyk3jkan","tag_id":"ckrtcb5pm00fbmcxqndhb1hqw","_id":"ckrtcb5qs00j7mcxq1stvc4sk"},{"post_id":"ckrtcb5po00ffmcxqjz3jaqqk","tag_id":"ckrtcb5ko004amcxq6bpgjqlz","_id":"ckrtcb5qs00j8mcxq6nt91vqr"},{"post_id":"ckrtcb5po00ffmcxqjz3jaqqk","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qs00jamcxqhjv5ebxa"},{"post_id":"ckrtcb5pp00fimcxqa9sufh3x","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qs00jbmcxq0m2f2mzg"},{"post_id":"ckrtcb5nl00asmcxqcc2bppg5","tag_id":"ckrtcb5po00fgmcxqjfv5tl8n","_id":"ckrtcb5qs00jdmcxqxrtq3wds"},{"post_id":"ckrtcb5pq00fkmcxqi6coathv","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5qs00jemcxqij9i6ibu"},{"post_id":"ckrtcb5pr00fnmcxq6sp1g61v","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5qt00jfmcxq6i2ux2db"},{"post_id":"ckrtcb5pr00fnmcxq6sp1g61v","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qt00jhmcxqfwzq8pmc"},{"post_id":"ckrtcb5nm00aumcxqm6wzqk34","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qt00jimcxql7cekd1w"},{"post_id":"ckrtcb5nm00aumcxqm6wzqk34","tag_id":"ckrtcb5pr00flmcxq4ydfstz5","_id":"ckrtcb5qu00jkmcxqirznc21z"},{"post_id":"ckrtcb5ps00fpmcxqlep3l3vy","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qu00jlmcxq5j83iyyt"},{"post_id":"ckrtcb5pt00fsmcxq7fsrvye4","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qu00jnmcxqfuamyv5g"},{"post_id":"ckrtcb5pu00fumcxq1a78j1p6","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qu00jomcxqjk5s818w"},{"post_id":"ckrtcb5ns00b7mcxqw6q4pshd","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qv00jqmcxq7cijqsqn"},{"post_id":"ckrtcb5ns00b7mcxqw6q4pshd","tag_id":"ckrtcb5ps00fqmcxqioq8gzp3","_id":"ckrtcb5qv00jrmcxqy353ehuo"},{"post_id":"ckrtcb5pw00g1mcxqpfmcnd3h","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qw00jtmcxqe0ayf8qk"},{"post_id":"ckrtcb5nu00bcmcxqyqyfbzxv","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qw00jumcxqrzevnd47"},{"post_id":"ckrtcb5nu00bcmcxqyqyfbzxv","tag_id":"ckrtcb5pv00fxmcxqhafno27n","_id":"ckrtcb5qw00jwmcxq4zny2943"},{"post_id":"ckrtcb5nu00bcmcxqyqyfbzxv","tag_id":"ckrtcb5px00g2mcxqzpu3bjej","_id":"ckrtcb5qw00jxmcxqy1phldpx"},{"post_id":"ckrtcb5q100gemcxqizaud6ba","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qw00jzmcxqhqi82e18"},{"post_id":"ckrtcb5q100gemcxqizaud6ba","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5qx00k0mcxqnpg8vwqt"},{"post_id":"ckrtcb5q100ggmcxq58y8yab1","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qx00k1mcxqz4v90152"},{"post_id":"ckrtcb5q300glmcxq91t45kcc","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5qx00k3mcxqb8ylflgq"},{"post_id":"ckrtcb5nw00bgmcxqe9h1o7oz","tag_id":"ckrtcb5pz00g7mcxqnfe8a9jf","_id":"ckrtcb5qx00k4mcxqd2920ss4"},{"post_id":"ckrtcb5nw00bgmcxqe9h1o7oz","tag_id":"ckrtcb5q100gcmcxqnjveesw5","_id":"ckrtcb5qy00k6mcxquwgcoe9k"},{"post_id":"ckrtcb5nw00bgmcxqe9h1o7oz","tag_id":"ckrtcb5q300gjmcxqa9gj53yh","_id":"ckrtcb5qy00k7mcxqz6uu1utb"},{"post_id":"ckrtcb5nw00bgmcxqe9h1o7oz","tag_id":"ckrtcb5kb003emcxq9z4dyulr","_id":"ckrtcb5qy00k9mcxqbn89qfc3"},{"post_id":"ckrtcb5nw00bgmcxqe9h1o7oz","tag_id":"ckrtcb5q500gomcxqkd4mq0kz","_id":"ckrtcb5qy00kamcxq311dtarg"},{"post_id":"ckrtcb5nx00blmcxqn5rt5h36","tag_id":"ckrtcb5q600gtmcxq3mtrfbyq","_id":"ckrtcb5qy00kcmcxq3juauyxw"},{"post_id":"ckrtcb5nx00blmcxqn5rt5h36","tag_id":"ckrtcb5lo006emcxq72ngfi40","_id":"ckrtcb5qz00kdmcxqz52opqe9"},{"post_id":"ckrtcb5q800gxmcxqkbvrxr55","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5qz00kemcxq1gm3xvfr"},{"post_id":"ckrtcb5q800gxmcxqkbvrxr55","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5qz00kgmcxqdalzk6ip"},{"post_id":"ckrtcb5q900h0mcxqfkfgwl02","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5qz00khmcxq43mtig7a"},{"post_id":"ckrtcb5qb00h5mcxq1uuwuv3t","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5r000kjmcxqnvmnffk1"},{"post_id":"ckrtcb5qb00h7mcxqqdetp7q9","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5r000kkmcxqkpd31n3i"},{"post_id":"ckrtcb5o100btmcxq31n10y6n","tag_id":"ckrtcb5lo006emcxq72ngfi40","_id":"ckrtcb5r100kmmcxqfva4erqm"},{"post_id":"ckrtcb5o100btmcxq31n10y6n","tag_id":"ckrtcb5q600gtmcxq3mtrfbyq","_id":"ckrtcb5r100knmcxqjb3n1ccp"},{"post_id":"ckrtcb5o100btmcxq31n10y6n","tag_id":"ckrtcb5qa00h3mcxq92bdnb52","_id":"ckrtcb5r100kpmcxqfcbb1cmu"},{"post_id":"ckrtcb5o300c0mcxq4400dann","tag_id":"ckrtcb5q600gtmcxq3mtrfbyq","_id":"ckrtcb5r100kqmcxqoas73l0j"},{"post_id":"ckrtcb5o500c5mcxq2eqf5f65","tag_id":"ckrtcb5q600gtmcxq3mtrfbyq","_id":"ckrtcb5r200krmcxqp73xocnj"},{"post_id":"ckrtcb5o500c5mcxq2eqf5f65","tag_id":"ckrtcb5lo006emcxq72ngfi40","_id":"ckrtcb5r200ksmcxq3ehkd6kk"},{"post_id":"ckrtcb5o600c7mcxqyfa07s9y","tag_id":"ckrtcb5lo006emcxq72ngfi40","_id":"ckrtcb5r200ktmcxq7enclz0k"},{"post_id":"ckrtcb5o600c7mcxqyfa07s9y","tag_id":"ckrtcb5q600gtmcxq3mtrfbyq","_id":"ckrtcb5r200kumcxqn9qs4p90"},{"post_id":"ckrtcb5o700camcxql5i08354","tag_id":"ckrtcb5q600gtmcxq3mtrfbyq","_id":"ckrtcb5r200kvmcxqtj935573"},{"post_id":"ckrtcb5o800ccmcxqmirgbcad","tag_id":"ckrtcb5lo006emcxq72ngfi40","_id":"ckrtcb5r200kwmcxq3l5bw3la"},{"post_id":"ckrtcb5o800ccmcxqmirgbcad","tag_id":"ckrtcb5q600gtmcxq3mtrfbyq","_id":"ckrtcb5r200kxmcxqyqlzbxsb"},{"post_id":"ckrtcb5o800ccmcxqmirgbcad","tag_id":"ckrtcb5lu006omcxq8famyn25","_id":"ckrtcb5r200kymcxqzszevola"},{"post_id":"ckrtcb5oa00ckmcxq75tt3ype","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5r200kzmcxq9r7jod3p"},{"post_id":"ckrtcb5oa00ckmcxq75tt3ype","tag_id":"ckrtcb5qh00homcxq5dre9jrr","_id":"ckrtcb5r200l0mcxq5wlltnk7"},{"post_id":"ckrtcb5oa00ckmcxq75tt3ype","tag_id":"ckrtcb5qh00hrmcxqk5286yen","_id":"ckrtcb5r200l1mcxqhrw2qrea"},{"post_id":"ckrtcb5oj00d1mcxqohjjm1bc","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5r200l2mcxqdqsmtrq7"},{"post_id":"ckrtcb5oj00d1mcxqohjjm1bc","tag_id":"ckrtcb5q300gjmcxqa9gj53yh","_id":"ckrtcb5r200l3mcxq2kl0j369"},{"post_id":"ckrtcb5ok00d3mcxq8tyr9gdb","tag_id":"ckrtcb5qj00hxmcxqa907cp9k","_id":"ckrtcb5r200l4mcxqzpxki918"},{"post_id":"ckrtcb5ok00d3mcxq8tyr9gdb","tag_id":"ckrtcb5qj00i0mcxqtqfcqeq2","_id":"ckrtcb5r200l5mcxqq9zogagl"},{"post_id":"ckrtcb5ol00d6mcxq4b9pbcld","tag_id":"ckrtcb5qk00i4mcxqhtgqx70b","_id":"ckrtcb5r200l6mcxq2mdg0e9e"},{"post_id":"ckrtcb5ol00d6mcxq4b9pbcld","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5r300l7mcxqqe4aymu4"},{"post_id":"ckrtcb5oo00dbmcxqdho834vm","tag_id":"ckrtcb5qk00i7mcxqqgn8sbfb","_id":"ckrtcb5r300l8mcxqi67y49we"},{"post_id":"ckrtcb5oo00dbmcxqdho834vm","tag_id":"ckrtcb5ql00iamcxq1jw2ij4r","_id":"ckrtcb5r300l9mcxqqq9c8ufi"},{"post_id":"ckrtcb5op00ddmcxqsva7xd0v","tag_id":"ckrtcb5ql00idmcxq8trkp0wu","_id":"ckrtcb5r300lamcxqk6xywdr1"},{"post_id":"ckrtcb5os00dlmcxq5vexqdpb","tag_id":"ckrtcb5q600gtmcxq3mtrfbyq","_id":"ckrtcb5r300lbmcxq29hgaegk"},{"post_id":"ckrtcb5os00dlmcxq5vexqdpb","tag_id":"ckrtcb5lo006emcxq72ngfi40","_id":"ckrtcb5r300lcmcxq6ubd7ose"},{"post_id":"ckrtcb5os00dlmcxq5vexqdpb","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5r300ldmcxq2o1pef2e"},{"post_id":"ckrtcb5ot00dnmcxqsjr9oavj","tag_id":"ckrtcb5jv002emcxq9655tmi5","_id":"ckrtcb5r300lemcxqxyupmwhm"},{"post_id":"ckrtcb5ot00dnmcxqsjr9oavj","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5r300lfmcxqst59p8ox"},{"post_id":"ckrtcb5ot00dnmcxqsjr9oavj","tag_id":"ckrtcb5qj00i0mcxqtqfcqeq2","_id":"ckrtcb5r300lgmcxqg9zf0y5a"},{"post_id":"ckrtcb5ov00dsmcxqypmdozhy","tag_id":"ckrtcb5q600gtmcxq3mtrfbyq","_id":"ckrtcb5r300lhmcxq9p81256w"},{"post_id":"ckrtcb5ov00dsmcxqypmdozhy","tag_id":"ckrtcb5lo006emcxq72ngfi40","_id":"ckrtcb5r300limcxqih500l4v"},{"post_id":"ckrtcb5oz00e2mcxql1zklet5","tag_id":"ckrtcb5qo00iqmcxqikkvjysq","_id":"ckrtcb5r300ljmcxqm6ewywf6"},{"post_id":"ckrtcb5oz00e2mcxql1zklet5","tag_id":"ckrtcb5o500c3mcxq1ajgvz4j","_id":"ckrtcb5r300lkmcxqm3f1nkeh"},{"post_id":"ckrtcb5p200eamcxqmfz3k49n","tag_id":"ckrtcb5qp00itmcxqqdruvn4m","_id":"ckrtcb5r300llmcxqtn6dkppx"},{"post_id":"ckrtcb5p200eamcxqmfz3k49n","tag_id":"ckrtcb5l50058mcxqgbw6c8v3","_id":"ckrtcb5r300lmmcxqmdsoqt9s"},{"post_id":"ckrtcb5p200eamcxqmfz3k49n","tag_id":"ckrtcb5lq006jmcxq4ha3bccp","_id":"ckrtcb5r300lnmcxqj661pwjn"},{"post_id":"ckrtcb5p200eamcxqmfz3k49n","tag_id":"ckrtcb5qp00iwmcxq0dilh0oa","_id":"ckrtcb5r300lomcxqfpnerxq8"},{"post_id":"ckrtcb5p200eamcxqmfz3k49n","tag_id":"ckrtcb5qq00izmcxq9jp9f05r","_id":"ckrtcb5r300lpmcxqsukf121c"},{"post_id":"ckrtcb5p900ejmcxqrruq8ldw","tag_id":"ckrtcb5qq00j3mcxqpdvclkge","_id":"ckrtcb5r300lqmcxqdh2hi9ls"},{"post_id":"ckrtcb5pb00eomcxq770ydxpd","tag_id":"ckrtcb5qr00j6mcxqtkqt8z79","_id":"ckrtcb5r300lrmcxq761qmit5"},{"post_id":"ckrtcb5pb00eomcxq770ydxpd","tag_id":"ckrtcb5qs00j9mcxq1k6chqk8","_id":"ckrtcb5r300lsmcxqk0kx3ywo"},{"post_id":"ckrtcb5pc00ermcxqmx7anokd","tag_id":"ckrtcb5qs00jcmcxq85cqedm3","_id":"ckrtcb5r300ltmcxqjny94a00"},{"post_id":"ckrtcb5pc00ermcxqmx7anokd","tag_id":"ckrtcb5qt00jgmcxqgnfxr84c","_id":"ckrtcb5r400lumcxq1jioyw5p"},{"post_id":"ckrtcb5pc00ermcxqmx7anokd","tag_id":"ckrtcb5km0045mcxqjbf859bd","_id":"ckrtcb5r400lvmcxqg01ss60m"},{"post_id":"ckrtcb5pu00fwmcxqltrsmr1p","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5r400lwmcxqbrrkf2x4"},{"post_id":"ckrtcb5pu00fwmcxqltrsmr1p","tag_id":"ckrtcb5qo00iqmcxqikkvjysq","_id":"ckrtcb5r400lxmcxqn1gdchdp"},{"post_id":"ckrtcb5pw00fzmcxqrvhs0ej8","tag_id":"ckrtcb5qu00jmmcxqnd4vsfsx","_id":"ckrtcb5r400lymcxqg7cm88pc"},{"post_id":"ckrtcb5px00g4mcxqryn5vsv8","tag_id":"ckrtcb5qu00jmmcxqnd4vsfsx","_id":"ckrtcb5r400lzmcxqq8567zwz"},{"post_id":"ckrtcb5px00g4mcxqryn5vsv8","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5r400m0mcxqus3d6vdj"},{"post_id":"ckrtcb5py00g6mcxqwad3jfhw","tag_id":"ckrtcb5qu00jmmcxqnd4vsfsx","_id":"ckrtcb5r400m1mcxqjnvo8q2q"},{"post_id":"ckrtcb5py00g6mcxqwad3jfhw","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5r400m2mcxqhbzyxavm"},{"post_id":"ckrtcb5py00g6mcxqwad3jfhw","tag_id":"ckrtcb5qw00jvmcxq77hcnyx3","_id":"ckrtcb5r400m3mcxqvda2k8qz"},{"post_id":"ckrtcb5pz00g9mcxqghomvxp6","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5r400m4mcxqx5m0ktm0"},{"post_id":"ckrtcb5pz00g9mcxqghomvxp6","tag_id":"ckrtcb5qw00jymcxqlcfk93v1","_id":"ckrtcb5r400m5mcxqqxe1vq6v"},{"post_id":"ckrtcb5pz00g9mcxqghomvxp6","tag_id":"ckrtcb5qx00k2mcxqf434lz57","_id":"ckrtcb5r400m6mcxq5mjca58o"},{"post_id":"ckrtcb5q000gbmcxqz8m5vbxj","tag_id":"ckrtcb5qx00k5mcxqqvsu94vd","_id":"ckrtcb5r400m7mcxq45s8e03j"},{"post_id":"ckrtcb5q200gimcxqm4tighd6","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5r400m8mcxq8nvg7vtt"},{"post_id":"ckrtcb5q200gimcxqm4tighd6","tag_id":"ckrtcb5qy00k8mcxqhwq0wty7","_id":"ckrtcb5r400m9mcxq8tw33x8x"},{"post_id":"ckrtcb5q400gnmcxq9c5qzqx0","tag_id":"ckrtcb5qy00kbmcxqg31ozay9","_id":"ckrtcb5r400mamcxqyx253l3o"},{"post_id":"ckrtcb5q400gnmcxq9c5qzqx0","tag_id":"ckrtcb5km0045mcxqjbf859bd","_id":"ckrtcb5r400mbmcxqwmd776mo"},{"post_id":"ckrtcb5q500gqmcxqtd0vccye","tag_id":"ckrtcb5ql00idmcxq8trkp0wu","_id":"ckrtcb5r400mcmcxqi41x73xi"},{"post_id":"ckrtcb5q600gsmcxqft0t2v1n","tag_id":"ckrtcb5ql00idmcxq8trkp0wu","_id":"ckrtcb5r400mdmcxqhy6uj34x"},{"post_id":"ckrtcb5q700gvmcxqonproq7d","tag_id":"ckrtcb5ql00idmcxq8trkp0wu","_id":"ckrtcb5r400memcxqjud88353"},{"post_id":"ckrtcb5q700gvmcxqonproq7d","tag_id":"ckrtcb5iv000bmcxq12nc9op6","_id":"ckrtcb5r500mfmcxqvucwdal9"},{"post_id":"ckrtcb5qa00h2mcxqjfqgkucb","tag_id":"ckrtcb5pz00g7mcxqnfe8a9jf","_id":"ckrtcb5r500mgmcxqyg40c84k"},{"post_id":"ckrtcb5qa00h2mcxqjfqgkucb","tag_id":"ckrtcb5r100komcxqli62sey2","_id":"ckrtcb5r500mhmcxq7riof88q"}],"Tag":[{"name":"cs","_id":"ckrtcb5im0003mcxqln0hs3uf"},{"name":"linux","_id":"ckrtcb5iv000bmcxq12nc9op6"},{"name":"bash","_id":"ckrtcb5j0000jmcxq802zskw3"},{"name":"internet","_id":"ckrtcb5jv002emcxq9655tmi5"},{"name":"haskell","_id":"ckrtcb5k0002lmcxqtpv0wvmb"},{"name":"gui","_id":"ckrtcb5k2002smcxq3l2jtyeb"},{"name":"apple","_id":"ckrtcb5k4002xmcxqffjc62l2"},{"name":"iap","_id":"ckrtcb5k60032mcxqo0mqoomi"},{"name":"payment","_id":"ckrtcb5k80037mcxqxg2hplcm"},{"name":"encoding","_id":"ckrtcb5kb003emcxq9z4dyulr"},{"name":"test","_id":"ckrtcb5kd003jmcxq30qj17z2"},{"name":"aws","_id":"ckrtcb5ke003omcxqjj5n37fy"},{"name":"ec2","_id":"ckrtcb5kg003tmcxq3ftqpvuj"},{"name":"timezone","_id":"ckrtcb5kj0040mcxqt88eifos"},{"name":"web","_id":"ckrtcb5km0045mcxqjbf859bd"},{"name":"computer","_id":"ckrtcb5ko004amcxq6bpgjqlz"},{"name":"game","_id":"ckrtcb5kr004fmcxqb8hgm1ce"},{"name":"algorithm","_id":"ckrtcb5kv004mmcxqjpoifxmh"},{"name":"design","_id":"ckrtcb5kx004rmcxqld12ioib"},{"name":"devops","_id":"ckrtcb5kz004wmcxq7nviwd3e"},{"name":"centos","_id":"ckrtcb5l20051mcxqghyogbyg"},{"name":"erlang","_id":"ckrtcb5l50058mcxqgbw6c8v3"},{"name":"dns","_id":"ckrtcb5l7005dmcxqyej8wnro"},{"name":"docker","_id":"ckrtcb5lc005nmcxq7zvetb29"},{"name":"network","_id":"ckrtcb5lf005smcxqjx5w67di"},{"name":"db","_id":"ckrtcb5lo006emcxq72ngfi40"},{"name":"elixir","_id":"ckrtcb5lq006jmcxq4ha3bccp"},{"name":"config","_id":"ckrtcb5lu006omcxq8famyn25"},{"name":"mix","_id":"ckrtcb5mm008mmcxq4ii1frfj"},{"name":"rebar","_id":"ckrtcb5mp008tmcxqlh2t793z"},{"name":"distillery","_id":"ckrtcb5mq008ymcxq9q0m8pbo"},{"name":"ets","_id":"ckrtcb5mx009dmcxqtgqyno9f"},{"name":"float","_id":"ckrtcb5n3009nmcxqza7sbu12"},{"name":"graph","_id":"ckrtcb5ne00a9mcxqe7fmnapt"},{"name":"macro","_id":"ckrtcb5ng00aemcxq0so75ldq"},{"name":"regex","_id":"ckrtcb5ni00ajmcxqsnhsd3v4"},{"name":"re","_id":"ckrtcb5nk00aomcxq1amwmiu3"},{"name":"vim","_id":"ckrtcb5nm00avmcxqxunwsfws"},{"name":"tcp","_id":"ckrtcb5nq00b0mcxqh46hj2ed"},{"name":"push","_id":"ckrtcb5nr00b5mcxqexyhea5g"},{"name":"firebase","_id":"ckrtcb5nu00bamcxq40ertail"},{"name":"android","_id":"ckrtcb5nw00bhmcxq86ftjah0"},{"name":"ios","_id":"ckrtcb5ny00bmmcxqlmfyx4ck"},{"name":"firewalld","_id":"ckrtcb5o000brmcxqhnk5t669"},{"name":"iptables","_id":"ckrtcb5o200bwmcxqzpac3cee"},{"name":"programming","_id":"ckrtcb5o500c3mcxq1ajgvz4j"},{"name":"c","_id":"ckrtcb5o700c8mcxq76fdvz13"},{"name":"versioncontrol","_id":"ckrtcb5o800cdmcxqcmzcg527"},{"name":"go","_id":"ckrtcb5oa00cimcxq4m4gsi2p"},{"name":"gnu","_id":"ckrtcb5od00cpmcxqa5183z3l"},{"name":"screen","_id":"ckrtcb5og00cumcxq7p2puxyw"},{"name":"hexo","_id":"ckrtcb5p000e3mcxqzc3pupt2"},{"name":"hex","_id":"ckrtcb5p500edmcxq7a9lr3zc"},{"name":"os","_id":"ckrtcb5pc00epmcxq01h7xa9s"},{"name":"monitoring","_id":"ckrtcb5pd00eumcxqdan547uk"},{"name":"java","_id":"ckrtcb5ph00ezmcxqnxj6joaq"},{"name":"jinterface","_id":"ckrtcb5pk00f4mcxq5pp1htop"},{"name":"compiler","_id":"ckrtcb5pm00fbmcxqndhb1hqw"},{"name":"json","_id":"ckrtcb5po00fgmcxqjfv5tl8n"},{"name":"root","_id":"ckrtcb5pr00flmcxq4ydfstz5"},{"name":"log","_id":"ckrtcb5ps00fqmcxqioq8gzp3"},{"name":"locale","_id":"ckrtcb5pv00fxmcxqhafno27n"},{"name":"terminal","_id":"ckrtcb5px00g2mcxqzpu3bjej"},{"name":"mac","_id":"ckrtcb5pz00g7mcxqnfe8a9jf"},{"name":"乱码","_id":"ckrtcb5q100gcmcxqnjveesw5"},{"name":"unicode","_id":"ckrtcb5q300gjmcxqa9gj53yh"},{"name":"emoji","_id":"ckrtcb5q500gomcxqkd4mq0kz"},{"name":"mysql","_id":"ckrtcb5q600gtmcxq3mtrfbyq"},{"name":"install","_id":"ckrtcb5qa00h3mcxq92bdnb52"},{"name":"nat","_id":"ckrtcb5qh00homcxq5dre9jrr"},{"name":"ssh","_id":"ckrtcb5qh00hrmcxqk5286yen"},{"name":"env","_id":"ckrtcb5qj00hxmcxqa907cp9k"},{"name":"proxy","_id":"ckrtcb5qj00i0mcxqtqfcqeq2"},{"name":"odbc","_id":"ckrtcb5qk00i4mcxqhtgqx70b"},{"name":"node","_id":"ckrtcb5qk00i7mcxqqgn8sbfb"},{"name":"npm","_id":"ckrtcb5ql00iamcxq1jw2ij4r"},{"name":"windows","_id":"ckrtcb5ql00idmcxq8trkp0wu"},{"name":"python","_id":"ckrtcb5qo00iqmcxqikkvjysq"},{"name":"http","_id":"ckrtcb5qp00itmcxqqdruvn4m"},{"name":"plug","_id":"ckrtcb5qp00iwmcxq0dilh0oa"},{"name":"cowboy","_id":"ckrtcb5qq00izmcxq9jp9f05r"},{"name":"keyboard","_id":"ckrtcb5qq00j3mcxqpdvclkge"},{"name":"ruby","_id":"ckrtcb5qr00j6mcxqtkqt8z79"},{"name":"rbenv","_id":"ckrtcb5qs00j9mcxq1k6chqk8"},{"name":"html","_id":"ckrtcb5qs00jcmcxq85cqedm3"},{"name":"javascript","_id":"ckrtcb5qt00jgmcxqgnfxr84c"},{"name":"ubuntu","_id":"ckrtcb5qu00jmmcxqnd4vsfsx"},{"name":"wifi","_id":"ckrtcb5qw00jvmcxq77hcnyx3"},{"name":"socket","_id":"ckrtcb5qw00jymcxqlcfk93v1"},{"name":"pam","_id":"ckrtcb5qx00k2mcxqf434lz57"},{"name":"charsets","_id":"ckrtcb5qx00k5mcxqqvsu94vd"},{"name":"ftp","_id":"ckrtcb5qy00k8mcxqhwq0wty7"},{"name":"sns","_id":"ckrtcb5qy00kbmcxqg31ozay9"},{"name":"xcode","_id":"ckrtcb5r100komcxqli62sey2"}]}}